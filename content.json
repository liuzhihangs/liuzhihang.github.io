{"meta":{"title":"Notes","subtitle":"Notes","description":"学，然后知不足；教，然后知困。","author":"liuzhihang","url":"https://liuzhihang.com","root":"/"},"pages":[{"title":"","date":"2019-12-23T06:35:08.833Z","updated":"2019-08-11T08:37:20.375Z","comments":true,"path":"google6f3e65f7f7a779a2.html","permalink":"https://liuzhihang.com/google6f3e65f7f7a779a2.html","excerpt":"","text":"google-site-verification: google6f3e65f7f7a779a2.html"},{"title":"关于我","date":"2020-09-12T17:22:04.193Z","updated":"2020-09-12T17:22:04.193Z","comments":true,"path":"about/index.html","permalink":"https://liuzhihang.com/about/index.html","excerpt":"","text":"Java开发, 热爱互联网, 闲暇时间会看看视频, 教程, 看书. 写写学习笔记.喜欢跑步 (这家伙很懒, 已经很久没跑步了~)偶尔打打王者 (混分大王~)更多的时间是比较宅! Label:java 后端 支付 开发 程序猿 coder Experience 2019-12 - 至今 北京欧非科技有限公司(Opay) 2017.04 - 2019-12 现在支付股份有限公司 Other欢迎通过以下方式了解我 Blog: https://liuzhihang.com/GitHub: https://github.com/liuzhihangsLeetCode: https://leetcode-cn.com/u/liuzhihang/CSDN: https://blog.csdn.net/qq_36535538知乎: https://www.zhihu.com/people/liuzhihang 公众号 扫码关注 视频号 扫码关注"},{"title":"分类","date":"2020-04-04T04:12:06.732Z","updated":"2020-04-04T04:12:06.732Z","comments":true,"path":"categories/index.html","permalink":"https://liuzhihang.com/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2020-09-12T17:22:04.174Z","updated":"2020-09-12T17:22:04.174Z","comments":true,"path":"contact/index.html","permalink":"https://liuzhihang.com/contact/index.html","excerpt":"","text":"欢迎留言大家有什么问题都可以给我留言, 非常欢迎和大家沟通交流. 博客内容为个人学习笔记, 肯定有理解的不到位的地方, 非常欢迎大家指正. 欢迎关注公众号"},{"title":"404 Not Found：该页无法显示","date":"2020-09-12T17:22:04.234Z","updated":"2020-09-12T17:22:04.234Z","comments":true,"path":"/404.html","permalink":"https://liuzhihang.com/404.html","excerpt":"","text":"啊~哦~ 您要查看的页面不存在或已删除！ 请检查您输入的网址是否正确，或者点击链接继续浏览空间 您可以在下方留言 返回上级 回到首页"},{"title":"友情链接","date":"2020-10-20T06:05:40.060Z","updated":"2020-10-20T06:05:40.060Z","comments":true,"path":"link/index.html","permalink":"https://liuzhihang.com/link/index.html","excerpt":"","text":"请按照以下格式留言 name: 姓名 link: 链接地址 avatar: 头像 descr: 介绍"},{"title":"friends","date":"2020-01-04T15:20:32.041Z","updated":"2020-01-04T15:20:32.041Z","comments":true,"path":"friends/index.html","permalink":"https://liuzhihang.com/friends/index.html","excerpt":"","text":"欢迎交换友链！格式1: 博客名字: liuzhihang博客地址: https://liuzhihang.com/博客头像: https://liuzhihang.com/medias/avatar.jpg博客简介: Work study notes about java programmers … 格式2: &amp;#123; \"name\": \"liuzhihang\", \"url\": \"https://liuzhihang.com/\", \"avatar\": \"https://liuzhihang.com/medias/avatar.jpg\", \"introduction\": \"Work study notes about java programmers ...\", \"title\": \"前去学习\" &amp;#125;"},{"title":"国内聚合支付","date":"2017-11-19T09:42:43.000Z","updated":"2019-10-01T09:07:11.366Z","comments":true,"path":"project/aggregate-pay.html","permalink":"https://liuzhihang.com/project/aggregate-pay.html","excerpt":"","text":"系统架构 聚合支付项目, 维护和迭代, 对接商户和渠道.参与项目: 公众号, 卡牌, 小程序 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构Spring + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper + RabbitMQ 开发时间2017.11 - 至今 项目介绍聚合支付系统一共涉及到 API系统, 公众号, 卡牌, 小程序, H5等交易系统, 应用中心, 清结算, 计费中心, 数据中心等其他支持系统, 这里仅仅介绍交易相关系统, 并且以公众号系统为例. API系统: 相当于网关, 对外提供统一接口, 负责统一加签验签, 根据参数路由到各个子系统, 过滤请求等等. 公众号系统: 聚合微信公众号, 支付宝服务窗, 手Q公众号等多种支付方式, 为商户提供统一接口, 如原生微信、 原生支付宝、 微众银行、 地方银商行等, 支持通道一键切换. 定时系统: 定时批处理, 补单等任务发起服务. 高峰时期日均800w笔交易. 责任描述系统代码维护和重构, 对接商户和渠道, 使用各种加签验签方式和渠道交互, 线上生产问题排查, 版本迭代, 及新需求新功能开发. 总结主要是对接银行等各个渠道, 银行之间的加密加签方式各不相同, 需要多进行测试.涉及到交易, 要保证交易金额正确, 防止资损.发生问题时要及时定位问题, 马上排查. 公众号:0模式: 服务商模式, 商户将应用挂在我方app下, 由我方拉起支付1模式: 商户下单, 我方返回支付要素 2.0 拆分对接渠道项目为渠道组件, 公众号、H5、SDK等各个渠道只需要引入渠道组件, 对接渠道组件即可. 即渠道组件负责将各个渠道的接口模型转换为固定的模型."},{"title":"跨境支付系统总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:11:31.222Z","comments":true,"path":"project/crossborder-pay.html","permalink":"https://liuzhihang.com/project/crossborder-pay.html","excerpt":"","text":"简述 来到这边接触的第一个项目, 很久之前了, 已经记得不是很清楚了. 项目描述跨境支付, 系统主要分为四块: 交易系统, 定时系统, 商户后台, 运营后台交易系统: 对接各个渠道(微信卡牌, 微信公众号, 支付宝等), 支持一码多付, 实时汇率等定时系统: 业务系统相关的各个定时任务商户后台: 商户查看交易记录, 发起退款等操作中心运营后台: 商户进件, 配置费率等 责任描述 和小伙伴一起重构代码+熟悉项目 对接支付宝跨境支付 对接商户 其他 暂时想不起来了"},{"title":"卡+系统","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.534Z","comments":true,"path":"project/go-card.html","permalink":"https://liuzhihang.com/project/go-card.html","excerpt":"","text":"基本逻辑 仅仅代表大致逻辑, 并不是流程图 会员通过小程序以八折购买某店铺的会员卡–go卡 普通用户消费, 通过二维码卡牌进行消费 后台通过算法, 计算出扣除 go卡编号, 扣除该卡面相同金额 金额以比例分润给用户和我司 好友在店铺消费可以指定使用哪张会员卡 – 还有消费 95折 收益点: 用户八折购买会员卡, 当卡面金额被消费完(自己消费和他人消费), 自身所获得收益远大于购买卡的金额风险点: 会员购卡金额存放, 如果直接给商户, 商户可能存在跑路风险 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构SpringBoot + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper 开发时间2017.06 - 2017.11 项目介绍购卡项目: 该系统分为 卡+金融, 会员中心, 商户后台, 定时系统, 前端系统, 这有卡算法核心等前端系统: 通过公众号/小程序展示商户信息, 卡收益率等信息, 负责和后台系统进行交互; 卡+金融: 项目核心, 分为有卡消费和无卡消费, 主要进行用户消费, 买单交易, 修改账户, 分红交易, 转账交易等操作; 会员中心: 验证会员登录, 维持登录态, 存储会员信息以及会员卡信息等; 商户后台: 商户实时查看卡销售和订单交易情况, 进行退款等操作的平台; 定时系统: 负责定时任务统一请求调度; 这有卡: 算法核心, 卡+金融请求这有卡, 这有卡通过算法计算出商户和用户实时收益率等卡信息, 消费时获取需要扣除金额卡的卡号; 责任描述参与架构设计, 流程梳理, 表结构设计等工作, 负责卡+金融系统 无卡消费, 分红结算, 异步通知, 同步清算交易, 上报数据中心等逻辑实现, 及定时任务编写实现; 负责商户后台 分红信息的查询和导出, 交易列表及详情的展示, 卡信息编辑展示; 总结 结合C端用户和商家的第一次尝试, 同时可以利用到公司的支付资源 本次使用的是公众号内进行卡销售, 后面这有卡单独开发 ‘卡拼拼’ 小程序来进行相关拼卡业务, 相当于是对本项目的迭代"},{"title":"喜茶总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.552Z","comments":true,"path":"project/heytea.html","permalink":"https://liuzhihang.com/project/heytea.html","excerpt":"","text":"系统架构 独立负责喜茶交易系统开发, 熟悉整体业务 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构SpringBoot + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper + RabbitMQ 开发时间2018.07 - 2019.03 项目介绍项目包括: API系统, 订单系统, 定时系统, 通知系统, 账户系统, 数据中心等几大系统API系统: 统一加签验签, 是外部请求的统一入口; 订单系统: 充值, 退款, 线上消费, 线下消费, 冲正等业务核心; 定时系统: 各系统定时任务触发的系统; 通知系统: 从mq中消费数据, 按照通知地址通知商户; 责任描述参与系统的设计与架构讨论, 并负责搭建开发 API系统, 订单系统, 定时系统 和通知系统.API系统, 统一加签验签, 和喜茶对接相关接口. 订单系统: 对接微信小程序支付, 微信退款, 开发账户充值, 消费, 冲正, 补单等业务逻辑, 其中流水号系统撤销, 使用雪花算法方式代替流水号系统; 定时系统: 设定合理的调度区间, 定时补单, 和查询交易状态, 补发通知状态; 通知系统: 消费MQ, 并通知商户, 同时存入数据库, 如果通知失败, 在指定时间间隔内, 补发通知. 总结 独立开发整个项目, 从API系统到业务系统, 通知系统 流水号系统使用雪花算法 使用阿里云MQ, 同时熟悉通知系统整体业务"},{"title":"现在支付","date":"2019-12-20T11:00:00.000Z","updated":"2020-04-22T09:25:54.889Z","comments":true,"path":"project/ipaynow.html","permalink":"https://liuzhihang.com/project/ipaynow.html","excerpt":"","text":"2017.04 - 2019-12 现在支付股份有限公司, 简称ipaynow做三方支付相关业务, 先后参与跨境支付, 付款平台, 监控系统等项目的开发. Project 长期运维, 不断迭代 跨境支付: 微信公众号 卡牌 支付宝, 后移交给别的组 国内聚合支付: 公众号 卡牌 小程序 付款平台&amp;渠道系统: 代扣业务 独立负责项目开发 喜茶钱包: 二类户 + 喜茶 合作项目 麦当劳Arch Card: 麦当劳钱包充值消费, 卡券消费 内部运维, 从头开始 日志系统: 统一日志系统, 方便查询问题 监控系统: 对各系统进行监控, 从商户和渠道两个方面对交易数据进行监控 skywalking应用监控: 实时查看各系统情况, 接口耗时 转换思路, 不断尝试 卡+: 会员卡的重新定义, 达到闲置会员卡充分利用, 真正可以赚钱的会员卡 停车管家: 一个相对比较糟糕的项目 摇钱树: 和二类户合作, 开户获取分红 内部活动, 临时小项目 定时抢: 一个临时小创意, 设置游戏规则, 按照排名领取红包"},{"title":"日志系统总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.539Z","comments":true,"path":"project/log-system.html","permalink":"https://liuzhihang.com/project/log-system.html","excerpt":"","text":"软件架构Filebeat + Logstash + Elasticsearch + Kibana + Search-Guard 项目介绍日志系统基于ELK, 使用filebeat从各个系统取指定格式的日志, 通过logstash将日志清洗然后上报到ES; Kibana使用Search-Guard进行权限控制 责任描述前期对ELK进行调研和搭建, 调研Search-Guard插件, 并测试使用效果, 评估可用性. 统一日志格式, 并通过logstash进行过滤. 对es进行相关系统学习, 了解底层原理及如何优化. 编写相关操作文档, 及日志系统接入文档, 帮助各个系统对接日志系统. 总结前期使用ELK+Search-Gurad, 后期小伙伴开发日志组件日志组件: 所有项目排掉日志模块, 统一依赖日志组件; 规范日志格式; 同时日志组件可以使用 log4j appender 直接上报数据到kafka 方便监控系统监控; 日志组件使用skywalking traceId, 可以进行全链路追踪;"},{"title":"麦当劳 Arch Card总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.536Z","comments":true,"path":"project/mcd-arch-card.html","permalink":"https://liuzhihang.com/project/mcd-arch-card.html","excerpt":"","text":"系统架构 使用了 SpringCloud, Feign, Apollo配置中心, CMQ 等 开发环境IDEA、JDK1.8、Tomcat 7、TDB、Git、Maven 软件架构SpringBoot + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper + SpringCloud + Apollo + CMQ 开发时间2018.07 - 至今 项目介绍项目包括: API系统, 订单系统, 定时系统, 通知系统, 账户系统, 数据中心等几大系统API系统: 统一加签验签, 是外部请求的统一入口; 订单系统: 充值, 退款, 线上消费, 线下消费, 卡券充值, 卡券消费, 冲正等业务核心; 定时系统: 各系统定时任务触发的系统; 通知系统: 从mq中消费数据, 按照通知地址通知商户;卡券系统: 负责卡券生成及核销; 商户后台: 查看交易统计数据以及发起退款. 责任描述参与系统的架构讨论和设计, 并搭建交易系统和定时系统交易系统: 对接微信充值, 开发钱包卡券充值, 卡券消费, 线上消费, 线下消费, 退款, 冲正等业务逻辑; 定时系统: 负责统一批处理调度; 和商户联调, 同时对接其他系统; 总结初始使用Dubbo+Zookeeper的方式, 后期改成 SpringCloud+Feign统一配置中心, Apollo 使用起来比较方便. (近期搭建了下 Nacos 感觉也挺不错)"},{"title":"摇贝总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.550Z","comments":true,"path":"project/money-tree.html","permalink":"https://liuzhihang.com/project/money-tree.html","excerpt":"","text":"系统架构开发环境软件架构开发时间项目介绍责任描述技术描述总结"},{"title":"监控系统项目总结","date":"2018-10-04T09:42:43.000Z","updated":"2019-09-30T13:08:23.531Z","comments":true,"path":"project/monitor-system.html","permalink":"https://liuzhihang.com/project/monitor-system.html","excerpt":"","text":"基本逻辑 v0.0.1 还未加入 Kafka后期为迭代以及ELK版本更新, 在Filebeat 和 Logstash 中间加入 MQ(Kafka)使用 Skywalking + ES 对应用进行监控 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构SpringBoot + SpringMVC + MyBatis + ELK(Elasticsearch、Logstash、Kibana) + Redis + Bootstrap + Thymeleaf 开发时间一期: 2018.05 一一 2018.07二期: 未启动 项目介绍基于ELK, 对各交易系统从渠道和商户的维度对下单、查询、支付、通知的TPS/QPS以及成功率、支付率进行监控, 确保一旦符合报警规则, 立即报警.报警方式: 短信、邮件、微信 ☞ 相关架构 责任描述1、参与系统架构, 表结构设计, 实现流程的讨论2、监控规则的制定3、商户维度监控逻辑实现4、系统的更新维护及版本迭代 技术描述1、基于Elasticsearch和MySql的CRUD2、使用Springboot Scheduled定时,监控指定区间内的数据变化3、使用Redis队列对Error信息立即报警4、使用Bootstrap+EChart模版展示监控数据信息 后期规划1、对接微信渠道, 支持公众号报警方式2、前端页面进行优化(后端程序员表示…)3、统一日志模块优化4、后台权限, 监控规则可配置(手动改库总是不太好.)"},{"title":"现在支付","date":"2019-12-20T11:00:00.000Z","updated":"2020-04-22T09:47:55.364Z","comments":true,"path":"project/operapay.html","permalink":"https://liuzhihang.com/project/operapay.html","excerpt":"","text":"2019-12 - 至今 北京欧非科技有限公司, 简称opay支付,及支付场景相关业务 这里啥也没有开始写~"},{"title":"Repositories","date":"2019-12-23T06:35:08.828Z","updated":"2019-09-08T04:26:22.862Z","comments":true,"path":"repository/index.html","permalink":"https://liuzhihang.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-04-04T04:12:07.018Z","updated":"2020-04-04T04:12:07.018Z","comments":true,"path":"tags/index.html","permalink":"https://liuzhihang.com/tags/index.html","excerpt":"","text":""},{"title":"付款平台和渠道系统","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.545Z","comments":true,"path":"project/pay-platform.html","permalink":"https://liuzhihang.com/project/pay-platform.html","excerpt":"","text":"系统架构 参与对原代付系统进行重构, 同时也了解相关业务 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构Spring + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper + RabbitMQ 开发时间2017.11 - 至今 项目介绍商户与自己的客户签订代收协议, 委托现在支付对已签约客户发起银行卡扣款, 并将资金划入商户在我司开通的余额账户, T+1 日结算到结算账户. 商户将资金冲入在我司开通的余额账户, 并委托我司将业务资金转账到指定的客户银行卡中.高峰时期日均流水近1亿元.代付系统: 包括 付款平台, 渠道系统, 定时系统付款平台: 主要负责对接商户, 校验参数, 风控, 和应用中心交互等业务; 渠道系统: 负责和银行对接, 包含大部分加签验签工具, 以及接收渠道异步通知. 责任描述参与对原代付系统进行重构, 负责退票逻辑实现, 运营后台查单, 发起退票等功能实现. 对接银行, 排查线上问题. 以及对项目进行维护. 总结和银行进行交互, 加解密验签方式比较复杂认识到代付业务: 补单, 查单, 压单, 窗口期了解到整体架构: 和 风控系统, 应用中心, 通知系统, 流水号系统, 清结算, 数据中心, 运营后台等系统的交互"},{"title":"国内聚合支付","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.542Z","comments":true,"path":"project/timing.html","permalink":"https://liuzhihang.com/project/timing.html","excerpt":"","text":"展示 总结周五周六两天时间, 设计+开发学习使用墨刀对接公司小程序支付并能够拉起支付页面"},{"title":"","date":"2020-06-19T03:34:52.113Z","updated":"2020-06-19T03:34:52.113Z","comments":true,"path":"resources/highlight/atom-one-dark.css","permalink":"https://liuzhihang.com/resources/highlight/atom-one-dark.css","excerpt":"","text":"/* 代碼框背景色和字體顔色,與hljs一樣就行 */ /* 必須配置(把下面.hljs的color和background複製到這裏來) */ #article-container pre, #article-container figure.highlight { color: #abb2bf; background: #282c34; } /* 代碼框工具欄 (如果你關掉了copy、lang和shrink,可不用配置這個 */ #article-container figure.highlight .highlight-tools { color: #5c6370; background: #282c34; } /* 代碼框行數(如果已經關掉line_number,可以不用配置這個) */ #article-container figure.highlight .gutter pre { color: #5c6370; background: #282c34; } /* 代碼塊figcaption配置(hexo自帶標簽https://hexo.io/zh-tw/docs/tag-plugins.html#Code-Block) */ /* 不需要可以不用配置這個 */ #article-container figure.highlight figcaption a { color: #282c34 !important } /* Atom One Dark by Daniel Gamage Original One Dark Syntax theme from https://github.com/atom/one-dark-syntax base: #282c34 mono-1: #abb2bf mono-2: #818896 mono-3: #5c6370 hue-1: #56b6c2 hue-2: #61aeee hue-3: #c678dd hue-4: #98c379 hue-5: #e06c75 hue-5-2: #be5046 hue-6: #d19a66 hue-6-2: #e6c07b */ #article-container figure.highlight .hljs { display: block; overflow-x: auto; padding: 0.5em; color: #abb2bf; background: #282c34; } .hljs-comment, .hljs-quote { color: #5c6370; font-style: italic; } .hljs-doctag, .hljs-keyword, .hljs-formula { color: #c678dd; } .hljs-section, .hljs-name, .hljs-selector-tag, .hljs-deletion, .hljs-subst { color: #e06c75; } .hljs-literal { color: #56b6c2; } .hljs-string, .hljs-regexp, .hljs-addition, .hljs-attribute, .hljs-meta-string { color: #98c379; } .hljs-built_in, .hljs-class .hljs-title { color: #e6c07b; } .hljs-attr, .hljs-variable, .hljs-template-variable, .hljs-type, .hljs-selector-class, .hljs-selector-attr, .hljs-selector-pseudo, .hljs-number { color: #d19a66; } .hljs-symbol, .hljs-bullet, .hljs-link, .hljs-meta, .hljs-selector-id, .hljs-title { color: #61aeee; } .hljs-emphasis { font-style: italic; } .hljs-strong { font-weight: bold; } .hljs-link { text-decoration: underline; }"},{"title":"","date":"2020-06-19T03:48:58.605Z","updated":"2020-06-19T02:42:28.773Z","comments":true,"path":"resources/highlight/atom-one-light.css","permalink":"https://liuzhihang.com/resources/highlight/atom-one-light.css","excerpt":"","text":"/* Atom One Light by Daniel Gamage Original One Light Syntax theme from https://github.com/atom/one-light-syntax base: #fafafa mono-1: #383a42 mono-2: #686b77 mono-3: #a0a1a7 hue-1: #0184bb hue-2: #4078f2 hue-3: #a626a4 hue-4: #50a14f hue-5: #e45649 hue-5-2: #c91243 hue-6: #986801 hue-6-2: #c18401 */ .hljs { display: block; overflow-x: auto; padding: 0.5em; color: #383a42; background: #fafafa; } .hljs-comment, .hljs-quote { color: #a0a1a7; font-style: italic; } .hljs-doctag, .hljs-keyword, .hljs-formula { color: #a626a4; } .hljs-section, .hljs-name, .hljs-selector-tag, .hljs-deletion, .hljs-subst { color: #e45649; } .hljs-literal { color: #0184bb; } .hljs-string, .hljs-regexp, .hljs-addition, .hljs-attribute, .hljs-meta-string { color: #50a14f; } .hljs-built_in, .hljs-class .hljs-title { color: #c18401; } .hljs-attr, .hljs-variable, .hljs-template-variable, .hljs-type, .hljs-selector-class, .hljs-selector-attr, .hljs-selector-pseudo, .hljs-number { color: #986801; } .hljs-symbol, .hljs-bullet, .hljs-link, .hljs-meta, .hljs-selector-id, .hljs-title { color: #4078f2; } .hljs-emphasis { font-style: italic; } .hljs-strong { font-weight: bold; } .hljs-link { text-decoration: underline; }"},{"title":"","date":"2020-06-19T03:21:26.567Z","updated":"2020-06-19T03:21:26.567Z","comments":true,"path":"resources/highlight/github.css","permalink":"https://liuzhihang.com/resources/highlight/github.css","excerpt":"","text":"/* 代碼框背景色和字體顔色,與hljs一樣就行 */ /* 必須配置(把下面.hljs的color和background複製到這裏來) */ #article-container pre, #article-container figure.highlight { color: #333; background: #f8f8f8; } /* 代碼框工具欄 (如果你關掉了copy、lang和shrink,可不用配置這個 */ #article-container figure.highlight .highlight-tools { color: #333; background: #f8f8f8; } /* 代碼框行數(如果已經關掉line_number,可以不用配置這個) */ /*#article-container figure.highlight .gutter pre {*/ /* background-color: xxx;*/ /* color: xxx*/ /*}*/ /* 代碼塊figcaption配置(hexo自帶標簽https://hexo.io/zh-tw/docs/tag-plugins.html#Code-Block) */ /* 不需要可以不用配置這個 */ /*#article-container figure.highlight figcaption a {*/ /* color: xxx !important*/ /*}*/ /* github.com style (c) Vasily Polovnyov */ #article-container figure.highlight .hljs { display: block; overflow-x: auto; padding: 0.5em; color: #333; background: #f8f8f8; } .hljs-comment, .hljs-quote { color: #998; font-style: italic; } .hljs-keyword, .hljs-selector-tag, .hljs-subst { color: #333; font-weight: bold; } .hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr { color: #008080; } .hljs-string, .hljs-doctag { color: #d14; } .hljs-title, .hljs-section, .hljs-selector-id { color: #900; font-weight: bold; } .hljs-subst { font-weight: normal; } .hljs-type, .hljs-class .hljs-title { color: #458; font-weight: bold; } .hljs-tag, .hljs-name, .hljs-attribute { color: #000080; font-weight: normal; } .hljs-regexp, .hljs-link { color: #009926; } .hljs-symbol, .hljs-bullet { color: #990073; } .hljs-built_in, .hljs-builtin-name { color: #0086b3; } .hljs-meta { color: #999; font-weight: bold; } .hljs-deletion { background: #fdd; } .hljs-addition { background: #dfd; } .hljs-emphasis { font-style: italic; } .hljs-strong { font-weight: bold; }"},{"title":"","date":"2019-12-23T06:35:09.080Z","updated":"2019-09-08T10:04:27.884Z","comments":true,"path":"resources/js/generator.js","permalink":"https://liuzhihang.com/resources/js/generator.js","excerpt":"","text":"function generator(locals) { var comparer, extractName, fileUtil, generateCategoriesJson, generatePostsJson, generateTagsJson, pathUtil; pathUtil = require('path'); generatePostsJson = function(posts) { var postsMeta; postsMeta = { posts: posts.map(function(post) { return { title: post.title, url: encodeURI(post.permalink), date: post.updated.toDate().toISOString() || post.date.toDate().toISOString() }; }) }; return { path: 'posts.json', data: JSON.stringify(postsMeta) }; }; comparer = function(a, b) { return b.length - a.length; }; extractName = function(obj) { return obj.name; }; generateCategoriesJson = function(categories) { var categoriesMeta; categoriesMeta = { categories: categories.sort(comparer).map(extractName) }; return { path: 'categories.json', data: JSON.stringify(categoriesMeta) }; }; generateTagsJson = function(tags) { var tagsMeta; tagsMeta = { tags: tags.sort(comparer).map(extractName) }; return { path: 'tags.json', data: JSON.stringify(tagsMeta) }; }; var jsons = new Array(); jsons.push(generatePostsJson(locals.posts.toArray())); jsons.push(generateCategoriesJson(locals.categories.toArray())); jsons.push(generateTagsJson(locals.tags.toArray())); return jsons; } module.exports = generator;"}],"posts":[{"title":"【工作笔记】- APP 莫名崩溃，开始以为是 Header 中 name 大小写的锅，最后发现原来是容器的错！","slug":"work/请求 header 大小写问题","date":"2020-10-18T23:00:00.000Z","updated":"2020-10-18T11:45:05.783Z","comments":true,"path":"2020/10/19/header-name-case.html","link":"","permalink":"https://liuzhihang.com/2020/10/19/header-name-case.html","excerpt":"","text":"前言 部署测试，部署预发布，一切测试就绪，上生产。 发布生产 闪退 What？？？ 马上回滚 开始排查 后端一模一样的代码，不是 APP 端的问题吧。可 APP 端没有发版啊。 …… 一番排查 原来是 APP 端打包，测试和预发布包 Header 传的都是 Authorization ，生产传的是 authorization 。就是大小写问题，那赶紧改。 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 背景首页接口只有登录才可以进入，因为首页要展示获取用户账户的一些信息。这里使用的是统一拦截，从 Header 中获取 token 后，使用 token 获取用户信息。 而现在要改为用户未登录也可以查看首页信息中的宣传文案等等，只不过账户信息不显示。 原流程 整个过程代码在 ThreadLocal底层原理 里面有所介绍。这里省略一部分代码。 @Component public class TokenInterceptor implements HandlerInterceptor &amp;#123; @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception &amp;#123; LocalUserUtils.remove(); &amp;#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &amp;#123; // 请求方法是否存在注解 boolean assignableFrom = handler.getClass().isAssignableFrom(HandlerMethod.class); if (!assignableFrom) &amp;#123; return true; &amp;#125; CheckToken checkToken = null; if (handler instanceof HandlerMethod) &amp;#123; checkToken = ((HandlerMethod) handler).getMethodAnnotation(CheckToken.class); &amp;#125; // 没有加注解 直接放过 if (checkToken == null) &amp;#123; return true; &amp;#125; // 从Header中获取Authorization String authorization = request.getHeader(\"Authorization\"); log.info(\"header authorization : &amp;#123;&amp;#125;\", authorization); if (StringUtils.isBlank(authorization)) &amp;#123; log.error(\"从Header中获取Authorization失败\"); throw CustomExceptionEnum.NOT_HAVE_TOKEN.throwCustomException(); &amp;#125; // 其他代码省略 return true; &amp;#125; &amp;#125; 从代码中可以看出这里大概过程如下： 是使用拦截器拦截请求 如果方法没有 CheckToken 注解直接放过 有 CheckToken 注解，则从 request 的 header 中获取 Authorization 新需求这里想到只需要把注解去掉，然后从请求参数中获取 token 即可。获取到走原逻辑，获取不到则只返回宣传文案等信息。 从 Header 中获取信息直接获取请求头某一个 headerName@PostMapping(\"/getAuthorizationByKey\") public String getAuthorizationByKey(@RequestHeader(\"Authorization\") String authorization) &amp;#123; log.info(\"获取 Authorization --->&amp;#123;&amp;#125;\", authorization); return authorization; &amp;#125; 使用 Map 获取所有请求头@PostMapping(\"/getAuthorizationByMap\") public String getAuthorizationByMap(@RequestHeader Map&lt;String, String> map) &amp;#123; String authorization = map.get(\"Authorization\"); log.info(\"获取 Authorization --->&amp;#123;&amp;#125;\", authorization); return authorization; &amp;#125; 使用 MultiValueMap 获取请求头@PostMapping(\"/getAuthorizationByMultiValueMap\") public String getAuthorizationByMultiValueMap(@RequestHeader MultiValueMap&lt;String, String> map) &amp;#123; List&lt;String> authorization = map.get(\"Authorization\"); log.info(\"获取 Authorization --->&amp;#123;&amp;#125;\", authorization); return \"SUCCESS\"; &amp;#125; 使用 HttpHeaders 获取请求头@PostMapping(\"/getAuthorizationByHeaders\") public String getAuthorizationByHeaders(@RequestHeader HttpHeaders headers) &amp;#123; List&lt;String> authorization = headers.get(\"Authorization\"); log.info(\"获取 Authorization --->&amp;#123;&amp;#125;\", authorization); return \"SUCCESS\"; &amp;#125; 使用 HttpServletRequest 获取@PostMapping(\"/getAuthorizationByServlet\") public String getAuthorizationByServlet(HttpServletRequest request) &amp;#123; String authorization = request.getHeader(\"Authorization\"); log.info(\"获取 Authorization --->&amp;#123;&amp;#125;\", authorization); return authorization; &amp;#125; 测试文件 经过测试这些都是可以的，最终选择使用 Map 接收 Header ，然后从 Map 中获取 Authorization。 PS: 可能有小伙伴测试不过，发现接受的 header 里的 name 全都是小写了，可以继续阅读。源码在文末，也可以关注公众号，发送 headerName/4 获取。 你以为事情如果到这里就结束了，那真是太天真了。 这不，出现了文章开头的描述的场景，赶紧回滚，然后排查问题，最后定位到是 Header 的 name 大小写问题。 思考 之前 APP 端也是这么传的，那为什么使用拦截器是正常的呢？ 上面的那几种方式是不是都是这样？ 不排除 tomcat 发现原来都会转换为小写，又是为什么？ 模拟排查环境配置模拟生产首先使用相同的容器配置，这里排除了内置的 tomcat 容器，并且使用 undertow 容器。 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;exclusions> &lt;exclusion> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-logging&lt;/artifactId> &lt;/exclusion> &lt;!-- Exclude the Tomcat dependency --> &lt;exclusion> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-tomcat&lt;/artifactId> &lt;/exclusion> &lt;/exclusions> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-undertow&lt;/artifactId> &lt;/dependency> 使用拦截器传小写为什么没有问题 修改使用小写 authorization debug 断点 神奇的一幕出现了，收到的确实是小写，但是 request.getHeader(“Authorization”); 却可以获取到 authorization F7 继续往里跟 io.undertow.servlet.spec.HttpServletRequestImpl#getHeader 第 190 行，从 HeaderMap 中获取第一个元素 io.undertow.util.HeaderMap#getFirst 第 297 行， 通过 getEntry 方法获取 header 继续追踪，发现在 io.undertow.util.HeaderMap#getEntry(java.lang.String) 方法 77~79 行的时候获取到了 header 信息。那就看一下这块的源码吧。 在仔细看一下发现是 77 行 final int hc = HttpString.hashCodeOf(headerName); 在获取 name 的 hashCode 时，这里无论大小写，都是同一个 hashCode。这块代码如下 higher 方法： private static int higher(byte b) &amp;#123; return b &amp; (b >= 'a' &amp;&amp; b &lt;= 'z' ? 0xDF : 0xFF); &amp;#125; 这块的含义 如果 b 是小写字符则 b &amp; 0xDF 如果 b 是大写字符则 b &amp; 0xFF 对照 ASCII 表，大小写字母相差 32 而 0xFF(255) 和 0xDF(223) 同样相差 32，所以问题定位到了。header 的 name 无论是大写还是小写，都会查出同一个值。 当然你也可以这么传 这样的话谁在上面，Header 中使用的 name 就是那个。 使用 Map 为什么会区分大小写传入的是大写 HttpServlet -> DispatcherServlet#doDispatch -> AbstractHandlerMethodAdapter#handle -> RequestMappingHandlerAdapter#handleInternal -> RequestMappingHandlerAdapter#invokeHandlerMethod -> ServletInvocableHandlerMethod#invokeAndHandle -> InvocableHandlerMethod#invokeForRequest (解析参数值) -> InvocableHandlerMethod#getMethodArgumentValues -> RequestHeaderMapMethodArgumentResolver#resolveArgument 如图所示 String headerName = iterator.next(); name 被区分大小写放到了 LinkedHashMap 中，后续会反射调用对应的 Controller 方法。 所以也就出现了我所遇到的问题。 当然理论上 APP 客户端不应该测试和预发布使用大写，而生产使用小写。 上面阅读的源码只是 Spring 对 Header 的处理，Spring 在 HttpServlet 收到请求时，Spring 没有对请求 Header 的 name 大小写进行转换，只是在获取对应 value 的时候，没有区分大小写进行获取。 容器对 header 的处理undertow 容器的处理 请求参数的处理 这里发现 undertow 并没有对请求参数进行大小写转换处理操作。 从 HttpServletRequest 获取 header debug 发现调用的是 io.undertow.servlet.spec.HttpServletRequestImpl#getHeader，这个过程就是上面的排查过程。 从 Headers 中获取 header 通过 debug 发现 jetty 调用的是 org.springframework.http.HttpHeaders#get，然后调用 org.springframework.util.MultiValueMapAdapter#get，然后调用 org.springframework.util.LinkedCaseInsensitiveMap#get 这里会不区分大小写 从 MultiValueMap 获取 header 这块 debug 发现是直接从 LinkedHashMap 获取的，所以区分了大小写。 tomcat 容器的处理 请求参数的处理 而如果没有排除的话，即使用内嵌的 tomcat 容器无论传递大写还是小写，接收到的全部都是小写，又是怎么个情况呢？ 通过 debug 发现没有排除 tomcat 使用的是，在接收请求时使用的是 org.apache.coyote.http11.Http11Processor。 在 Http11Processor#service 方法中 类 284 行负责处理解析 header 进入 org.apache.coyote.http11.Http11InputBuffer#parseHeaders 方法 第 589 行 （Download Sources 后），阅读 parseHeader 方法 发现会将请求 header 的 name 转换为小写 从 HttpServletRequest 获取 header 当使用 tomcat 容器时，调用 org.apache.catalina.connector.RequestFacade#getHeader， org.apache.catalina.connector.Request#getHeader， org.apache.coyote.Request#getHeader org.apache.tomcat.util.http.MimeHeaders#getHeader 最后调用 org.apache.tomcat.util.http.MimeHeaders#getValue 获取 header 这里也会忽略大小写判断 从 Headers 获取 header 通过 debug 发现 tomcat 容器下调用的是 org.springframework.http.HttpHeaders#get，然后调用 org.springframework.util.MultiValueMapAdapter#get，然后调用 org.springframework.util.LinkedCaseInsensitiveMap#get 这里会不区分大小写 从 MultiValueMap 获取 header 这块 debug 发现是直接从 LinkedHashMap 获取的，所以区分了大小写。 jetty 容器的处理 请求参数的处理 如果换成 jetty 容器的话 在 org.eclipse.jetty.server.HttpConnection 中又会发现无论传入大写还是小写都会被转换为驼峰。 源码可以阅读 org.eclipse.jetty.http.HttpParser#parseFields 会转换为驼峰命名法。 从 HttpServletRequest 获取 header 通过 debug 发现 jetty 调用的是 org.eclipse.jetty.server.Request#getHeader jetty 在获取 header 时，会调用 org.eclipse.jetty.http.HttpFields#get 原来在获取的时候忽略了大小写 从 Headers 获取 header 通过 debug 发现 jetty 容器下调用的是 org.springframework.http.HttpHeaders#get，然后调用 org.springframework.util.MultiValueMapAdapter#get，然后调用 org.springframework.util.LinkedCaseInsensitiveMap#get 这里会不区分大小写 从 MultiValueMap 获取 也是调用的 org.springframework.util.MultiValueMapAdapter#get 然后不区分大小写。和从 Headers 中获取相同。 总结Q&amp;AQ: 为什么拦截器获取 Authorization 可以不区分大小写？ A: 从拦截器获取 Authorization 其实就是从 HttpServletRequest 中获取，这里无论使用 tomcat 还是使用 undertow 或者 jetty 获取 Header 是都是忽略 headerName 的大小写的。具体可以阅读上面的源码分析。 Q: 这么多获取 Header 的方式有什么区别？A: 不同的容器下实现方式不同，这里列表说明 undertow tomcat jetty 请求参数大小写转换 不变 小写 驼峰 直接获取请求头某一个 headerName 忽略大小写，不能为空 忽略大小写，不能为空 忽略大小写，不能为空 使用 Map 获取所有请求头 Map 的 key 和传入 headerName 大小写的一致，保持一致可获取到 Map 的 key 全是小写，需要使用小写headerName 获取 Map 的 key 是驼峰命名法，要使用驼峰命名才可以获取到 使用 MultiValueMap 获取请求头 实际是从 LinkedHashMap 中获取，区分大小写 实际是从 LinkedHashMap 中获取，区分大小写 从 LinkedCaseInsensitiveMap 获取，不区分大小写 使用 HttpHeaders 获取请求头 从 LinkedCaseInsensitiveMap 获取，不区分大小写 从 LinkedCaseInsensitiveMap 获取，不区分大小写 从 LinkedCaseInsensitiveMap 获取，不区分大小写 使用 HttpServletRequest 获取 使用 HttpString.hashCodeOf(headerName) 忽略了大小写 调用 MimeHeaders#getValue 忽略了大小写 HttpFields#get 忽略了大小写 通过表格发现，即使是不同的容器在使用 HttpHeaders 获取请求头是都是调用了 Spring 的 LinkedCaseInsensitiveMap 获取 header，并且内部忽略了大小写，这里比较推荐使用。 同样使用 HttpServletRequest 的方式获取也比较推荐。 结束语本文主要是分析生产遇到的一个问题，然后开始探究原因，开始的时候发现是 Spring 的原因，因为使用 Map 接收时， headerName 什么格式就是什么格式。 在自己写 demo 时又发现，原来和 Spring 的关系并不大，是容器的原因。不同的容器处理方式不同。所以总结出来相关文章，供大家参考，不足之处，欢迎指正。 相关资料 本文源码地址：https://github.com/liuzhihangs/header-demo","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"}]},{"title":"【工作笔记】- 几行代码轻松实现跨系统传递 traceId，再也不用担心对不上日志了！","slug":"work/MDC 跨系统链路追踪","date":"2020-10-18T05:00:00.000Z","updated":"2020-10-18T06:27:25.457Z","comments":true,"path":"2020/10/18/log-trace-id.html","link":"","permalink":"https://liuzhihang.com/2020/10/18/log-trace-id.html","excerpt":"","text":"前言 新项目查日志太麻烦，多台机器之间查来查去，还不知道是不是同一个请求的。打印日志时使用 MDC 在日志上添加一个 traceId，那这个 traceId 如何跨系统传递呢？ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 背景同样是新项目开发的笔记，因为使用的是分布式架构，涉及到各个系统之间的交互 这时候就会遇到一个很常见的问题： 单个系统是集群部署，日志分布在多台服务器上； 多个系统的日志在多台机器，但是一次请求，查日志更是难上加难。 解决方案 使用 SkyWalking traceid 进行链路追踪； 使用 Elastic APM 的 trace.id 进行链路追踪； 自己生成 traceId 并 put 到 MDC 里面。 MDCMDC（Mapped Diagnostic Context）是一个映射，用于存储运行上下文的特定线程的上下文数据。因此，如果使用log4j进行日志记录，则每个线程都可以拥有自己的MDC，该MDC对整个线程是全局的。属于该线程的任何代码都可以轻松访问线程的MDC中存在的值。 如何使用 MDC 在 log4j2-spring.xml 的日志格式中添加 %X&#123;traceId&#125; 配置。 &lt;Property name=\"LOG_PATTERN\"> [%d&amp;#123;yyyy-MM-dd HH:mm:ss.SSS&amp;#125;]-[%t]-[%X&amp;#123;traceId&amp;#125;]-[%-5level]-[%c&amp;#123;36&amp;#125;:%L]-[%m]%n &lt;/Property> &lt;Property name=\"LOG_PATTERN_ERROR\"> [%d&amp;#123;yyyy-MM-dd HH:mm:ss.SSS&amp;#125;]-[%t]-[%X&amp;#123;traceId&amp;#125;]-[%-5level]-[%l:%M]-[%m]%n &lt;/Property> &lt;!-- 省略 --> &lt;!--这个输出控制台的配置--> &lt;Console name=\"Console\" target=\"SYSTEM_OUT\" follow=\"true\"> &lt;!--输出日志的格式--> &lt;PatternLayout charset=\"UTF-8\" pattern=\"$&amp;#123;LOG_PATTERN&amp;#125;\"/> &lt;/Console> 新增拦截器 拦截所有请求，从 header 中获取 traceId 然后放到 MDC 中，如果没有获取到，则直接用 UUID 生成一个。 @Slf4j @Component public class LogInterceptor implements HandlerInterceptor &amp;#123; private static final String TRACE_ID = \"traceId\"; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception arg3) throws Exception &amp;#123; &amp;#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView arg3) throws Exception &amp;#123; &amp;#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &amp;#123; String traceId = request.getHeader(TRACE_ID); if (StringUtils.isEmpty(traceId)) &amp;#123; MDC.put(TRACE_ID, UUID.randomUUID().toString()); &amp;#125; else &amp;#123; MDC.put(TRACE_ID, traceId); &amp;#125; return true; &amp;#125; &amp;#125; 配置拦截器 @Configuration public class WebConfig implements WebMvcConfigurer &amp;#123; @Resource private LogInterceptor logInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &amp;#123; registry.addInterceptor(logInterceptor) .addPathPatterns(\"/**\"); &amp;#125; &amp;#125; 跨服务之间如何传递 traceId FeignClient 因为这边使用的是 FeignClient 进行服务之间的调用，只需要新增请求拦截器即可 @Configuration public class FeignInterceptor implements RequestInterceptor &amp;#123; private static final String TRACE_ID = \"traceId\"; @Override public void apply(RequestTemplate requestTemplate) &amp;#123; requestTemplate.header(TRACE_ID, MDC.get(TRACE_ID)); &amp;#125; &amp;#125; Dubbo 如果是 Dubbo 可以通过扩展 Filter 的方式传递 traceId 编写 filter @Activate(group = &amp;#123;\"provider\", \"consumer\"&amp;#125;) public class TraceIdFilter implements Filter &amp;#123; @Override public Result invoke(Invoker&lt;?> invoker, Invocation invocation) throws RpcException &amp;#123; RpcContext rpcContext = RpcContext.getContext(); String traceId; if (rpcContext.isConsumerSide()) &amp;#123; traceId = MDC.get(\"traceId\"); if (traceId == null) &amp;#123; traceId = UUID.randomUUID().toString(); &amp;#125; rpcContext.setAttachment(\"traceId\", traceId); &amp;#125; if (rpcContext.isProviderSide()) &amp;#123; traceId = rpcContext.getAttachment(\"traceId\"); MDC.put(\"traceId\", traceId); &amp;#125; return invoker.invoke(invocation); &amp;#125; &amp;#125; 指定 filter src |-main |-java |-com |-xxx |-XxxFilter.java (实现Filter接口) |-resources |-META-INF |-dubbo |-org.apache.dubbo.rpc.Filter (纯文本文件，内容为：xxx=com.xxx.XxxFilter) 截图如下： 测试结果如下： dubbo filter 相关源码地址在文末也可以关注公众号，发送 traceid 获取 其他方式当然如果小伙伴们有使用 SkyWalking 或者 Elastic APM 也可以通过以下方式进行注入： SkyWalking &lt;dependency> &lt;groupId>org.apache.skywalking&lt;/groupId> &lt;artifactId>apm-toolkit-log4j-2.x&lt;/artifactId> &lt;version>&amp;#123;project.release.version&amp;#125;&lt;/version> &lt;/dependency 然后将 [%traceId] 配置在 log4j2.xml 文件的 pattern 中即可 Elastic APM 在启动时指定 enable_log_correlation 为 true 将 %X&#123;trace.id&#125; 配置在 log4j2.xml 文件的 pattern 中 扩展统一日志采集虽然有了 traceId 可以进行全链路追踪查询日志，但是毕竟也是在多台服务器上，为了提高查询效率，可以考虑将日志汇总到一起。 常用的使用方法就是基于 ELK 的日志系统： 使用 filebeat 采集日志报送到 logstash logstash 进行分词过滤等处理，输出到 Elasticsearch 使用 Kinbana 或者自己开发的可视化工具从 Elasticsearch 查询日志 结束语本文主要记录近期开发过程中的遇到的一点问题，希望对小伙伴也有所帮助。不足之处，欢迎指正。如果小伙伴有其他的建议或者观点欢迎留言讨论，共同进步。 相关资料 Log4j 2 API：https://logging.apache.org/log4j/2.x/manual/thread-context.html SkyWalking：https://github.com/apache/skywalking/tree/master/docs/en/setup/service-agent/java-agent Elastic APM：https://www.elastic.co/guide/en/apm/agent/java/current/log-correlation.html Dubbo filter：http://dubbo.apache.org/zh-cn/docs/dev/impls/filter.html 本文 Dubbo filter demo：https://github.com/liuzhihangs/trace","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"链路追踪","slug":"工作笔记/链路追踪","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"链路追踪","slug":"链路追踪","permalink":"https://liuzhihang.com/tags/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"}]},{"title":"【工作笔记】- 老大问我：“建表为啥还设置个自增 id ？用流水号当主键不正好么？”","slug":"work/新建表为什么要有自增id","date":"2020-10-11T05:00:00.000Z","updated":"2020-10-11T05:11:00.786Z","comments":true,"path":"2020/10/11/work-trans-why-table-id.html","link":"","permalink":"https://liuzhihang.com/2020/10/11/work-trans-why-table-id.html","excerpt":"","text":"又要开始新项目了，一顿操作猛如虎，梳理流程加画图。这不，开始对流程及表结构了。我：吧啦吧啦吧啦 ……老大：这个建表为啥还设置个自增 id ？直接用流水号（用户号/产品号）当主键不就行了？我：这个是 DBA 规定的，创建表 id、create_time、update_time 这三个字段都要有。《Java 开发规范》也是这么规定的。小伙伴：（附和）是的，规定的是这样的！老大：流水号在你这是唯一索引吧？设置成主键，这样就不用 id 了，还减少一次回表查询？我：…… （说的好像很有道理，咱也不敢说话。）老大：既然他们规定了，那你回去查一下为什么要设计个自增 id ？我：掏出小本本（回去查资料~）。 建表规约 在工作中，创建表的时候，DBA 也会审核一下建表 SQL，检查是否符合规范以及常用字段是否设置索引。 CREATE TABLE `xxxx` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键', `create_time` datetime(3) NOT NULL DEFAULT current_timestamp(3) COMMENT '创建时间', `update_time` datetime(3) NOT NULL DEFAULT current_timestamp(3) ON UPDATE current_timestamp(3) COMMENT '更新时间', PRIMARY KEY (`id`) USING BTREE, KEY `idx_create_time` (`create_time`) USING BTREE, KEY `idx_update_time` (`update_time`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4 COMMENT='表注释'; 所以在我使用的过程中，流水号都是单独设置了一个字段，比如叫 trans_no，但是这次就遇到了疑问：trans_no 既然是唯一的，那为什么不直接用 trans_no 当做 id 呢？ 下面开始通过查阅相关资料，一步一步的了解是为什么？ 主键什么是主键 https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_primary_key 这段定义咱们主要关注最后一句： When choosing primary key values, consider using arbitrary values (a synthetic key) rather than relying on values derived from some other source (a natural key). 意思是创建主键的时候尽量使用 MySQL 自增主键而不是使用业务生成的值当做主键。 主键的特征 简而言之： 非空、唯一、少更改或不更改 。 如何添加主键 可以在 create 创建表的时候指定，也可以使用 alter 语句后面添加主键，不过官方建议在创建表时就指定。 为什么要添加主键 主键可以唯一标识这一行数据，从而保证在删除更新操作时，只是操作这一行数据。 索引需要，每个 InnoDB 表又有一个特殊的索引，即聚簇索引，用来存储行数据。通常，聚簇索引和主键同义。 声明主键，InnoDB 会将主键作为聚簇索引。 未声明时，会在 UNIQUE 所有键列所在位置找到第一个索引，NOT NULL 并将其作为聚簇索引 未声明且找不到合适的 UNIQUE 索引，则内部生成一个隐藏的聚簇索引 GEN_CLUST_INDEX，这个隐藏的行 ID 是 6 字节且单调增加。 图 -&gt; 那什么是索引 索引这里仅介绍 InnoDB 引擎，具体可以参考官方文档，并且介绍的相对比较简单。 索引分类 聚簇索引：表存储是根据主键列的值组织的，以加快涉及主键列的查询和排序。在介绍主键时也对聚簇索引进行了介绍。 二级索引：也可以叫辅助索引，在辅助索引中会记录对应的主键列以及辅助索引列。根据辅助索引进行搜索的时候，会先根据辅助索引获取到对应的主键列，然后再根据主键去聚簇索引里面搜索。一般不建议主键很长，因为主键很长辅助索引就会使用更多的空间。 补充： 回表：先在二级索引查询到对应的主键值，然后根据主键再去聚簇索引里面取查询。索引覆盖：二级索引记录了主键列和二级索引列，如果我只查询主键列的值和二级索引列的值，那就不需要回表了。 索引的物理结构InnoDB 使用的 B+ 数数据结构，根据聚簇索引值（主键/UNQIUE/或者自己生成）构建一颗 B+ 树，叶子节点中存放行记录数据，所以每个叶子节点也可以叫数据页。每个数据页大小默认为 16k，支持自定义。 数据的插入当数据插入时，InnoDB 会使页面 1/16 空闲，以备将来插入和更新索引记录。 顺序插入（升序或降序）：会将索引页剩余的大约 15/16 装满 随机插入：只会使用容量的 1/2 到 15/16 在随机插入中，会频繁的移动、分页，从而造成大量的碎片，并且使索引树不够紧凑。而使用顺序插入的方式，则数据比较紧凑，有更高的空间利用率。 总结Q&amp;AQ: 什么是回表和索引覆盖？ A: 回表：先在二级索引查询到对应的主键值，然后根据主键再去聚簇索引里面取查询。 索引覆盖：二级索引记录了主键列和二级索引列，如果我只查询主键列的值和二级索引列的值，那就不需要回表了。 Q: 为什么要设置自增主键 id ？ A: 可以唯一标识一行数据，在 InnoDB 构建索引树的时候会使用主键。 自增 id 是顺序的，可以保证索引树上的数据比较紧凑，有更高的空间利用率以及减少数据页的分裂合并等操作，提高效率。 一般使用手机号、身份证号作为主键等并不能保证顺序性。 流水号一般相对较长，比如 28 位，32 位等，过长的话会二级索引占用空间较多。同时为了业务需求，流水号具有一定的随机性。 结束语本文主要通过查阅资料，了解为什么要设置一个和业务无关的自增 id 用来当做主键，很多内容比较浅显，比如 InnoDB 的 B+ 树，页分裂及页合并，插入过程等都没有进行深入研究，有兴趣的小伙伴可以更深入的研究下。 同时在建表时除了要设置一个自增 id 用来当做主键，小伙伴们在业务开发过程中是否也会遇到一种情况：用户的注销，数据的删除等都是进行的逻辑删除，而不是物理删除。 本篇文章介绍比较简陋，不足之处，希望大家多多指正。","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"}]},{"title":"【JDK源码笔记】- 基于链表的有界阻塞队列 —— LinkedBlockingQueue","slug":"source-code/java/LinkedBlockingQueue","date":"2020-10-04T06:30:00.000Z","updated":"2020-10-04T06:48:58.869Z","comments":true,"path":"2020/10/04/source-code-linkedblockingqueue.html","link":"","permalink":"https://liuzhihang.com/2020/10/04/source-code-linkedblockingqueue.html","excerpt":"","text":"前言 上一节看了基于数据的有界阻塞队列 ArrayBlockingQueue 的源码，通过阅读源码了解到在 ArrayBlockingQueue 中入队列和出队列操作都是用了 ReentrantLock 来保证线程安全。下面咱们看另一种有界阻塞队列：LinkedBlockingQueue。 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍一个基于链接节点的，可选绑定的 BlockingQueue 阻塞队列。 对元素 FIFO（先进先出）进行排序。队列的头部是已在队列中停留最长时间的元素。队列的尾部是最短时间出现在队列中的元素。将新元素插入队列的尾部，并检索队列操作获取队列开头的元素。 基于连表的队列通常具有比基于数组的队列有更高的吞吐量，但是大多数并发应用程序中的可预测性较差。 基本使用public class LinkedBlockingQueueTest &amp;#123; private static final LinkedBlockingQueue&lt;String> QUEUE = new LinkedBlockingQueue&lt;>(10); public static void main(String[] args) throws InterruptedException &amp;#123; // 入队列 QUEUE.put(\"put 入队列, 队列满则会阻塞等待\"); QUEUE.add(\"add 入队列, 队列满则会抛出异常\"); QUEUE.offer(\"offer 入队列, 队列满会返回 false\"); // 出队列 // 队列空返回 null String poll = QUEUE.poll(); // 队列空会阻塞等待 String take = QUEUE.take(); // 仅仅看一下最早入队列的元素 String peek = QUEUE.peek(); &amp;#125; &amp;#125; 问题疑问 LinkedBlockingQueue 的实现原理是什么？ LinkedBlockingQueue 和 ArrayBlockingQueue 的区别是什么？ 源码分析基本结构 参数介绍static class Node&lt;E> &amp;#123; E item; /** * One of: * - 真正的后继节点 * - 有值，表示后继者是head.next * - null，表示没有后继（这是最后一个节点） */ Node&lt;E> next; Node(E x) &amp;#123; item = x; &amp;#125; &amp;#125; 首先在 LinkedBlockingQueue 中有一个静态内部类 Node 支持泛型，下面看下其他字段： /** 初始容量，如果没有，则为Integer.MAX_VALUE */ private final int capacity; /** 当前元素数 */ private final AtomicInteger count = new AtomicInteger(); /** * 链表头 * 不变的是: head.item == null */ transient Node&lt;E> head; /** * 链表尾 * 不变的是: last.next == null */ private transient Node&lt;E> last; /** 执行 take, poll 等操作需要获取到 takeLock */ private final ReentrantLock takeLock = new ReentrantLock(); /** 等待执行 take 操作的线程，会放入这个条件队列 */ private final Condition notEmpty = takeLock.newCondition(); /** 执行 put, offer 等操作需要获取到 putLock */ private final ReentrantLock putLock = new ReentrantLock(); /** 等待执行 put 操作的线程，会被放入这个条件队列 */ private final Condition notFull = putLock.newCondition(); 构造函数public LinkedBlockingQueue() &amp;#123; this(Integer.MAX_VALUE); &amp;#125; // 创建时指定容量 public LinkedBlockingQueue(int capacity) &amp;#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E>(null); &amp;#125; 通过构造函数可以看出，在初始化 LinkedBlockingQueue 时，如果不传入容量则会默认指定 Integer.MAX_VALUE。 添加元素add 方法是直接调用的父类 AbstractQueue 的方法，内部调用的 LinkedBlockingQueue 自己实现的 offer 方法 public boolean add(E e) &amp;#123; if (offer(e)) return true; else throw new IllegalStateException(\"Queue full\"); &amp;#125; 主要阅读的还是 LinkedBlockingQueue 的 put 和 offer 方法： public void put(E e) throws InterruptedException &amp;#123; // 插入元 if (e == null) throw new NullPointerException(); // Note: 所有put / take / etc中的约定是预设本地变量 // 保持计数为负表示失败，除非置位。 int c = -1; Node&lt;E> node = new Node&lt;E>(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &amp;#123; // 如果已经到最大容量，则等待 while (count.get() == capacity) &amp;#123; notFull.await(); &amp;#125; enqueue(node); // 总数进行增加， 返回的是先前的容量 c = count.getAndIncrement(); // 判断是否需要唤醒入队列阻塞的线程 if (c + 1 &lt; capacity) notFull.signal(); &amp;#125; finally &amp;#123; putLock.unlock(); &amp;#125; if (c == 0) // 唤醒因调用 notEmpty 的 await 方法而被阻塞的线程 signalNotEmpty(); &amp;#125; public boolean offer(E e) &amp;#123; // 为空抛出异常 if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; // 如果已经到最大容量，返回 false if (count.get() == capacity) return false; int c = -1; Node&lt;E> node = new Node&lt;E>(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &amp;#123; if (count.get() &lt; capacity) &amp;#123; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &amp;#125; &amp;#125; finally &amp;#123; putLock.unlock(); &amp;#125; if (c == 0) signalNotEmpty(); return c >= 0; &amp;#125; 通过上面两段代码可以看出 put 和 offer 的最大区别在于是否阻塞。 put 方法当队列达到指定容量时，会阻塞，等待有元素出队列。而 offer 方法会直接返回 false。 同时两个方法操作元素入队列都是调用的 enqueue(node) 方法，下面一起看下 enqueue 方法。 private void enqueue(Node&lt;E> node) &amp;#123; // assert putLock.isHeldByCurrentThread(); // assert last.next == null; last = last.next = node; &amp;#125; 在 enqueue 方法中，直接指定当前尾节点的 next 为传入的元素即可。 获取元素public E poll() &amp;#123; final AtomicInteger count = this.count; // 队列为空返回 null if (count.get() == 0) return null; E x = null; int c = -1; // 加锁 final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &amp;#123; if (count.get() > 0) &amp;#123; x = dequeue(); // 减少队列元素计数，返回的是旧值 c = count.getAndDecrement(); if (c > 1) // 旧值大于 1 ，就是当前大于 0 // 唤醒调用 notEmpty.await 等待的线程 notEmpty.signal(); &amp;#125; &amp;#125; finally &amp;#123; takeLock.unlock(); &amp;#125; if (c == capacity) // 如果旧值等于 capacity 说明当前空了一个位置 signalNotFull(); return x; &amp;#125; public E take() throws InterruptedException &amp;#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &amp;#123; // 阻塞等待 while (count.get() == 0) &amp;#123; notEmpty.await(); &amp;#125; x = dequeue(); c = count.getAndDecrement(); if (c > 1) notEmpty.signal(); &amp;#125; finally &amp;#123; takeLock.unlock(); &amp;#125; if (c == capacity) signalNotFull(); return x; &amp;#125; 通过上面代码可以看出 poll 和 take 方法逻辑大致相同。区别就是在当前队列为空时的处理逻辑。poll 在当前队列为空时返回 null，take 会阻塞等待，知道当前队列中有元素。 poll 和 take 都试用 dequeue() 方法从队列中获取元素。 private E dequeue() &amp;#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E> h = head; Node&lt;E> first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x; &amp;#125; dequeue() 方法逻辑就是获取头节点，并将 head 指向下一个节点。 查看元素public E peek() &amp;#123; if (count.get() == 0) return null; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &amp;#123; Node&lt;E> first = head.next; if (first == null) return null; else return first.item; &amp;#125; finally &amp;#123; takeLock.unlock(); &amp;#125; &amp;#125; peek() 方法比较简单，直接获取 head 的元素值即可。 总结Q&amp;AQ: LinkedBlockingQueue 的实现原理？ A: LinkedBlockingQueue 是基于链表实现的，内部使用 ReentrantLock 互斥锁，防止并发放置元素或者取出元素的冲突问题。 take、poll、peek 等从队列中获取元素的操作共用 takeLock 锁。 add、put、offer 等向队列中添加元素的操作共同 putLock 锁。 notEmpty 和 notFull 是 Condition 类型，在 take 和 put 操作时，如果如果队列为空或者队列已满，会调用相应的 await 将线程放入条件队列。 Q: 入队列和出队列方法之间的区别是什么？ 方法 作用 add 添加元素，队列满了，添加失败抛出遗产 offer 添加元素， 队列满了，添加失败，返回 false put 添加元素，队列满了，阻塞等待 poll 弹出元素，队列为空则返回 null take 弹出元素，队列为空则等待队列中有元素 peek 查看队列中放入最早的一个元素 结束语LinkedBlockingQueue 使用和 ArrayBlockingQueue 并没有什么区别，内部实现都是使用的 ReentrantLock，可以对照着阅读。同时 Condition 这块也需要着重了解一下。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- AQS 都看完了，Condition 原理可不能少！","slug":"source-code/java/Condition","date":"2020-10-01T10:00:00.000Z","updated":"2020-10-01T10:16:48.650Z","comments":true,"path":"2020/10/01/source-code-condition.html","link":"","permalink":"https://liuzhihang.com/2020/10/01/source-code-condition.html","excerpt":"","text":"前言 在介绍 AQS 时，其中有一个内部类叫做 ConditionObject，当时并没有进行介绍，并且在后续阅读源码时，会发现很多地方用到了 Condition ，这时就会很诧异，这个 Condition 到底有什么作用？那今天就通过阅读 Condition 源码，从而弄清楚 Condition 到底是做什么的？当然阅读这篇文章的时候希望你已经阅读了 AQS、ReentrantLock 以及 LockSupport 的相关文章或者有一定的了解（当然小伙伴也可以直接跳到文末看总结）。 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍Object 的监视器方法：wait、notify、notifyAll 应该都不陌生，在多线程使用场景下，必须先使用 synchronized 获取到锁，然后才可以调用 Object 的 wait、notify。 Condition 的使用，相当于用 Lock 替换了 synchronized，然后用 Condition 替换 Object 的监视器方法。 Conditions（也称为条件队列或条件变量）为一种线程提供了一种暂停执行（等待），直到另一线程通知被阻塞的线程，某些状态条件现在可能为真。 因为访问到此共享状态信息发生在不同的线程中，因此必须对其进行保护，所以会使用某种形式的锁。等待条件提供的关键属性是它以原子地释放了关联的锁，并且挂起当前线程，就像 Object.wait 一样。 Condition 实例本质上要绑定到锁。 为了获得 Condition 实例，一般使用 Lock 实例的 newCondition() 方法。 Lock lock = new ReentrantLock(); Condition con = lock.newCondition(); 基本使用class BoundedBuffer &amp;#123; final Lock lock = new ReentrantLock(); // condition 实例依赖于 lock 实例 final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putPtr, takePtr, count; public void put(Object x) throws InterruptedException &amp;#123; lock.lock(); try &amp;#123; // put 时判断是否已经满了 // 则线程在 notFull 条件上排队阻塞 while (count == items.length) &amp;#123; notFull.await(); &amp;#125; items[putPtr] = x; if (++putPtr == items.length) &amp;#123; putPtr = 0; &amp;#125; ++count; // put 成功之后，队列中有元素 // 唤醒在 notEmpty 条件上排队阻塞的线程 notEmpty.signal(); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; public Object take() throws InterruptedException &amp;#123; lock.lock(); try &amp;#123; // take 时，发现为空 // 则线程在 notEmpty 的条件上排队阻塞 while (count == 0) &amp;#123; notEmpty.await(); &amp;#125; Object x = items[takePtr]; if (++takePtr == items.length) &amp;#123; takePtr = 0; &amp;#125; --count; // take 成功，队列不可能是满的 // 唤醒在 notFull 条件上排队阻塞的线程 notFull.signal(); return x; &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; &amp;#125; 上面是官方文档的一个例子，实现了一个简单的 BlockingQueue ，看懂这里，会发现在同步队列中很多地方都是用的这个逻辑。必要的代码说明都已经在代码中进行注释。 问题疑问 Condition 和 AQS 有什么关系？ Condition 的实现原理是什么？ Condition 的等待队列和 AQS 的同步队列有什么区别和联系？ 源码分析基本结构 通过 UML 可以看出，Condition 只是一个抽象类，它的主要实现逻辑是在 AQS 的内部类 ConditionObject 实现的。下面主要从 await 和 signal 两个方法入手，从源码了解 ConditionObject。 创建 ConditionLock lock = new ReentrantLock(); Condition con = lock.newCondition(); 一般使用 lock.newCondition() 创建条件变量。 public class ReentrantLock implements Lock, java.io.Serializable &amp;#123; private final Sync sync; public Condition newCondition() &amp;#123; return sync.newCondition(); &amp;#125; // Sync 集成 AQS abstract static class Sync extends AbstractQueuedSynchronizer &amp;#123; final ConditionObject newCondition() &amp;#123; return new ConditionObject(); &amp;#125; &amp;#125; &amp;#125; 这里使用的是 ReentrantLock 的源码，里面调用的 sync.newCondition()，Sync 继承 AQS，其实就是创建了一个 AQS 内部类的 ConditionObject 的实例。 这里需要注意的是 lock 每调用一次 lock.newCondition() 都会有一个新的 ConditionObject 实例生成，就是说一个 lock 可以创建多个 Condition 实例。 Condition 参数/** 条件队列的第一个节点 */ private transient Node firstWaiter; /** 条件队列的最后一个节点 */ private transient Node lastWaiter; await 方法await 方法，会造成当前线程在等待，直到收到信号或被中断。 与此 Condition 相关联的锁被原子释放，并且出于线程调度目的，当前线程被禁用，并且处于休眠状态，直到发生以下四种情况之一： 其他一些线程调用此 Condition 的 signal 方法，而当前线程恰好被选择为要唤醒的线程； 其他一些线程调用此 Condition 的 signalAll 方法； 其他一些线程中断当前线程，并支持中断线程挂起； 发生虚假唤醒。 在所有情况下，在此方法可以返回之前，当前线程必须重新获取与此条件关联的锁。当线程返回时，可以保证保持此锁。 现在来看 AQS 内部的实现逻辑： public final void await() throws InterruptedException &amp;#123; // 响应中断 if (Thread.interrupted()) throw new InterruptedException(); // 添加到条件队列尾部（等待队列） // 内部会创建 Node.CONDITION 类型的 Node Node node = addConditionWaiter(); // 释放当前线程获取的锁（通过操作 state 的值） // 释放了锁就会被阻塞挂起 int savedState = fullyRelease(node); int interruptMode = 0; // 节点已经不在同步队列中，则调用 park 让其在等待队列中挂着 while (!isOnSyncQueue(node)) &amp;#123; // 调用 park 阻塞挂起当前线程 LockSupport.park(this); // 说明 signal 被调用了或者线程被中断，校验下唤醒原因 // 如果因为终端被唤醒，则跳出循环 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &amp;#125; // while 循环结束， 线程开始抢锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 统一处理中断的 if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &amp;#125; await 方法步骤如下： 创建 Node.CONDITION 类型的 Node 并添加到条件队列（ConditionQueue）的尾部； 释放当前线程获取的锁（通过操作 state 的值） 判断当前线程是否在同步队列（SyncQueue）中，不在的话会使用 park 挂起。 循环结束之后，说明已经已经在同步队列（SyncQueue）中了，后面等待获取到锁，继续执行即可。 在这里一定要把条件队列和同步队列进行区分清楚！！ 条件队列/等待队列：即 Condition 的队列同步队列：AQS 的队列。 下面对 await 里面重要方法进行阅读： addConditionWaiter() 方法 private Node addConditionWaiter() &amp;#123; Node t = lastWaiter; // If lastWaiter is cancelled, clean out. // 判断尾节点状态，如果被取消，则清除所有被取消的节点 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &amp;#123; unlinkCancelledWaiters(); t = lastWaiter; &amp;#125; // 创建新节点，类型为 Node.CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); // 将新节点放到等待队列尾部 if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &amp;#125; addConditionWaiter 方法可以看出，只是创建一个类型为 Node.CONDITION 的节点并放到条件队列尾部。同时通过这段代码还可以得出其他结论： 条件队列内部的 Node，只用到了 thread、waitStatus、nextWaiter 属性； 条件队列是单向队列。 作为对比，这里把条件队列和同步队列做出对比： AQS 同步队列如下： 再来看下 Condition 的条件队列 waitStatus 在 AQS 中已经进行了介绍： 默认状态为 0； waitStatus &gt; 0 (CANCELLED 1) 说明该节点超时或者中断了，需要从队列中移除； waitStatus = -1 SIGNAL 当前线程的前一个节点的状态为 SIGNAL，则当前线程需要阻塞（unpark）； waitStatus = -2 CONDITION -2 ：该节点目前在条件队列； waitStatus = -3 PROPAGATE -3 ：releaseShared 应该被传播到其他节点，在共享锁模式下使用。 fullyRelease 方法 （AQS） final int fullyRelease(Node node) &amp;#123; boolean failed = true; try &amp;#123; // 获取当前节点的 state int savedState = getState(); // 释放锁 if (release(savedState)) &amp;#123; failed = false; return savedState; &amp;#125; else &amp;#123; throw new IllegalMonitorStateException(); &amp;#125; &amp;#125; finally &amp;#123; if (failed) node.waitStatus = Node.CANCELLED; &amp;#125; &amp;#125; fullyRelease 方法是由 AQS 提供的，首先获取当前的 state，然后调用 release 方法进行释放锁。 public final boolean release(int arg) &amp;#123; if (tryRelease(arg)) &amp;#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &amp;#125; return false; &amp;#125; release 方法在 AQS 中做了详细的介绍。它的主要作用就是释放锁，并且需要注意的是： fullyRelease 会一次性释放所有的锁，所以说不管重入多少次，在这里都会全部释放的。 这里会抛出异常，主要是在释放锁失败时，这时就会在 finally 里面将节点状态置为 Node.CANCELLED。 isOnSyncQueue(node) 通过上面的流程，节点已经放到了条件队列并且释放了持有的锁，而后就会挂起阻塞，直到 signal 唤醒。但是在挂起时要保证节点已经不在同步队列（SyncQueue）中了才可以挂起。 final boolean isOnSyncQueue(Node node) &amp;#123; // 当前节点是条件队列节点，或者上一个节点是空 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue return true; return findNodeFromTail(node); &amp;#125; // 从尾部开始遍历 private boolean findNodeFromTail(Node node) &amp;#123; Node t = tail; for (;;) &amp;#123; if (t == node) return true; if (t == null) return false; t = t.prev; &amp;#125; &amp;#125; 如果一个节点（总是一个最初放置在条件队列中的节点）现在正等待在同步队列上重新获取，则返回true。 这段代码的主要作用判断节点是不是在同步队列中，如果不在同步队列中，后面才会调用 park 进行阻塞当前线程。这里就会有一个疑问：AQS 的同步队列和 Condition 的条件队列应该是无关的，这里为什么会要保证节点不在同步队列之后才可以进行阻塞？因为 signal 或者 signalAll 唤醒节点之后，节点就会被放到同步队列中。 线程到这里已经被阻塞了，当有其他线程调用 signal 或者 signalAll 时，会唤醒当前线程。 而后会验证是否因中断唤醒当前线程，这里假设没有发生中断。那 while 循环的 isOnSyncQueue(Node node) 必然会返回 true ，表示当前节点已经在同步队列中了。 后续会调用 acquireQueued(node, savedState) 进行获取锁。 final boolean acquireQueued(final Node node, int arg) &amp;#123; // 是否拿到资源 boolean failed = true; try &amp;#123; // 中断状态 boolean interrupted = false; // 无限循环 for (;;) &amp;#123; // 当前节点之前的节点 final Node p = node.predecessor(); // 前一个节点是头节点， 说明当前节点是 头节点的 next 即真实的第一个数据节点 （因为 head 是虚拟节点） // 然后再尝试获取资源 if (p == head &amp;&amp; tryAcquire(arg)) &amp;#123; // 获取成功之后 将头指针指向当前节点 setHead(node); p.next = null; // help GC failed = false; return interrupted; &amp;#125; // p 不是头节点， 或者 头节点未能获取到资源 （非公平情况下被别的节点抢占） // 判断 node 是否要被阻塞，获取不到锁就会一直阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &amp;#125; &amp;#125; finally &amp;#123; if (failed) cancelAcquire(node); &amp;#125; &amp;#125; 这里就是 AQS 的逻辑了，同样可以阅读 AQS 的相关介绍。 不断获取本节点的上一个节点是否为 head，因为 head 是虚拟节点，如果当前节点的上一个节点是 head 节点，则当前节点为 第一个数据节点&gt;； 第一个数据节点不断的去获取资源，获取成功，则将 head 指向当前节点； 当前节点不是头节点，或者 tryAcquire(arg) 失败（失败可能是非公平锁）。这时候需要判断前一个节点状态决定当前节点是否要被阻塞（前一个节点状态是否为 SIGNAL）。 值得注意的是，当节点放到 AQS 的同步队列时，也是进行争抢资源，同时设置 savedState 的值，这个值则是代表当初释放锁的时候释放了多少重入次数。 总体流程画图如下： signalpublic final void signal() &amp;#123; // 是否为当前持有线程 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); &amp;#125; private void doSignal(Node first) &amp;#123; do &amp;#123; // firstWaiter 头节点指向条件队列头的下一个节点 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 将原来的头节点和同步队列断开 first.nextWaiter = null; &amp;#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &amp;#125; final boolean transferForSignal(Node node) &amp;#123; // 判断节点是否已经在之前被取消了 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 调用 enq 添加到 同步队列的尾部 Node p = enq(node); int ws = p.waitStatus; // node 的上一个节点 修改为 SIGNAL 这样后续就可以唤醒自己了 if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; &amp;#125; enq 同样可以阅读 AQS 的代码 private Node enq(final Node node) &amp;#123; for (;;) &amp;#123; Node t = tail; // 尾节点为空 需要初始化头节点，此时头尾节点是一个 if (t == null) &amp;#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &amp;#125; else &amp;#123; // 不为空 循环赋值 node.prev = t; if (compareAndSetTail(t, node)) &amp;#123; t.next = node; return t; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 通过 enq 方法将节点放到 AQS 的同步队列之后，要将 node 的前一个节点的 waitStatus 设置为 Node.SIGNAL。signalAll 的代码也是类似。 总结Q&amp;AQ: Condition 和 AQS 有什么关系？ A: Condition 是基于 AQS 实现的，Condition 的实现类 ConditionObject 是 AQS 的一个内部类，在里面共用了一部分 AQS 的逻辑。 Q: Condition 的实现原理是什么？ A: Condition 内部维护一个条件队列，在获取锁的情况下，线程调用 await，线程会被放置在条件队列中并被阻塞。直到调用 signal、signalAll 唤醒线程，此后线程唤醒，会放入到 AQS 的同步队列，参与争抢锁资源。 Q: Condition 的等待队列和 AQS 的同步队列有什么区别和联系？A: Condition 的等待队列是单向链表，AQS 的是双向链表。二者之间并没有什么明确的联系。仅仅在节点从阻塞状态被唤醒后，会从等待队列挪到同步队列中。 结束语本文主要是阅读 Condition 的相关代码，不过省略了线程中断等逻辑。有兴趣的小伙伴。可以更深入的研究相关的源码。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- 基于数组的有界阻塞队列 —— ArrayBlockingQueue","slug":"source-code/java/ArrayBlockingQueue","date":"2020-09-27T14:50:00.000Z","updated":"2020-09-27T14:54:57.558Z","comments":true,"path":"2020/09/27/source-code-arrayblockingqueue.html","link":"","permalink":"https://liuzhihang.com/2020/09/27/source-code-arrayblockingqueue.html","excerpt":"","text":"前言 在阅读完和 AQS 相关的锁以及同步辅助器之后，来一起阅读 JUC 下的和队列相关的源码。先从第一个开始：ArrayBlockingQueue。 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍由数组支持的有界BlockingQueue阻塞队列。 这个队列的命令元素FIFO（先入先出）。 队列的头是元素一直在队列中时间最长。 队列的尾部是该元素已经在队列中的时间最短。 新元素插入到队列的尾部，并且队列检索操作获取在队列的头部元素。 这是一个典型的“有界缓冲区”，在其中一个固定大小的数组保持由生产者插入并受到消费者的提取的元素。 一旦创建，容量不能改变。 试图put 一个元素到一个满的队列将导致操作阻塞; 试图 take 从空队列一个元素将类似地阻塞。 此类支持订购等待生产者和消费者线程可选的公平政策。 默认情况下，这个顺序不能保证。 然而，队列公平设置为构建 true 保证线程以FIFO的顺序进行访问。 公平性通常会降低吞吐量，但减少了可变性和避免饥饿。 基本使用 public class ArrayBlockingQueueTest &amp;#123; private static final ArrayBlockingQueue&lt;String> QUEUE = new ArrayBlockingQueue&lt;>(10); private static final CountDownLatch LATCH = new CountDownLatch(2); public static void main(String[] args) &amp;#123; ExecutorService pool = new ThreadPoolExecutor(2, 2, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;>(1024), new ThreadFactoryBuilder().setNameFormat(\"Thread-pool-%d\").build(), new ThreadPoolExecutor.AbortPolicy()); pool.submit(() -> &amp;#123; for (int i = 0; i &lt; 100; i++) &amp;#123; try &amp;#123; Thread.sleep(1000L); QUEUE.put(\"鸡蛋\" + Thread.currentThread().getName()); System.out.println(\"put 放入元素\"); &amp;#125; catch (InterruptedException ignored) &amp;#123; &amp;#125; &amp;#125; LATCH.countDown(); &amp;#125;); pool.submit(() -> &amp;#123; for (int i = 0; i &lt; 100; i++) &amp;#123; try &amp;#123; Thread.sleep(500L); String take = QUEUE.take(); System.out.println(\"take = \" + take); &amp;#125; catch (InterruptedException ignored) &amp;#123; &amp;#125; &amp;#125; LATCH.countDown(); &amp;#125;); try &amp;#123; LATCH.await(); &amp;#125; catch (InterruptedException ignored) &amp;#123; &amp;#125; pool.shutdown(); &amp;#125; &amp;#125; demo 只是临时写的一个，很简单的版本。 问题疑问 ArrayBlockingQueue 的实现原理是什么？ 入队列和出队列方法之间的区别是什么？ 源码分析基本结构 参数介绍 /** 数组 - 存储队列中的元素 */ final Object[] items; /** 下一个 take, poll, peek or remove 的索引 */ int takeIndex; /** 下一个 put, offer, or add 的索引 */ int putIndex; /** 队列中的元素数 */ int count; /** Main lock guarding all access */ final ReentrantLock lock; /** take 操作时是否等待 */ private final Condition notEmpty; /** put 操作时是否等待 */ private final Condition notFull; 构造函数public ArrayBlockingQueue(int capacity) &amp;#123; this(capacity, false); &amp;#125; // 指定容量，及是否公平 public ArrayBlockingQueue(int capacity, boolean fair) &amp;#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); &amp;#125; // 初始化的时候放入元素 public ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E> c) &amp;#123; this(capacity, fair); final ReentrantLock lock = this.lock; lock.lock(); // Lock only for visibility, not mutual exclusion try &amp;#123; int i = 0; try &amp;#123; for (E e : c) &amp;#123; checkNotNull(e); items[i++] = e; &amp;#125; &amp;#125; catch (ArrayIndexOutOfBoundsException ex) &amp;#123; throw new IllegalArgumentException(); &amp;#125; count = i; putIndex = (i == capacity) ? 0 : i; &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; 添加元素public boolean add(E e) &amp;#123; return super.add(e); &amp;#125; // 父类的方法，其实调用的也是 offer public boolean add(E e) &amp;#123; if (offer(e)) return true; else throw new IllegalStateException(\"Queue full\"); &amp;#125; // 使用锁 public boolean offer(E e) &amp;#123; checkNotNull(e); // 加锁 final ReentrantLock lock = this.lock; lock.lock(); try &amp;#123; if (count == items.length) return false; else &amp;#123; enqueue(e); return true; &amp;#125; &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; // 放入元素， 如果队列满了，则等待 public void put(E e) throws InterruptedException &amp;#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &amp;#123; while (count == items.length) notFull.await(); enqueue(e); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; add 方法：调用的是父类 AbstractQueue 的 add 方法，内部调用的是 offer 方法，如果 offer 返回 false，则抛出异常。 offer 方法：校验元素非空，加互斥锁，如果队列满了，则返回 false，如果队列未满，则调用 enqueue 方法，添加元素。 put 方法：校验元素非空，加互斥锁，如果队列满了，则一直自旋等待，队列未满则调用 enqueue 方法，添加元素。 所以下面还是需要看一下 enqueue 方法： // 只有在获取锁的时候才可以调用 private void enqueue(E x) &amp;#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; // putIndex 下一个 put, offer, or add 的索引 // 对其进行赋值，然后进行 ++putIndex 操作 items[putIndex] = x; // 如果等于长度，则指定为开始 if (++putIndex == items.length) putIndex = 0; // 对元素数进行 ++ count++; // 有元素入队列，唤醒在等待获取元素的线程 notEmpty.signal(); &amp;#125; 获取元素public E poll() &amp;#123; final ReentrantLock lock = this.lock; lock.lock(); try &amp;#123; return (count == 0) ? null : dequeue(); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; public E take() throws InterruptedException &amp;#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &amp;#123; while (count == 0) notEmpty.await(); return dequeue(); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; 通过源码可以看出： pool 和 take 都是从队列中获取元素，二者不同的是，当队列中没有元素时，poll 方法返回 null，而 take 方法会一直阻塞等待，直到从队列中获取到元素。 poll 和 take 方法获取元素都是调用的 dequeue 方法。 private E dequeue() &amp;#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(\"unchecked\") // 获取元素并将元素置为 null E x = (E) items[takeIndex]; items[takeIndex] = null; // takeIndex 下一个 take, poll, peek or remove 的索引 // 指向下一个元素，并且 元素数减少 if (++takeIndex == items.length) takeIndex = 0; count--; // 更新迭代器状态 if (itrs != null) itrs.elementDequeued(); // 唤醒等待放入元素的线程 notFull.signal(); return x; &amp;#125; 查看元素public E peek() &amp;#123; final ReentrantLock lock = this.lock; lock.lock(); try &amp;#123; return itemAt(takeIndex); // null when queue is empty &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; 总结Q&amp;AQ: ArrayBlockingQueue 的实现原理？ A: ArrayBlockingQueue 是基于数组实现的，内部使用 ReentrantLock 互斥锁，防止并发放置元素或者取出元素的冲突问题。 Q: 入队列和出队列方法之间的区别是什么？ 方法 作用 add 添加元素，队列满了，添加失败抛出遗产 offer 添加元素， 队列满了，添加失败，返回 false put 添加元素，队列满了，阻塞等待 poll 弹出元素，队列为空则返回 null take 弹出元素，队列为空则等待队列中有元素 peek 查看队列中放入最早的一个元素 结束语ArrayBlockingQueue 中使用了 ReentrantLock 互斥锁，在元素入队列和出队列的时候都进行了加锁，所以同时只会有一个线程进行入队列或者出队列，从而保证线程安全。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- 使用递增计数器的线程同步工具 —— 信号量，它的原理是什么样子的？","slug":"source-code/java/Semaphore","date":"2020-09-20T23:00:00.000Z","updated":"2020-09-21T00:04:01.368Z","comments":true,"path":"2020/09/21/source-code-semaphore.html","link":"","permalink":"https://liuzhihang.com/2020/09/21/source-code-semaphore.html","excerpt":"","text":"前言 在 JUC 中线程同步器除了 CountDownLatch 和 CycleBarrier ，还有一个叫做 Semaphore （信号量），同样是基于 AQS 实现的。下面来看看信号量的内部原理。 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍一个计数信号量。 从概念上讲，信号量维护了一组许可。 如果有必要，在许可可用之前调用 acquire 方法会被阻塞，直到许可证可用。 调用 release 方法会增加了一个许可证，从而释放被阻塞的线程。 声明时指定初始许可数量。 调用 acquire(int permits) 方法，指定目标许可数量。 调用 release(int permits) 方法，发布指定的许可数量。 在许可数量没有到达指定目标数量时，调用 acquire 方法的线程会被阻塞。 基本使用public class SemaphoreTest1 &amp;#123; private static final Semaphore SEMAPHORE = new Semaphore(0); public static void main(String[] args) throws InterruptedException &amp;#123; ExecutorService pool = new ThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;>(1024), new ThreadFactoryBuilder().setNameFormat(\"Thread-pool-%d\").build(), new ThreadPoolExecutor.AbortPolicy()); for (int i = 0; i &lt; 5; i++) &amp;#123; pool.submit(() -> &amp;#123; try &amp;#123; Thread.sleep(1000 + new Random().nextInt(1000)); &amp;#125; catch (InterruptedException ignored) &amp;#123; &amp;#125; System.out.println(\"当前线程: \" + Thread.currentThread().getName() + \" 发布一个许可\"); SEMAPHORE.release(1); &amp;#125;); &amp;#125; System.out.println(\"-----> 这里是主线程\"); SEMAPHORE.acquire(5); System.out.println(\"-----> 主线程执行完毕\"); pool.shutdown(); &amp;#125; &amp;#125; -----> 这里是主线程 当前线程: Thread-pool-2 发布一个许可 当前线程: Thread-pool-4 发布一个许可 当前线程: Thread-pool-1 发布一个许可 当前线程: Thread-pool-0 发布一个许可 当前线程: Thread-pool-3 发布一个许可 -----> 主线程执行完毕 上面这个方法也是模拟了类似 CountDownLatch 的用法， 在子线程执行完毕之后，主线程继续执行。只不过 Semaphore 和 CountDownLatch 区别最大的是： Semaphore 是从指定数值开始增加，直到到达许可数量，然后被阻塞线程开始继续执行。 CountDownLatch 是从指定数量的线程开始减少，直到为 0 时，被阻塞的线程开始继续执行。 当然这只是最简单的用法，除此让主线程等待，同样也可以让其他线程等待，然后再开始执行。 问题疑问 Semaphore 和 AQS 有什么关系？ Semaphore 和 CountDownLatch 有什么区别？ 源码分析基本结构 通过类图可以看出在 Semaphore 里面有一个静态内部类 Sync 继承了 AQS，同时为了区分公平和非公平的情况，Sync 分别有两个子类：NonfairSync 、FairSync。 下面根据案例分别从构造函数、acquire()、release() 入手，从而了解内部实现原理。 初始化public Semaphore(int permits) &amp;#123; sync = new NonfairSync(permits); &amp;#125; 初始化默认非公平锁， 同时需要传入指定许可数， 可以看到这块代码是调用的 AQS 的 setState(permits) 方法。代码如下： static final class NonfairSync extends Sync &amp;#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &amp;#123; super(permits); &amp;#125; &amp;#125; abstract static class Sync extends AbstractQueuedSynchronizer &amp;#123; private static final long serialVersionUID = 1192457210091910933L; Sync(int permits) &amp;#123; setState(permits); &amp;#125; &amp;#125; setState 方法其实就是对 AQS 的 state 进行赋值。 补充 在 ReentrantLock 中 state 代表加锁状态，0 没有线程获得锁，大于等于 1 已经有线程获得锁，大于 1 说明该获得锁的线程多次重入。 在 ReentrantReadWriteLock 中 state 代表锁的状态。state 为 0 ，没有线程持有锁，state 的高 16 为代表读锁状态，低 16 为代表写锁状态。通过位运算可以获取读写锁的实际值。 而在这里 （CountDownLatch）则代表门闩或者说计数的值。 如果对 state 有所遗忘，可以阅读前面的 AQS 、CAS 相关代码。 state 在这里代表的是信号量的许可数量。 acquire()public void acquire() throws InterruptedException &amp;#123; sync.acquireSharedInterruptibly(1); &amp;#125; public void acquire(int permits) throws InterruptedException &amp;#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireSharedInterruptibly(permits); &amp;#125; acquire() 和 acquire(int permits) 调用的都是 sync.acquireSharedInterruptibly(permits) 方法，只不过一个支持传递参数，一个默认为 1。 acquireSharedInterruptibly 方法，其实就是 Sync 继承自 AQS 的。 这块可以阅读 AQS 的文章，这里简单介绍下： private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &amp;#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &amp;#123; for (;;) &amp;#123; final Node p = node.predecessor(); if (p == head) &amp;#123; int r = tryAcquireShared(arg); if (r >= 0) &amp;#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &amp;#125; &amp;#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &amp;#125; &amp;#125; finally &amp;#123; if (failed) cancelAcquire(node); &amp;#125; &amp;#125; 在失败后会使用 doAcquireSharedInterruptibly(arg); 不断获取资源； final Node node = addWaiter(Node.SHARED); 会创建节点以共享模式放到队列里； 在循环中不断判断前一个节点，如果是 head，则尝试获取共享资源； 在共享模式下获取到资源后会使用 setHeadAndPropagate(node, r); 设置头节点，同时唤醒后续节点。 tryAcquireShared 是需要子类实现，也就是在 Semaphore.Sync 的实现类中实现了，这里以 FairSync 做讲解： static final class FairSync extends Sync &amp;#123; private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &amp;#123; super(permits); &amp;#125; protected int tryAcquireShared(int acquires) &amp;#123; for (;;) &amp;#123; // 如果前面有节点，则直接返回 -1 表示失败 if (hasQueuedPredecessors()) return -1; // 获取当前信号量 int available = getState(); // 获取当前剩余量 int remaining = available - acquires; // 如果小于 0 或者 CAS 设置信号量成功 则直接返回 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &amp;#125; &amp;#125; &amp;#125; 而这段代码的含义： 如果前面有节点，则直接阻塞； 如果当前剩余信号量小于 0 ，则返回负值，直接阻塞； 如果当前剩余量大于等于 0 ，会 CAS 更新信号量，并返回非负数。 这块数值的含义，在 AQS 中定义了，含义如下： 小于 0: 表示失败； 等于 0: 表示共享模式获取资源成功，但后续的节点不能以共享模式获取成功; 大于 0: 表示共享模式获取资源成功，后续节点在共享模式获取也可能会成功，在这种情况下，后续等待线程必须检查可用性。 release()public void release() &amp;#123; sync.releaseShared(1); &amp;#125; public void release(int permits) &amp;#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits); &amp;#125; 发布许可证的给定数量，该数量增加可用的许可数量。 看其内部调用的是 Sync 的 releaseShared， 其实就是 AQS 的对应方法： public final boolean releaseShared(int arg) &amp;#123; if (tryReleaseShared(arg)) &amp;#123; doReleaseShared(); return true; &amp;#125; return false; &amp;#125; 如果实现tryReleaseShared返回true，以共享模式释放资源。 其中的 tryReleaseShared 部分由 Semaphore.Sync 中实现，逻辑如下： protected final boolean tryReleaseShared(int releases) &amp;#123; for (;;) &amp;#123; // 获取当前 state int current = getState(); // 对 state 进行增加 int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); // 使用 CAS 赋值 if (compareAndSetState(current, next)) return true; &amp;#125; &amp;#125; 通过上面代码可以看出，在 Semaphore 的 release 方法中主要就是对 state 进行增加，增加成功后会调用 AQS 的 doReleaseShared 方法唤醒头节点。 总结Q&amp;AQ: 既然 Semaphore 也是基于 AQS， 那在 Semaphore 中 state 的含义代表什么？A: 在 Semaphore 中 state 代表许可数量，acquire 方法当许可小于指定数量会阻塞线程，release 方法增加许可当许可增加成功则唤醒阻塞节点。 Q: Semaphore 基于 AQS 具体是怎么实现的呢？A: 初始设置 state 的初始值，即初始许可数量。 acquire 方法设置目标数量，当目标数量大于当前数量时，会阻塞线程并将其放到阻塞队列中。此处基于 AQS 实现。 release 对 state 进行增加，成功后会调用 AQS 的 doReleaseShared 唤醒头结点。同样是基于 AQS 实现。 Q: Semaphore 和 CountDownLatch 有什么区别？A: Semaphore 的计数器是递加的，而 CountDownLatch 是递减的。相同点就是计数器都不可以重置。 结束语在阅读 Semaphore 源码过程中，发现其主要功能都是基于 AQS 实现的，可以回顾阅读 AQS 的相关笔记。同样 Semaphore 也支持公平和非公平模式，这块就需要小伙伴自己去阅读啦。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【工作笔记】- 你有没有想过为什么交易和退款要拆开不同的表？","slug":"work/为什么要拆交易和退款表","date":"2020-09-19T02:00:00.000Z","updated":"2020-09-19T02:02:51.081Z","comments":true,"path":"2020/09/19/work-trans-refund-table.html","link":"","permalink":"https://liuzhihang.com/2020/09/19/work-trans-refund-table.html","excerpt":"","text":"前言 近期做新项目，在设计表结构的时候，突然想起来之前面试的时候遇到的一个问题，那时候也是初出茅庐，对很多东西一知半解（当然现在也是），当时那个小哥哥问我为什么交易和退款要拆成两个表？是基于什么考虑？有什么好处和优点么？ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 背景那是一个风和日丽的下午，当然，风和日丽的下午应该配点其他的形容词，实在是我才疏学浅，只能用这个词充当了下开头…… （此处省略小五千字） 赶紧进入正文！ 因为之前一直做聚合支付，而在使用过程中，也是支付和退款表拆开的，一直这么用，并没有觉得不妥。 比如一个交易表基本就是这样的： 字段 类型 含义 id bigint 主键 id trans_id varchar 交易订单号 trans_amount bigint 订单金额 trans_status tinyint 交易状态 …… …… …… create_time datetime 创建时间 update_time datetime 更新时间 退款表是这样子的： 字段 类型 含义 id bigint 主键 id refund_id varchar 退款订单号 origin_trans_id varchar 原始交易订单号 refund_status tinyint 退款状态 refund_amount bigint 退款金额 …… …… …… create_time datetime 创建时间 update_time datetime 更新时间 大概两个表就是这样子的吧！像一些其他字段就先省略了，平常用着也觉得没什么。 但是恰好那次那个小哥哥就问了这个问题，支付和退款为什么要分开记录？ 当时也是确实是实力不允许，我只是说了就是这么用的，把正向流程和逆向流程拆开，分开实现逻辑，比较方便。 个人见解这里说的不仅仅是交易和退款，同时泛指正向交易和逆向交易，比如充值和消费，借款和贷款，账户出账入账等等，下面仅说说个人见解，只做讨论，如果小伙伴有更好的说法，希望可以留言指出，共同学习。 对账需要对账户而言，出款表和入款表最后两方的金额是能对的上的，也就是说收支平衡。 当然这个记在一个表里也是完全可以的。毕竟对出入账只是流水没有状态变化，比如出账中，入账中，等等，流水表完全可以记在一个里面，然后用字段进行标识是出账还是入账。 拆表需要在网上看资料经常会说分库分表，而像订单这种（交易/退款）完全两种业务，使用两张表相对而言比较合适，毕竟交易的订单相比退款订单要多的多。 字段设计交易和退款是完全不同的两种业务，不像账户流水就是资金记录。 交易除了订单状态还有一些交易信息比如商户号、优惠金额、实付金额、交易渠道、商品 id 名称、备注等各种信息。 退款则是根据原单进行退款，需要记录原始订单号、退款金额（部分退款）、退款信息等。 虽然交易和退款总体上都包含 订单号、状态、金额等，但是如果强行放在一个表，就会导致以下问题： 很多字段为空的情况，比如交易不需要原始订单号，退款需要存储原始订单号。本来可以设置索引来提高查询效率的字段也不太合适设置了。 状态也不一定可以完全兼容，像交易状态和退款状态就很难互相兼容。 开发效率交易和退款分开之后，两个人负责不同的业务进行开发，包括业务逻辑和查询展示。如果放在一起，就很多字段不能保证别人知道有还是没有，是存储还是不存储，毕竟表里设置的都可以为空。这种情况下需要很多沟通，或者干脆一个人进行开发。 设计模式及原则其他从设计模式及原则的角度上来说，可以说是职责单一，当然再高大上偏理论的我这就扯不出来了。 总结Q&amp;AQ: 那前端要将两种甚至多种在一个列表展示该如何处理？ A: 在很多 APP 中大家看到的多种订单都是在一个列表里面展示出来的，比如：支付宝的账单页面。 当然，如果前端分 tab 页，分开展示不同的业务，那对后端来说简直不要太友好。不过实际往往不是这样，这时候就需要将订单统一存储。 在订单成功的时候存储到一个公共存储中，可以通过 MQ 等，将数据保送到另一张表/库，或者 ES 中用来存储。这样订单查询还可以和业务逻辑的表/库分开。也可以通过 binlog 进行处理，这里的方案只做参考。 结束语之所以写这篇文章，也是为了总结一下最近工作中遇到的问题，以及处理方法。同时一瞬间想起来了很久前遇到的相同的问题。 如果小伙伴们还有别的看法，欢迎留言，发表自己的意见及看法，共同讨论。","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"}]},{"title":"【JDK源码笔记】- CyclicBarrier 不就是比 CountDownLatch 多了个回环么？","slug":"source-code/java/CyclicBarrier","date":"2020-09-12T17:30:00.000Z","updated":"2020-09-12T18:05:58.207Z","comments":true,"path":"2020/09/13/source-code-cyclicbarrier.html","link":"","permalink":"https://liuzhihang.com/2020/09/13/source-code-cyclicbarrier.html","excerpt":"","text":"前言 看完 CountDownLatch 正准备表示一番，突然看到了一个 CyclicBarrier —— 回环屏障。沃特？回环还屏障？说比 CountDownLatch 要多一个回环，那咱可得瞧一瞧，看一看了！ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍一个同步辅助，它允许一组线程的所有等待彼此达成共同屏障点。 CyclicBarrier 在涉及固定线程数且必须等待彼此的程序非常有用。 该屏障被称为回环屏障 ，因为它在等待的线程被释放后可以被重新利用。 CyclicBarrier 支持一个可选的 Runnable 命令，该命令在障碍中的最后一个线程到达之后，但在释放任何线程之前，每个屏障点运行一次。 此屏障操作对于在任何一方继续之前更新共享状态很有用。 通过上面的源码注释基本可以得出以下结论： CyclicBarrier 和 CountDownLatch 类似，但它是一组线程等待，直到在其他线程中执行的一组操作完成为止。 CountDownLatch 是计数递减，结束后再调用 await 或者 countdown 都会立即返回，但是 CyclicBarrier 可以重置屏障。 CyclicBarrier 还可以传入参数 Runnable ，Runnable 会在释放线程之前执行。 基本使用既然上面总结了三个结论，下面当然从三个方面演示如何使用的： - 屏障功能 public class CyclicBarrierTest &amp;#123; private static final CyclicBarrier CYCLIC_BARRIER = new CyclicBarrier(11); public static void main(String[] args) throws BrokenBarrierException, InterruptedException &amp;#123; ExecutorService pool = new ThreadPoolExecutor(10, 10, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;>(1024), new ThreadFactoryBuilder().setNameFormat(\"Thread-pool-%d\").build(), new ThreadPoolExecutor.AbortPolicy()); for (int i = 0; i &lt; 10; i++) &amp;#123; pool.submit(() -> &amp;#123; try &amp;#123; System.out.println(Thread.currentThread().getName() + \" 开始执行\"); Thread.sleep(5000); System.out.println(Thread.currentThread().getName() + \" 执行结束，准备调用 await\"); CYCLIC_BARRIER.await(); &amp;#125; catch (InterruptedException | BrokenBarrierException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125;); &amp;#125; System.out.println(\"主线程执行 —————————————— >>>\"); CYCLIC_BARRIER.await(); System.out.println(\"主线程继续执行 —————————————— >>>\"); pool.shutdown(); &amp;#125; &amp;#125; 通过上面代码其实模拟了个类似 CountDownLatch 的功能，让所有线程等待，直到都调用 await 之后，各个线程继续执行，同时主线程也继续往下执行。 不过相对 CountDownLatch 的指定一个线程或多个等待，直到其他线程执行结束，等待的线程才继续执行来说，CyclicBarrier 相对来说还是逊色。 差别总结如下： CountDownLatch 是指定等待的线程，其他线程进行 countDown，等计数为 0 时，等待的线程继续执行。 CyclicBarrier 是一组线程调用 await 进行等待，当所有的都进入等待的时候，这一组就会一起冲破屏障继续执行。 - 回环功能 public class CyclicBarrierTest2 &amp;#123; private static final CyclicBarrier CYCLIC_BARRIER = new CyclicBarrier(5); public static void main(String[] args) throws BrokenBarrierException, InterruptedException &amp;#123; ExecutorService pool = new ThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;>(1024), new ThreadFactoryBuilder().setNameFormat(\"Thread-pool-%d\").build(), new ThreadPoolExecutor.AbortPolicy()); for (int i = 0; i &lt; 5; i++) &amp;#123; pool.submit(() -> &amp;#123; try &amp;#123; System.out.println(Thread.currentThread().getName() + \" 开始执行\"); CYCLIC_BARRIER.await(); System.out.println(Thread.currentThread().getName() + \" 冲破屏障 >>> 1\"); CYCLIC_BARRIER.await(); System.out.println(Thread.currentThread().getName() + \" 冲破屏障 >>>>> 2\"); CYCLIC_BARRIER.await(); &amp;#125; catch (InterruptedException | BrokenBarrierException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125;); &amp;#125; pool.shutdown(); &amp;#125; &amp;#125; 上面演示的回环的用法。 - 回环 Runnable 这块只需要在声明的 CyclicBarrier 修改为以下即可： private static final CyclicBarrier CYCLIC_BARRIER = new CyclicBarrier(5, new Runnable() &amp;#123; @Override public void run() &amp;#123; System.out.println(\"执行一次 Runnable \"); &amp;#125; &amp;#125;); 打印结果如下： 可以看出只是在下一个计数开始之前，先执行 Runnable 。至于是不是在释放屏障之前，那很容易，直接 Debug 走一遭就知道了！专门录制了个视频： 通过 debug 可以看出Runnable 会在释放线程之前执行。 问题疑问？ CyclicBarrier 和 AQS 有什么关系？ CyclicBarrier 的实现原理是什么？ CyclicBarrier 是如何实现回环的？ 下面就带着疑问去源码阅读，一探究竟！ 源码分析基本结构 通过 UML 乍一看，CyclicBarrier 和 AQS 并无什么关系，那下面开始从参数、构造器、await()方法分别看源码。 参数public class CyclicBarrier &amp;#123; /** * 屏障的每次使用都表示为一个生成实例。 * broken 表示屏障是否被打破。 */ private static class Generation &amp;#123; boolean broken = false; &amp;#125; /** 锁 */ private final ReentrantLock lock = new ReentrantLock(); /** 条件等待，直到屏障 */ private final Condition trip = lock.newCondition(); /** 等待计数 */ private final int parties; /* The command to run when tripped */ private final Runnable barrierCommand; /** 当前 generation 新创建的*/ private Generation generation = new Generation(); /** 仍在等待的 parties 数量，递减 为 0 会重置 */ private int count; &amp;#125; 通过上面可以看出： 内部使用了一个静态类 Generation ，它有什么功能呢？通过注释了解到，每次使用屏障的时候都会生成，具体有什么用，其实就是用来标示屏障是否被打破。 内部还有一个 parties 表示等待计数，count 表示仍在等待的计数。 那就继续往下看吧！ 构造器public CyclicBarrier(int parties, Runnable barrierAction) &amp;#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; &amp;#125; 这里的入参有两个： parties（等待计数）：记录多少个线程调用 await 之后，才会一起打破屏障。 barrierAction：冲破屏障前执行的行为。 但是会同时对 parties 和 count 赋值为传入的 parties。 单参数构造，其实就是将 barrierAction 赋值为 null。 await() 方法在示例中用的 await() 方法， 那就从 await() 方法入手： public int await() throws InterruptedException, BrokenBarrierException &amp;#123; try &amp;#123; return dowait(false, 0L); &amp;#125; catch (TimeoutException toe) &amp;#123; throw new Error(toe); // cannot happen &amp;#125; &amp;#125; await() 才是重头戏， 先来根据源码注释，了解是干嘛的，看看作者怎么讲： 等到所有各方都在此障碍上调用await。 如果当前线程不是最后到达的线程，则出于线程调度目的将其禁用，并使其处于休眠状态，直到发生以下情况之一： 最后一个线程到达； 其他一些线程中断当前线程； 其他一些线程中断其他正在等待的线程之一； 等待屏障的时候其他线程超时； 其他一些线程在此屏障上调用 reset。 看到这些，咱们最想看的当然是 2.1 ，等待最后一个线程到达屏障，之后所有的线程一起继续执行。 private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &amp;#123; // 加锁 final ReentrantLock lock = this.lock; lock.lock(); try &amp;#123; // 在这里用到了这个代 final Generation g = generation; if (g.broken) throw new BrokenBarrierException(); // 线程终中断标示 if (Thread.interrupted()) &amp;#123; breakBarrier(); throw new InterruptedException(); &amp;#125; // 对计数进行递减 int index = --count; // 如果是 0 则 if (index == 0) &amp;#123; // tripped boolean ranAction = false; try &amp;#123; final Runnable command = barrierCommand; // 不是 null 先执行行为 if (command != null) // 这里不是新开线程 command.run(); ranAction = true; // 下一代 nextGeneration(); return 0; &amp;#125; finally &amp;#123; // 任务未成功时，即 ranAction 还是 false 打破屏障 if (!ranAction) breakBarrier(); &amp;#125; &amp;#125; // loop until tripped, broken, interrupted, or timed out // 自旋 for (;;) &amp;#123; try &amp;#123; // 没有设置超时时间 if (!timed) // 进入等待 trip.await(); else if (nanos > 0L) nanos = trip.awaitNanos(nanos); &amp;#125; catch (InterruptedException ie) &amp;#123; if (g == generation &amp;&amp; ! g.broken) &amp;#123; breakBarrier(); throw ie; &amp;#125; else &amp;#123; Thread.currentThread().interrupt(); &amp;#125; &amp;#125; if (g.broken) throw new BrokenBarrierException(); // 已经下一代了 if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) &amp;#123; breakBarrier(); throw new TimeoutException(); &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; 这一大坨代码，完全没有看的欲望，直接划过去吧！ 所以…… 直接看到了这里吧。 代码还是要阅读的，分开来看（异常流程省略）： 使用了 ReentrantLock 互斥锁，因此对 count、broken 的修改是原子性的。 对 count 进行 –count 操作，这样就理解为什么说 count 是仍在等待的计数，或者说还有多少才能到达屏障点。 当 count 为 0 ，表示到达屏障点了 command 不为 null，会先执行 **command.run()**， 值得注意的是这里并不是新开了个线程。 **nextGeneration()**开始新的下一代，即重置 count 为 parties。 在 finally 里面使用 breakBarrier() 打破屏障。 当 count 不是 0 自旋，直到是 0. 这后面还有两个方法不能少： private void nextGeneration() &amp;#123; // 唤醒线程 trip.signalAll(); // 更新 count 为 parties count = parties; // 更新 Generation generation = new Generation(); &amp;#125; // 打破屏障，并唤醒全部 private void breakBarrier() &amp;#123; generation.broken = true; count = parties; trip.signalAll(); &amp;#125; reset() public void reset() &amp;#123; final ReentrantLock lock = this.lock; lock.lock(); try &amp;#123; breakBarrier(); // break the current generation nextGeneration(); // start a new generation &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; 将屏障重置为其初始状态，reset() 方法其实还是调用的 breakBarrier() 和 nextGeneration()，前者时打破当前代，后者是开始新的一轮。 总结Q: CyclicBarrier 和 AQS 有什么关系？A: 通过阅读源码，其实发现是使用了 ReentrantLock 互斥锁 以及 Condition 的等待唤醒功能。 Q: CyclicBarrier 的实现原理是什么？A: 内部含有两个计数，分别是 parties 和 count ，初始是二者相等，当有线程调用 await() 时，count 递减，只要 count 不为 0 ， 就会阻塞线程，直到 count 递减为 0 时，此时会所有线程一起释放，同时将 count 重置为 parties。 Q: CyclicBarrier 是如何实现回环的？A: 使用两个计数，count 递减，当 count 为 0 时，会重置为 parties，从而达到回环效果。 Q: 为什么 count 的 –count 操作没有使用 CAS？A: 因为已经 lock.lock() 了，使用了 ReentrantLock 锁能够保证 count 的原子性。 CyclicBarrier 和 CountDownLatch 的区别 回环：CyclicBarrier 可以回环，重新计数。CountDownLatch 只能一轮。 计数器：CyclicBarrier 的计数器自己维护递减， CountDownLatch 的计数器维护则是交给使用者。 阻塞线程：CyclicBarrier 阻塞的是自身，当到达屏障后，所有被阻塞的线程一起释放。CountDownLatch 可以指定阻塞线程。 结束语本文主要介绍了 CyclicBarrier 的常用方式，通过源码方式，分析如何达到屏障以及回环的效果。不对之处，请多指正。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【工具册】- 给大家介绍下，这是我的流程图软件 —— draw.io","slug":"tool/画图软件","date":"2020-09-06T09:00:00.000Z","updated":"2020-09-12T17:22:04.211Z","comments":true,"path":"2020/09/06/source-tool-drawio.html","link":"","permalink":"https://liuzhihang.com/2020/09/06/source-tool-drawio.html","excerpt":"","text":"前言 之前推了一篇文章《十张图带大家看懂 ES 原理 ！明白为什么说：ES 是准实时的！》，很多小伙伴都比较好奇在文章中的图是用的什么画图软件？看那么明显的手绘风格，当然是手画的啦！（开玩笑），其实我用的是 draw.io ，下面分享我的画图软件 —— draw.io 。 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 为什么需要画图？俗话说：“一图顶百字！”，好吧！这是我现想的俗话。 在新项目开发，技术分享，阅读代码笔记，或者面试的时候，画个流程图，架构图等等，比较直观，便于理解等。优点啥的就不多介绍了，这里主要介绍我的画图软件。 基本要求 免费 使用方便 支持离线使用 用过的其他软件 Visio：使用方便，在最开始的时候就是使用 Visio，不过只能在 Win 系统上使用。 ProcessOn：在线版，使用方便，很简洁。个人免费，不过限制文件数量。 OmniGraffle：Mac 客户端，收费，有很多功能，不过对我来说有点玩不熟练。 语雀：语雀也支持画简单的流程图。 其他一些，暂时没想起来的。 体验了很多画图软件，最后还是（暂时）选择了 draw.io 。 原因很简单，支持多平台（网页/Win/Mac/Linux），开源免费，文件存储在本地，也可以选择存储位置。 下面简单介绍下 draw.io draw.io使用在线版可以直接访问 https://draw.io 或者 https://app.diagrams.net/ 使用，进去之后如下所示： 可以选择存储，当然也有离线版本，即 drawio-desktop ，下载地址：https://github.com/jgraph/drawio-desktop 选择对应的平台下载安装即可： 设置语言打开 app 或者 进入 app 之后可以设置语言，如下： 使用都已经到这里了，就不用说怎么使用的了吧！下面展示之前画的图： 手绘风格那手绘风格是怎么画的呢？ 秘籍就在右侧工具栏，选中 Sketch 选项，之后图片就会变为手绘风格的了！ 总结本篇文章主要分享我常用的画图软件，有兴趣的小伙伴可以使用试一下。软件万万千，自己用的顺手的才是最重要的。不过 draw.io 还是比较推荐的。 后续我也会分享一些其他软件工具等，有兴趣的小伙伴可以关注以下。如果有什么比较有趣或生产力软件都可以给推荐下。","categories":[{"name":"工具册","slug":"工具册","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E5%85%B7%E5%86%8C/"}],"tags":[{"name":"工具册","slug":"工具册","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E5%85%B7%E5%86%8C/"}]},{"title":"【JDK源码笔记】- 快来看看！AQS 和  CountDownLatch 有怎么样的关系？","slug":"source-code/java/CountDownLatch","date":"2020-09-06T04:00:00.000Z","updated":"2020-09-12T17:22:04.112Z","comments":true,"path":"2020/09/06/source-code-countdownlatch.html","link":"","permalink":"https://liuzhihang.com/2020/09/06/source-code-countdownlatch.html","excerpt":"","text":"前言 CountDownLatch 一个同步辅助工具，同样是基于 AQS 实现，本篇文件主要是介绍 CountDownLatch 的使用，以及源码。 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍一个同步辅助工具，允许一个或多个线程等待，直到在其他线程中执行的一组操作完成为止 一个 CountDownLatch 初始化为给定计数。 在 await 方法阻塞，调用 countDown 方法会减少计数直到达到零，此后所有等待的线程被释放，任何后续调用 await 都会立即返回。 这是一次性的现象 - 计数不能复位。 如果你需要一个版本重置计数，请考虑使用CyclicBarrier 。 CountDownLatch 是一种通用的同步工具，可用于多种用途。 用作一个简单的开/关锁存器，或者门：所有线程调用await在门口等待，直到被调用 countDown 的线程打开。 初始化计数为 N ，用一个线程等待，直到 N 个线程完成某项操作，或某些动作已经完成 N 次。 CountDownLatch 一个有用的属性是，它不要求调用 countDown 线程等待计数到达零之前继续，它只是阻止任何线程通过await ，直到所有线程可以通过。 基本使用在我之前 CAS 那篇文章《从JUC源码看CAS，我做了个笔记 ……》中介绍 CAS 举例时使用了 CountDownLatch，其代码如下： public class CasTest &amp;#123; private static final CountDownLatch LATCH = new CountDownLatch(10); private static int NUM_I = 0; private static volatile int NUM_J = 0; private static final AtomicInteger NUM_K = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException &amp;#123; ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) &amp;#123; threadPool.execute(new Runnable() &amp;#123; public void run() &amp;#123; for (int j = 0; j &lt; 10000; j++) &amp;#123; NUM_I++; NUM_J++; NUM_K.incrementAndGet(); &amp;#125; LATCH.countDown(); &amp;#125; &amp;#125;); &amp;#125; LATCH.await(); System.out.println(\"NUM_I = \" + NUM_I); System.out.println(\"NUM_J = \" + NUM_J); System.out.println(\"NUM_K = \" + NUM_K.get()); threadPool.shutdown(); &amp;#125; &amp;#125; 简单介绍下这段代码的主要逻辑及功能： CountDownLatch 初始化计数为 10 。 开 10 个线程去处理业务逻辑，业务逻辑结束会调用 LATCH.countDown() 对计数进行 -1 操作。 在 LATCH.await() 处会阻塞等待，直到 LATCH 的值为 0 ，即 10 个线程业务都处理结束。 然后主线程继续执行。 问题疑问 CountDownLatch 和 AQS 有什么关系？ CountDownLatch 的实现原理是什么？ 源码分析基本结构 通过类图可以看出，CountDownLatch 内部存在一个静态类 Sync，而 Sync 继承了 AbstractQueuedSynchronizer。具体内部是如何实现的，则下面通过源码和画图一步一步的进行介绍。 初始化public CountDownLatch(int count) &amp;#123; if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count); &amp;#125; 通过初始化构造器可以看出，在 new 创建对象时必须传递一个 int 类型的非负数。实现逻辑可以看出，是创建了一个 Sync 对象。 private static final class Sync extends AbstractQueuedSynchronizer &amp;#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &amp;#123; setState(count); &amp;#125; int getCount() &amp;#123; return getState(); &amp;#125; &amp;#125; 之前在介绍 AQS 源码中已经介绍了 state 的含义，state 在不同子类中代表不同的含义。 在 ReentrantLock 中 state 代表加锁状态，0 没有线程获得锁，大于等于 1 已经有线程获得锁，大于 1 说明该获得锁的线程多次重入。 在 ReentrantReadWriteLock 中 state 代表锁的状态。state 为 0 ，没有线程持有锁，state 的高 16 为代表读锁状态，低 16 为代表写锁状态。通过位运算可以获取读写锁的实际值。 而在这里 （CountDownLatch）则代表门闩或者说计数的值。 countDownpublic void countDown() &amp;#123; sync.releaseShared(1); &amp;#125; 递减锁存器的计数： 如果当前计数大于零，则递减。 如果计数到达零，则释放所有等待的线程。 如果那么当前计数等于零没有任何反应。 此处调用的是 AQS 的 releaseShard() 方法，释放共享资源。 // AQS 代码 public final boolean releaseShared(int arg) &amp;#123; if (tryReleaseShared(arg)) &amp;#123; doReleaseShared(); return true; &amp;#125; return false; &amp;#125; 在 AQS 释放共享资源方法中 tryReleaseShared(arg) 部分是在 CountDownLatch 的内部类 Sync 中实现的，代码部分如下： protected boolean tryReleaseShared(int releases) &amp;#123; // Decrement count; signal when transition to zero for (;;) &amp;#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &amp;#125; &amp;#125; 递减更新 state ，如果 state 为 0 则返回 false，否则返回 true 。 此时再对照上面 AQS 代码，发现：如果 tryReleaseShared 返回 true ，则会唤醒后续节点开始执行操作。所以也就是说，如果 state 不为 0，则不会唤醒后续节点，直到 state 为 0 。 awaitpublic void await() throws InterruptedException &amp;#123; sync.acquireSharedInterruptibly(1); &amp;#125; 导致当前线程等待，直到锁存器倒计数至零，除非线程被中断。 如果当前计数为零，则此方法立即返回。 如果当前计数大于零，则当前线程用于线程调度目的，禁用并一直处于休眠状态的两件事情之一发生： 因调用countDown方法使计数达到0; 其他某些线程中断当前线程。 public final void acquireSharedInterruptibly(int arg) throws InterruptedException &amp;#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); &amp;#125; AQS 定义了 tryAcquireShared 返回值分为 3 种： 小于 0: 表示失败； 等于 0: 表示共享模式获取资源成功，但后续的节点不能以共享模式获取成功; 大于 0: 表示共享模式获取资源成功，后续节点在共享模式获取也可能会成功，在这种情况下，后续等待线程必须检查可用性。 其中 tryAcquireShared 同样由 CountDownLatch 的内部类 Sync 中实现，内部逻辑主要是判断 state 的值，进行返回。 在内部实现中返回的值只有 1 和 -1 ，说明在 state == 0 时，返回 1 ，即唤醒后续节点。不等于 0 时，会阻塞。 protected int tryAcquireShared(int acquires) &amp;#123; return (getState() == 0) ? 1 : -1; &amp;#125; 总结Q: CountDownLatch 和 AQS 有什么关系？ A: CountDownLatch 是基于 AQS 的共享模式实现的。 Q: CountDownLatch 的实现原理是什么？ A: 可以参考上面的源码解析，进行总结介绍。 CountDownLatch 是基于 AQS 共享模式实现的，在初始化时必须传入计数，该计数实际上是 AQS 的 state 值。在 countDown 时对 state 进行递减，在 当 state 为 0 时 会唤醒 AQS 队列中的所有等待的节点 （因为是共享模式）。而 await 方法是判断 state 的值，如果不是 0 ，则所有线程在队列中阻塞，等待唤醒。 Q: state 在代表的含义是什么？A: 在 ReentrantLock 中 state 代表加锁状态，0 没有线程获得锁，大于等于 1 已经有线程获得锁，大于 1 说明该获得锁的线程多次重入。 在 ReentrantReadWriteLock 中 state 代表锁的状态。state 为 0 ，没有线程持有锁，state 的高 16 为代表读锁状态，低 16 为代表写锁状态。通过位运算可以获取读写锁的实际值。 而在这里 （CountDownLatch）则代表门闩或者说计数的值。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【Elasticsearch 技术分享】—— 十张图带大家看懂 ES 原理 ！明白为什么说：ES 是准实时的！","slug":"elk/5. ES 为什么是准实时的","date":"2020-08-28T17:20:00.000Z","updated":"2020-09-12T17:22:04.165Z","comments":true,"path":"2020/08/29/technology-sharing-es-5.html","link":"","permalink":"https://liuzhihang.com/2020/08/29/technology-sharing-es-5.html","excerpt":"","text":"前言 说到 Elasticsearch ，其中最明显的一个特点就是 near real-time 准实时 —— 当文档存储在Elasticsearch中时，将在1秒内以几乎实时的方式对其进行索引和完全搜索。那为什么说 ES 是准实时的呢？ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ Lucene 和 ESLuceneLucene 是 Elasticsearch所基于的 Java 库，它引入了按段搜索的概念。 Segment： 也叫段，类似于倒排索引，相当于一个数据集。 Commit point：提交点，记录着所有已知的段。 Lucene index： “a collection of segments plus a commit point”。由一堆 Segment 的集合加上一个提交点组成。 对于一个 Lucene index 的组成，如下图所示。 Elasticsearch一个 Elasticsearch Index 由一个或者多个 shard （分片） 组成。 而 Lucene 中的 Lucene index 相当于 ES 的一个 shard。 写入过程写入过程 1.0 （不完善） 不断将 Document 写入到 In-memory buffer （内存缓冲区）。 当满足一定条件后内存缓冲区中的 Documents 刷新到磁盘。 生成新的 segment 以及一个 Commit point 提交点。 这个 segment 就可以像其他 segment 一样被读取了。 画图如下： 将文件刷新到磁盘是非常耗费资源的，而且在内存缓冲区和磁盘中间存在一个高速缓存（cache），一旦文件进入到 cache 就可以像磁盘上的 segment 一样被读取了。 写入过程 2.0 不断将 Document 写入到 In-memory buffer （内存缓冲区）。 当满足一定条件后内存缓冲区中的 Documents 刷新到 高速缓存（cache）。 生成新的 segment ，这个 segment 还在 cache 中。 这时候还没有 commit ，但是已经可以被读取了。 画图如下： 数据从 buffer 到 cache 的过程是定期每秒刷新一次。所以新写入的 Document 最慢 1 秒就可以在 cache 中被搜索到。 而 Document 从 buffer 到 cache 的过程叫做 ?refresh 。一般是 1 秒刷新一次，不需要进行额外修改。当然，如果有修改的需要，可以参考文末的相关资料。这也就是为什么说 Elasticsearch 是准实时的。 使文档立即可见： PUT /test/_doc/1?refresh &#123;\"test\": \"test\"&#125; // 或者 PUT /test/_doc/2?refresh=true &#123;\"test\": \"test\"&#125; Translog 事务日志此处可以联想 Mysql 的 binlog， ES 中也存在一个 translog 用来失败恢复。 Document 不断写入到 In-memory buffer，此时也会追加 translog。 当 buffer 中的数据每秒 refresh 到 cache 中时，translog 并没有进入到刷新到磁盘，是持续追加的。 translog 每隔 5s 会 fsync 到磁盘。 translog 会继续累加变得越来越大，当 translog 大到一定程度或者每隔一段时间，会执行 flush。 flush 操作会分为以下几步执行： buffer 被清空。 记录 commit point。 cache 内的 segment 被 fsync 刷新到磁盘。 translog 被删除。 值得注意的是： translog 每 5s 刷新一次磁盘，所以故障重启，可能会丢失 5s 的数据。 translog 执行 flush 操作，默认 30 分钟一次，或者 translog 太大 也会执行。 手动执行flush： POST /my-index-000001/_flush 删除和更新segment 不可改变，所以 docment 并不能从之前的 segment 中移除或更新。 所以每次 commit， 生成 commit point 时，会有一个 .del 文件，里面会列出被删除的 document（逻辑删除）。而查询时，获取到的结果在返回前会经过 .del 过滤。 更新时，也会标记旧的 docment 被删除，写入到 .del 文件，同时会写入一个新的文件。此时查询会查询到两个版本的数据，但在返回前会被移除掉一个。 segment 合并每 1s 执行一次 refresh 都会将内存中的数据创建一个 segment。 segment 数目太多会带来较大的麻烦。 每一个 segment 都会消耗文件句柄、内存和cpu运行周期。更重要的是，每个搜索请求都必须轮流检查每个 segment ；所以 segment 越多，搜索也就越慢。 在 ES 后台会有一个线程进行 segment 合并。 refresh操作会创建新的 segment 并打开以供搜索使用。 合并进程选择一小部分大小相似的 segment，并且在后台将它们合并到更大的 segment 中。这并不会中断索引和搜索。 当合并结束，老的 segment 被删除 说明合并完成时的活动： 新的 segment 被刷新（flush）到了磁盘。 写入一个包含新 segment 且排除旧的和较小的 segment的新 commit point。 新的 segment 被打开用来搜索。 老的 segment 被删除。 物理删除： 在 segment merge 这块，那些被逻辑删除的 document 才会被真正的物理删除。 总结主要介绍了内部写入和删除的过程，需要了解 refresh、fsync、flush、.del、segment merge 等名词的具体含义。 完整画图如下： 以上就是个人分享的 ES 相关的内容，主要目的是组内技术分享，进行扫盲。不对之处，希望大家留言指正。 相关资料 准实时搜索： https://www.elastic.co/guide/en/elasticsearch/reference/7.9/near-real-time.html Refresh API：https://www.elastic.co/guide/en/elasticsearch/reference/7.9/indices-refresh.html Flush API：https://www.elastic.co/guide/en/elasticsearch/reference/7.9/indices-flush.html","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"工作笔记/ELK","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/ELK/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"【Elasticsearch 技术分享】—— ES 查询检索数据的过程，是什么样子的？","slug":"elk/4. ES 查询检索的过程","date":"2020-08-26T12:20:00.000Z","updated":"2020-09-12T17:22:04.178Z","comments":true,"path":"2020/08/26/technology-sharing-es-4.html","link":"","permalink":"https://liuzhihang.com/2020/08/26/technology-sharing-es-4.html","excerpt":"","text":"前言 ES 使用过程中常用的就是查询以及检索，那查询和检索的过程，什么样的呢？ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 查询流程GET my-index/_doc/0 Client 将请求发送到任意节点 node，此时 node 节点就是协调节点（coordinating node）。 协调节点对 id 进行路由，从而判断该数据在哪个shard。 在 primary shard 和 replica shard 之间 随机选择一个，请求获取 doc。 接收请求的节点会将数据返回给协调节点，协调节点会将数据返回给Client。 可以通过 preference 参数指定执行操作的节点或分片。默认为随机。 检索流程GET /my-index/_search Client 将请求发送到任意节点 node，此时 node 节点就是协调节点（coordinating node） 协调节点进行分词等操作后，去查询所有的 shard （primary shard 和 replica shard 选择一个） 所有 shard 将满足条件的数据 id 排序字段 等信息返回给路由节点 路由节点重新进行排序，截取数据后，获取到真正需要返回的数据的 id 路由节点再次请求对应的 shard （此时有 id 了，可以直接定位到对应shard） 获取到全量数据，返回给 Client 总结主要介绍了 ES 查询以及检索的流程，不足及错误之处欢迎指正。 参考文档 协调节点：https://www.elastic.co/guide/en/elasticsearch/reference/7.9/modules-node.html#coordinating-node","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"工作笔记/ELK","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/ELK/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"【Elasticsearch 技术分享】—— Elasticsearch 存储一条数据， put 过程是什么样子的？","slug":"elk/3. ES 数据的存储 put 的过程","date":"2020-08-25T16:10:00.000Z","updated":"2020-09-12T17:22:04.108Z","comments":true,"path":"2020/08/26/technology-sharing-es-3.html","link":"","permalink":"https://liuzhihang.com/2020/08/26/technology-sharing-es-3.html","excerpt":"","text":"前言 在前面已经介绍了 ES 中常用的一些名词，知道了数据是存储在 shard 中的，而 index 会映射一个或者多个 shard 。那这时候我要存储一条数据到某个索引下，这条数据是在哪个 index 下的呢？ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ ES 演示一切按照官方教程使用 三条命令，在本机启动三个节点组装成伪集群。 ~ % > ./elasticsearch ~ % > ./elasticsearch -Epath.data=data2 -Epath.logs=log2 ~ % > ./elasticsearch -Epath.data=data3 -Epath.logs=log3 创建索引curl -X PUT \"localhost:9200/my-index-000001?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"settings\": &amp;#123; \"index\": &amp;#123; \"number_of_shards\": 3, \"number_of_replicas\": 2 &amp;#125; &amp;#125; &amp;#125; ' 当前版本 7.9 文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html ES 默认 number_of_shards 为 1默认 number_of_replicas 为 1，即一个分片只有一个副本 下面命令可以查看索引信息 curl -X GET \"localhost:9200/_cat/indices/my-index-000001?v&amp;s=index&amp;pretty\" 存放数据curl -X PUT \"localhost:9200/my-index-000001/_doc/0825?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"name\": \"liuzhihang\" &amp;#125; ' 查询数据curl -X GET \"localhost:9200/my-index-000001/_doc/0825?pretty\" 文档地址：https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html 一条数据该存放在哪个 shard通过命令可以看出：在存放数据时并没有指定到哪个 shard，那数据是存在哪里的呢？ 当一条数据进来，会默认会根据 id 做路由 shard = hash(routing) % number_of_primary_shards 从而确定存放在哪个 shard。 routing 默认是 _id， 也可以设置其他。 这个 id 可以自己指定也可以系统给生成, 如果不指定则会系统自动生成。 put 一条数据的过程是什么样的？ 写入过程主要分为三个阶段 协调阶段：Client 客户端选择一个 node 发送 put 请求，此时当前节点就是协调节点（coordinating node）。协调节点根据 document 的 id 进行路由，将请求转发给对应的 node。这个 node 上的是 primary shard 。 主要阶段：对应的 primary shard 处理请求，写入数据 ，然后将数据同步到 replica shard。 primary shard 会验证传入的数据结构 本地执行相关操作 将操作转发给 replica shard 当数据写入 primary shard 和 replica shard 成功后，路由节点返回响应给 Client。 副本阶段：每个 replica shard 在转发后，会进行本地操作。 在写操作时，默认情况下，只需要 primary shard 处于活跃状态即可进行操作。 在索引设置时可以设置这个属性 index.write.wait_for_active_shards 默认是 1，即 primary shard 写入成功即可返回。 如果设置为 all 则相当于 number_of_replicas+1 就是 primary shard 数量 + replica shard 数量。 就是需要等待 primary shard 和 replica shard 都写入成功才算成功。 可以通过索引设置动态覆盖此默认设置。 总结如何查看数据在哪个 shard 上呢？curl -X GET \"localhost:9200/my-index-000001/_search_shards?routing=0825&amp;pretty\" 通过上面命令可以查到数据 0825 的所在 shard。 相关资料 ES 创建索引：https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html ES 查询数据：https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html ES 检索 shard：https://www.elastic.co/guide/en/elasticsearch/reference/current/search-shards.html","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"工作笔记/ELK","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/ELK/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"【Elasticsearch 技术分享】—— ES 常用名词及结构","slug":"elk/2. ES的常用名词及结构","date":"2020-08-23T02:00:00.000Z","updated":"2020-09-12T17:22:04.123Z","comments":true,"path":"2020/08/23/technology-sharing-es-2.html","link":"","permalink":"https://liuzhihang.com/2020/08/23/technology-sharing-es-2.html","excerpt":"","text":"前言 看完什么是 Elasticsearch 以及了解到了倒排索引的概念，下面就熟悉下 ES 中常用的一些名词。 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 常用术语 名词 解释 cluster 一个或者多个 node 指定相同的 cluster name，则它们会组成集群，并且自动选举 master，以及在故障时自动选举。 node 节点是属于集群的Elasticsearch的运行实例 。在启动时，节点将使用单播来发现具有相同集群名称的现有集群，并将尝试加入该集群。 index 类似关系数据库的表，映射一个或者多个主分片，同时拥有零个或多个副本分片。 index alias 索引别名是用于引用一个或多个现有索引的辅助名称。大多数Elasticsearch API接受索引别名代替索引名称。 mapping 每个 index 都有一个 mapping ，定义一个 type 以及许多索引范围的设置。mapping 可以明确定义，也可以在为文档建立索引后自动生成。 shard 分片是单个Lucene实例。最小的工作单位，由Elasticsearch自动管理。索引是指向主分片和副本分片的逻辑命名空间。 primary shard 每个文档都存储在一个主分片中。当您为文档建立索引时，将首先在主 shard 上建立索引，然后在主 shard 的所有副本上建立索引。默认情况下，索引具有一个主分片。您可以指定更多的主要分片来扩展 索引可以处理的文档数量。创建索引后，您将无法更改索引中的主要分片数量。但是，可以使用split API将索引拆分为新索引 。 replica shard 每个主分片可以具有零个或多个副本。副本是 primary shard 的副本。 document document 是存储在 Elasticsearch 中的 JSON 文档。每个 document 都存储在索引中，并且有 type 和 id。被索引的 JSON 文档 将存储在 _source 字段中，该字段在获取或搜索文档时默认返回。 id 每个 document 都有不同的 id，没有指定的话，会自动生成。 field 一个 document 包含字段或键值对的列表。字段类似于关系数据库中表中的列。 source field 默认情况下，索引的JSON文档存储在 _source 字段中，并且将由所有 get 和 search 请求返回。这样，可以直接从搜索结果中访问原始对象，而无需执行第二步来从 ID 中检索对象。 画图出来就是下面这个样子 replica shard 有什么用？ 增加故障转移：如果主副本发生故障，副本副本可以提升为主副本 提高性能：获取和搜索请求可以由主或副本分片处理。 默认情况下，每个主分片都有一个副本，但是可以在现有索引上动态更改副本的数量。副本分片永远不会与其主分片在同一节点上启动。 除了定义索引应具有的主分片和副本分片的数量外，您无需直接引用分片。相反，您的代码应仅处理索引。 Elasticsearch 在 集群中的所有节点之间分配分片，并且在节点发生故障或添加新节点的情况下，可以自动将分片从一个节点移动到另一个节点。 分片 默认是 5个，副本默认为 1个。 总结这篇文章简单介绍了 ES 的常用名词，因为只有了解到这些名词，在小伙伴讨论 ES 的时候，才不会一脸懵逼。","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"工作笔记/ELK","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/ELK/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"【Elasticsearch 技术分享】—— Elasticsearch ？倒排索引？这都是什么？","slug":"elk/1.初识es","date":"2020-08-18T05:00:00.000Z","updated":"2020-09-12T17:22:04.115Z","comments":true,"path":"2020/08/18/technology-sharing-es-1.html","link":"","permalink":"https://liuzhihang.com/2020/08/18/technology-sharing-es-1.html","excerpt":"","text":"前言 革命同志是块砖，哪里需要哪里搬！这不，老大发话，要我在组内做一个 Elasticsearch 技术分享。这不话题一转，开始看起来 ES 了。虽然很久之前用过 ELK 做过日志监控系统，但是毕竟时隔已久，还是得从头看起。当然手头的活也不能停，话不多说，开始分享。先看看什么是 ES？ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 什么是ESElasticsearch 是分布式搜索和分析引擎。 Elasticsearch 为所有类型的数据提供近实时（near real-time）的搜索和分析。 常用场景： 网站搜索 ELK 日志采集，存储，分析 地理信息系统分析 像下图中使用的设计： 特点： ES是一个分布式文档存储，存储的数据都是序列化为 JSON documents 。 使用倒排索引存储数据，倒排索引比较适合全文本搜索。 基于Apache Lucene搜索引擎库，可以存储，检索文档及元数据。 支持 JSON 样式的查询语言——Query DSL，也支持 SQL 样式的查询。 集群部署，易于扩展。节点（node）分片（shard），将新的 node 添加到集群时，ES 会自动迁移 shard 到新 node 上，重新平衡集群。 shard 分为两种 主分片（primary shard）和 副本分片 （replica shard） replica shard 存放的是 primary shard 的冗余副本 —— 可以防止集群故障，数据丢失，同时可以提高搜索或检索速度。 在创建索引时 primary shard 数量是固定的，而replica shard 数量是可以更改的。 分片由索引配置，分片越多，维护索引则开销则越大，分片大小越大，则 ES 在增减节点重新平衡集群时，分片移动时间越长。 集群恢复： 跨集群复制 （CCR），可以自动将索引从主集群同步到热备份的辅助远程集群。 什么是倒排索引？倒排索引也可以成为反向索引。 作为开发咱们经常接触到的就是 MySql，假设有一堆技术书籍，并且已经编上号。 Java 并发编程之美 Java 开发手册 深入分布式缓存 Java 并发程序设计 算法 数据结构与算法 如果放在 MySql 里面就是这样 id book_name 1 Java 并发编程之美 2 Java 开发手册 3 深入分布式缓存 4 Java 并发程序设计 5 算法 6 数据结构与算法 此时我想查询所有关于 并发 的书籍。 select * from table_book where book_name like %并发%; 然后会开始遍历表格，查找到 1和4两条记录。 如果是倒排索引处理的话 首先会将每个名称进行分词，比如 Java 并发编程之美 会被分为 Java 并发 编程 之 美。分词结束之后按照词关联书籍的编号。 term ids Java 1、2、4 并发 1、4 编程 1 算法 5、6 分布式 3 … … 在倒排索引中搜索并发，然后进行检索，就很容易定位到关于并发书籍的编号。 那什么是 Lucene？Lucene 可以理解为一个开源的、高性能、可伸缩的信息搜索库。使用 Java 开发，封装了各种倒排索引和搜索的API。相当于一个组件。 而 ES 就是在 Lucene 之上进行的开发，从而可以高可用、集群部署、故障迁移、备份容灾等。 总结就这么多，先知道个 ES 是干嘛的。后续再慢慢看、慢慢总结。","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"工作笔记/ELK","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/ELK/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"【JDK源码笔记】- 除了读写锁，JUC 下面还有个 StampedLock！还不过来了解一下么？","slug":"source-code/java/StampedLock","date":"2020-08-09T07:30:00.000Z","updated":"2020-09-12T17:22:04.225Z","comments":true,"path":"2020/08/09/source-code-stamped-lock.html","link":"","permalink":"https://liuzhihang.com/2020/08/09/source-code-stamped-lock.html","excerpt":"","text":"前言 在了解完 ReentrantLock 和 ReentrantReadWriteLock 之后，惊奇的发现 JUC 下还有一个 StampedLock 。 查阅资料发现是 JDK8 新增的一个锁。现在已经 JDK15 了，原谅我的孤陋寡闻，实在是业务开发中用的太少。那行吧，赶紧来看一下 StampedLock 到底是什么？为什么有了 ReentrantLock 和 ReentrantReadWriteLock 之后还要设计一个 StampedLock ？ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍往期回顾在介绍 StampedLock 之前还是先看一下 ReentrantLock 和 ReentrantReadWriteLock。 ReentrantLock：互斥锁，同时只有一个线程可以持有。支持锁重入。 ReentrantReadWriteLock：读写锁，分为读锁和写锁，支持重入。其中读读共享，写写独占，读写互斥，写读互斥。支持锁降级，线程获取写锁后可以降级为读锁。适合读多写少的场景。 那为什么要设计 StampedLock 呢？先来看一下源码上的注释： StampedLock基于功能的锁，具有三种模式来控制读/写访问。StampedLock的状态由版本和模式组成。锁获取方法返回一个 stamp 用来表示并控制锁状态的访问；这些方法的“try”版本可能会返回特殊值零，以表示无法获取访问权限。锁的释放和转换方法需要使用 stamp 作为参数，如果它们与锁的状态不匹配，则会失败。 三种模式是：写锁、读锁、乐观读锁。 并且具有以下特征： 获取锁的时候（无论读锁还是写锁或者乐观读锁）都会返回一个 stamp，在释放锁的时候需要使用这个 stamp； 支持三种模式转换； 不是可重入的，所以获得锁的时候，不要尝试再次获取。 使用样例/** * @author liuzhihang * @date 2020/8/6 15:27 */ public class Count &amp;#123; private int num; private final StampedLock stampedLock = new StampedLock(); // 使用写锁，在对 num 进行写入的时候加锁 void write(int x) &amp;#123; long stamp = stampedLock.writeLock(); try &amp;#123; num += x; &amp;#125; finally &amp;#123; stampedLock.unlockWrite(stamp); &amp;#125; &amp;#125; // 乐观读 int read() &amp;#123; // 获取乐观读锁；返回 stamp long stamp = stampedLock.tryOptimisticRead(); try &amp;#123; // validate 验证是否被写锁持有 // 没有被写锁持有，可以直接返回 if (!stampedLock.validate(stamp)) &amp;#123; // 被写锁持有，那只能获取读锁 stamp = stampedLock.readLock(); &amp;#125; return num; &amp;#125; finally &amp;#123; stampedLock.unlockRead(stamp); &amp;#125; &amp;#125; void convertWrite(int x) &amp;#123; // 读 long stamp = stampedLock.readLock(); try &amp;#123; while (num == x) &amp;#123; // 满足条件，转换为写锁 long ws = stampedLock.tryConvertToWriteLock(stamp); // 转为写锁成功 if (ws != 0L) &amp;#123; stamp = ws; num = x; break; &amp;#125; else &amp;#123; // 转换失败，释放读锁 stampedLock.unlockRead(stamp); // 再次获取写锁 stamp = stampedLock.writeLock(); &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; stampedLock.unlock(stamp); &amp;#125; &amp;#125; &amp;#125; 写锁使用方法一样； 乐观读，可以先去读数据，发现没有改变可以返回，发现改变了，则重新获取读锁，然后再返回； 读锁可以升级为写锁，通过 tryConvertToWriteLock 方法。 总结UML 通过 UML 可以看出 StampedLock 和 AQS 并无任何关系。 StampedLock 和 ReentrantReadWriteLock 的区别？ StampedLock 也是读写锁，但是和 AQS 没有关系 StampedLock 除了 读锁和写锁，还有一个乐观读。 StampedLock 的读锁可以升级为写锁。 StampedLock 不支持锁重入。 总结本文主要介绍 StampedLock 的相关使用及和 ReentrantReadWriteLock 的区别。 因为工作确实很少使用，阅读源码，内部自旋逻辑等有很多。如果介绍的话会篇幅特别长，这里就省略了。有兴趣的小伙伴可以自己阅读源码。 因为 StampedLock 提供的乐观读锁支持，所以在多线程多读情况下，性能比 ReentrantReadWriteLock 要更好，但是需要注意的是 StampedLock 是不支持锁重入的。 另一个需要记住的就是 StampedLock 和 AQS 并没有什么关系，它是在自己内部维护了一个双向阻塞队列。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"IDEA插件开发常用API","slug":"plugin/idea插件开发常用api","date":"2020-08-01T03:58:16.000Z","updated":"2020-09-12T17:22:04.188Z","comments":true,"path":"2020/08/01/idea-plugin-development-common-api.html","link":"","permalink":"https://liuzhihang.com/2020/08/01/idea-plugin-development-common-api.html","excerpt":"","text":"在开发Toolkit过程中查阅相关资料和阅读其他开源项目总结的一些常用API.整体内容来源于网络, 以及自己使用开发Toolkit过程中使用到的.总结的不到位的地方欢迎指正. AnAction操作 创建Action集成AnAction并实现其actionPerformed方法. 在方法中可以获取到AnActionEvent对象. 代码如下: public class JsonFormatAction extends AnAction &amp;#123; @Override public void actionPerformed(AnActionEvent event) &amp;#123; // 获取当前project对象 Project project = event.getData(PlatformDataKeys.PROJECT); // 获取当前编辑的文件, 可以进而获取 PsiClass, PsiField 对象 PsiFile psiFile = event.getData(CommonDataKeys.PSI_FILE); Editor editor = event.getData(CommonDataKeys.EDITOR); // 获取Java类或者接口 PsiClass psiClass = getTargetClass(editor, psiFile); // 创建并调起 DialogWrapper DialogWrapper dialog = new JsonFormat(project, psiFile, editor, psiClass); dialog.show(); &amp;#125; 其他方式 // 获取project. 内部调用 getData(CommonDataKeys.PROJECT) = getDataContext().getData(CommonDataKeys.PROJECT) Project project = e.getProject(); // 获取数据上下文 DataContext dataContext = e.getDataContext(); // context可以也获取到其他信息, 入参为 PlatformDataKeys 定义的字段 Project project1 = dataContext.getData(PlatformDataKeys.PROJECT); Editor editor = dataContext.getData(PlatformDataKeys.EDITOR); PsiFile psiFile = dataContext.getData(PlatformDataKeys.PSI_FILE); PsiElement psiElement = dataContext.getData(PlatformDataKeys.PSI_ELEMENT); // 虚拟文件 VirtualFile virtualFile = dataContext.getData(PlatformDataKeys.VIRTUAL_FILE); 获取PsiClassPsiClass为java类或者接口 @Nullable protected PsiClass getTargetClass(Editor editor, PsiFile file) &amp;#123; int offset = editor.getCaretModel().getOffset(); PsiElement element = file.findElementAt(offset); if (element == null) &amp;#123; return null; &amp;#125; else &amp;#123; PsiClass target = PsiTreeUtil.getParentOfType(element, PsiClass.class); return target instanceof SyntheticElement ? null : target; &amp;#125; &amp;#125; Psixxx操作PsiClass操作API源码有注释且比较清楚, 此处仅记录我用到的一部分 // 获取全类名 String qualifiedName = aClass.getQualifiedName(); // 获取所有字段 PsiField[] fields = aClass.getFields(); PsiField操作// 获取字段名 String name = psiField.getName() PsiElement操作PsiClass和PsiField都实现了PsiElement // 删除 element.delete() // 添加元素, 向一个类中添加方法, 字段等, 也可以调用 addBefore, addAfter add(PsiElement element) PsiType操作PsiType支持常用基本类型, 但是当创建对象时则不支持.需要自己创建 PsiElementFactory psiElementFactory = JavaPsiFacade.getElementFactory(project); // String 类型 PsiType stringPsiType = psiElementFactory.createTypeFromText(\"java.lang.String\", null) // list PsiType listPsiType = psiElementFactory.createTypeFromText(\"java.util.List&lt;String>\", null); // 自定义list PsiType typeFromText = psiElementFactory.createTypeFromText(\"java.util.List&lt;\" + className + \">\", null); 其他APIXML 文件操作参考地址：https://jetbrains.org/intellij/sdk/docs/reference_guide/frameworks_and_external_apis/xml_dom_api.html 以 Mapper.xml 举例声明接口，继承 DomElement，并配合 @Attribute、@SubTag 、@SubTagsList 注解定义一个 xml model，其中需要注意 @SubTagsList 方法要使用复数形式。 public interface Mapper extends DomElement &amp;#123; /** * namespace * * @return */ @Attribute(\"namespace\") GenericAttributeValue&lt;String> getNamespace(); /** * * 增删改查对应的节点 * * @return */ @SubTagsList(&amp;#123;\"select\", \"insert\", \"update\", \"delete\"&amp;#125;) List&lt;Statement> getStatements(); ​ @SubTagList(\"select\") List&lt;Select> getSelects(); @SubTagList(\"insert\") List&lt;Insert> getInserts(); @SubTagList(\"update\") List&lt;Update> getUpdates(); @SubTagList(\"delete\") List&lt;Delete> getDeletes(); &amp;#125; 搜索文件比如想搜索项目中的所有 xml 文件，上面使用 Mapper 接口定义了 Mapper.xml 的结构，就可以利用 DomService 搜索所有的 Mapper.xml： // 当前项目的所有元素 mapper, 分别填入类型, 作用域 GlobalSearchScope List&lt;DomFileElement&lt;Mapper>> fileElements = DomService.getInstance().getFileElements(Mapper.class, project, GlobalSearchScope.allScope(project)); 写入文件需要调用WriteCommandAction进行异步写入. WriteCommandAction.runWriteCommandAction(project, () -> &amp;#123; doGenerate(psiClass, jsonObject); &amp;#125;); 通知在操作成功之后，在 IDEA 右下角通知用户，使用 NotificationGroup 类即可。 // 静态属性 private static final NotificationGroup NOTIFICATION_GROUP = new NotificationGroup(\"Java2Json.NotificationGroup\", NotificationDisplayType.BALLOON, true); public void actionPerformed(@NotNull AnActionEvent e) &amp;#123; // 在方法中调用 Notification success = NOTIFICATION_GROUP.createNotification(message, NotificationType.INFORMATION); Notifications.Bus.notify(success, project); &amp;#125; 也可以定义为工具类，如下 /** * * 进行消息通知工具类 * * @author liuzhihang * @date 2020/2/28 18:52 */ public class NotificationUtils &amp;#123; private static NotificationGroup notificationGroup = new NotificationGroup(\"ApiDoc.NotificationGroup\", NotificationDisplayType.BALLOON, true); public static void warnNotify(String message, Project project) &amp;#123; Notifications.Bus.notify(notificationGroup.createNotification(message, NotificationType.WARNING), project); &amp;#125; public static void infoNotify(String message, Project project) &amp;#123; Notifications.Bus.notify(notificationGroup.createNotification(message, NotificationType.INFORMATION), project); &amp;#125; public static void errorNotify(String message, Project project) &amp;#123; Notifications.Bus.notify(notificationGroup.createNotification(message, NotificationType.ERROR), project); &amp;#125; &amp;#125; 总结基本上常用的就是这些了，也可以查找官方文档，官方文档现在还是比较全面的，地址在相关资料中。也可以 Clone Toolkit 这个插件源码，源码中有一些注释。在其他优秀的插件中，同样可有相关使用方法。 相关资料 Toolkit: https://github.com/liuzhihangs/toolkit copy-as-json: https://github.com/liuzhihangs/copy-as-json IntelliJ Platform SDK: https://jetbrains.org/intellij/sdk/docs/intro/welcome.html","categories":[{"name":"IDEA","slug":"IDEA","permalink":"https://liuzhihang.com/categories/IDEA/"}],"tags":[{"name":"plugin","slug":"plugin","permalink":"https://liuzhihang.com/tags/plugin/"}]},{"title":"【工具册】- IDEA 插件找不到？看这里！那就自己敲一个！","slug":"plugin/IDEA插件开发","date":"2020-07-29T05:00:00.000Z","updated":"2020-09-12T17:22:04.200Z","comments":true,"path":"2020/07/29/tool-book-copy-as-json.html","link":"","permalink":"https://liuzhihang.com/2020/07/29/tool-book-copy-as-json.html","excerpt":"","text":"前言 大家都经常使用 IDEA 进行开发，肯定会使用一些 IDEA 插件，我之前也写过两个插件，不过已经很久没有更新了，就让它先放着吧！ 那小伙伴你是否想亲手写一个插件，或者你是否有一些插件的想法，但是找不到插件。那就自己实现一个吧！ 公众号：liuzhihangs，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 创建项目使用 Gradle 创建写插件，先从创建项目开始： File -&gt; New -&gt; Project... 这里使用 Gradle，其中 Java 已经默认选中，咱们再额外选择 IntelliJ Platform Plugin。 点击 Next ，然后填写项目名称，路径等选项。 项目结构 build.gradle 为项目配置文件。resources/META-INF/plugin.xml 为插件配置文件。 使用 GitHub 模版 访问 https://github.com/JetBrains/intellij-platform-plugin-template 点击 Use this template 创建模版。 Clone 项目到自己本地。 注：模版生成的项目是使用的 Kotlin，所以这里使用的第一种方式创建。 开始开发修改 build.gradle 配置文件原内容如下： 修改后： plugins &amp;#123; id 'java' id 'org.jetbrains.intellij' version '0.4.15' &amp;#125; group 'com.liuzhihang.toolkit' version '1.0.2' sourceCompatibility = 1.8 repositories &amp;#123; mavenLocal() maven &amp;#123; url \"https://maven.aliyun.com/repository/public\" &amp;#125; mavenCentral() jcenter() &amp;#125; dependencies &amp;#123; testCompile group: 'junit', name: 'junit', version: '4.12' &amp;#125; // See https://github.com/JetBrains/gradle-intellij-plugin/ intellij &amp;#123; version '2019.1.1' pluginName 'Copy as Json' updateSinceUntilBuild false sameSinceUntilBuild false &amp;#125; patchPluginXml &amp;#123; pluginDescription(file(descriptionFile).text) changeNotes(file(changesFile).text) &amp;#125; 修改 repositories 使用阿里云 修改 patchPluginXml 使用外置文件 在根目录下创建 parts 路径，并创建 changeNotes.html、pluginDescription.html 修改 resources/META-INF/plugin.xml 插件信息原内容如下： 修改后： &lt;idea-plugin> &lt;id>com.liuzhihang.toolkit.copyasjson&lt;/id> &lt;name>Copy as Json&lt;/name> &lt;vendor email=\"liuzhihangs@qq.com\" url=\"https://liuzhihang.com\">Liu ZhiHang&lt;/vendor> &lt;description>&lt;![CDATA[ Description will be added by gradle build]]>&lt;/description> &lt;!-- please see http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started/plugin_compatibility.html on how to target different products --> &lt;depends>com.intellij.modules.java&lt;/depends> &lt;idea-version since-build=\"181.00\"/> &lt;extensions defaultExtensionNs=\"com.intellij\"> &lt;!-- Add your extensions here --> &lt;/extensions> &lt;actions> &lt;/actions> &lt;/idea-plugin> plugin.xml 说明：https://jetbrains.org/intellij/sdk/docs/basics/plugin_structure/plugin_configuration_file.html 创建 Action 先在 main 下 创建 java 目录，及包路径。 New -&gt; Plugin DevKit -&gt; Action 设置 Action 的 id 、Class Name 、 description 、 group 及快捷键等 这时候会发现在 plugin.xml 也插入了 action。 &lt;actions> &lt;action id=\"Toolkit.Json.CopyAsJsonAction\" class=\"com.liuzhihang.toolkit.action.CopyAsJsonAction\" text=\"CopyAsJsonAction\" description=\"Copy As Json\"> &lt;add-to-group group-id=\"EditorTabsGroup\" anchor=\"first\"/> &lt;keyboard-shortcut keymap=\"$default\" first-keystroke=\"shift meta J\"/> &lt;/action> &lt;/actions> 到这里已经结构完全创建完毕了，下面将演示插件 copy-as-json 的内部逻辑。当然这块也可以直接跳过，阅读源码即可。 源码地址：文末相关资料或公众号发送 copy-as-json 获取。 插件效果：将 JavaBean 复制为 Json 字符串。 开发笔记首先需要知道一些常用的 API，常用 API 可以阅读官方文档或者关注公众号后面会推送，这里仅介绍一些在这里用到的。 打开 CopyAsJsonAction 该类继承并需要实现 actionPerformed 方法。在 actionPerformed 方法中可以通过以下三个方法获取到项目相关信息： // 获取项目 Project project = e.getData(PlatformDataKeys.PROJECT); // 获取Psi文件 PsiFile psiFile = e.getData(CommonDataKeys.PSI_FILE); // 获取当前编辑的文件 Editor editor = e.getData(CommonDataKeys.EDITOR); 获取到当前编辑的文件 @Nullable public static PsiClass getTargetClass(@NotNull Editor editor, @NotNull PsiFile file) &amp;#123; int offset = editor.getCaretModel().getOffset(); PsiElement element = file.findElementAt(offset); if (element != null) &amp;#123; // 当前类 PsiClass target = PsiTreeUtil.getParentOfType(element, PsiClass.class); return target instanceof SyntheticElement ? null : target; &amp;#125; return null; &amp;#125; 从当前编辑的文件里面获取到字段 将当前编辑的 JavaBean 中的字段提取，并转换为 Map。 Map&lt;String, Object> fieldsMap = getFields(selectedClass); getFields 方法篇幅较长，请参考源码。 将字段转化成 Json 字符串，并格式化 使用 Gson 将 Map 转换为 Json 字符串，并格式化。其中格式化自定义了缩进。 见代码：com.liuzhihang.toolkit.utils.GsonFormatUtil Gson gson = new GsonBuilder().create(); String json = GsonFormatUtil.gsonFormat(gson, fieldsMap); // 使用自定义缩进格式 String json = new GsonBuilder().setPrettyPrinting().create().toJson(fieldsMap); StringSelection selection = new StringSelection(json); 将 Json 字符串拷贝到剪贴板 StringSelection selection = new StringSelection(json); Clipboard clipboard = Toolkit.getDefaultToolkit().getSystemClipboard(); clipboard.setContents(selection, selection); 发出提示 success String message = \"Convert \" + selectedClass.getName() + \" to JSON success, copied to clipboard.\"; Notification success = NOTIFICATION_GROUP.createNotification(message, NotificationType.INFORMATION); Notifications.Bus.notify(success, project); 测试运行右侧 Gradle -&gt; 选择 intellij -&gt; 点击 runlde 打包右侧 Gradle -&gt; 选择 intellij -&gt; 点击 buildPlugin 此时在项目路径下会生成插件，把这个插件包发给小兄弟安装使用就行了。 上传到 IDEA 插件库访问 https://plugins.jetbrains.com/ 创建账号，将插件包上传到仓库即可。当然也有其他的方式，这块就没有研究了。 总结通过上面的方式已经简单开发一个插件了，要问这个插件有什么用？ 其实就是在写文档，或者接口调用的时候，直接将 Java Bean 复制为 Json 串，省过一个一个敲，然后手写 Json 了。 相关资料[1] IntelliJ Platform SDK DevGuide：https://jetbrains.org/intellij/sdk/docs/intro/intellij_platform.html[2] JetBrains Plugins Repository：https://plugins.jetbrains.com/[3] Toolkit： https://github.com/liuzhihangs/toolkit[4] copy-as-json：https://github.com/liuzhihangs/copy-as-json[5] copy-as-json 插件地址：https://plugins.jetbrains.com/plugin/13606-copy-as-json","categories":[{"name":"工具册","slug":"工具册","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E5%85%B7%E5%86%8C/"},{"name":"IDEA","slug":"工具册/IDEA","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E5%85%B7%E5%86%8C/IDEA/"}],"tags":[{"name":"工具册","slug":"工具册","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E5%85%B7%E5%86%8C/"},{"name":"IDEA","slug":"IDEA","permalink":"https://liuzhihang.com/tags/IDEA/"},{"name":"plugin","slug":"plugin","permalink":"https://liuzhihang.com/tags/plugin/"}]},{"title":"【JDK源码笔记】- 快进来！花几分钟看一下 ReentrantReadWriteLock 的原理！","slug":"source-code/java/ReentrantReadWriteLock","date":"2020-07-27T15:50:00.000Z","updated":"2020-09-12T17:22:04.133Z","comments":true,"path":"2020/07/27/source-code-reentrant-read-write-lock.html","link":"","permalink":"https://liuzhihang.com/2020/07/27/source-code-reentrant-read-write-lock.html","excerpt":"","text":"前言 在看完 ReentrantLock 之后，在高并发场景下 ReentrantLock 已经足够使用，但是因为 ReentrantLock 是独占锁，同时只有一个线程可以获取该锁，而很多应用场景都是读多写少，这时候使用 ReentrantLock 就不太合适了。读多写少的场景该如何使用？在 JUC 包下同样提供了读写锁 ReentrantReadWriteLock 来应对读多写少的场景。 介绍支持类似 ReentrantLock 语义的 ReadWriteLock 的实现。 具有以下属性： 获取顺序 此类不会将读取优先或写入优先强加给锁访问的排序。但是，它确实支持可选的公平 策略。 支持公平模式和非公平模式，默认为非公平模式。 重入 允许 reader 和 writer 按照 ReentrantLock 的样式重新获取读锁或写锁。在写线程释放持有的所有写锁后，reader 才允许重入使用它们。此外，writer 可以获取读锁，但反过来则不成立。 锁降级 重入还允许从写锁降级为读锁，通过先获取写锁，然后获取读锁，最后释放写锁的方式降级。但是，从读锁升级到写锁是不可能的。 锁获取的中断 读锁和写锁都支持锁获取期间的中断。 Condition 支持 写锁提供了一个 Condition 实现，对于写锁来说，该实现的方式与 ReentrantLock.newCondition() 提供的 Condition 实现对 ReentrantLock 所做的行为相同。当然，此 Condition 只能用于写锁。读锁不支持 Condition。 监测 此类支持一些确定是保持锁还是争用锁的方法。这些方法设计用于监视系统状态，而不是同步控制。 锁最多支持 65535 个递归写锁和 65535 个读锁 以上为 Java Api 官方文档[1] 的解释，总结一下内容如下： 支持非公平和公平模式，默认为非公平模式。 支持重入，读锁可以重入获取读锁，写锁可以重入获取写锁，写锁可以获取读锁，读锁不可以获取写锁。 锁可以降级，从写锁降级为读锁，但是不可能从读锁升级到写锁。 基本使用class CachedData &amp;#123; Object data; volatile boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() &amp;#123; // 读锁加锁 rwl.readLock().lock(); if (!cacheValid) &amp;#123; // 获取写锁之前必须释放读锁 rwl.readLock().unlock(); // 写锁加锁 rwl.writeLock().lock(); try &amp;#123; // 重新检查状态，因为另一个线程可能 // 在执行操作之前获取了写锁定并更改了状态 if (!cacheValid) &amp;#123; data = ... cacheValid = true; &amp;#125; // 通过在释放写锁之前获取读锁来降级 rwl.readLock().lock(); &amp;#125; finally &amp;#123; rwl.writeLock().unlock(); // Unlock write, still hold read &amp;#125; &amp;#125; try &amp;#123; use(data); &amp;#125; finally &amp;#123; rwl.readLock().unlock(); &amp;#125; &amp;#125; &amp;#125; 上面只是官方文档提供的一个 demo。 问题疑问 在 ReentrantReadWriteLock 中 state 代表什么？ 线程获取锁的流程是怎么样的？ 读锁和写锁的可重入性是如何实现的？ 当前线程获取锁失败，被阻塞的后续操作是什么？ 锁降级是怎么降级的？ 源码分析代码结构 public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &amp;#123; private static final long serialVersionUID = -6992448646407690164L; /** 提供读锁的内部类 */ private final ReentrantReadWriteLock.ReadLock readerLock; /** 提供写锁的内部类 */ private final ReentrantReadWriteLock.WriteLock writerLock; /** 执行所有同步机制 */ final Sync sync; &amp;#125; state之前在阅读 ReentrantLock 源码的时候 state 代表了锁的状态，0 表示没有线程持有锁，大于 1 表示已经有线程持有锁及其重入的次数。而在 ReentrantReadWriteLock 是读写锁，那就需要保存读锁和写锁两种状态的，那是怎么样表示的呢？ 在 ReentrantReadWriteLock 中同样存在一个 Sync 继承了 AbstractQueuedSynchronizer，也是 FairSync、NonfairSync 的父类。内部定义了 state 的一些操作。 abstract static class Sync extends AbstractQueuedSynchronizer &amp;#123; private static final long serialVersionUID = 6317671515068378041L; // 移位数 static final int SHARED_SHIFT = 16; // 单位 static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT); // 最大数量 1 &lt;&lt; 16 -> 65536 static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1; // 计算独占数使用 1 &lt;&lt; 16 -> 65536 static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; // 返回共享保留数 static int sharedCount(int c) &amp;#123; return c >>> SHARED_SHIFT; &amp;#125; // 返回独占保留数 static int exclusiveCount(int c) &amp;#123; return c &amp; EXCLUSIVE_MASK; &amp;#125; &amp;#125; 在 AQS 中定义 state 为 int 类型，而在 ReentrantReadWriteLock 中，将 state 的 高 16 位和低 16 位拆开表示读写锁。其中高 16 位表示读锁，低 16 位表示写锁。分别使用 sharedCount 和 exclusiveCount 方法获取读锁和写锁的当前状态。 下面分别从读锁和写锁的角度来看如何进行加锁和释放锁的？ ReadLock.lock public static class ReadLock implements Lock, java.io.Serializable &amp;#123; /** * 获取读取锁。 * 如果写锁没有被另一个线程持有，则获取读锁并立即返回。 * 如果写锁由另一个线程持有，则出于线程调度目的， * 当前线程将被禁用，并处于休眠状态，直到获取读锁为止。 */ public void lock() &amp;#123; // 调用 AQS 获取共享资源 sync.acquireShared(1); &amp;#125; &amp;#125; 获取共享资源，这块使用的 AQS 的逻辑，其中 tryAcquireShared(arg) 是在 ReentrantReadWriteLock.Sync 中实现的。并且 AQS 中有规定，tryAcquireShared 分为三种返回值： 小于 0: 表示失败； 等于 0: 表示共享模式获取资源成功，但后续的节点不能以共享模式获取成功; 大于 0: 表示共享模式获取资源成功，后续节点在共享模式获取也可能会成功，在这种情况下，后续等待线程必须检查可用性。 abstract static class Sync extends AbstractQueuedSynchronizer &amp;#123; protected final int tryAcquireShared(int unused) &amp;#123; Thread current = Thread.currentThread(); // 获取 state 值 int c = getState(); // 独占计数不为 0 且 不是当前线程， 说明已经有写锁 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 获取共享计数（读锁计数） int r = sharedCount(c); // 不需要阻塞读锁 &amp;&amp; 共享计数小于最大值 &amp;&amp; state 更新成功 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &amp;#123; if (r == 0) &amp;#123; // 当前读锁计数为 0 // firstReader是获得读锁的第一个线程 // firstReaderHoldCount是firstReader的保持计数 firstReader = current; firstReaderHoldCount = 1; &amp;#125; else if (firstReader == current) &amp;#123; // 读锁重入 firstReaderHoldCount++; &amp;#125; else &amp;#123; // 当前缓存计数 HoldCounter rh = cachedHoldCounter; // 当前线程没有计数 或者 没有创建计数器 if (rh == null || rh.tid != getThreadId(current)) // 创建计数，基于 ThreadLocal cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); // 计数累加 rh.count++; &amp;#125; return 1; &amp;#125; // 完整地获取共享锁方法，作为tryAcquireShared方法因CAS获取锁失败后的处理。 // 因为前面可能失败 CAS 失败， 队列策略失败等原因。 return fullTryAcquireShared(current); &amp;#125; &amp;#125; 先获取 state ，通过 exclusiveCount 方法获取到写锁的计数值，不为 0 且 不是当前线程， 说明已经有写锁。返回 -1 失败。 通过 sharedCount 获取读锁计数，判断是否需要阻塞以及是否超过上限后，使用 CAS 更新 读锁计数。 设置或更新 firstReader、firstReaderHoldCount、 cachedHoldCounter。 最后会进行完整的获取共享锁方法，作为之前获取失败的后续处理方法。 firstReader：firstReader是获得读锁的第一个线程；firstReaderHoldCount：firstReaderHoldCount是firstReader的保持计数。即获得读锁的第一个线程的重入次数。cachedHoldCounter：最后一个获得读锁的线程获得读锁的重入次数。 final int fullTryAcquireShared(Thread current) &amp;#123; HoldCounter rh = null; // 无限循环 for (;;) &amp;#123; int c = getState(); // 是否有写锁 if (exclusiveCount(c) != 0) &amp;#123; // 有写锁，但是不是当前线程，直接返回失败 if (getExclusiveOwnerThread() != current) return -1; &amp;#125; else if (readerShouldBlock()) &amp;#123; // 需要阻塞 // 没有写锁，确保没有重新获取读锁 if (firstReader == current) &amp;#123; // assert firstReaderHoldCount > 0; &amp;#125; else &amp;#123; // 当前线程的读锁计数 ThreadLocal 中 if (rh == null) &amp;#123; rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &amp;#123; rh = readHolds.get(); // 计数结束，remove 掉 if (rh.count == 0) readHolds.remove(); &amp;#125; &amp;#125; // 为 0 直接失败 if (rh.count == 0) return -1; &amp;#125; &amp;#125; // 到达上限 抛出异常 if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // CAS 设置读锁 if (compareAndSetState(c, c + SHARED_UNIT)) &amp;#123; if (sharedCount(c) == 0) &amp;#123; firstReader = current; firstReaderHoldCount = 1; &amp;#125; else if (firstReader == current) &amp;#123; firstReaderHoldCount++; &amp;#125; else &amp;#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &amp;#125; return 1; &amp;#125; &amp;#125; &amp;#125; 首先会一直循环 有写锁，但是不是当前线程，直接返回失败。但是，有写锁，如果是当前线程，是会继续执行的。 设置或更新 firstReader、firstReaderHoldCount、 cachedHoldCounter。 当存在写锁（独占锁）时，方法会返回 -1 失败，后续会调用 AQS 的 doAcquireShared 方法，循环获取资源。doAcquireShared 方法会不断循环，尝试获取读锁，一旦获取到读锁，当前节点会立即唤醒后续节点，后续节点开始尝试获取读锁，依次传播。 ReadLock.unlockpublic static class ReadLock implements Lock, java.io.Serializable &amp;#123; public void unlock() &amp;#123; sync.releaseShared(1); &amp;#125; &amp;#125; 调用 AQS 的 releaseShared 释放共享资源方法。 其中 tryReleaseShared 有 ReadLock 实现。 protected final boolean tryReleaseShared(int unused) &amp;#123; Thread current = Thread.currentThread(); if (firstReader == current) &amp;#123; // 第一个线程是当前线程 if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; &amp;#125; else &amp;#123; // 第一个线程不是当前线程，更新自己的 ThreadLocal 里面的计数 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) &amp;#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &amp;#125; --rh.count; &amp;#125; // 循环 for (;;) &amp;#123; int c = getState(); int nextc = c - SHARED_UNIT; // 使用 CAS 更新 state if (compareAndSetState(c, nextc)) // 但是如果现在读和写锁都已释放， // 它可能允许等待的写程序继续进行。 return nextc == 0; &amp;#125; &amp;#125; 如果是第一个线程，直接更新技术，不是则更新自己 ThreadLocal 里面保存的计数。 循环，使用 CAS 更新 state 的值。 如果 state 更新后的值为 0，说明没有线程持有读锁或者写锁了。 当 state 为 0，此时会调用 AQS 的 doReleaseShared 方法。此时队列如果有写锁，那就会被写锁获取的锁。 WriteLock.lockpublic static class WriteLock implements Lock, java.io.Serializable &amp;#123; /** * 获取写入锁。 * 如果没有其他线程持有读锁或写锁，会直接返回，并将写锁计数设置为1。 * 如果当前线程持有写锁，则将写锁计数 +1，然后返回。 * 如果锁正在被其他线程持有，则当前线程用于线程调度目的， * 当前线程将被禁用，并处于休眠状态，直到获取读锁并将写锁计数设置为1。 */ public void lock() &amp;#123; sync.acquire(1); &amp;#125; &amp;#125; tryAcquire 方法由 Write 自己实现，方式和 ReentrantLock 类似。 protected final boolean tryAcquire(int acquires) &amp;#123; // 如果读锁计数为非零或写锁计数为非零，并且所有者是另一个线程，则失败。 // 如果计数饱和，则失败。只有在count不为零时，才可能发生这种情况。 // 否则，如果该线程是可重入获取或队列策略允许的话，则有资格进行锁定。 // 如果是这样，请更新状态并设置所有者。 Thread current = Thread.currentThread(); int c = getState(); // 写锁计数 int w = exclusiveCount(c); // c ！= 0 说明有有线程获取锁了 if (c != 0) &amp;#123; // (Note: if c != 0 and w == 0 then shared count != 0) // 判断是不是自己，不是自己 返回 false if (w == 0 || current != getExclusiveOwnerThread()) return false; // 判断有没有超过上限 if (w + exclusiveCount(acquires) > MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 重入 setState(c + acquires); return true; &amp;#125; // 不需要阻塞，或者 CAS 更新 state 失败 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; &amp;#125; 获取 state ， 如果 state 不为 0 则判断是否为当前线程重入获取。 state 为 0 ，则当前线程 CAS 更新 state，获取锁。 更新成功之后绑定当前线程。 如果失败会继续调用 AQS 的 acquireQueued，将当前阻塞放在 AQS 队列中。AQS 会不断循环，等待上一个锁释放后，尝试获得锁。 WriteLock.unlockpublic static class WriteLock implements Lock, java.io.Serializable &amp;#123; // 如果当前线程是此锁的持有者，则保持计数递减。 // 如果保持现在的计数为零，则解除锁定。 // 如果当前线程不是此锁的持有者则IllegalMonitorStateException异常。 public void unlock() &amp;#123; sync.release(1); &amp;#125; &amp;#125; 同样这块代码是使用 AQS 的逻辑，tryRelease 部分由 WriteLock 自己实现。 protected final boolean tryRelease(int releases) &amp;#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; if (free) setExclusiveOwnerThread(null); setState(nextc); return free; &amp;#125; 如果是当前线程重入，扣减重入次数。 扣减后如果为 0，则设置锁持有线程为 null，更新 state 值。AQS 会唤醒后续节点获取锁。 总结问题Q：在 ReentrantReadWriteLock 中 state 代表什么？ A：state 代表锁的状态。state 为 0 ，没有线程持有锁，state 的高 16 为代表读锁状态，低 16 为代表写锁状态。通过位运算可以获取读写锁的实际值。 Q：线程获取锁的流程是怎么样的？ A：可以参考上面的源码笔记，以及后面的流程图。 Q：读锁和写锁的可重入性是如何实现的？ A：在加锁的时候，判断是否为当前线程，如果是当前线程，则直接累加计数。值得注意的是：读锁重入计数使用的 ThreadLocal 在线程中缓存计数，而写锁则直接用的 state 进行累加（其实和 state 低 16 位进行累加一样）。 Q：当前线程获取锁失败，被阻塞的后续操作是什么？ A：获取失败，会放到 AQS 等待队列中，在队列中不断循环，监视前一个节点是否为 head ，是的话，会重新尝试获取锁。 Q：锁降级是怎么降级的？ A： 如图，在圈出部分 fullTryAcquireShared 代码中，可以看出来，在获取读锁的时候，如果当前线程持有写锁，是可以获取读锁的。这块就是指锁降级，比如线程 A 获取到了写锁，当线程 A 执行完毕时，它需要获取当前数据，假设不支持锁降级，就会导致 A 释放写锁，然后再次请求读锁。而在这中间是有可能被其他阻塞的线程获取到写锁的。从而导致线程 A 在一次执行过程中数据不一致。 小结 ReentrantReadWriteLock 读写锁，内部实现是 ReadLock 读锁 和 WriteLock 写锁。读锁，允许共享；写锁，是独占锁。 读写锁都支持重入，读锁的重入次数记录在线程维护的 ThreadLocal 中，写锁维护在 state 上（低 16 位）。 支持锁降级，从写锁降级为读锁，防止脏读。 ReadLock 和 WriteLock 都是通过 AQS 来实现的。获取锁失败后会放到 AQS 等待队列中，后续不断尝试获取锁。区别在读锁只有存在写锁的时候才放到等待队列，而写锁是只要存在非当前线程锁（无论写锁还是读锁）都会放到等待队列。 通过源码分析，可以得出读写锁适合在读多写少的场景中使用。 相关资料[1] Java Api：https://docs.oracle.com/javase/8/docs/api/overview-summary.html","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- 不能再被问住了！ReentrantLock 源码、画图一起看一看！","slug":"source-code/java/ReentrantLock","date":"2020-07-25T01:50:00.000Z","updated":"2020-09-12T17:22:04.221Z","comments":true,"path":"2020/07/25/source-code-reentrant-lock.html","link":"","permalink":"https://liuzhihang.com/2020/07/25/source-code-reentrant-lock.html","excerpt":"","text":"在阅读完 JUC 包下的 AQS 源码之后，其中有很多疑问，最大的疑问就是 state 究竟是什么含义？并且 AQS 主要定义了队列的出入，但是获取资源、释放资源都是交给子类实现的，那子类是怎么实现的呢？下面开始了解 ReentrantLock。 介绍一个可重入的互斥锁与隐式监视器锁synchronized具有相同的基本行为和语义，但功能更强大。 具有以下特征： 互斥性：同时只有一个线程可以获取到该锁，此时其他线程请求获取锁，会被阻塞，然后被放到该锁内部维护的一个 AQS 阻塞队列中。 可重入性：维护 state 变量，初始为 0，当一个线程获取到锁时，state 使用 cas 更新为 1，本线程再次申请获取锁，会对 state 进行 CAS 递增，重复获取次数即 state，最多为 2147483647 。试图超出此限制会从锁定方法抛出 Error。 公平/非公平性：在初始化时，可以通过构造器传参，指定是否为公平锁，还是非公平锁。当设置为 true 时，为公平锁，线程争用锁时，会倾向于等待时间最长的线程。 基本使用class X &amp;#123; private final ReentrantLock lock = new ReentrantLock(); // ... public void m() &amp;#123; lock.lock(); // block until condition holds try &amp;#123; // ... method body &amp;#125; finally &amp;#123; lock.unlock() &amp;#125; &amp;#125; &amp;#125; 问题疑问？首先在阅读本文时，对 AQS 有了一定的了解，如果不了解的话，可以看以下之前的文章。图文讲解 AQS 在 AQS 中介绍 state 时，说 state 含义由子类进行定义，那在 ReentrantLock 中 state 代表什么？ ReentrantLock 和 AQS 有什么关系？ 线程是如何获取到锁的？ 锁的可重入性是如何实现的？ 当前线程获取锁失败，被阻塞的后续操作是什么？ 公平锁和非公平锁是如何体现的？ 锁是如何释放的？ 将通过源码及画图的方式，围绕上面几个问题，展开阅读和分析。 源码分析基本结构 基本结构如图所示，ReentrantLock 类实现了接口 Lock，在接口 Lock 中定义了使用锁时的方法，方法及含义如下： public interface Lock &amp;#123; // 获取锁，如果没有获取到，会阻塞。 void lock(); // 获取锁，如果没有获取到，会阻塞。响应中断。 void lockInterruptibly() throws InterruptedException; // 尝试获取锁，如果获取到，返回 true，没有获取到 返回 false boolean tryLock(); // 尝试获取锁，没有有获取到，会等待指定时间，响应中断。 boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // 释放锁 void unlock(); &amp;#125; 而 ReentrantLock 也只是实现了 Lock 接口，并实现了这些方法，那 ReentrantLock 和 AQS 到底有什么关系呢？这就需要看内部具体如何实现的了。 通过上面类图可以看出，在 ReentrantLock 中含有两个内部类，分别是 NonfairSync FairSync 而它俩又实现了 抽象类 Sync，抽象类 Sync 继承了 AbstractQueuedSynchronizer 即 AQS。具体代码如下： public class ReentrantLock implements Lock, java.io.Serializable &amp;#123; private final Sync sync; // 锁的同步控制基础类。 子类具体到公平和非公平的版本。 使用AQS状态来表示持有该锁的数量。 abstract static class Sync extends AbstractQueuedSynchronizer &amp;#123; // 省略 ... &amp;#125; static final class NonfairSync extends Sync &amp;#123; // 非公平锁逻辑 省略 ... &amp;#125; static final class FairSync extends Sync &amp;#123; // 公平锁逻辑 省略 ... &amp;#125; // 默认非公平锁 public ReentrantLock() &amp;#123; sync = new NonfairSync(); &amp;#125; // 根据传参指定公平锁还是非公平锁，true 公平锁，false 非公平锁 public ReentrantLock(boolean fair) &amp;#123; sync = fair ? new FairSync() : new NonfairSync(); &amp;#125; &amp;#125; 通过上面代码可以看出： 锁的基本控制是由 NonfairSync 和 FairSync 进行控制的，而它俩的父类 Sync 继承了 AQS (AbstractQueuedSynchronizer)，这也就是说明 ReentrantLock 的实现和 AQS 是有关的。 NonfairSync 代表非公平锁实现逻辑，FairSync 代表公平锁实现逻辑。 构造器传参可以看出，初始化时，默认为 NonfairSync 非公平锁。也可以指定声明为公平锁或非公平锁，传参 true 为 公平锁，false 为非公平锁。 具体 ReentrantLock 和 AQS 的关系是怎样的，就需要通过加锁的过程来分析了。 lock 如图所示，默认声明非公平锁，lock 方法内部调用 sync.lock(); 此时应该是使用的非公平锁内部的 lock 加锁操作。 final void lock() &amp;#123; // 通过 CAS 设置 state 值 0 -> 1 if (compareAndSetState(0, 1)) // 设置成功当前线程获取到了锁 setExclusiveOwnerThread(Thread.currentThread()); else // 设置失败，则调用 AQS 的方法，尝试获取锁。 acquire(1); &amp;#125; 首先会 使用 CAS 更新 state 的值， 此时就会发现， state 在这里代表的锁的状态。 0 未加锁，1 加锁。 设置失败，会调用 AQS 的 acquire(1); 方法。 再看下 AQS 的 acquire 代码 public final void acquire(int arg) &amp;#123; // tryAcquire 尝试获取 state，获取失败则会加入到队列 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &amp;#125; 在之前分析 AQS 源码时，已经介绍 tryAcquire 是尝试获取 state 的值，AQS 中并不提供可用的方法，此处是由子类实现的。所以这块代码还是在 NonfairSync 类中自己实现的业务逻辑。 static final class NonfairSync extends Sync &amp;#123; // NonfairSync 实现 protected final boolean tryAcquire(int acquires) &amp;#123; // 调用父类的方法 return nonfairTryAcquire(acquires); &amp;#125; &amp;#125; abstract static class Sync extends AbstractQueuedSynchronizer &amp;#123; // NonfairSync 的父类 Sync 中有实现 // state 传参是 1 final boolean nonfairTryAcquire(int acquires) &amp;#123; // 获取当前线程 final Thread current = Thread.currentThread(); // 获取 state int c = getState(); // 如果 c 是 0 if (c == 0) &amp;#123; // 使用 cas 更新为 1 if (compareAndSetState(0, acquires)) &amp;#123; // 设置持有线程为当前 setExclusiveOwnerThread(current); return true; &amp;#125; &amp;#125; else if (current == getExclusiveOwnerThread()) &amp;#123; // 如果是当前线程持有 // 对 state 进行累加 int nextc = c + acquires; // 不允许超过 int 的最大值 2147483647 + 1 = -2147483648 if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); // 设置 state 的值 setState(nextc); return true; &amp;#125; return false; &amp;#125; &amp;#125; 当前线程加锁，直接使用 CAS 方式对 state 从 0 更新为 1，更新成功，则获得锁，更新失败，则获取失败。 更新失败后会调用 AQS 的 acquire(1); 方法， 此处传参为 1。 tryAcquire 再次尝试获取锁。 state 是 0，尝试获取。获取成功返回 true； state 不是 0，判断是否为当前线程持有，是当前线程持有则对 state 进行累加。 tryAcquire 获取锁失败，则走 AQS 的 acquireQueued 逻辑，创建节点，并加入到等待队列中。 流程画图如下： 初始为单个线程 此时其他线程来请求获取锁 加锁流程图 再来看下公平锁是如何体现的？static final class FairSync extends Sync &amp;#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &amp;#123; acquire(1); &amp;#125; protected final boolean tryAcquire(int acquires) &amp;#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &amp;#123; // 判断有无节点排队 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &amp;#123; setExclusiveOwnerThread(current); return true; &amp;#125; &amp;#125; else if (current == getExclusiveOwnerThread()) &amp;#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &amp;#125; return false; &amp;#125; &amp;#125; 拉出来代码比较一下： 可以看出在公平锁（FairSync）中多了一个判断条件 !hasQueuedPredecessors() hasQueuedPredecessors 方法在 AQS 中，如果有当前线程前面的线程排队返回true，如果当前线程是在队列的头部或队列为空，返回false。 代码如下： public final boolean hasQueuedPredecessors() &amp;#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &amp;#125; 如果当前加锁时已经有节点在排队，那就去节点尾部排队，否则才会去抢占锁。 到这里基本上已经知道公平锁和非公平锁的区别了： 非公平锁：不管有没有节点在排队，都会试图去获取锁，如果获取失败，进入 acquire 方法，还是会试图获取一次，之后才会进入队列中。公平锁：已经有节点在排队，那就自己去节点后面排队。 tryLock public boolean tryLock() &amp;#123; return sync.nonfairTryAcquire(1); &amp;#125; 直接调用的 Sync 中的 nonfairTryAcquire， 尝试获取锁，获取失败，就返回 false，获取到锁或者是当前线程持有锁则对 state 累加后都返回 true。 unlockpublic void unlock() &amp;#123; sync.release(1); &amp;#125; 发现 unlock 直接调用的 AQS 的 release 方法，进行释放资源。 public final boolean release(int arg) &amp;#123; if (tryRelease(arg)) &amp;#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &amp;#125; return false; &amp;#125; 这块在 AQS 中有介绍，也说明 tryRelease 由子类进行实现，现在在 ReentrantLock 重点关注 tryRelease 的实现。 // 释放资源，传入值为 1 protected final boolean tryRelease(int releases) &amp;#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &amp;#123; free = true; setExclusiveOwnerThread(null); &amp;#125; setState(c); return free; &amp;#125; 获取当前的 state 进行 -1 操作； 判断了下当前线程是否为持有线程； 如果释放完之后 state 为 0 ，则设置持有线程为 null； 更新并返回 state 的值。 总结通过上面的源码及画图，基本上对开始的问题已经有了答案： Q：在 AQS 中介绍 state 时，说 state 含义由子类进行定义，那在 ReentrantLock 中 state 代表什么？A：在 ReentrantLock 中 state 代表加锁状态，0 没有线程获得锁，大于等于 1 已经有线程获得锁，大于 1 说明该获得锁的线程多次重入。 Q：ReentrantLock 和 AQS 有什么关系？A：ReentrantLock 内部基于 AQS 实现，无论是锁状态，还是进入等待队列，锁释放等都是基于 AQS 实现。ReentrantLock 的公平锁和非公平锁都是 NonfairSync、FairSync 来实现的，而他们的父类 Sync 继承了 AQS。 Q：线程是如何获取到锁的？A：线程通过修改 state 字段的状态来获取到锁。 Q：锁的可重入性是如何实现的？A：当前线程发现 state 不是 0 ，则说明有锁已经被获取了，此时会判断当前获取到锁的线程是不是自己，如果是，则对 state 进行累加。 Q：当前线程获取锁失败，被阻塞的后续操作是什么？A：获取失败，会放到 AQS 等待队列中，在队列中不断循环，监视前一个节点是否为 head ，是的话，会重新尝试获取锁。 Q：公平锁和非公平锁是如何体现的？A：公平锁主要体现在如果当前队列中已经有排队的线程了，则自己直接排在后面。非公平锁是不管当前队列都没有线程排队，都会直接尝试修改 state 获取锁。 Q：锁是如何释放的？A：锁释放资源，即将 state 进行 -1 操作，如果 -1 后 state 为 0，则释放节点，后续节点尝试获取锁。此处可以看 AQS 相关逻辑。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【工作笔记】- 老大说新项目的结构和 xxx 项目一样就可以了，我 ……","slug":"work/archetype","date":"2020-07-18T05:00:00.000Z","updated":"2020-09-12T17:22:04.217Z","comments":true,"path":"2020/07/18/work-archetype.html","link":"","permalink":"https://liuzhihang.com/2020/07/18/work-archetype.html","excerpt":"","text":"又要开发新项目了，还是创建新项目，怎么办？老大说按照 xxx 项目的结构创建一个新项目就可以了。 在工作中经常有新项目需要创建，此时就会有三种常用的方式 CC 大法 新建项目，然后找到之前的各种工具类，复制粘贴进来，此时还不一定能跑起来，然后再进行各种调试。 CD 大法 复制老项目，然后改 module 名字，依赖名字，删除老代码，当然也不一定能跑起来，此时再进行各种调试。 当然，这里肯定不是使用这两种办法，下面咱们介绍一种更简洁的方式，使用 maven archetype 生成项目模版，一键创建项目。 Action！！！ 什么是 Archetype ？简而言之，Archetype 是 Maven 项目模板工具箱。 An archetype is defined as an original pattern or model from which all other things of the same kind are made. 原型被定义为原始样式或模型，从中可以制成所有其他同类项目。 官方解释，简洁明了，就是使用已有的项目，生成一个模版。以后使用这个模版就可以快速生成结构相同的项目了。在团队开发中很有用。 其实就是官方解释，地址贴上来：http://maven.apache.org/archetype/maven-archetype-plugin/index.html 下面使用 IDEA 作为演示工具，一步一步开始介绍。 准备模版项目这里还是要有一个模版项目，比如这样： 这是一个多 module 项目，一个简单的 demo 使用了 nacos 作为注册中心； fegin 作为调用工具； 有通用校验 token 工具类； 假设里面也有一些公司的公共配置（MQ，链路监控，统一日志等）。 当然这个项目是可以跑起来的。新创建的项目也是这个模版。 进入主题使用命令**archetype:generate ** 这样是基于当前项目生成，你也可以使用官网的用法分别指定参数 mvn archetype:generate 然后一步一步按照提示输入； 一次性输入，其中 DarchetypeGroupId 、DarchetypeArtifactId 、DarchetypeVersion 为生成的 Archetype 项目的组织版本。 mvn archetype:generate \\ -DarchetypeGroupId=&lt;archetype-groupId> \\ -DarchetypeArtifactId=&lt;archetype-artifactId> \\ -DarchetypeVersion=&lt;archetype-version> \\ -DgroupId=&lt;my.groupid> \\ -DartifactId=&lt;my-artifactId> 高级用法 mvn clean archetype:create-from-project 执行图示如下： 执行后返回 IDEA 查看项目，在 target/generated-sources 目录下的 archetype 即生成的项目模版。 结构如图所示： main/resources/archetype-resources：项目的模版，生成新项目，就是根据这块的代码进行生成的。 .idea 无用，删除掉。 __rootArtifactId__xxx 项目的各个 module main/resources/META-INF/maven/archetype-metadata.xml：模版工程的元数据配置。 可以把 archetype 拷出去，这是一个单独的工程模版，拷出去之后，使用 IDEA 打开。 下面开始介绍 archetype 里面都有什么。 archetype 模版项目介绍使用 IDEA 打开之后发现，还是一个 Maven 项目。 archetype-resources 打开 pom 文件，可以看到里面 $&#123;groupId&#125; 、 $&#123;artifactId&#125; 、$&#123;version&#125; 使用占位符指定的组织版本，这些就是新创建项目时指定的。 archetype-metadata.xmlarchetype-metadata.xml 里面为元数据配置。 fileSet：用来生成一些项目中的文件。如果文件或目录名称包含 __property__ 模式，则将其替换为相应的属性值。 属性 类型 描述 filtered boolean 过滤文集，将指定文件直接复制不需要修改。默认值为：false。 packaged boolean 打包文件，指定文件将在package属性之前的目录结构中生成/复制。它们可以是非打包的，这意味着所选文件将在没有该前缀的情况下生成/复制。默认值为：false。 encoding String 过滤内容时使用的编码。 fileSet 包含以下元素： 元素 类型 描述 directory String 生成项目文件的目录 includes/include* List 包含文件 excludes/exclude* List 排除文件 因为生成项目不需要 .idea *.iml 文件，所以直接删除： module 就是要生成的项目一共几个 module 属性 类型 描述 id String The module’s artifactId. dir String The module’s directory. name String The module’s name. 元素 类型 描述 fileSets/fileSet* List 文件 modules/module* List 模块 可以看出里面就是自己的项目模版。 __rootArtifactId__-controller 在生成的时候，就会根据传入的 artifactId 生成指定的 module 名字。 使用 clean install IDEA Add Archetype 选择使用 Archetype 生成新项目 填写新生成项目的名字等 生成新项目 扩展Q: 如何自定义包路径？ A: 可以使用 requiredProperties 自定义参数。通过传入自定义的参数，来生成自定的包路径。 比如发现新生成项目的包路径都是 com.liuzhihang.archetype，这样肯定是不行的，每个项目有每个项目自己的包路径。只需要做以下修改： 将 requiredProperties 添加到项目中，然后添加新变量 middlePackage。 &lt;requiredProperties> &lt;!--使用archetype时候必须要求输入的参数--> &lt;requiredProperty key=\"groupId\"> &lt;!--可以设置默认值，使用archetype会使用默认值--> &lt;defaultValue>com.liuzhihang&lt;/defaultValue> &lt;/requiredProperty> &lt;requiredProperty key=\"package\"> &lt;defaultValue>com.liuzhihang&lt;/defaultValue> &lt;/requiredProperty> &lt;requiredProperty key=\"middlePackage\"> &lt;defaultValue>$&amp;#123;rootArtifactId&amp;#125;&lt;/defaultValue> &lt;/requiredProperty> &lt;/requiredProperties> 修改模版的文件名 如果文件或目录名称包含 __property__ 模式，则将其替换为相应的属性值。到这里还不行，因为生成的包名还没改。 修改内部文件的包路径。包括 .java 、** .xml** 、** .properties** 等。 重新 clean install 注：此时可能会报错，需要在 src/test/resources/projects/basic/archetype.properties 下添加 middlePackage=basic 再重新尝试下。 在生成时注意指定 middlePackage 属性。 Q: 我想自定义 Application 的名字怎么弄？ A: 同样使用 requiredProperties 自定义参数。 &lt;requiredProperty key=\"appName\"> &lt;/requiredProperty> 当然也可以起一个通用的名字。 Q: 别的小伙伴怎么用？ A: 当然是 deploy 到私服了， 在 pom 里面添加如下配置，指定自己公司的私服。deploy ，这样就可以和小伙伴一起愉快的使用啦。 &lt;!-- 远程仓库 --> &lt;distributionManagement> &lt;repository> &lt;id>releases&lt;/id> &lt;name>Nexus Release Repository&lt;/name> &lt;url>http://liuzhihang.com:xxxx/repository/maven-releases/&lt;/url> &lt;/repository> &lt;snapshotRepository> &lt;id>snapshots&lt;/id> &lt;name>Nexus Snapshot Repository&lt;/name> &lt;url>http://liuzhihang.com:xxxx/repository/maven-snapshots/&lt;/url> &lt;/snapshotRepository> &lt;/distributionManagement> Q: 我要怎么从 IDEA 删除 Archetype ​？ A: 这么好用怎么舍得删除​呢？只要找到以下路径 liuzhihang % > pwd /Users/liuzhihang/Library/Caches/JetBrains/IntelliJIdea2020.1/Maven/Indices 里面有一个 UserArchetypes.xml​， 打开，删除掉里面的 archetype 就行。 补充Maven Archetype 文档：http://maven.apache.org/archetype/maven-archetype-plugin/index.html 代码地址：https://github.com/liuzhihangs/archetype-demo","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"Archetype","slug":"工作笔记/Archetype","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/Archetype/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"Archetype","slug":"Archetype","permalink":"https://liuzhihang.com/tags/Archetype/"}]},{"title":"【JDK源码笔记】- 别走！这里有个笔记：图文讲解 AQS ，一起看看 AQS 的源码……(图文较长)","slug":"source-code/java/AQS","date":"2020-07-12T05:00:00.000Z","updated":"2020-09-12T17:22:04.170Z","comments":true,"path":"2020/07/12/source-code-aqs.html","link":"","permalink":"https://liuzhihang.com/2020/07/12/source-code-aqs.html","excerpt":"","text":"AbstractQueuedSynchronizer 抽象队列同步器，简称 AQS 。是在 JUC 包下面一个非常重要的基础组件，JUC 包下面的并发锁 ReentrantLock CountDownLatch 等都是基于 AQS 实现的。所以想进一步研究锁的底层原理，非常有必要先了解 AQS 的原理。 介绍先看下 AQS 的类图结构，以及源码注释，有一定的大概了解之后再从源码入手，一步一步研究它的底层原理。 “ 源码注释 提供了实现阻塞锁和相关同步器依靠先入先出（FIFO）等待队列（信号量，事件等）的框架。 此类中设计了一个对大多数基于 AQS 的同步器有用的原子变量来表示状态（state）。 子类必须定义 protected 方法来修改这个 state，并且定义 state 值在对象中的具体含义是 acquired 或 released。 考虑到这些，在这个类中的其他方法可以实现所有排队和阻塞机制。 子类可以保持其他状态字段，但只能使用方法 getState 、setState 和 compareAndSetState 以原子方式更新 state 。 子类应被定义为用于实现其封闭类的同步性能的非公共内部辅助类。 类AbstractQueuedSynchronizer没有实现任何同步接口。 相反，它定义了一些方法，如 acquireInterruptibly 可以通过具体的锁和相关同步器来调用适当履行其公共方法。 此类支持独占模式和共享模式。 在独占模式下，其他线程不能获取成功，共享模式下可以（但不一定）获取成功。 此类不“理解”，在机械意义上这些不同的是，当共享模式获取成功，则下一个等待的线程（如果存在）也必须确定它是否能够获取。 线程在不同模式下的等待共享相同的FIFO队列。 通常情况下，实现子类只支持其中一种模式，但同时使用两种模式也可以，例如ReadWriteLock 。 仅共享模式不需要定义支持未使用的模式的方法的子类。 这个类中定义了嵌套类 AbstractQueuedSynchronizer.ConditionObject ，可用于作为一个 Condition 由子类实现，并使用 isHeldExclusively 方法说明当前线程是否以独占方式进行，release()、 getState() acquire() 方法用于操作 state 原子变量。 此类提供检查和监视内部队列的方法，以及类似方法的条件对象。 根据需要进使用以用于它们的同步机制。 要使用这个类用作同步的基础上，需要重新定义以下方法，如使用，通过检查和或修改 getState 、setState 或 compareAndSetState 方法： tryAcquiretryReleasetryAcquireSharedtryReleaseSharedisHeldExclusively “ 通过上面的注释可以得出大概的印象： 内部依靠先入先出（FIFO） 等待队列。 存在 state 表示状态信息。state 值只能用 getState 、setState 和 compareAndSetState 方法以原子方式更新。 支持独占模式和共享模式，但具体需要子类实现具体支持哪种模式。 嵌套 AbstractQueuedSynchronizer.ConditionObject 可以作为 Condition 由子类实现。 子类需要重新定义 tryAcquire、tryRelease、tryAcquireShared、tryReleaseShared、isHeldExclusively 方法。 队列节点 Node Node节点，包含以下元素： 元素 含义 prev 上一个节点 next 下一个节点 thread 持有线程 waitStatus 节点状态 nextWaiter 下一个处于 CONDITION 状态的节点 组合成等待队列则如下： 下面是等待队列节点的 Node 属性： static final class Node &amp;#123; // 节点正在共享模式下等待的标记 static final Node SHARED = new Node(); // 指示节点正在以独占模式等待的标记 static final Node EXCLUSIVE = null; // 指示线程已取消 static final int CANCELLED = 1; // 指示后续线程需要唤醒 static final int SIGNAL = -1; // 指示线程正在等待条件 static final int CONDITION = -2; // 指示下一次acquireShared应该无条件传播 static final int PROPAGATE = -3; /** * 状态字段，仅使用以下值 * SIGNAL -1 ：当前节点释放或者取消时，必须 unpark 他的后续节点。 * CANCELLED 1 ：由于超时（timeout）或中断（interrupt），该节点被取消。节点永远不会离开此状态。特别是，具有取消节点的线程永远不会再次阻塞。 * CONDITION -2 ：该节点目前在条件队列。 但它不会被用作同步队列节点，直到转移，转移时的状态将被设置为 0 。 * PROPAGATE -3 ：releaseShared 应该被传播到其他节点。 * 0：都不是 * 值以数字表示以简化使用，大多数时候可以检查符号（是否大于0）以简化使用 */ volatile int waitStatus; // 上一个节点 volatile Node prev; // 下一个节点 volatile Node next; // 节点持有线程 volatile Thread thread; // 链接下一个等待条件节点，或特殊值共享 Node nextWaiter; // 节点是否处于 共享状态 是， 返回 true final boolean isShared() &amp;#123; return nextWaiter == SHARED; &amp;#125; // 返回前一个节点， 使用时 前一个节点不能为空 final Node predecessor() throws NullPointerException &amp;#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &amp;#125; Node() &amp;#123; // Used to establish initial head or SHARED marker &amp;#125; Node(Thread thread, Node mode) &amp;#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &amp;#125; Node(Thread thread, int waitStatus) &amp;#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &amp;#125; &amp;#125; 在 Node 节点中需要重点关注 waitStatus 默认状态为 0； waitStatus &gt; 0 (CANCELLED 1) 说明该节点超时或者中断了，需要从队列中移除； waitStatus = -1 SIGNAL 当前线程的前一个节点的状态为 SIGNAL，则当前线程需要阻塞（unpark）； waitStatus = -2 CONDITION -2 ：该节点目前在条件队列； waitStatus = -3 PROPAGATE -3 ：releaseShared 应该被传播到其他节点，在共享锁模式下使用。 了解完 Node 的结构之后，再了解下 AQS 结构，并从常用方法入手，逐步了解具体实现逻辑。 AbstractQueuedSynchronizerpublic abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &amp;#123; // 等待队列的头，延迟初始化。 除了初始化，它是仅经由方法setHead修改。 注意：如果头存在，其waitStatus保证不会是 CANCELLED 状态 private transient volatile Node head; // 等待队列的尾部，延迟初始化。 仅在修改通过方法ENQ添加新节点等待。 private transient volatile Node tail; // 同步状态 private volatile int state; // 获取状态 protected final int getState() &amp;#123; return state; &amp;#125; // 设置状态值 protected final void setState(int newState) &amp;#123; state = newState; &amp;#125; // 原子更新状态值 protected final boolean compareAndSetState(int expect, int update) &amp;#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &amp;#125; &amp;#125; 在 AQS 中主要参数为： 参数 含义 head 等待队列头 tail 等待队列尾 state 同步状态 通过注释了解到，在 AQS 里主要分为两种操作模式，分别是：独占模式、共享模式，下面分别从两个不同的角度去分析源码。 操作 含义 acquire 以独占模式获取，忽略中断。 通过调用至少一次实施tryAcquire ，在成功时返回。 否则，线程排队，可能重复查封和解封，调用tryAcquire直到成功为止。 这种方法可以用来实现方法Lock.lock 。 release 以独占模式释放。 通过疏通一个或多个线程，如果实现tryRelease返回true。 这种方法可以用来实现方法Lock.unlock 。 acquireShared 获取在共享模式下，忽略中断。 通过至少一次第一调用实现tryAcquireShared ，在成功时返回。 否则，线程排队，可能重复查封和解封，调用tryAcquireShared直到成功为止。 releaseShared 以共享模式释放。 通过疏通一个或多个线程，如果实现tryReleaseShared返回true。 无论是共享模式还是独占模式在这里面都会用到 addWaiter 方法，将当前线程及模式创建排队节点。 独占模式获取独占资源 acquire public final void acquire(int arg) &amp;#123; // tryAcquire 尝试获取 state，获取失败则会加入到队列 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &amp;#125; 在独占模式下会尝试获取 state，当获取失败时会调用 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)。 tryAcquire(arg)，尝试获取 state 这块由子类自己实现，不同的子类逻辑不同，这块在介绍子类代码时会说明。 获取 state 失败后，会进行 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，这块代码可以拆分为两块：addWaiter(Node.EXCLUSIVE)，acquireQueued(node, arg)。 addWaiter(Node.EXCLUSIVE) 返回的是当前新创建的节点。 acquireQueued(node, arg) 线程获取锁失败，使用 addWaiter(Node.EXCLUSIVE) 放入等待队列，而 acquireQueued(node, arg) 使用循环，不断的为队列中的节点去尝试获取资源，直到获取成功或者被中断。 总结获取资源主要分为三步： 尝试获取资源 入队列 出队列 尝试获取资源 tryAcquire(arg)，由子类实现，那下面则着手分别分析 入队列、出队列。 入队列：addWaiter(Node.EXCLUSIVE)使用 addWaiter(Node.EXCLUSIVE) 方法将节点插入到队列中，步骤如下： 根据传入的模式创建节点 判断尾节点是否存在，不存在则需要使用 enq(node) 方法初始化节点，存在则直接尝试插入尾部。 尝试插入尾部时使用 CAS 插入，防止并发情况，如果插入失败，会调用 enq(node) 自旋直到插入。 private Node addWaiter(Node mode) &amp;#123; Node node = new Node(Thread.currentThread(), mode); // 定位到队列末尾的 node Node pred = tail; if (pred != null) &amp;#123; // 新节点的上一个节点 指向尾节点 node.prev = pred; // 使用 CAS 设置尾节点，tail 如果等于 pred 则更新为 node if (compareAndSetTail(pred, node)) &amp;#123; // 更新成功则将 pred 的下一个节点指向 node pred.next = node; return node; &amp;#125; &amp;#125; // 尾节点没有初始化，或竞争失败，自旋 enq(node); return node; &amp;#125; /** * tailOffset 也就是成员变量 tail 的值 * 此处相当于：比较 tail 的值和 expect 的值是否相等， 相等则更新为 update */ private final boolean compareAndSetTail(Node expect, Node update) &amp;#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update); &amp;#125; private final boolean compareAndSetHead(Node update) &amp;#123; return unsafe.compareAndSwapObject(this, headOffset, null, update); &amp;#125; private Node enq(final Node node) &amp;#123; for (;;) &amp;#123; Node t = tail; // 尾节点为空 需要初始化头节点，此时头尾节点是一个 if (t == null) &amp;#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &amp;#125; else &amp;#123; // 不为空 循环赋值 node.prev = t; if (compareAndSetTail(t, node)) &amp;#123; t.next = node; return t; &amp;#125; &amp;#125; &amp;#125; &amp;#125; 看完代码和注释肯定还是有点模糊，现在用图一步一步进行说明。 因为根据初始尾节点是否为空分为两种情况，这里使用两幅图： 第一幅为第一次添加节点，此时 head 会延迟初始化； 第二幅图为已经存在队列，进行插入节点； 注意看代码，enq 方法返回的是之前的尾节点； addWaiter 方法 返回的是当前插入的新创建的节点。 节点添加到队列之后，返回当前节点，而下一步则需要调用方法 acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 不断的去获取资源。 出队列：acquireQueued(addWaiter(Node.EXCLUSIVE), arg)方法会通过循环不断尝试获取拿到资源，直到成功。代码如下： final boolean acquireQueued(final Node node, int arg) &amp;#123; // 是否拿到资源 boolean failed = true; try &amp;#123; // 中断状态 boolean interrupted = false; // 无限循环 for (;;) &amp;#123; // 当前节点之前的节点 final Node p = node.predecessor(); // 前一个节点是头节点， 说明当前节点是 头节点的 next 即真实的第一个数据节点 （因为 head 是虚拟节点） // 然后再尝试获取资源 if (p == head &amp;&amp; tryAcquire(arg)) &amp;#123; // 获取成功之后 将头指针指向当前节点 setHead(node); p.next = null; // help GC failed = false; return interrupted; &amp;#125; // p 不是头节点， 或者 头节点未能获取到资源 （非公平情况下被别的节点抢占） // 判断 node 是否要被阻塞， if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &amp;#125; &amp;#125; finally &amp;#123; if (failed) cancelAcquire(node); &amp;#125; &amp;#125; 不断获取本节点的上一个节点是否为 head，因为 head 是虚拟节点，如果当前节点的上一个节点是 head 节点，则当前节点为 第一个数据节点； 第一个数据节点不断的去获取资源，获取成功，则将 head 指向当前节点； 当前节点不是头节点，或者 tryAcquire(arg) 失败（失败可能是非公平锁）。这时候需要判断前一个节点状态决定当前节点是否要被阻塞（前一个节点状态是否为 SIGNAL）。 /** * 根据上一个节点的状态，判断当前线程是否应该被阻塞 * SIGNAL -1 ：当前节点释放或者取消时，必须 unpark 他的后续节点。 * CANCELLED 1 ：由于超时（timeout）或中断（interrupt），该节点被取消。节点永远不会离开此状态。特别是，具有取消节点的线程永远不会再次阻塞。 * CONDITION -2 ：该节点目前在条件队列。 但它不会被用作同步队列节点，直到转移，转移时的状态将被设置为 0 。 * PROPAGATE -3 ：releaseShared 应该被传播到其他节点。 * 0：都不是 * */ private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &amp;#123; // 前一个节点的等待状态 int ws = pred.waitStatus; // 前一个节点需要 unpark 后续节点 if (ws == Node.SIGNAL) return true; // 当前节点处于取消状态 if (ws > 0) &amp;#123; do &amp;#123; // 将取消的节点从队列中移除 node.prev = pred = pred.prev; &amp;#125; while (pred.waitStatus > 0); pred.next = node; &amp;#125; else &amp;#123; // 设置前一个节点为 SIGNAL 状态 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &amp;#125; return false; &amp;#125; 在 shouldParkAfterFailedAcquire 方法中，会判断前一个节点的状态，同时取消在队列中当前节点前面无效的节点。 再继续阅读 出队列 acquireQueued 方法，发现有一个 finally 会判断状态后执行 cancelAcquire(node); ，也就是上面流程图中下面的红色方块。 cancelAcquire(Node node) final boolean acquireQueued(final Node node, int arg) &amp;#123; // 是否拿到资源 boolean failed = true; try &amp;#123; // 省略 // 在 finally 会将当前节点置为取消状态 &amp;#125; finally &amp;#123; if (failed) cancelAcquire(node); &amp;#125; &amp;#125; private void cancelAcquire(Node node) &amp;#123; // 节点不存在 直接返回 if (node == null) return; // 取消节点关联线程 node.thread = null; //跳过已经取消的节点，获取当前节点之前的有效节点 Node pred = node.prev; while (pred.waitStatus > 0) node.prev = pred = pred.prev; // 获取当前节点之前的有效节点的下一个节点 Node predNext = pred.next; // 当前节点设置为取消 node.waitStatus = Node.CANCELLED; // 当前节点如果是尾节点，则将最后一个有效节点设置为尾节点，并将 predNext 设置为空 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &amp;#123; compareAndSetNext(pred, predNext, null); &amp;#125; else &amp;#123; int ws; // pred 不是头节点(node 的上一个有效节点 不是 head) &amp;&amp; （ pred的状态是 SIGNAL || pred 的状态设置为 SIGNAL 成功 ） &amp;&amp; pred 的绑定线程不为空 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &amp;#123; // 当前节点的后继节点 Node next = node.next; // 后继节点不为空 且 状态有效 将 pred 的 后继节点设置为 当前节点的后继节点 if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &amp;#125; else &amp;#123; // node 的上一个有效节点 是 head， 或者其他情况 唤醒当前节点的下一个有效节点 unparkSuccessor(node); &amp;#125; node.next = node; // help GC &amp;#125; &amp;#125; private void unparkSuccessor(Node node) &amp;#123; // 判断当前节点状态 int ws = node.waitStatus; if (ws &lt; 0) // 将节点状态更新为 0 compareAndSetWaitStatus(node, ws, 0); // 下一个节点， 一般是下一个节点应该就是需要唤醒的节点，即颁发证书。 Node s = node.next; // 大于 0 CANCELLED ： 线程已取消 // 但是有可能 后继节点 为空或者被取消了。 if (s == null || s.waitStatus > 0) &amp;#123; s = null; // 从尾节点开始遍历，直到定位到 t.waitStatus &lt;= 0 的节点 // 定位到后并不会停止，会继续执行，相当于找到最开始的那个需要唤醒的节点 // t.waitStatus &lt;= 0 ： SIGNAL（ -1 后续线程需要释放） // CONDITION （ -2 线程正在等待条件） // PROPAGATE （ -3 releaseShared 应该被传播到其他节点） for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &amp;#125; // 定位到需要唤醒的节点后 进行 unpark if (s != null) LockSupport.unpark(s.thread); &amp;#125; 流程分析： 找到当前节点的前一个非无效节点 pred； 当前节点如果是尾节点，则将最后一个有效节点设置为尾节点，并将 predNext 设置为空； pred 不是头节点 &amp;&amp; （ pred的状态是 SIGNAL || pred 的状态设置为 SIGNAL 成功 ） &amp;&amp; pred 的绑定线程不为空； 其他情况。 下面分别画图： Q: 通过图可以看出来，只操作了 next 指针，但是没有操作 prev 指针，这是为什么呢？ A: 在 出队列：acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 方法中，shouldParkAfterFailedAcquire 方法会判断前一个节点的状态，同时取消在队列中当前节点前面无效的节点。这时候会移除之前的无效节点，此处也是为了防止指向一个已经被移除的节点。同时保证 prev 的稳定，有利于从 tail 开始遍历列表，这块在 unparkSuccessor(node); 中也可以看到是从后往前表里列表。 Q: unparkSuccessor(Node node) 为什么从后往前遍历？ A: 在 addWaiter(Node.EXCLUSIVE) 插入新节点时，使用的是 尾插法，看红框部分，此时有可能还未指向next。 Q: node.next = node; 这块导致 head不是指向最新节点，链表不就断了么？A： acquireQueued 方法介绍中，里面有个循环，会不断尝试获取资源，成功之后会设置为 head。并且在 shouldParkAfterFailedAcquire 中也会清除当前节点前的无效节点。 释放独占资源 releasepublic final boolean release(int arg) &amp;#123; if (tryRelease(arg)) &amp;#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &amp;#125; return false; &amp;#125; 以独占模式释放。 通过释放一个或多个线程，如果实现tryRelease返回true。 这种方法可以用来实现方法Lock.unlock 。 tryRelease(arg) 操作释放资源，同样是由子类实现，后面介绍子类时会进行说明。返回 true 说明资源现在已经没有线程持有了，其他节点可以尝试获取； 释放成功，且 head != null &amp;&amp; h.waitStatus != 0, 会继续执行 unparkSuccessor(h)； 这块会看到 只要 tryRelease(arg) 操作释放资源成功， 后面无论执行是否成功，都会返回 true，unparkSuccessor(h) 相当于只是附加操作。 共享模式获取共享资源 acquireSharedpublic final void acquireShared(int arg) &amp;#123; // 小于 0 表示获取资源失败 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &amp;#125; private void doAcquireShared(int arg) &amp;#123; // 添加到节点 此处是共享节点 final Node node = addWaiter(Node.SHARED); // 根据是否拿到资源 判断是否需要取消 boolean failed = true; try &amp;#123; boolean interrupted = false; for (;;) &amp;#123; // 返回前一个节点 final Node p = node.predecessor(); if (p == head) &amp;#123; // 再次尝试获取共享资源 int r = tryAcquireShared(arg); // 表示获取成功 if (r >= 0) &amp;#123; // 设置当前节点为头节点 并尝试唤醒后续节点 setHeadAndPropagate(node, r); // 释放头节点 GC 会回收 p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &amp;#125; &amp;#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &amp;#125; &amp;#125; finally &amp;#123; if (failed) cancelAcquire(node); &amp;#125; &amp;#125; tryAcquireShared(arg)，尝试获取资源，这块由子类实现； 返回值分为 3 种： 小于 0: 表示失败； 等于 0: 表示共享模式获取资源成功，但后续的节点不能以共享模式获取成功; 大于 0: 表示共享模式获取资源成功，后续节点在共享模式获取也可能会成功，在这种情况下，后续等待线程必须检查可用性。 在失败后会使用 doAcquireShared(arg); 不断获取资源； final Node node = addWaiter(Node.SHARED); 同样会创建节点； 在循环中不断判断前一个节点如果是 head，则尝试获取资源； 在共享模式下获取到资源后会使用 setHeadAndPropagate(node, r); 设置头节点，同时唤醒后续节点。 设置头节点，并传播唤醒后续节点// node 是当前节点 // propagate 是 前一步 tryAcquireShared 的返回值 进来时 >=0 // 大于 0: 表示共享模式获取资源成功，后续节点在共享模式获取也可能会成功，在这种情况下，后续等待线程必须检查可用性。 private void setHeadAndPropagate(Node node, int propagate) &amp;#123; // 记录下当前头节点 Node h = head; // Record old head for check below // 设置传入 node 为头节点 setHead(node); // 判断条件，唤醒后续节点 // propagate > 0 有后续资源 // h == null 旧的头节点 因为前面 addWaiter， 肯定不会为空，应该是防止 h.waitStatus &lt; 0 空指针的写法 // (h = head) == null 当前的 头节点，再判断状态 // waitStatus &lt; 0 后续节点就需要被唤醒 if (propagate > 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &amp;#123; Node s = node.next; // 后续节点为共享，则需要唤醒 if (s == null || s.isShared()) doReleaseShared(); &amp;#125; &amp;#125; doReleaseShared() 释放共享资源 private void doReleaseShared() &amp;#123; // 循环 for (;;) &amp;#123; // 从头开始 Node h = head; // 判断队列是否为空，就是刚初始化 if (h != null &amp;&amp; h != tail) &amp;#123; int ws = h.waitStatus; // SIGNAL（ -1 后续线程需要释放） if (ws == Node.SIGNAL) &amp;#123; // 将等待状态更新为 0 如果失败，会循环 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 唤醒后续节点， 同时将当前节点设置为 取消 unparkSuccessor(h); &amp;#125; // 如果状态是 0 则会更新状态为 PROPAGATE // PROPAGATE （ -3 releaseShared 应该被传播到其他节点） else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &amp;#125; // 判断头节点有没有变化，有变化 是因为竞争，别的线程获取到了锁，会继续循环 // 没有变化直接结束 if (h == head) // loop if head changed break; &amp;#125; &amp;#125; 从头节点开始进行，如果 h != null &amp;&amp; h != tail 说明队列不是空或者刚初始化； 节点状态为 SIGNAL（ -1 ）说明后续线程需要释放； 会更改当前节点状态，成功后唤醒后续节点，失败则继续循环； 节点状态如果是 0 则更新为 PROPAGATE，会将状态传播。 释放共享资源 releaseSharedpublic final boolean releaseShared(int arg) &amp;#123; if (tryReleaseShared(arg)) &amp;#123; // 释放共享资源 doReleaseShared(); return true; &amp;#125; return false; &amp;#125; 以共享模式释放。 通过释放一个或多个线程，如果实现tryReleaseShared返回true。 总结Q: AQS 到底是什么？A: AQS 内部提供了一个先入先出（FIFO）双向等待队列，内部依靠 Node 实现，并提供了在独占模式和共享模式下的出入队列的公共方法。而关于状态信息 state 的定义是由子类实现。tryAcquire、tryRelease、tryAcquireShared、tryReleaseShared等尝试获取资源操作都是由子类进行定义和实现的。而 AQS 中提供了子类获取资源之后的相关操作，包括节点 Node 的出入队列，自旋获取资源等等。 Q: AQS 获取资源失败后会如何操作？A: 线程获取资源失败后，会放到等待队列中，在队列中会不断尝试获取资源（自旋），说明线程只是进入等待状态，后面还是可以再次获取资源的。 Q: AQS 等待队列的数据结构是什么？A: CLH变体的先入先出（FIFO）双向等待队列。（CLH锁是一个自旋锁。能确保无饥饿性。提供先来先服务的公平性。是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。） Q: AQS 等待队列中的节点如何获取获取和释放资源的？A: 可以看下独占模式中的讲述过程，通过代码梳理。 本文分别从 独占模式 和 共享模式介绍的 AQS 基本逻辑，并通过源码和作图理解基本思路。但是并没有对需要子类实现的业务逻辑做介绍。这块会在后面介绍 ReentrantLock、CountDownLatch 等子类的时候做介绍。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- JUC 包下工具类，它的名字叫 LockSupport ！你造么？","slug":"source-code/java/LockSupport","date":"2020-07-05T12:20:20.000Z","updated":"2020-09-12T17:22:04.137Z","comments":true,"path":"2020/07/05/source-code-locksupport.html","link":"","permalink":"https://liuzhihang.com/2020/07/05/source-code-locksupport.html","excerpt":"","text":"LockSupport 是 JUC 中常用的一个工具类，主要作用是挂起和唤醒线程。在阅读 JUC 源码中经常看到，所以很有必要了解一下。 介绍 基本线程阻塞原语创建锁和其他同步类。Basic thread blocking primitives for creating locks and other synchronization classes. LockSupport 类每个使用它的线程关联一个许可（在意义上的Semaphore类）。 如果许可可用，调用 park 将立即返回，并在此过程中消费它; 否则可能阻塞。如果许可不是可用，可以调用 unpark 使得许可可用。（但与Semaphore不同，许可不能累积。最多有一个。） 方法 park 和 unpark 提供了阻塞的有效手段和解锁线程不会遇到死锁问题，而 Thread.suspend 和 Thread.resume 是不能用于这种目的：因为许可的存在，一个线程调用 park 和另一个线程试图 unpark 它之间的竞争将保持活性。 此外，如果调用者线程被中断，park 将返回，并且支持设置超时。 该 park 方法也可能返回在其他任何时间，“毫无理由”，因此通常必须在一个循环中调用的返回后重新检查条件。 在这个意义上park作为“忙碌等待”不会浪费太多的时间自旋的优化，但必须以配对 unpark 使用。 这三种形式的 park 还支持 blocker 对象参数。而线程被阻塞时是允许使用监测和诊断工具，以确定线程被阻塞的原因。（诊断工具可以使用getBlocker(Thread) 方法 。）同时推荐使用带有 blocker 参数的 park方法，通常做法是 blocker 被设置为 this 。 上面的意思总结下来个人理解是： 许可（permit）的上限是1，也就是说只有 0 或 1 。 park: 没有许可的时候，permit 为 0 ，调用 park 会阻塞；有许可的时候，permit 为 1 ， 调用 park 会扣除一个许可，然后返回。 unpark：没有许可的时候，permit 为 0 ，调用 unpark 会增加一个许可，因为许可上限是 1 ， 所以调用多次也只会为 1 个。 线程初始的时候是没有许可的。 park 的当前线程如果被中断，会立即返回，并不会抛出中断异常。 park 方法的调用一般要放在一个循环判断体里面。 大概如图所示： 下面是源码注释中的案例： /** * FIFO 独占锁 */ class FIFOMutex &amp;#123; private final AtomicBoolean locked = new AtomicBoolean(false); private final Queue&lt;Thread> waiters = new ConcurrentLinkedQueue&lt;Thread>(); public void lock() &amp;#123; boolean wasInterrupted = false; Thread current = Thread.currentThread(); waiters.add(current); // Block while not first in queue or cannot acquire lock // 不在队列头，或者锁被占用，则阻塞， 就是只有队列头的可以获得锁 while (waiters.peek() != current || !locked.compareAndSet(false, true)) &amp;#123; LockSupport.park(this); if (Thread.interrupted()) // ignore interrupts while waiting wasInterrupted = true; &amp;#125; waiters.remove(); if (wasInterrupted) // reassert interrupt status on exit current.interrupt(); &amp;#125; public void unlock() &amp;#123; locked.set(false); LockSupport.unpark(waiters.peek()); &amp;#125; &amp;#125; 验证线程初始有没有许可？public class LockSupportTest &amp;#123; public static void main(String[] args) &amp;#123; System.out.println(\"开始执行……\"); LockSupport.park(); System.out.println(\"LockSupport park 之后……\"); &amp;#125; &amp;#125; 执行后会发现，代码在 park 处阻塞。说明，线程初始是没有许可的。 添加许可并消耗许可public class LockSupportTest &amp;#123; public static void main(String[] args) &amp;#123; System.out.println(\"开始执行……\"); LockSupport.unpark(Thread.currentThread()); System.out.println(\"执行 - park\"); LockSupport.park(); System.out.println(\"LockSupport park 之后……\"); &amp;#125; &amp;#125; public class LockSupportTest &amp;#123; public static void main(String[] args) throws InterruptedException &amp;#123; Thread thread = new Thread(new Runnable() &amp;#123; @Override public void run() &amp;#123; System.out.println(\"线程 \" + Thread.currentThread().getName() + \"开始执行 park\"); LockSupport.park(this); System.out.println(\"线程 \" + Thread.currentThread().getName() + \"执行 park 结束\"); &amp;#125; &amp;#125;); thread.start(); // 保证 上面线程先执行，然后再主线程 Thread.sleep(5000); System.out.println(\"开始执行 unpark(thread)\"); LockSupport.unpark(thread); Thread.sleep(5000); System.out.println(\"执行 unpark(thread) 结束\"); &amp;#125; &amp;#125; 通过上面示例可以看出： 执行 unpark 可以进行给予指定线程一个证书。 线程当前被 park 阻塞，此时给予证书之后， park 会消耗证书，然后继续执行。 许可上限为 1 public class LockSupportTest &amp;#123; public static void main(String[] args) &amp;#123; System.out.println(\"unpark 1次\"); LockSupport.unpark(Thread.currentThread()); System.out.println(\"unpark 2次\"); LockSupport.unpark(Thread.currentThread()); System.out.println(\"执行 - park 1 次\"); LockSupport.park(); System.out.println(\"执行 - park 2 次\"); LockSupport.park(); System.out.println(\"LockSupport park 之后……\"); &amp;#125; &amp;#125; 线程阻塞，可以看出 permit 只能有一个 中断可以使 park 继续执行并不会抛出异常public class LockSupportTest &amp;#123; public static void main(String[] args) &amp;#123; Thread thread = new Thread(new Runnable() &amp;#123; @Override public void run() &amp;#123; System.out.println(\"线程 \" + Thread.currentThread().getName() + \"开始执行 park\"); LockSupport.park(this); System.out.println(\"线程 \" + Thread.currentThread().getName() + \"执行 park 结束\"); System.out.println(\"线程 \" + Thread.currentThread().getName() + \"开始执行 park 第二次\"); LockSupport.park(this); System.out.println(\"线程 \" + Thread.currentThread().getName() + \"执行 park 第二次 结束\"); &amp;#125; &amp;#125;); try &amp;#123; thread.start(); // 保证 上面线程先执行，然后再主线程 Thread.sleep(5000); System.out.println(\"开始执行 unpark(thread)\"); // LockSupport.unpark(thread); thread.interrupt(); Thread.sleep(5000); System.out.println(\"执行 unpark(thread) 结束\"); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 输出结果： /Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home/bin/java ... 线程 Thread-0开始执行 park 开始执行 unpark(thread) 线程 Thread-0执行 park 结束 线程 Thread-0开始执行 park 第二次 线程 Thread-0执行 park 第二次 结束 执行 unpark(thread) 结束 可以看出线程中断，park 会继续执行，并且没有抛出异常。 thread.interrupt(); 调用之后， 设置线程中断标示，unpark 没有清除中断标示，第二个 park 也会继续执行。 使用诊断工具liuzhihang % > jps 76690 LockSupportTest 77130 Jps liuzhihang % > jstack 77265 ... \"main\" #1 prio=5 os_prio=31 tid=0x00007f7f3e80a000 nid=0xe03 waiting on condition [0x000070000dfcd000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304) at com.liuzhihang.source.LockSupportTest.main(LockSupportTest.java:14) 中间省略部分，但是可以看出线程进入 WAITING 状态 源码分析 public class LockSupport &amp;#123; private static final sun.misc.Unsafe UNSAFE; /** * 为线程 thread 设置一个许可 * 无许可，则添加一个许可，有许可，则不添加 * 如果线程因为 park 被阻塞， 添加许可之后，会解除阻塞状态 */ public static void unpark(Thread thread) &amp;#123; if (thread != null) UNSAFE.unpark(thread); &amp;#125; /** * 有许可，则使用该许可 * 没有许可，阻塞线程，直到获得许可 * 传递 blocker 是为了方便使用诊断工具 */ public static void park(Object blocker) &amp;#123; Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null); &amp;#125; /** * 设置线程的 blocker 属性 */ private static void setBlocker(Thread t, Object arg) &amp;#123; // Even though volatile, hotspot doesn't need a write barrier here. UNSAFE.putObject(t, parkBlockerOffset, arg); &amp;#125; &amp;#125; LockSupport 的 park unpark 方法，实际调用的是底层 Unsafe 类的 native 方法。 public final class Unsafe &amp;#123; public native void unpark(Object var1); public native void park(boolean var1, long var2); &amp;#125; 既然调用了 Unsafe 到此处肯定不能善罢甘休。 hotspot 源码这块是下载的官方包中的源码，阅读并查阅资料了解的大概逻辑，不清楚之处，希望指导出来。 也可以直接跳过直接看结论。 查看jdk源码http://hg.openjdk.java.net/jdk8u/jdk8u/hotspot/file/5a83b7215107/src/share/vm/runtime/park.hpp 这块在以 os_linux 代码为例http://hg.openjdk.java.net/jdk8u/jdk8u/hotspot/file/5a83b7215107/src/os/linux/vm/os_linux.cpp 在底层维护了一个 _counter 通过更新 _counter 的值来标示是否有证明。 在 park 时，判断 _counter 为 0，则阻塞等待，为 1 则获得更新为 0 并返回。 在 unpark 时，判断 _counter 为 0，则给予凭证，并唤醒线程，为 1 则直接返回。 总结总结也是和预想的是相同的。 许可（permit）的上限是1，也就是说只有 0 或 1 。 park: 没有许可的时候，permit 为 0 ，调用 park 会阻塞；有许可的时候，permit 为 1 ， 调用 park 会扣除一个许可，然后返回。 unpark：没有许可的时候，permit 为 0 ，调用 unpark 会增加一个许可，因为许可上限是 1 ， 所以调用多次也只会为 1 个。 线程初始的时候是没有许可的。 park 的当前线程如果被中断，会立即返回，并不会抛出中断异常。 扩展 park/unpark 和 wait/notify 区别 park 阻塞当前线程，unpark 唤醒指定线程。 wait() 需要结合锁使用，并释放锁资源，如果没有设置超时时间，则需要 notify() 唤醒。而 notify() 是随机唤醒线程。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- JDK 8 新增的 LongAdder，得过来看一下！","slug":"source-code/java/LongAddr","date":"2020-06-28T15:50:20.000Z","updated":"2020-09-12T17:22:04.161Z","comments":true,"path":"2020/06/28/source-code-longadder.html","link":"","permalink":"https://liuzhihang.com/2020/06/28/source-code-longadder.html","excerpt":"","text":"在介绍 AtomicInteger 时，已经说明在高并发下大量线程去竞争更新同一个原子变量时，因为只有一个线程能够更新成功，其他的线程在竞争失败后，只能一直循环，不断的进行 CAS 尝试，从而浪费了 CPU 资源。而在 JDK 8 中新增了 LongAdder 用来解决高并发下变量的原子操作。下面同样通过阅读源码来了解 LongAdder 。 介绍一个或多个变量共同维持初值为 0 总和。 当跨线程竞争更新时，变量集可以动态增长以减少竞争。 方法 sum 返回当前变量集的总和。 当多个线程更新时，这个类是通常优选 AtomicLong ，比如用于收集统计信息，不用于细粒度同步控制的共同总和。 在低更新竞争，这两个类具有相似的特征。 但在高更新竞争时，使用 LongAdder 性能要高于 AtomicLong，同样要消耗更高的空间为代价。 LongAdder 继承了 Striped64，内部维护一个 Cells 数组，相当于多个 Cell 变量， 每个 Cell 里面都有一个初始值为 0 的 long 型变量。 源码分析Cell 类Cell 类 是 Striped64 的静态内部类。 @sun.misc.Contended static final class Cell &amp;#123; volatile long value; Cell(long x) &amp;#123; value = x; &amp;#125; final boolean cas(long cmp, long val) &amp;#123; return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); &amp;#125; // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long valueOffset; static &amp;#123; try &amp;#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?> ak = Cell.class; valueOffset = UNSAFE.objectFieldOffset (ak.getDeclaredField(\"value\")); &amp;#125; catch (Exception e) &amp;#123; throw new Error(e); &amp;#125; &amp;#125; &amp;#125; Cell 使用 @sun.misc.Contended 注解。 内部维护一个被 volatile 修饰的 long 型 value 。 提供 cas 方法，更新value。 其中 @sun.misc.Contended 注解作用是为了减少缓存争用。什么是缓存争用，这里只做下简要介绍。 伪共享CPU 存在多级缓存，其中最小存储单元是 Cache Line，每个 Cache Line 能存储 64 个字节的数据。在多线程场景下，A B 两个线程数据如果被存储到同一个 Cache Line 上，此时 A B 更新各自的数据，就会发生缓存争用，导致多个线程之间相互牵制，变成了串行程序，降低了并发。@sun.misc.Contended 注解，则可以保证该变量独占一个 Cache Line。详细可参考：http://openjdk.java.net/jeps/142 Striped64 核心属性abstract class Striped64 extends Number &amp;#123; /** CPU 的数量，以限制表大小 */ static final int NCPU = Runtime.getRuntime().availableProcessors(); /** * cell 数组，当非空时，大小是 2 的幂。 */ transient volatile Cell[] cells; /** * Base 值，在无争用时使用，表初始化竞赛期间的后备。使用 CAS 更新 */ transient volatile long base; /** * 调整大小和创建Cells时自旋锁（通过CAS锁定）使用。 */ transient volatile int cellsBusy; &amp;#125; Striped64 类主要提供以下几个属性： NCPU：CPU 的数量，以限制表大小。 cells：Cell[] cell 数组，当非空时，大小是 2 的幂。 base：long 型，Base 值，在无争用时使用，表初始化竞赛期间的后备。使用 CAS 更新。 cellsBusy：调整大小和创建Cells时自旋锁（通过CAS锁定）使用。 下面看是进入核心逻辑： LongAdder#addpublic class LongAdder extends Striped64 implements Serializable &amp;#123; public void add(long x) &amp;#123; Cell[] as; long b, v; int m; Cell a; // cells 是 数组，base 是基础值 if ((as = cells) != null || !casBase(b = base, b + x)) &amp;#123; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) longAccumulate(x, null, uncontended); &amp;#125; &amp;#125; &amp;#125; abstract class Striped64 extends Number &amp;#123; // 使用 CAS 更新 BASE 的值 final boolean casBase(long cmp, long val) &amp;#123; return UNSAFE.compareAndSwapLong(this, BASE, cmp, val); &amp;#125; // 返回当前线程的探测值。 由于包装限制，从ThreadLocalRandom复制 static final int getProbe() &amp;#123; return UNSAFE.getInt(Thread.currentThread(), PROBE); &amp;#125; &amp;#125; 首先会对 Base 值进行 CAS 更新，当 Base 发生竞争时， 会更新数组内的 Cell 。 数组未初始化，Cell 未初始化， Cell 更新失败，即 Cell 也发生竞争时，会调用 Striped64 的 longAccumulate 方法。 Striped64#longAccumulate abstract class Striped64 extends Number &amp;#123; /** * x 要增加的值 * wasUncontended 有没有发生竞争 */ final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &amp;#123; int h; // 当前线程有无初始化线程探测值， 给当前线程生成一个 非 0 探测值 if ((h = getProbe()) == 0) &amp;#123; ThreadLocalRandom.current(); // force initialization h = getProbe(); wasUncontended = true; &amp;#125; boolean collide = false; // True if last slot nonempty // 循环 for (;;) &amp;#123; Cell[] as; Cell a; int n; long v; // 数组不为空切数组长度大于 0 if ((as = cells) != null &amp;&amp; (n = as.length) > 0) &amp;#123; // (n - 1) &amp; h 获取到索引，索引处 cell 是否为 null， cell未初始化 if ((a = as[(n - 1) &amp; h]) == null) &amp;#123; // 判断 cellsBusy 是否为 0 if (cellsBusy == 0) &amp;#123; // Try to attach new Cell Cell r = new Cell(x); // Optimistically create // cellsBusy == 0 且 使用 casCellsBusy 方法将其更新为 1，失败会继续循环 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &amp;#123; boolean created = false; try &amp;#123; // Recheck under lock Cell[] rs; int m, j; // 重新检查状态 并创建 if ((rs = cells) != null &amp;&amp; (m = rs.length) > 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &amp;#123; rs[j] = r; created = true; &amp;#125; &amp;#125; finally &amp;#123; // 创建完成之后， 改回 cellsBusy 值 cellsBusy = 0; &amp;#125; if (created) break; // 未创建继续循环 continue; // Slot is now non-empty &amp;#125; &amp;#125; collide = false; &amp;#125; // 传入的 wasUncontended 为 false 即发生碰撞了， 修改为未碰撞， 此处会继续循环，走到下一步，相当于会一直循环这个 cell else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash // cas 更新 cell 的 value， 成功则返回 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // 数组到最大长度 即大于等于 CPU 数量， 或者 cells 数组被改变， else if (n >= NCPU || cells != as) collide = false; // At max size or stale else if (!collide) collide = true; // 乐观锁 进行扩容 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &amp;#123; try &amp;#123; if (cells == as) &amp;#123; // Expand table unless stale Cell[] rs = new Cell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs; &amp;#125; &amp;#125; finally &amp;#123; cellsBusy = 0; &amp;#125; collide = false; continue; // Retry with expanded table &amp;#125; // 当前探针值不能操作成功，则重新设置一个进行尝试 h = advanceProbe(h); &amp;#125; // 没有加 cellsBusy 乐观锁 且 没有初始化，且获得锁成功（此时 cellsBusy == 1） else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &amp;#123; boolean init = false; try &amp;#123; // Initialize table if (cells == as) &amp;#123; Cell[] rs = new Cell[2]; rs[h &amp; 1] = new Cell(x); cells = rs; init = true; &amp;#125; &amp;#125; finally &amp;#123; cellsBusy = 0; &amp;#125; if (init) break; &amp;#125; // 尝试在base上累加 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // Fall back on using base &amp;#125; &amp;#125; &amp;#125; longAccumulate 方法一共有三种情况 (as = cells) != null &amp;&amp; (n = as.length) &gt; 0 数组不为空且长度大于 0 。 获取索引处的 cell ， cell 为空则进行初始化。 cell 不为空，使用 cas 更新， 成功 break; 跳出循环， 失败则还在循环内，会一直尝试。 collide 指是否发生冲突，冲突后会进行重试。 冲突后会尝试获得锁并进行扩容，扩容长度为原来的 2 倍，然后继续重试。 获得锁失败（说明其他线程在扩容）会重新进行计算探针值。 cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy() 数组为空，获得乐观锁成功。 直接初始化数组。 初始数组长度为 2 。 casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))) 获得乐观锁失败。 说明有其他线程在初始化数组，直接 CAS 更新 base 。 LongAdder#sum public class LongAdder extends Striped64 implements Serializable &amp;#123; public long sum() &amp;#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &amp;#123; for (int i = 0; i &lt; as.length; ++i) &amp;#123; if ((a = as[i]) != null) sum += a.value; &amp;#125; &amp;#125; return sum; &amp;#125; &amp;#125; 数组为空，说明没有发生竞争，直接返回 base 。 数组不为空，说明发生竞争，累加 cell 的 value 和 base 的和进行返回。 总结基本流程 LongAdder 继承了 Striped64，内部维护一个 Cells 数组，相当于多个 Cell 变量， 每个 Cell 里面都有一个初始值为 0 的 long 型变量。 未发生竞争时（Cells 数组未初始化），是对 base 变量进行原子操作。 发生竞争时，每个线程对自己的 Cell 变量的 value 进行原子操作。 如何确定哪个线程操作哪个 cell？通过 getProbe() 方法获取该线程的探测值，然后和数组长度 n - 1 做 &amp; 操作 (n - 1) &amp; h 。 static final int getProbe() &amp;#123; return UNSAFE.getInt(Thread.currentThread(), PROBE); &amp;#125; Cells 数组初始化及扩容？初始化扩容时会判断 cellsBusy， cellsBusy 使用 volatile 修饰，保证线程见可见性，同时使用 CAS 进行更新。 0 表示空闲，1 表示正在初始化或扩容。 初始化时会创建长度为 2 的 Cell 数组。扩容是创建一个长度是原数组长度 2 倍的新数组，并循环赋值。 如果线程访问分配的 Cell 元素有冲突后，会使用 advanceProbe() 方法重新获取探测值，再次进行尝试。 使用场景在高并发情况下，需要相对高的性能，同时数据准确性要求不高，可以考虑使用 LongAdder。 当要保证线程安全，并允许一定的性能损耗时，并对数据准确性要求较高，优先使用 AtomicLong。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- 请介绍下你了解的ThreadLocal，它的底层原理！","slug":"source-code/java/ThreadLocal","date":"2020-06-21T02:00:00.000Z","updated":"2020-09-12T17:22:04.141Z","comments":true,"path":"2020/06/21/source-code-threadlocal.html","link":"","permalink":"https://liuzhihang.com/2020/06/21/source-code-threadlocal.html","excerpt":"","text":"前言 业务开发中经常使用 ThreadLocal 来存储用户信息等线程私有对象… ThreadLocal 内部构造是什么样子的？为什么可以线程私有？常说的内存泄露又是怎么回事？ 公众号：liuzhihangs ，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍 ThreadLocal 类提供了线程局部变量。和正常对象不同的是，每个线程都可以访问 get()、set() 方法，获取独属于自己的副本。 ThreadLocal 实例通常是类中的私有静态字段，并且其状态和线程关联。每个线程都保持对其线程局部变量副本的隐式引用，只要线程是活动的并且 ThreadLocal 实例访问; 一个线程消失之后，所有的线程局部实例的副本都会被垃圾回收（除非存在对这些副本的其他引用）。 使用有这么一种使用场景，收到 web 请求，先进行 token 验证，而这个 token，可以解析出用户 user 的信息。所以我这边一般是这样使用的： 自定义注解， @CheckToken ， 标识该方法需要校验 token。 在 Interceptor（拦截器）中检查，如果方法有 @CheckToken 注解则校验 token。 从Header中获取 Authorization ，请求第三方或者自己的逻辑校验 token ，并解析成 user。 将user放到ThreadLocal中。 controller、service 在后续使用中， 如果需要 user 信息，可以直接从 ThreadLocal 中获取。 使用结束后进行remove。 代码如下： public class LocalUserUtils &amp;#123; /** * 用户信息保存至 ThreadLocal 中 */ private static final ThreadLocal&lt;User> USER_THREAD_LOCAL = new ThreadLocal&lt;>(); public static void set(User user) &amp;#123; USER_THREAD_LOCAL.set(user); &amp;#125; public static User get() &amp;#123; return USER_THREAD_LOCAL.get(); &amp;#125; public static void remove() &amp;#123; USER_THREAD_LOCAL.remove(); &amp;#125; &amp;#125; /** * 1. 加上注解 CheckToken * 只有方法， 类忽略 */ @CheckToken @PostMapping(\"/doXxx\") public Result&lt;Resp> doXxx(@RequestBody Req req) &amp;#123; Resp resp = xxxService.doXxx(req); return result.success(resp); &amp;#125; /** * 2. 3. 4. */ @Component public class TokenInterceptor implements HandlerInterceptor &amp;#123; @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception &amp;#123; LocalUserUtils.remove(); &amp;#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &amp;#123; // 请求方法是否存在注解 boolean assignableFrom = handler.getClass().isAssignableFrom(HandlerMethod.class); if (!assignableFrom) &amp;#123; return true; &amp;#125; CheckToken checkToken = null; if (handler instanceof HandlerMethod) &amp;#123; checkToken = ((HandlerMethod) handler).getMethodAnnotation(CheckToken.class); &amp;#125; // 没有加注解 直接放过 if (checkToken == null) &amp;#123; return true; &amp;#125; // 从Header中获取Authorization String authorization = request.getHeader(\"Authorization\"); log.info(\"header authorization : &amp;#123;&amp;#125;\", authorization); if (StringUtils.isBlank(authorization)) &amp;#123; log.error(\"从Header中获取Authorization失败\"); throw CustomExceptionEnum.NOT_HAVE_TOKEN.throwCustomException(); &amp;#125; User user = xxxUserService.checkAuthorization(authorization); // 放到 LocalUserUtils.set(user); return true; &amp;#125; &amp;#125; /** * 5. 使用 * 只有方法， 类忽略 */ @Override public Resp doXxx(Req req) &amp;#123; User user = LocalUserUtils.get(); // do something ... return resp; &amp;#125; 抛出问题 为什么可以线程私有？ 为什么建议声明为静态？ 为什么强制使用后必须remove？ 图 | 阿里巴巴 - Java开发手册（截图） 图 | 阿里巴巴 - Java开发手册（截图） 源码分析Thread public class Thread implements Runnable &amp;#123; // 省略 ... ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; // 省略 ... &amp;#125; 可以看出 Thread 对象中声明了 ThreadLocal.ThreadLocalMap 对象，每个线程都有自己的工作内存，每个线程都有自己的 ThreadLocal. ThreadLocalMap 对象，所以在线程之间是互相隔离的。 ThreadLocalThreadLocal则是一个泛型类，同时提供 set()、get()、remove() 等静态方法。 public class ThreadLocal&lt;T> &amp;#123; // 线程本地hashCode private final int threadLocalHashCode = nextHashCode(); // 获取此线程局部变量的当前线程副本中的值 public T get() &amp;#123;...&amp;#125; // 设置当前线程的此线程局部变量的复制到指定的值 public void set(T value) &amp;#123;...&amp;#125; // 删除当前线程的此线程局部变量的值 public void remove() &amp;#123;...&amp;#125; // ThreadLocalMap只是用来维持线程本地值的定制Map static class ThreadLocalMap &amp;#123;...&amp;#125; &amp;#125; set(T value)方法 public void set(T value) &amp;#123; // 获取当前线程 Thread t = Thread.currentThread(); // 获取当前线程的 threadLocals 属性 ThreadLocalMap map = getMap(t); if (map != null) // 存在则赋值 map.set(this, value); else // 不存在则直接创建 createMap(t, value); &amp;#125; // 根据线程获取当前线程的ThreadLocalMap ThreadLocalMap getMap(Thread t) &amp;#123; return t.threadLocals; &amp;#125; // 创建ThreadLocalMap 并赋值给当前线程的threadLocals字段 void createMap(Thread t, T firstValue) &amp;#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &amp;#125; 1.Thread.currentThread() 先获取到当前线程。2. 获取当前线程的 threadLocals 属性，即 ThreadLocalMap。3. 判断 Map 是否存在，存在则赋值，不存在则创建对象。 get()方法 public T get() &amp;#123; // 获取当前线程 Thread t = Thread.currentThread(); // 获取当前线程的 threadLocals 属性 ThreadLocalMap map = getMap(t); // map不为空 if (map != null) &amp;#123; // 根据当前ThreadLocal获取的ThreadLocalMap的Entry节点 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &amp;#123; // 获取节点的value 并返回 @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &amp;#125; &amp;#125; // 设置初始值并返回 （null） return setInitialValue(); &amp;#125; 1.Thread.currentThread() 先获取到当前线程。2. 获取当前线程的 threadLocals 属性，即 ThreadLocalMap 。3. 判断 Map 不为空，根据当前 ThreadLocal 对象获取 ThreadLocalMap.Entry 节点, 从节点中获取 value。4.ThreadLocalMap 为空或者 ThreadLocalMap.Entry 为空，则初始化 ThreadLocalMap 并返回。 remove()方法public void remove() &amp;#123; // 获取当前线程的ThreadLocalMap ThreadLocalMap m = getMap(Thread.currentThread()); // 不为空， 从ThreadLocalMap中移除该属性 if (m != null) m.remove(this); &amp;#125; 阅读 set()、get()、remove() 的源码之后发现后面其实是操作的 ThreadLocalMap, 主要还是操作的 ThreadLocalMap 的 set()、getEntry()、remove() 以及构造函数。下面看是看 ThreadLocalMap 的源码。 ThreadLocalMapstatic class ThreadLocalMap &amp;#123; /** * Entry节点继承WeakReference是弱引用 */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?>> &amp;#123; /** 与此ThreadLocal关联的值。 */ Object value; Entry(ThreadLocal&lt;?> k, Object v) &amp;#123; super(k); value = v; &amp;#125; &amp;#125; // 初始容量-必须是2的幂 private static final int INITIAL_CAPACITY = 16; // 表，根据需要调整大小. table.length必须始终为2的幂. private ThreadLocal.ThreadLocalMap.Entry[] table; // 表中的条目数。 private int size = 0; // 扩容阈值 private int threshold; // Default to 0 // 设置阀值为长度的 2/3 private void setThreshold(int len) &amp;#123; threshold = len * 2 / 3; &amp;#125; // 构造函数 ThreadLocalMap(ThreadLocal&lt;?> firstKey, Object firstValue) &amp;#123;...&amp;#125; // 根据ThreadLocal获取节点Entry private ThreadLocal.ThreadLocalMap.Entry getEntry(ThreadLocal&lt;?> key) &amp;#123;...&amp;#125; // set ThreadLocalMap的k-v private void set(ThreadLocal&lt;?> key, Object value) &amp;#123;...&amp;#125; // 移除当前值 private void remove(ThreadLocal&lt;?> key) &amp;#123;...&amp;#125; &amp;#125; Entry 继承了 WeakReference&lt;ThreadLocal&lt;?&gt; 也就意味着， Entry 节点的 key 是弱引用。 Entry 对象的key弱引用，指向的是 ThreadLocal 对象。 线程对象执行完毕，线程对象内实例属性会被回收，此时线程内 ThreadLocal 对象的引用被置为 null ，即 Entry 的 key 为 null, key 会被垃圾回收。 ThreadLocal 对象通常为私有静态变量， 生命周期不会至少不会随着线程技术而结束。 ThreadLocal 对象存在，并且 Entry的 key == null &amp;&amp; value != null ，这时就会造成内存泄漏。 小补充 强引用、软引用、弱引用、虚引用强引用（StrongReference）：最常见，直接 new Object(); 创建的即为强引用。当内存空间不足，Java虚拟机宁愿抛出 OOM，也不愿意随意回收具有强引用的对象来解决内存不足问题。 软引用（SoftReference）：内存足够，垃圾回收器不会回收软引用对象；内存不足时，垃圾回收器会回收。 弱引用（WeakReference）：垃圾回收器线程，发现就会回收。 虚引用（PhantomReference）：任何时候都有可能被垃圾回收，必须引用队列联合使用。 内存泄露：内存泄漏（Memory leak）是在计算机科学中，由于疏忽或错误造成程序未能释放已经不再使用的内存。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控制，从而造成了内存的浪费。 —— 维基百科 构造函数及hash计算ThreadLocalMap(ThreadLocal&lt;?> firstKey, Object firstValue) &amp;#123; // 初始化Entry数组， 长度为16 table = new Entry[INITIAL_CAPACITY]; // 获取key的hashCode，并计算出在数组中的索引， // 长度是 2的幂的情况下，取模 a % b == a &amp; (b - 1) int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); // 设置数组元素数 size = 1; // 设置扩容阈值 setThreshold(INITIAL_CAPACITY); &amp;#125; threadLocalHashCode 是 ThreadLocal 的静态属性，通过 nextHashCode 方法获取。 private final int threadLocalHashCode = nextHashCode(); // 被赋予了接下来的哈希码。 原子更新。 从零开始。 private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() &amp;#123; // 返回下一个hash码，通过步长 0x61c88647 累加生成，这块注释说明是最佳哈希值 return nextHashCode.getAndAdd(HASH_INCREMENT); &amp;#125; 初始化数组，长度16。 计算 key 的 hashCode，对2的幂取模。 设置元素，元素数及扩容阈值。 hashCode 通过步长 0x61c88647 累加生成， 并且使用了 AtomicInteger，保证原子性。 set()方法 private void set(ThreadLocal&lt;?> key, Object value) &amp;#123; Entry[] tab = table; int len = tab.length; // hashcode取模求数组索引 int i = key.threadLocalHashCode &amp; (len-1); // 获取数组中对应的位置， 重点关注 e = tab[i = nextIndex(i, len)] for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &amp;#123; // 获取key ThreadLocal&lt;?> k = e.get(); // key 存在则覆盖 if (k == key) &amp;#123; e.value = value; return; &amp;#125; // key 不存在则赋值 if (k == null) &amp;#123; replaceStaleEntry(key, value, i); return; &amp;#125; &amp;#125; // 此时 e == null 直接执创建节点 tab[i] = new Entry(key, value); int sz = ++size; // cleanSomeSlots 循环数组 查找全部key==null的Entry if (!cleanSomeSlots(i, sz) &amp;&amp; sz >= threshold) rehash(); &amp;#125; 获取循环 Entry 数组，获取 tab[i] 处的 e， e != null 继续循环 此时发现 e 的 key 不存在，并且不是 null （hash冲突了。） 那就通过 e = tab[i = nextIndex(i, len)]) 继续获取下一个 i，并获取新的 tab[i] 处的 e。 赋值替换值结束结束并返回。 e == null 结束循环。 // 下一个index，如果 i + 1 &lt; len 直接返回下一个位置 // 如果 i + 1 >= len 则返回 0， 从头开始。 private static int nextIndex(int i, int len) &amp;#123; return ((i + 1 &lt; len) ? i + 1 : 0); &amp;#125; private static int prevIndex(int i, int len) &amp;#123; return ((i - 1 >= 0) ? i - 1 : len - 1); &amp;#125; 这块利用环形设计，如果长度到达数组长度，则从开头开始继续查找。 int i = key.threadLocalHashCode &amp; (len-1); 求出索引，并不是从0开始的。 /** * staleSlot 为当前索引位置， 并且当前索引位置的 k == null */ private void replaceStaleEntry(ThreadLocal&lt;?> key, Object value, int staleSlot) &amp;#123; Entry[] tab = table; int len = tab.length; Entry e; // 需要清除的 entry 的索引 int slotToExpunge = staleSlot; // 循环获取到上一个 key==null 的节点及其索引，有可能还是自己 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // 继续上一层的循环，查找下一个 k == key 的节点索引 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &amp;#123; ThreadLocal&lt;?> k = e.get(); if (k == key) &amp;#123; // key 相等 则直接赋值 e.value = value; // 并且将 此处的 entry替换为 tab[staleSlot] tab[i] = tab[staleSlot]; tab[staleSlot] = e; // 如果发现要清除的 entry和传入的在一个位置上， 则直接赋值 if (slotToExpunge == staleSlot) slotToExpunge = i; // 清除掉过期的 expungeStaleEntry(slotToExpunge) 会清除 entry的value，将其设置为null并将其设置为null， 并返回下一个需要清除的entry的索引位置 // cleanSomeSlots 循环数组 查找全部key==null的Entry cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &amp;#125; // 如果向后扫描没有找到，并且已经到第初始传入的索引位置处了 if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &amp;#125; // 没找到， 直接将旧值 Entry 设置为 null 并指向新创建的Entry tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 结束之后发现要清楚的 key的索引 不等于当前传入的索引， 说明还有其他需要清除。 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &amp;#125; 这里存在三个属性 key， value，以及 staleSlot， staleSlot节点的 Entry != null 但是 k == null。 向前扫描获取到上一个 Entry != null 但是 k == null 的节点及其索引, 赋值给 slotToExpunge， 没有扫描到的话 slotToExpunge 还是等于 staleSlot。 向后扫描 Entry != null 的节点，因为在 set 方法中， 后面还有一段数组没有遍历。 发现 key 相等的Entry节点了， 直接赋值，然后清除其他 Entry != null 但是 k == null 的节点， 并返回。 没有找到key相等的节点，但是找到了下一个 Entry != null 但是 k == null， 且此时 slotToExpunge 未发生变化，还是指向 staleSlot， 则 i 赋值给 slotToExpunge。 向后扫描没有扫描到，则直接对当前节点（索引值为staleSlot）的节点的value设置为null，并指向新value。 结束之后发现 slotToExpunge 被改变了， 说明还有其他的要清除。 getEntry()方法 private Entry getEntry(ThreadLocal&lt;?> key) &amp;#123; // hashcode取模求数组索引 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) // 存在则返回 return e; else // 不存在 return getEntryAfterMiss(key, i, e); &amp;#125; private Entry getEntryAfterMiss(ThreadLocal&lt;?> key, int i, Entry e) &amp;#123; Entry[] tab = table; int len = tab.length; while (e != null) &amp;#123; ThreadLocal&lt;?> k = e.get(); if (k == key) return e; if (k == null) // key 已经 == null 了 清除一下 value expungeStaleEntry(i); else // 继续获取下一个 i = nextIndex(i, len); e = tab[i]; &amp;#125; return null; &amp;#125; hashcode 取模求数组索引。 索引处获取到 Entry 则直接返回。 获取不到或者获取到的 Entry key 不相等时，有可能是因为 hash 冲突，被放到别的地方， 调用 getEntryAfterMiss 方法。 getEntryAfterMiss 方法中。 e == null 返回null。 e != null 判断key， key相等返回 Entry， key == null， 那就需要清除这个节点，然后继续按照 nextIndex(i, len) 方法找下一个节点。 remove()方法 private void remove(ThreadLocal&lt;?> key) &amp;#123; Entry[] tab = table; int len = tab.length; // hashcode 取模求数组索引 int i = key.threadLocalHashCode &amp; (len-1); // 清除当前节点的value for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &amp;#123; if (e.get() == key) &amp;#123; // 清楚对象引用 e.clear(); // value 指向 null expungeStaleEntry(i); return; &amp;#125; &amp;#125; &amp;#125; public void clear() &amp;#123; this.referent = null; &amp;#125; hashcode 取模求数组索引。 循环查找数组，将当前 key 的 Entry 的引用，将 value 设置为 null， 后面会被垃圾回收掉。 总结为什么可以线程私有？ThreadLocal 的 get()、set()、remove()方法中都有 Thread t = Thread.currentThread(); 操作的其实是本线程，获取本线程的ThreadLocalMap。 每个线程都有自己的 ThreadLocal，并且是将 value 存放在一个以 ThreadLocal 为 key 的 ThreadLocalMap 中的。所以线程间隔离。 为什么建议声明为静态？Java开发手册已经给出说明，还有就是，如果 ThreadLocal 设置为非静态，那就是某个线程的实例类，这样的话就会失去了线程共享的本质属性。 为什么强制必须时候后remove()？这块可以和内存泄露一块说明， 通过上面的 ThreadLocalMap 处关于弱引用的讲解已经说明会产生内存泄露。至于如何解决也给出了答案： 1.set() 时清除 Entry != null &amp;&amp; key == null 的节点， 将其 value 设置为 null。2.getEntry() 时清除当前 key 到 nextIndex(i, len)==null 之间的 Entry != null &amp;&amp; key == null 的节点， 将其 value 设置为 null。3.remove() 时清除指定key的 Entry != null &amp;&amp; key == null 的节点， 将其 value 设置为 null。 之所以使用remove()，还是为了解决内存泄露的问题。 Last 使用时注意声明为 private static final。 使用后要 remove()。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- 从JUC源码看CAS，我做了个笔记 ......","slug":"source-code/java/CAS","date":"2020-06-12T15:50:20.000Z","updated":"2020-09-12T17:22:04.102Z","comments":true,"path":"2020/06/12/source-code-cas.html","link":"","permalink":"https://liuzhihang.com/2020/06/12/source-code-cas.html","excerpt":"","text":"前言JUC包下大量使用了CAS，工作和面试中也经常遇到CAS，包括说到乐观锁，也不可避免的想起CAS，那CAS究竟是什么？ 概念说到CAS，基本上都会想到乐观锁、AtomicInteger、Unsafe … 当然也有可能啥也没想到！ 不管你们怎么想， 我第一印象是乐观锁，毕竟做交易更新交易状态经常用到乐观锁，就自然想到这个SQL： update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0; 其实就是 set和where里面都携带order_status。 那什么是CAS？ CAS就是Compare-and-Swap，即比较并替换，在并发算法时常用，并且在JUC（java.util.concurrent）包下很多类都使用了CAS。 非常常见的问题就是多线程操作i++问题。一般解决办法就是添加 synchronized 关键字修饰，当然也可以使用 AtomicInteger 代码举例如下： public class CasTest &amp;#123; private static final CountDownLatch LATCH = new CountDownLatch(10); private static int NUM_I = 0; private static volatile int NUM_J = 0; private static final AtomicInteger NUM_K = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException &amp;#123; ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) &amp;#123; threadPool.execute(new Runnable() &amp;#123; public void run() &amp;#123; for (int j = 0; j &lt; 10000; j++) &amp;#123; NUM_I++; NUM_J++; NUM_K.incrementAndGet(); &amp;#125; LATCH.countDown(); &amp;#125; &amp;#125;); &amp;#125; LATCH.await(); System.out.println(\"NUM_I = \" + NUM_I); System.out.println(\"NUM_J = \" + NUM_J); System.out.println(\"NUM_K = \" + NUM_K.get()); threadPool.shutdown(); &amp;#125; &amp;#125; 下面就从AtomicInteger开始了解CAS。 源码分析public class AtomicInteger extends Number implements java.io.Serializable &amp;#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &amp;#123; try &amp;#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &amp;#125; catch (Exception ex) &amp;#123; throw new Error(ex); &amp;#125; &amp;#125; private volatile int value; public final int incrementAndGet() &amp;#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &amp;#125; public final int decrementAndGet() &amp;#123; return unsafe.getAndAddInt(this, valueOffset, -1) - 1; &amp;#125; &amp;#125; 可以看出里面使用了Unsafe类下的getAndAddInt方法，Unsafe类很多方法是本地（native）方法，主要是硬件级别的原子操作。 /** * @param var1 当前对象 * @param var2 当前对象在内存偏移量，Unsafe可以根据内存偏移地址获取数据 * @param var4 操作值 * @return */ public final int getAndAddInt(Object var1, long var2, int var4) &amp;#123; int var5; do &amp;#123; // 获取在var1在内存的值 var5 = this.getIntVolatile(var1, var2); // 将var1赋值为var5+var4， 赋值时会判断var1是否为var5 &amp;#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &amp;#125; // 原子操作 public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 至于 compareAndSwapInt 的分析就忽略了。 看完代码过程其实就是： 比较var1的值是否为var4，是的话将var1更新为var5。 如果不是的话就一直循环，直到var1是var4。 问题 这要是一直获取不到，岂不是一直循环。线程多的情况下，会自旋很长时间，导致浪费资源。 你更新了， 我又给你更新回去了，你也不知道。ABA问题！比如像这样，A想更新值为a，还未抢到资源，这时候B进行了更新，将对象更新为了b，然后又马上更新回了a， 这时候A是什么都不知道的。 以乐观锁举例： -- 0 -> 1 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0; -- 1 -> 0 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0; -- 0 -> 1 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0; 解决办法可以添加version进行版本号控制。 -- 0 -> 1 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0 and version = 0; -- 1 -> 0 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0 and version = 1; -- 0 -> 1 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0 and version = 0; 代码中可以看 AtomicStampedReference 类： /** * 以原子方式设置该引用和标志给定的更新值的值， * 如果当前引用==预期的引用，并且当前标志==预期标志。 * * @param expectedReference 预期引用 * @param newReference 更新的值 * @param expectedStamp 预期标志 * @param newStamp 更新的标志 * @return &amp;#123;@code true&amp;#125; if successful */ public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) &amp;#123; Pair&lt;V> current = pair; return expectedReference == current.reference &amp;&amp; expectedStamp == current.stamp &amp;&amp; ((newReference == current.reference &amp;&amp; newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp))); &amp;#125; 其实就是额外增加一个标志（stamp）来防止ABA的问题， 类似乐观锁的version。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- HashMap红黑树","slug":"source-code/java/HashMap红黑数","date":"2020-05-25T12:50:20.000Z","updated":"2020-09-12T17:22:04.073Z","comments":true,"path":"2020/05/25/source-code-hashmap-red-black-tree.html","link":"","permalink":"https://liuzhihang.com/2020/05/25/source-code-hashmap-red-black-tree.html","excerpt":"","text":"前言在阅读HashMap源码时，会发现在HashMap中使用了红黑树，所以需要先了解什么是红黑树，以及其原理。从而再进一步阅读HashMap中的链表到红黑树的转换，红黑树的增删节点等。 什么是红黑树？ 在HashMap中是怎么应用的？ 什么是红黑树？ 红黑树（英语：Red–black tree）是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。它在1972年由鲁道夫·贝尔发明，被称为”对称二叉B树”，它现代的名字源于Leo J. Guibas和Robert Sedgewick于1978年写的一篇论文。红黑树的结构复杂，但它的操作有着良好的最坏情况运行时间，并且在实践中高效：它可以在O(logN)时间内完成查找、插入和删除，这里的n是树中元素的数目。 红黑树的性质红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求： 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 红黑树操作左旋、右旋 插入 以二叉查找树的方法增加节点 新插入节点为红色（如果设为黑色，就会导致根到叶子的路径上有一条路上，多一个额外的黑节点，这个是很难调整的。但是设为红色节点后，可能会导致出现两个连续红色节点的冲突，那么可以通过颜色调换（color flips）和树旋转来调整。） 注意： 性质1和性质3是永远保持着的。 性质4只在增加红色节点、重绘黑色节点为红色，或做旋转时受到威胁。 性质5只在增加黑色节点、重绘红色节点为黑色，或做旋转时受到威胁。 插入时会遇到以下五种情形： 情形1：插入第一个节点情形2：插入新节点，父节点是黑色情形3：插入新节点，父节点是红色，叔父节点是红色情形4：插入新节点，父节点是红色，叔父节点是黑色或缺省，新节点是右子节点，父节点又是其父节点的左子节点情形5：插入新节点，父节点是红色，叔父节点是黑色或缺省，新节点是左子节点，父节点又是其父节点的左子节点。 情形1： 操作：插入第一个节点违反性质2：” 根是黑色。 “情形：直接插入红色节点，然后进行染色为黑色 情形2： 操作：插入新节点，父节点是黑色未违反性质情形：直接插入 情形3： 操作：插入新节点，父节点是红色，叔父节点是红色违反性质4：” 每个红色节点必须有两个黑色的子节点。 “情形：将祖父节点染色，祖父节点染色后再进行重新判断进行染色或旋转 情形4： 操作：插入新节点，父节点是红色，叔父节点是黑色或缺省，新节点是右子节点，父节点又是其父节点的左子节点违反性质4：” 每个红色节点必须有两个黑色的子节点。 “情形：进行左旋，旋转后父节点变成左子节点，新节点变成父节点，然后重新判断进行染色或旋转 情形5： 操作：插入新节点，父节点是红色，叔父节点是黑色或缺省，新节点是左子节点，父节点又是其父节点的左子节点。违反性质4：” 每个红色节点必须有两个黑色的子节点。 “情形：父节点染色为黑色，进行右旋，祖父节点变为右子节点，然后重新判断进行染色或旋转 HashMap结构static final class TreeNode&lt;K,V> extends LinkedHashMap.Entry&lt;K,V> &amp;#123; TreeNode&lt;K,V> parent; // red-black tree links TreeNode&lt;K,V> left; TreeNode&lt;K,V> right; TreeNode&lt;K,V> prev; // needed to unlink next upon deletion boolean red; // ... 省略 &amp;#125; 三个参数/** * 链表转为树阈值。 * 大于等于8时，会转换为树。 * 8 是综合性能考虑确定的值 */ static final int TREEIFY_THRESHOLD = 8; /** * 从树转换为链表的阈值 */ static final int UNTREEIFY_THRESHOLD = 6; /** * 最小树形化容量，只有哈希表元素数到达64才会进行树转换 */ static final int MIN_TREEIFY_CAPACITY = 64; 链表转红黑树-treeifyBin 数组（哈希表）长度到达64 当链表长度大于等于8是会将链表转换为红黑树 final void treeifyBin(Node&lt;K,V>[] tab, int hash) &amp;#123; int n, index; Node&lt;K,V> e; // 数组为null或者数组长度小于MIN_TREEIFY_CAPACITY（64）时，进行扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &amp;#123; // 头尾节点 hd-头 tl-尾 TreeNode&lt;K,V> hd = null, tl = null; do &amp;#123; // 创建树节点 Node -> TreeNode // 循环执行完之后得到的是双向链表 TreeNode&lt;K,V> p = replacementTreeNode(e, null); if (tl == null) hd = p; else &amp;#123; p.prev = tl; tl.next = p; &amp;#125; tl = p; &amp;#125; while ((e = e.next) != null); // 此时得到的仅仅是双向链表 // 指针指向链表头 if ((tab[index] = hd) != null) // 将双向链表转换为树 hd.treeify(tab); &amp;#125; &amp;#125; final void treeify(Node&lt;K,V>[] tab) &amp;#123; TreeNode&lt;K,V> root = null; for (TreeNode&lt;K,V> x = this, next; x != null; x = next) &amp;#123; next = (TreeNode&lt;K,V>)x.next; x.left = x.right = null; if (root == null) &amp;#123; // 情形1：插入第一个节点 x.parent = null; x.red = false; root = x; &amp;#125; else &amp;#123; // 当前节点的 key 和 hash K k = x.key; int h = x.hash; Class&lt;?> kc = null; // 再次循环 for (TreeNode&lt;K,V> p = root;;) &amp;#123; int dir, ph; // 内层循环的key K pk = p.key; // 当前节点的hash和内层循环的hash值作比较 if ((ph = p.hash) > h) // &lt; 0 left查找 dir = -1; else if (ph &lt; h) // > 0 right 查找 dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) // 比较对象 dir = tieBreakOrder(k, pk); TreeNode&lt;K,V> xp = p; // dir &lt;= 0 则走 left查找 > 0 则走 right查找 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &amp;#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; // 正式转换为红黑树 root = balanceInsertion(root, x); break; &amp;#125; &amp;#125; &amp;#125; &amp;#125; moveRootToFront(tab, root); &amp;#125; // root 根节点 // x 要操作的节点 static &lt;K,V> TreeNode&lt;K,V> balanceInsertion(TreeNode&lt;K,V> root, TreeNode&lt;K,V> x) &amp;#123; // 默认节点为红色 x.red = true; // xp：x的父节点 // xpp：x的祖父节点 // xppl：x祖父节点的左子节点 // xppr：x祖父节点的右子节点 for (TreeNode&lt;K,V> xp, xpp, xppl, xppr;;) &amp;#123; // 情形1： 父节点为null， 直接置为根 if ((xp = x.parent) == null) &amp;#123; x.red = false; return x; &amp;#125; // 父节点黑色 或者 祖父节点为空，直接返回 // 情形2：插入新节点，父节点是黑色 else if (!xp.red || (xpp = xp.parent) == null) return root; // 父节点是祖父节点的左子节点 if (xp == (xppl = xpp.left)) &amp;#123; // 祖父节点的右子节点不为空且是红色 // 情形3：插入新节点，父节点是红色，叔父节点是红色 if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &amp;#123; xppr.red = false; //祖父节点的右子节点设置为黑色 xp.red = false; // 父节点设置为黑色 xpp.red = true; // 祖父节点设置为红色 x = xpp; // 继续操作祖父节点 &amp;#125; // 旋转 else &amp;#123; // 新插入的是右子节点 if (x == xp.right) &amp;#123; // 插入的x是父节点的右子节点， 进行左旋 root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &amp;#125; if (xp != null) &amp;#123; // 父节点设置为黑色 xp.red = false; if (xpp != null) &amp;#123; xpp.red = true; // 右旋 root = rotateRight(root, xpp); &amp;#125; &amp;#125; &amp;#125; &amp;#125; // 父节点是祖父节点的右子节点 else &amp;#123; // 祖父节点的左子节点不为空且为红色 if (xppl != null &amp;&amp; xppl.red) &amp;#123; xppl.red = false; // 祖父节点的左子节点设置为黑色 xp.red = false; // 父节点设置为黑色 xpp.red = true; // 祖父节点设置为红色 x = xpp; // 继续操作祖父节点 &amp;#125; // 旋转 else &amp;#123; if (x == xp.left) &amp;#123; root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &amp;#125; if (xp != null) &amp;#123; xp.red = false; if (xpp != null) &amp;#123; xpp.red = true; root = rotateLeft(root, xpp); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125;","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- HashMap扩容","slug":"source-code/java/HashMap扩容","date":"2020-05-17T12:50:20.000Z","updated":"2020-09-12T17:22:04.079Z","comments":true,"path":"2020/05/17/source-code-hashmap-resize.html","link":"","permalink":"https://liuzhihang.com/2020/05/17/source-code-hashmap-resize.html","excerpt":"","text":"描述下HashMap put(k,v)的流程？它的扩容流程是怎么样的？ HashMap put(k,v)流程 通过hash(key方法)获取到key的hash值 调用put方法, 将value存放到指定的位置 根据hash值确定当前key所在node数组的索引 (n - 1) &amp; hash 如果node[i]==null 则直接创建新数组 如果node[i]!=null 判断 当前node的头结点的 hash和key是否都相等, 相等则需要操作的就是该node 判断当前节点是否为TreeNode，对TreeNode进行操作，并返回结果e 如果是链表则遍历链表，key存在则返回节点e，不存在则赋值 判断节点e有没有被赋值，覆盖旧值 hashMap size进行加1，同时判断v新size是否大于扩容阈值从而判断是否需要扩容 public V put(K key, V value) &amp;#123; return putVal(hash(key), key, value, false, true); &amp;#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &amp;#123; // 声明Node数组tab, Node节点 Node&lt;K,V>[] tab; Node&lt;K,V> p; int n, i; // 对tab数组赋值为当前HashMap的table, 并判断是否为空, 或者长度为0 // 为0进行则resize()数组, 并对 n赋值为当前tab的长度 // resize() 对HashMap的table扩容, 并返回扩容后的新数组 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 对 node p 进行赋值, 数组所在位置 即 node p 如果是null 则直接赋值 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &amp;#123; // p 不为null, 声明 node e, key k Node&lt;K,V> e; K k; // 如果hash值相等且key相等, 直接将 e 赋值为当前node的头节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) // 如果是红黑树, 则对树进行操作, 返回节点e e = ((TreeNode&lt;K,V>)p).putTreeVal(this, tab, hash, key, value); else &amp;#123; // 对链表进行遍历, 找到对应的节点 for (int binCount = 0; ; ++binCount) &amp;#123; // 将 e 赋值为 头节点p的next, 如果下一个节点为null if ((e = p.next) == null) &amp;#123; // 对节点进行赋值 p.next = newNode(hash, key, value, null); // 如果长度到达数转换阈值, 则需要转换为红黑树 if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &amp;#125; // 如果e节点的hash相等, key相等, 则 直接跳出循环 e 已经被赋值为 p.next // 此时e节点的value没有被赋值 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // 指针指向下一个节点, 继续遍历 p = e; &amp;#125; &amp;#125; if (e != null) &amp;#123; // existing mapping for key V oldValue = e.value; // 对旧值进行覆盖, 并返回旧值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &amp;#125; &amp;#125; ++modCount; // 是否需要扩容 if (++size > threshold) resize(); afterNodeInsertion(evict); return null; &amp;#125; resize()扩容过程 JDK 1.7 扩容流程, 每次都需要数组扩容后, 链表需要重新计算在新数组的位置 JDK 1.8 不需要重新计算 (优化点) 数组下标: (n - 1) &amp; hash 即数组长度-1 &amp; key的hash 扩容后的数组下标: ((n &lt;&lt; 1) - 1) &amp; hash 相当于在 高位1之前加了个1 如图所示, 真正发生影响的是新增的那一位(红色箭头所指), 所以 oldCap &amp; hash 完全可以判断该值是放在旧索引值的位置还是放在旧索引值+旧数组长度的位置 final Node&lt;K,V>[] resize() &amp;#123; // 旧数组 Node&lt;K,V>[] oldTab = table; // 旧数组长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 旧的扩容阈值 int oldThr = threshold; // 新的数组长度和新扩容阈值 int newCap, newThr = 0; // 旧数组存在 if (oldCap > 0) &amp;#123; if (oldCap >= MAXIMUM_CAPACITY) &amp;#123; threshold = Integer.MAX_VALUE; return oldTab; &amp;#125; // 新数组长度为旧数组长度的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap >= DEFAULT_INITIAL_CAPACITY) // 扩容阈值是旧扩容阈值的2倍 newThr = oldThr &lt;&lt; 1; // double threshold &amp;#125; // 旧数组不存在, 相当于首次put(K, V)时, 将数组长度置为扩容阈值 else if (oldThr > 0) // initial capacity was placed in threshold newCap = oldThr; else &amp;#123; // zero initial threshold signifies using defaults // 旧数组不存在, new HashMap()未指定长度, 初次put(K, V), 设置为默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &amp;#125; // 新的扩容阈值是0, 则将扩容阈值设置为 新数组长度*负载因子 if (newThr == 0) &amp;#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &amp;#125; // 对全局的扩容阈值进行赋值 threshold = newThr; @SuppressWarnings(&amp;#123;\"rawtypes\",\"unchecked\"&amp;#125;) // 创建新数组, 长度为新长度, 即原数组长度的2倍 Node&lt;K,V>[] newTab = (Node&lt;K,V>[])new Node[newCap]; // 将table复制为新数组 table = newTab; if (oldTab != null) &amp;#123; // 对旧数组进行遍历 for (int j = 0; j &lt; oldCap; ++j) &amp;#123; Node&lt;K,V> e; // 旧节点node赋值 if ((e = oldTab[j]) != null) &amp;#123; oldTab[j] = null; if (e.next == null) // 只有头结点, 直接计算新的位置并赋值 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 树单独处理 ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap); else &amp;#123; // preserve order Node&lt;K,V> loHead = null, loTail = null; Node&lt;K,V> hiHead = null, hiTail = null; Node&lt;K,V> next; do &amp;#123; // next节点 next = e.next; // 节点hash与旧数组长度 &amp; 的结果来决定元素所在位置, 参考上面图示所讲 if ((e.hash &amp; oldCap) == 0) &amp;#123; // 在元索引出创建新链表 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &amp;#125; else &amp;#123; // 新索引出创建链表 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &amp;#125; &amp;#125; while ((e = next) != null); if (loTail != null) &amp;#123; loTail.next = null; // 索引j处直接赋值 newTab[j] = loHead; &amp;#125; if (hiTail != null) &amp;#123; hiTail.next = null; // 索引 j + 老数组长度位置存放hiHead newTab[j + oldCap] = hiHead; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; return newTab; &amp;#125;","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- HashMap的初始化","slug":"source-code/java/HashMap初始化","date":"2020-05-11T10:50:20.000Z","updated":"2020-09-12T17:22:04.206Z","comments":true,"path":"2020/05/11/source-code-hashmap-init.html","link":"","permalink":"https://liuzhihang.com/2020/05/11/source-code-hashmap-init.html","excerpt":"","text":"HashMap初始化参数都是什么？默认是多少？为什么建议初始化设置容量？tableSizeFor方法是做什么的？如何获取到一个key的hash值？及计算下标？ HashMap初始化参数都是什么？默认是多少？HashMap初始化参数分别是初始容量和负载因子。 初始容量(threshold)：默认 16， 必须是2的幂， 最大容量为 1 &lt;&lt; 30 负载因子(loadFactor)：是指哈希表的负载因子，当哈希表的长度大于capacity * loadFactor时会进行扩容，默认 0.75f 为什么建议初始化设置容量 这块涉及到HashMap的扩容， 在阿里巴巴Java开发手册中已经说明了原因。主要是为了减少频繁的扩容造成的资源损耗。 tableSizeFor方法是做什么的？初始化HashMap时, 如果传入初始容量, 在初始化时会调用 tableSizeFor(initialCapacity) 方法寻找大于等于当前值的下一个2的幂值. 代码如下： static final int tableSizeFor(int cap) &amp;#123; int n = cap - 1; // -1操作, 防止当cap正好是2的幂时的处理 n |= n >>> 1; // n无符号右移1位, 然后和n做 | 运算, (1|0=1 1|1=1 0|0=0 0|1=1) n |= n >>> 2; // n无符号右移2位, 然后和n做 | 运算, n |= n >>> 4; // n无符号右移4位, 然后和n做 | 运算, n |= n >>> 8; // n无符号右移8位, 然后和n做 | 运算, n |= n >>> 16; // n无符号右移16位, 然后和n做 | 运算, // 最后获得的结果为 cap-1的下一个2的幂值-1, 只需要对n+1即可 return (n &lt; 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &amp;#125; 假设cap值为100, 即0110 0100 cap的下一个2的幂为 0111 1111 即 1000 0000 0000 = 0111 1111 + 1 只需要考虑将 首个为1的最高位之后的值置为1, 然后+1即可 为防止cap本来就是2的幂, 则需要先进行减一操作 如图所示: 最后执行的结果进行加1即可 如何获取到一个key的hash值？static final int hash(Object key) &amp;#123; int h; // key的hashCode ^ 上自己的高16位， 如果是null的话则hash为0 return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); &amp;#125; 获取到了hash值， 那如何计算在数组的那个位置呢？ // n为数组长度 数组下标 i = (n - 1) &amp; hash 数组长度都是 2的幂假设 n = 1 &gt;&gt; x则 n - 1 则表示 一个低x位全为1的数 (n - 1) &amp; hash 则相当于 一个低x位全为1的数和hash做&amp;操作. 通过图可以看出, 参与运算的只有低x位, 相当于之前的所有值都不会有效. 所以前面的hash(key) 将key.hashCode()高低16位做^操作, 可以保证, 高低16位都能参与运算.一定程度上避免hash碰撞.在源码注释中已经说明, 是肯定会有碰撞, 但是这是权衡之后的结果.","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"markdown代码折叠","slug":"other/markdown代码折叠","date":"2020-04-20T07:20:20.000Z","updated":"2020-09-12T17:22:04.230Z","comments":true,"path":"2020/04/20/markdown-code-folding.html","link":"","permalink":"https://liuzhihang.com/2020/04/20/markdown-code-folding.html","excerpt":"","text":"效果展示折叠内容 折叠内容 在markdown中折叠一部分内容, 点击可以展开. 折叠代码 折叠代码 public class HelloWorld &amp;#123; public static void main(String[] args) &amp;#123; System.out.println(\"HelloWorld\"); &amp;#125; &amp;#125; 使用方式使用html &lt;details> &lt;summary>折叠内容&lt;/summary> 在markdown中折叠一部分内容, 点击可以展开. &lt;/details> &lt;details> &lt;summary>折叠代码&lt;/summary> 代码块 &lt;/details>","categories":[{"name":"markdown","slug":"markdown","permalink":"https://liuzhihang.com/categories/markdown/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://liuzhihang.com/tags/markdown/"},{"name":"小技巧","slug":"小技巧","permalink":"https://liuzhihang.com/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"雪花算法","slug":"distributed/使用雪花算法生成流水号","date":"2020-04-13T08:03:09.000Z","updated":"2020-09-12T17:22:04.099Z","comments":true,"path":"2020/04/13/snowflake-algorithm.html","link":"","permalink":"https://liuzhihang.com/2020/04/13/snowflake-algorithm.html","excerpt":"","text":"简单介绍下雪花算法, 以及Java版雪花算法的代码.仅仅是一个最简单版本, 更深层次的指针回拨等. 相当于在开发过成功可以先使用.尽量还是使用统一的分布式流水号生成系统, 保证流水号全局唯一. 雪花算法0 0000000000 0000000000 0000000000 0000000000 0 00000 00000 000000000000 使用64位long型数字作为全局唯一id1位 无意义 041位 时间戳5位 机房id5位 机器id12位自增序号 表示同一时间同一机房同一机器生成的序列号 第一位为什么无意义 二进制中 第一位代表符号位, 默认 0 表示生成的序列号为正数 41位时间戳 41位最大能表示 2^41-1 的数字. 毫秒值 69.7年 (2^41-1)/1000/60/60/24 当时间大于69.7即时间戳差值大于 2199023255551, 会开始出现负值流水号 10位 机房id+机器id 2^10 1024台机器 // 但是使用中不可能每部署一台机器都改下编号, 所以我做出以下改动 // 8位机器号(最大256) 2位机房号 // 机器号使用IP地址后三位 机房id 默认1 // 只需要确保机器的ip后三位不同即可 private static final long MACHINE_BIT = 8; private static final long DATA_CENTER_BIT = 2; private static final long DATA_CENTER_ID = 1;private static long address;static { InetAddress localIp = IpUtils.getLocalIp(); address = localIp.getAddress()[3] &amp; 0xff; log.info(“当前系统的 address 为: {}”, address);} 4. 12位序列号 表示同一毫秒内生成的id 2^12-1 个正整数 SnowFlake每秒能够产生26万ID左右 优点: 生成ID时不依赖于DB，完全在内存生成，高性能高可用。 ID呈趋势递增，后续插入索引树的时候性能较好。 缺点: 依赖于系统时钟的一致性。如果某台机器的系统时钟回拨，有可能造成ID冲突，或者ID乱序 ### SerialNumber ```java public class SerialNumber &#123; /** * 起始的时间戳 2018-01-01 00:00:00 */ private static final long START_STAMP = 1514736000000L; /** * 每一部分占用的位数 * 序列号 占用位数 12 位 (同一毫秒内生成的id 2^12-1 个正整数) * 机器标识 占用位数 8 位 (一般是使用5位) * 数据中心 占用位数 2 位 (一般是使用5位) * */ private static final long SEQUENCE_BIT = 12; private static final long MACHINE_BIT = 8; private static final long DATA_CENTER_BIT = 2; /** * 每一部分的最大值 */ private static final long MAX_DATA_CENTER_NUM = ~(-1L &lt;&lt; DATA_CENTER_BIT); private static final long MAX_MACHINE_NUM = ~(-1L &lt;&lt; MACHINE_BIT); private static final long MAX_SEQUENCE = ~(-1L &lt;&lt; SEQUENCE_BIT); /** * 每一部分向左的位移 * 机器Id左移12位 (SEQUENCE_BIT = 12) * 数据中心左移20位 (SEQUENCE_BIT + MACHINE_BIT = 12 + 8) * 时间戳左移22位 (DATA_CENTER_LEFT + DATA_CENTER_BIT = 12 + 8 + 2) * */ private static final long MACHINE_LEFT = SEQUENCE_BIT; private static final long DATA_CENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private static final long TIME_STAMP_LEFT = DATA_CENTER_LEFT + DATA_CENTER_BIT; /** * 数据中心 机器标识 序列号 上一次时间戳 * 数据中心标识和机器标识一般是外部传入 */ private static final long DATA_CENTER_ID = 1; private static long address; private long sequence = 0L; private long lastStamp = -1L; private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormatter.ofPattern(&quot;yyMMdd&quot;); static &#123; InetAddress localIp = IpUtils.getLocalIp(); address = localIp.getAddress()[3] &amp; 0xff; log.info(&quot;当前系统的 address 为: &#123;&#125;&quot;, address); &#125; /** * 产生下一个ID * * @return */ private synchronized long nextId() &#123; long currStamp = getNewStamp(); if (currStamp &lt; lastStamp) &#123; throw new RuntimeException(&quot;Clock moved backwards. Refusing to generate id&quot;); &#125; if (currStamp == lastStamp) &#123; // 相同毫秒内，序列号自增 (sequence + 1) &amp; (~(-1L &lt;&lt; SEQUENCE_BIT)) sequence = (sequence + 1) &amp; MAX_SEQUENCE; // 同一毫秒的序列数已经达到最大 if (sequence == 0L) &#123; currStamp = getNextMill(); &#125; &#125; else &#123; // 不同毫秒内，序列号置为0 sequence = 0L; &#125; lastStamp = currStamp; // 时间戳部分 数据中心部分 机器标识部分 序列号部分 return (currStamp - START_STAMP) &lt;&lt; TIME_STAMP_LEFT | DATA_CENTER_ID &lt;&lt; DATA_CENTER_LEFT | address &lt;&lt; MACHINE_LEFT | sequence; &#125; private long getNextMill() &#123; long mill = getNewStamp(); while (mill &lt;= lastStamp) &#123; mill = getNewStamp(); &#125; return mill; &#125; private long getNewStamp() &#123; return System.currentTimeMillis(); &#125; &#125; IpUtilsimport java.net.*; import java.util.Enumeration; /** * @author liuzhihang * @date 2019/12/19 16:03 */ public class IpUtils &amp;#123; public static InetAddress getLocalIp() &amp;#123; try &amp;#123; for (Enumeration&lt;NetworkInterface> e = NetworkInterface.getNetworkInterfaces(); e.hasMoreElements(); ) &amp;#123; NetworkInterface item = e.nextElement(); for (InterfaceAddress address : item.getInterfaceAddresses()) &amp;#123; if (item.isLoopback() || !item.isUp()) &amp;#123; continue; &amp;#125; if (address.getAddress() instanceof Inet4Address) &amp;#123; return address.getAddress(); &amp;#125; &amp;#125; &amp;#125; return InetAddress.getLocalHost(); &amp;#125; catch (SocketException | UnknownHostException e) &amp;#123; throw new RuntimeException(e); &amp;#125; &amp;#125; &amp;#125;","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"流水号","slug":"流水号","permalink":"https://liuzhihang.com/tags/%E6%B5%81%E6%B0%B4%E5%8F%B7/"},{"name":"雪花算法","slug":"雪花算法","permalink":"https://liuzhihang.com/tags/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95/"}]},{"title":"项目启动失败:java.lang.NoClassDefFoundError","slug":"issue/项目启动失败","date":"2020-04-12T05:20:48.000Z","updated":"2020-09-12T17:22:04.127Z","comments":true,"path":"2020/04/12/no-class-def-found-error-rule-configuration.html","link":"","permalink":"https://liuzhihang.com/2020/04/12/no-class-def-found-error-rule-configuration.html","excerpt":"","text":"近期遇到一个很久没有启动过的项目, 然后启动失败, 报 java.lang.NoClassDefFoundError, 现在记录问题排查情况. 错误代码 错误代码较长, 可以收缩, 直接看排查 Error starting ApplicationContext. To display the conditions report re-run your application with &#39;debug&#39; enabled.] [2020-04-10 13:26:11.478]-[main]-[]-[ERROR]-[org.springframework.boot.SpringApplication:821]-[Application run failed] org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:155) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:742) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:389) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:311) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1213) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1202) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at com.opay.im.WebApplication.main(WebApplication.java:32) [classes!/:1.0-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_221] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_221] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_221] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_221] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [opay-im-web-1.0-SNAPSHOT.jar:1.0-SNAPSHOT] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [opay-im-web-1.0-SNAPSHOT.jar:1.0-SNAPSHOT] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [opay-im-web-1.0-SNAPSHOT.jar:1.0-SNAPSHOT] at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:58) [opay-im-web-1.0-SNAPSHOT.jar:1.0-SNAPSHOT] Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:124) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;(TomcatWebServer.java:86) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:414) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:178) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:179) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:152) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] ... 16 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;servletEndpointRegistrar&#39; defined in class path resource [org/springframework/boot/actuate/autoconfigure/endpoint/web/ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.ServletEndpointRegistrar]: Factory method &#39;servletEndpointRegistrar&#39; threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;healthEndpoint&#39; defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Unsatisfied dependency expressed through method &#39;healthEndpoint&#39; parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;healthIndicatorRegistry&#39; defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthIndicatorAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthIndicatorRegistry]: Factory method &#39;healthIndicatorRegistry&#39; threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthIndicatorAutoConfiguration&#39;: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;dataSource&#39; defined in class path resource [com/opay/im/config/DatabaseConfig.class]: Unsatisfied dependency expressed through method &#39;dataSource&#39; parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;defaultDataSource&#39; defined in class path resource [com/opay/im/config/DatabaseConfig.class]: Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: org/apache/shardingsphere/api/config/RuleConfiguration at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:607) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:211) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:202) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:96) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.&lt;init&gt;(ServletContextInitializerBeans.java:85) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:252) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] 问题定位 开始排查是因为缺少 sharding-core-api-4.0.0-RC2.2-1.8.jar 包下的一个文件, 但是本地是有的 本地可以启动 服务器启动失败, 可能是jar包缺少 最后结果发现 sharding-core-api-4.0.0-RC2.2-1.8.jar 是通过公司封装的一个包传递进来的, 而封装的那个jar包在私服上已经被删除了. 删除原因","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"error","slug":"error","permalink":"https://liuzhihang.com/tags/error/"}]},{"title":"Mac创建data目录失败","slug":"mac/mac创建data目录失败","date":"2020-01-05T10:30:30.000Z","updated":"2020-09-12T17:22:04.130Z","comments":true,"path":"2020/01/05/mac-create-data-directory-failed.html","link":"","permalink":"https://liuzhihang.com/2020/01/05/mac-create-data-directory-failed.html","excerpt":"","text":"问题描述 部分项目log日志输出路径为 /data/log, 发现无法创建目录错误信息: mkdir: cannot create directory ‘data’: Read-only file system 解决方式关闭SPI 重启 按住CMD+R进入恢复模式 打开终端 终端输入命令：csrutil disable 挂载data 在用户目录(可以自己找一个目录下创建data) ~ % > cd ~ ~ % > mkdir data 执行 sudo mount -uw / 重新挂载根目录 建立软链sudo ln -s /Users/liuzhihang/data /data 之后可以重启再打开spi了","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"},{"name":"mac","slug":"mac","permalink":"https://liuzhihang.com/tags/mac/"}]},{"title":"Hexo中插入Bilibili视频","slug":"hexo/hexo插入bilibili视频","date":"2019-09-14T07:06:54.000Z","updated":"2020-09-12T17:22:04.183Z","comments":true,"path":"2019/09/14/hexo-inserts-bilibili-video.html","link":"","permalink":"https://liuzhihang.com/2019/09/14/hexo-inserts-bilibili-video.html","excerpt":"","text":"修改matery主题首页显示视频为Bilibili视频 在Markdown插入Bilibili视频, 并设置大小. 首先找到分享嵌入代码 &lt;iframe src=\"//player.bilibili.com/player.html?aid=17963687&amp;cid=29326684&amp;page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> &lt;/iframe> 在markdown中使用嵌入代码 调整大小和居中等iframe标签属性设置 &lt;!-- 调整大小: width=\"xxx\" height=\"xxx\" --> &lt;iframe src=\"//player.bilibili.com/player.html?aid=17963687&amp;cid=29326684&amp;page=1\" width=\"600\" height=\"400\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> &lt;/iframe> 设置自适应&lt;div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> &lt;iframe src=\"//player.bilibili.com/player.html?aid=17963687&amp;cid=29326684&amp;page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\">&lt;/iframe> &lt;/div> matery 主题修改首页展示视频找到 /themes/hexo-theme-matery/layout/_widget/video.ejs 将第十一行左右代码改成Bilibili视频即可, 引入的 script 可以删掉. 修改后如下. &lt;div class=\"video-player\"> &lt;% if (theme.video.showTitle) &amp;#123; %> &lt;div class=\"title center-align\"> &lt;i class=\"fas fa-video-camera\">&lt;/i>&amp;nbsp;&amp;nbsp;&lt;%- theme.video.title %> &lt;/div> &lt;% &amp;#125; %> &lt;div class=\"row\"> &lt;div class=\"col l8 offset-l2 m10 offset-m1 s12\"> &lt;div id=\"dplayer\" class=\"dplayer-video\"> &lt;div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> &lt;iframe src=\"//player.bilibili.com/player.html?aid=16316393&amp;cid=26620787&amp;page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\">&lt;/iframe> &lt;/div> &lt;/div> &lt;/div> &lt;/div> &lt;/div>","categories":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/tags/hexo/"}]},{"title":"Redis分布式锁的生产问题解决方案","slug":"distributed/redis分布式锁的生产问题解决方案","date":"2019-08-18T08:36:20.000Z","updated":"2020-09-12T17:22:04.145Z","comments":true,"path":"2019/08/18/redis-distributed-lock-production-problem-solution.html","link":"","permalink":"https://liuzhihang.com/2019/08/18/redis-distributed-lock-production-problem-solution.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 使用方式SET KEY VALUE TIME NX DEL KEY 一般使用 NX, 只有在锁不存在的时候才加锁成功, 设置时间是为了锁永远得不到释放 存在问题及解决方法 A加锁, B释放 方法: Redisson 在tryLock时 long threadId = Thread.currentThread().getId(); protected String getLockName(long threadId) &amp;#123; return id + \":\" + threadId; &amp;#125; // id 为 UUID 会将当前 uuId+线程id写入到锁信息中, unlock时会校验是否是当前线程 A lock锁住之后, 设置了时间, 但是在时间内未完成, 导致锁自动释放, 然后B获取锁同时进行操作 方法: Redisson 在lock时会启动异步线程, 自动延期, 时间为 lockWatchdogTimeout(默认30s) Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() &amp;#123; 省略... &amp;#125;, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS); 看源码是延时 1/3的时间后开始, 就是每次1/3时间的时候延期一次. 这样理解不知道对不对 主从下, A 加锁 Master 成功后未同步给Slave 便宕机, 导致 B发现未加锁 方法: 可以修改源码, 同时加锁Master-Slave 才算加锁成功 集群状态下可以参考RedLock(红锁), 加锁多台机器, 多数成功才算成功(locks.size()/2 + 1) public class RedissonRedLock extends RedissonMultiLock &amp;#123; public RedissonRedLock(RLock... locks) &amp;#123; super(locks); &amp;#125; &amp;#125;","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"如何落地最终一致性事务","slug":"distributed/如何落地最终一致性事务","date":"2019-08-17T07:55:55.000Z","updated":"2020-09-12T17:22:04.118Z","comments":true,"path":"2019/08/17/how-to-land-the-final-consistency-transaction.html","link":"","permalink":"https://liuzhihang.com/2019/08/17/how-to-land-the-final-consistency-transaction.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 作业：如果对自己的系统落地最终一致性事务，如何落地实现？ 首先熟悉自己负责的业务, 熟悉系统间交互流程, 哪些可以异步, 哪些是必须同步 异步的时候要考虑是否需要一致性, 当前系统通知流程如图 如何落地最终一致性事务 根据课程思考最终一致性事务修改: 在收到交易请求, 成功时可以 commit half message 同时 需要实现 check方法, 供RocketMQ回调, 检查本地事务状态 在交易成功或失败时再进行commit或rollback rollback消息 RocketMQ会定期删除 通知系统收到消息存储到本地并通知商户 问题但是考虑到在这边系统完全没有必要增加事务, 因为发送消息到MQ是在交易结束后, 直接用一个字段判断状态, 然后用定时保证投递到MQ即可. RocketMQ的两段提交 half message 执行流程 根据流程结果: commit/rockback 可以改成 执行流程 RocketMQ send(普通消息) 在这边的使用场景中, 因为提交了 half message 也不会发送消息, 等到流程执行结束了, 然后使用send发送普通消息即可.","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"交易系统架构图","slug":"distributed/交易系统架构图","date":"2019-08-10T03:19:54.000Z","updated":"2020-09-12T17:22:04.105Z","comments":true,"path":"2019/08/10/trading-system-architecture.html","link":"","permalink":"https://liuzhihang.com/2019/08/10/trading-system-architecture.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 交易系统架构 请求流程: 请求首先到SLB(阿里云)经过负载均衡后, 到Nginx Nginx做简单负载均衡后发给交易API系统, 4C8G * 5 ECS(阿里云) 交易会根据请求参数, 路由到各个子系统, 使用dubbo 子系统收到请求, 请求风控系统校验风控 请求应用中心获取应用参数 (appId, appKey等) 拼装报文,请求渠道系统 返回信息 日志报送流程 交易成功报送清结算, 报送数据中心 filebeat拉取日志, 报送kafka, 因filebeat升级 同时存在5.x和6.x 需要加中间一层, 之前是直接报logstash logstash对数据进行过滤然后根据type 分别保送到 elasticsearch和redis 监控系统监控redis队列数据, 满足规则, 报警(发消息到通知系统) 监控系统对es数据进行过滤, 放到mysql, 用来展示商户, 渠道的交易变化等信息 kibana(直接用的kibana)提供给技术支持查询日志. es数据会定期删除, 保留15-30天的数据, 仅仅技术支持用, 不需要效率很高, 所以机器配置相对较差. 扩容方案公司体量较小, QPS高峰期也就500左右, TPS高峰期在100~200, 所以基本没有遇到问题.之前有过一段时间公众号支付交易量较大, 主要做法是增加公众号机器, 同时增加API系统机器.假如交易量提高, 一般应对就是增加机器, 和提高机器配置, 基本上都可以应对. 存在问题定时系统是仅仅通过dubbo发送调用请求, 没有业务逻辑. 所以单体基本没有遇到挂掉. 也在考虑分布式定时任务.","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"SpringCloud架构原理图","slug":"distributed/springcloud架构原理图","date":"2019-08-04T09:01:06.000Z","updated":"2020-09-12T17:22:04.095Z","comments":true,"path":"2019/08/04/springcloud-architecture-schematic.html","link":"","permalink":"https://liuzhihang.com/2019/08/04/springcloud-architecture-schematic.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 springcloud 通信原理 1. Eureka 集群 Eureka启动后, 会向其他节点注册, 相互直接视为 peer, 并互相同步注册信息. 2. 缓存机制Eureka存在三个map: registry、readWriteCacheMap、readOnlyCacheMap registry: CurrentHashMap 实时更新readWriteCacheMap: Guava Cache/LoadingCache 也是实时更新readOnlyCacheMap: CurrentHashMap 30秒同步 readWriteCacheMap一次 3. 服务注册服务注册后每30s发送一次心跳(renew)客户端每30秒请注册中心获取一次配置, 并存到本地内存中 注册中心会定时检查心跳, 连续没有3个回踢掉服务","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Dubbo底层原理架构图","slug":"distributed/dubbo底层原理架构图","date":"2019-08-03T06:33:00.000Z","updated":"2020-09-12T17:22:04.121Z","comments":true,"path":"2019/08/03/dubbo-bottom-structure-diagram.html","link":"","permalink":"https://liuzhihang.com/2019/08/03/dubbo-bottom-structure-diagram.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 操作流程图 1. 服务注册, 故障及下线 注册: provider和consumer同时在zk上注册临时节点, 同时consumer订阅zk /dubbo/**/providers provider地址, providers发生变化, zk自动推送给consumer zk上结构如下 ls /dubbo/cn.xxx.xxxService [consumers, routers, providers, configurators] [consumer://机器ip/接口?application=服务名&category=consumers&check=false&default.check=false&default.group=beta&default.timeout=5000&default.version=1.0.0&dubbo=2.6.2&interface=接口&methods=方法1,方法2&pid=7828&revision=0.0.1&side=consumer&timestamp=1556173624632] [dubbo://机器1ip:端口/接口?anyhost=true&application=WalletOrderApplicationConsumer&delay=2000&dubbo=2.5.3&group=beta&heartbeat=10000&interface=接口&methods=方法1,方法2&pid=22419&retries=0&revision=1.0.0&side=provider&timeout=10000&timestamp=1564743170669&version=1.0.0, dubbo://机器2ip:端口/接口?anyhost=true&application=WalletOrderApplicationConsumer&delay=2000&dubbo=2.5.3&group=beta&heartbeat=10000&interface=cn.ipaynow.webank.wallet.order.api.provider.DataCenterTaskService&methods=syncRechargesRefund,syncTrans,syncTransCancel,syncTransRefunds,syncRecharges&pid=16801&retries=0&revision=0.0.1&side=provider&timeout=10000&timestamp=1563792977340&version=1.0.0] 故障: zk自动删除临时节点 下线: 取消注册, 主动删除节点 2. Proxy 动态代理根据配置的接口, 生成动态代理对象, 使用 JDK + JAVAASSIST 方式 在服务提供端，将服务的具体实现类转为Invoker 在消费端，通过 getProxy(Invoker invoker)将invoker转为客户端需要的接口 Invoker封装了Provider地址及Service接口信息 3. Cluster 集群层获取到要调用的Invoker 多个服务端会有多个 Invoker对象, 组合成Directory, Directory在zk推送Provider节点变更时, 会发生变化 Router, 按照路由规则选出本次可以调用的 Directory子集, zk注册中心 routers节点下配置 LoadBalance 从子集中按照负载均衡选出本次调用 Random LoadBalance 随机 RoundRobin LoadBalance 轮询 LeastActive LoadBalance 最少活跃 ConsistentHash LoadBalance 一致性哈希 容错 Failover Cluster 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2″ 来设置重试次数(不含第一次)。 Failfast Cluster：快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster：失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster：并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2″ 来设置最大并行数。 4. Protocol 远程调用层包含两个接口, 分别是 暴露服务(export) 和 引用服务(refer) 分别对应provider 和 consumer选择通信协议 dubbo, hessian, http等 5. Exchange 数据交换层将请求信息封装为Request, 然后发送给 Transport层, 并将返回信息封装为Response 6. Transport 网络传输层使用netty或mina进行网络通信 7. serialize 序列化层将请求报文和返回报文记性序列化和反序列化 8. provider收到请求后先进行反序列化, 然后在解析请求, 通过动态代理调用相应方法","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"SpringBoot项目中使用SpringSecurity和JWT做权限认证","slug":"spring/springboot项目中使用springsecurity和jwt做权限认证","date":"2019-07-22T05:36:22.000Z","updated":"2020-09-12T17:22:04.085Z","comments":true,"path":"2019/07/22/springsecurity-jwt-springboot-project.html","link":"","permalink":"https://liuzhihang.com/2019/07/22/springsecurity-jwt-springboot-project.html","excerpt":"","text":"背景 前段时间做了一个项目, 因为涉及到权限认证, 所以分别调研了 SpringSecurity 和 Apache Shiro. 最后选择使用了 SpringSecurity + JWT做权限认证, 现在项目已经结束, 总相关笔记.项目下载地址 jwt-demo 使用JWT生成token token存储在数据库中 使用 application/json 登录 使用手机号进行登录 URI动态拦截 配置过程添加依赖 分别添加 SpringSecurity JWT 和 fastjson 依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-security&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>io.jsonwebtoken&lt;/groupId> &lt;artifactId>jjwt&lt;/artifactId> &lt;version>0.9.0&lt;/version> &lt;/dependency> &lt;!--json--> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;version>1.2.60&lt;/version> &lt;/dependency> 基础准备对象 主要是在用户登录成功handle时使用JWT生成Token返回给客户端. 基础使用dto请求返回基类 @Data public class BaseReqDto implements Serializable &amp;#123; private String version; &amp;#125; @Data public class BaseRespDto implements Serializable &amp;#123; private String resultCode; private String resultMsg; private String resultTime; &amp;#125; 登录请求返回对象 @Data public class LoginReqDto &amp;#123; private String username; private String token; &amp;#125; @Data public class LoginRespDto extends BaseRespDto &amp;#123; private String token; &amp;#125; 用于验证的用户package com.liuzhihang.demo.bean; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import java.io.Serializable; import java.util.Collection; /** * 用户信息校验验证码 * * @author liuzhihang */ public class UserDetailsImpl implements UserDetails, Serializable &amp;#123; /** * 用户名 */ private String username; /** * 密码 */ private String password; /** * 权限集合 */ private Collection&lt;? extends GrantedAuthority> authorities; @Override public Collection&lt;? extends GrantedAuthority> getAuthorities() &amp;#123; return this.authorities; &amp;#125; public void setAuthorities(Collection&lt;? extends GrantedAuthority> authorities) &amp;#123; this.authorities = authorities; &amp;#125; @Override public String getPassword() &amp;#123; return this.password; &amp;#125; @Override public String getUsername() &amp;#123; return this.username; &amp;#125; public void setUsername(String username) &amp;#123; this.username = username; &amp;#125; public void setPassword(String password) &amp;#123; this.password = password; &amp;#125; @Override public boolean isAccountNonExpired() &amp;#123; return true; &amp;#125; @Override public boolean isAccountNonLocked() &amp;#123; return true; &amp;#125; @Override public boolean isCredentialsNonExpired() &amp;#123; return true; &amp;#125; @Override public boolean isEnabled() &amp;#123; return true; &amp;#125; &amp;#125; 用户未登录handle /** * 用户登录认证, 未登录返回信息 * * @author liuzhihang * @date 2019-06-04 13:52 */ @Component public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint &amp;#123; private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"); @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException e) throws IOException &amp;#123; response.setContentType(\"application/json;charset=UTF-8\"); LoginRespDto respDto = new LoginRespDto(); respDto.setResultCode(\"0001\"); respDto.setResultMsg(\"用户未登录\"); respDto.setResultTime(LocalDateTime.now().format(FORMATTER)); response.getWriter().write(JSON.toJSONString(respDto)); &amp;#125; &amp;#125; 用户登录验证失败handle/** * 用户登录认证失败返回的信息 * * @author liuzhihang * @date 2019-06-04 13:57 */ @Component public class AuthenticationFailureHandlerImpl implements AuthenticationFailureHandler &amp;#123; private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"); @Override public void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response, AuthenticationException exception) throws IOException &amp;#123; response.setContentType(\"application/json;charset=UTF-8\"); LoginRespDto respDto = new LoginRespDto(); respDto.setResultCode(\"0001\"); respDto.setResultMsg(\"用户登录认证失败\"); respDto.setResultTime(LocalDateTime.now().format(FORMATTER)); response.getWriter().write(JSON.toJSONString(respDto)); &amp;#125; &amp;#125; 用户无权访问handle/** * 当用户访问无权限页面时, 返回信息 * * @author liuzhihang * @date 2019-06-04 14:03 */ @Component public class AccessDeniedHandlerImpl implements AccessDeniedHandler &amp;#123; private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"); @Override public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException &amp;#123; response.setContentType(\"application/json;charset=UTF-8\"); LoginRespDto respDto = new LoginRespDto(); respDto.setResultCode(\"0002\"); respDto.setResultMsg(\"用户无权访问\"); respDto.setResultTime(LocalDateTime.now().format(FORMATTER)); response.getWriter().write(JSON.toJSONString(respDto)); &amp;#125; &amp;#125; 用户登录成功handle /** * 用户登录成功之后的返回信息 * * @author liuzhihang * @date 2019-06-04 14:20 */ @Slf4j @Component public class AuthenticationSuccessHandlerImpl implements AuthenticationSuccessHandler &amp;#123; private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"); @Resource private JwtTokenUtil jwtTokenUtil; @Override public void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException &amp;#123; UserDetailsImpl userDetails = (UserDetailsImpl) authentication.getPrincipal(); String jwtToken = jwtTokenUtil.generateToken(userDetails); // 把生成的token更新到数据库中 // 更新DB操作 ... response.setContentType(\"application/json;charset=UTF-8\"); LoginRespDto respDto = new LoginRespDto(); respDto.setToken(jwtToken); respDto.setResultCode(\"0000\"); respDto.setResultMsg(\"登录成功\"); respDto.setResultTime(LocalDateTime.now().format(FORMATTER)); response.getWriter().write(JSON.toJSONString(respDto)); &amp;#125; &amp;#125; JwtTokenUtil主要用来生成token和通过token解析对象等操作. package com.liuzhihang.demo.utils; import com.liuzhihang.demo.bean.UserDetailsImpl; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.stereotype.Component; import java.time.Instant; import java.util.Date; /** * 使用 java-jwt jwt类库 * * @author liuzhihang * @date 2019-06-05 09:22 */ @Component public class JwtTokenUtil &amp;#123; private static final SignatureAlgorithm SIGN_TYPE = SignatureAlgorithm.HS256; public static final String SECRET = \"jwt-secret\"; /** * JWT超时时间 */ public static final long EXPIRED_TIME = 7 * 24 * 60 * 60 * 1000L; /** * claims 为自定义的私有声明, 要放在前面 * &lt;p> * 生成token */ public String generateToken(UserDetails userDetails) &amp;#123; long instantNow = Instant.now().toEpochMilli(); Claims claims = Jwts.claims(); claims.put(Claims.SUBJECT, userDetails.getUsername()); return Jwts.builder().setClaims(claims).setIssuedAt(new Date(instantNow)) .setExpiration(new Date(instantNow + EXPIRED_TIME)) .signWith(SIGN_TYPE, SECRET).compact(); &amp;#125; /** * claims 为自定义的私有声明, 要放在前面 * &lt;p> * 生成token */ public String generateToken(String userName) &amp;#123; long instantNow = Instant.now().toEpochMilli(); Claims claims = Jwts.claims(); claims.put(Claims.SUBJECT, userName); return Jwts.builder().setClaims(claims).setIssuedAt(new Date(instantNow)) .setExpiration(new Date(instantNow + EXPIRED_TIME)) .signWith(SIGN_TYPE, SECRET).compact(); &amp;#125; /** * 将token解析, 映射为 UserDetails * * @param jwtToken * @return */ public UserDetails getUserDetailsFromToken(String jwtToken) &amp;#123; Claims claimsFromToken = getClaimsFromToken(jwtToken); String userName = claimsFromToken.get(Claims.SUBJECT, String.class); UserDetailsImpl userDetails = new UserDetailsImpl(); userDetails.setUsername(userName); return userDetails; &amp;#125; /** * 验证token */ public Boolean validateToken(String token, UserDetails userDetails) &amp;#123; UserDetailsImpl user = (UserDetailsImpl) userDetails; String username = getPhoneNoFromToken(token); return (username.equals(user.getUsername()) &amp;&amp; !isTokenExpired(token)); &amp;#125; /** * 刷新令牌 * * @param token 原令牌 * @return 新令牌 */ public String refreshToken(String token) &amp;#123; String refreshedToken; try &amp;#123; Claims claims = getClaimsFromToken(token); long instantNow = Instant.now().toEpochMilli(); refreshedToken = Jwts.builder().setClaims(claims).setIssuedAt(new Date(instantNow)) .setExpiration(new Date(instantNow + EXPIRED_TIME)) .signWith(SIGN_TYPE, SECRET).compact(); &amp;#125; catch (Exception e) &amp;#123; refreshedToken = null; &amp;#125; return refreshedToken; &amp;#125; /** * 获取token是否过期 */ public Boolean isTokenExpired(String token) &amp;#123; Date expiration = getExpirationDateFromToken(token); return expiration.before(new Date()); &amp;#125; /** * 根据token获取username */ public String getPhoneNoFromToken(String token) &amp;#123; return getClaimsFromToken(token).getSubject(); &amp;#125; /** * 获取token的过期时间 */ public Date getExpirationDateFromToken(String token) &amp;#123; return getClaimsFromToken(token).getExpiration(); &amp;#125; /** * 解析JWT */ private Claims getClaimsFromToken(String token) &amp;#123; return Jwts.parser().setSigningKey(SECRET).parseClaimsJws(token).getBody(); &amp;#125; &amp;#125; WebSecurityConfig 核心配置package com.liuzhihang.demo.config; import com.liuzhihang.demo.filter.CustomizeAuthenticationFilter; import com.liuzhihang.demo.filter.JwtPerTokenFilter; import com.liuzhihang.demo.service.UserDetailServiceImpl; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.web.AuthenticationEntryPoint; import org.springframework.security.web.access.AccessDeniedHandler; import org.springframework.security.web.authentication.AuthenticationFailureHandler; import org.springframework.security.web.authentication.AuthenticationSuccessHandler; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import javax.annotation.Resource; /** * @author liuzhihang * @date 2019-06-03 14:25 */ @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter &amp;#123; @Autowired private UserDetailServiceImpl userDetailServiceImpl; @Resource private JwtPerTokenFilter jwtPerTokenFilter; @Resource(name = \"authenticationEntryPointImpl\") private AuthenticationEntryPoint authenticationEntryPoint; @Resource(name = \"authenticationSuccessHandlerImpl\") private AuthenticationSuccessHandler authenticationSuccessHandler; @Resource(name = \"authenticationFailureHandlerImpl\") private AuthenticationFailureHandler authenticationFailureHandler; @Resource(name = \"accessDeniedHandlerImpl\") private AccessDeniedHandler accessDeniedHandler; /** * 创建用于认证授权的用户 * * @param auth * @throws Exception */ @Autowired public void configureUserInfo(AuthenticationManagerBuilder auth) throws Exception &amp;#123; // 放入自己的认证授权用户, 内部逻辑需要自己实现 // UserDetailServiceImpl implements UserDetailsService auth.userDetailsService(userDetailServiceImpl); &amp;#125; @Override protected void configure(HttpSecurity http) throws Exception &amp;#123; http // 使用JWT, 关闭session .csrf().disable().sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and().httpBasic().authenticationEntryPoint(authenticationEntryPoint) // 登录的权限, 成功返回信息, 失败返回信息 .and().formLogin().permitAll() .loginProcessingUrl(\"/login\") // 配置url 权限 antMatchers: 匹配url 权限 .and().authorizeRequests() .antMatchers(\"/login\", \"/getVersion\") .permitAll() // 其他需要登录才能访问 .anyRequest().access(\"@dynamicAuthorityService.hasPermission(request,authentication)\") // 访问无权限 location 时 .and().exceptionHandling().accessDeniedHandler(accessDeniedHandler) // 自定义过滤 .and().addFilterAt(customAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class) .addFilterBefore(jwtPerTokenFilter, UsernamePasswordAuthenticationFilter.class) .headers().cacheControl(); &amp;#125; /** * 密码加密器 */ @Bean public PasswordEncoder passwordEncoder() &amp;#123; /** * BCryptPasswordEncoder：相同的密码明文每次生成的密文都不同，安全性更高 */ return new BCryptPasswordEncoder(); &amp;#125; @Bean CustomizeAuthenticationFilter customAuthenticationFilter() throws Exception &amp;#123; CustomizeAuthenticationFilter filter = new CustomizeAuthenticationFilter(); filter.setAuthenticationSuccessHandler(authenticationSuccessHandler); filter.setAuthenticationFailureHandler(authenticationFailureHandler); filter.setAuthenticationManager(authenticationManagerBean()); return filter; &amp;#125; &amp;#125; 登录校验过程graph TD; A(请求登录) --&gt; B(CustomizeAuthenticationFilter#attemptAuthentication 解析请求的json); B --&gt; C(UserDetailServiceImpl#loadUserByUsername 验证用户名密码); C --&gt; D(AuthenticationSuccessHandlerImpl#onAuthenticationSuccess 构建返回参数 包括token); D --&gt; E(返回结果) 自定义拦截器解析 json 报文前端请求登录报文类型为 application/json 需要后端增加拦截器, 对登录请求报文进行解析 package com.liuzhihang.demo.filter; import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONException; import com.alibaba.fastjson.JSONObject; import lombok.extern.slf4j.Slf4j; import org.springframework.http.MediaType; import org.springframework.security.authentication.AuthenticationServiceException; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.Authentication; import org.springframework.security.core.AuthenticationException; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.BufferedReader; import java.io.IOException; /** * * 自定义拦截器, 重写UsernamePasswordAuthenticationFilter 从而可以处理 application/json 中的json请求报文 * * @author liuzhihang * @date 2019-06-12 19:04 */ @Slf4j public class CustomizeAuthenticationFilter extends UsernamePasswordAuthenticationFilter &amp;#123; @Override public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &amp;#123; // attempt Authentication when Content-Type is json if (request.getContentType().equalsIgnoreCase(MediaType.APPLICATION_JSON_UTF8_VALUE) || request.getContentType().equalsIgnoreCase(MediaType.APPLICATION_JSON_VALUE)) &amp;#123; try &amp;#123; BufferedReader br = request.getReader(); String str; StringBuilder jsonStr = new StringBuilder(); while ((str = br.readLine()) != null) &amp;#123; jsonStr.append(str); &amp;#125; log.info(\"本次登录请求参数:&amp;#123;&amp;#125;\", jsonStr); JSONObject jsonObject = JSON.parseObject(jsonStr.toString()); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( jsonObject.getString(\"username\"), jsonObject.getString(\"password\")); setDetails(request, authRequest); return this.getAuthenticationManager().authenticate(authRequest); &amp;#125; catch (IOException e) &amp;#123; log.info(\"用户登录, 请求参数 不正确\"); throw new AuthenticationServiceException(\"获取报文请求参数失败\"); &amp;#125; catch (JSONException e) &amp;#123; log.info(\"用户登录, 请求报文格式 不正确\"); throw new AuthenticationServiceException(\"请求报文, 转换Json失败\"); &amp;#125; &amp;#125; else &amp;#123; log.error(\"用户登录, contentType 不正确\"); throw new AuthenticationServiceException( \"请求 contentType 不正确, 请使用 application/json;charset=UTF-8 或者 application/json;\"); &amp;#125; &amp;#125; &amp;#125; 用户认证模块 根据获取到的username从数据库中查询到密码, 将用户名密码赋值给UserDetails对象, 返回其他的框架会进行校验 这边使用中是使用的手机号+验证码登录, 所以 上面json解析的也是 phoneNo+verificationCode 在这块 username仅仅代指登录名, 可以是手机号可以是别的. 这边使用中验证码是从redis中获取的. 获取不到返回失败, 获取到和传递的不一致也算失败. package com.liuzhihang.demo.service; import com.liuzhihang.demo.bean.UserDetailsImpl; import lombok.extern.slf4j.Slf4j; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.stereotype.Component; /** * @author liuzhihang */ @Slf4j @Component(\"userDetailServiceImpl\") public class UserDetailServiceImpl implements UserDetailsService &amp;#123; /** * 用来验证登录名是否有权限进行登录 * * 可以通过数据库进行校验 也可以通过redis 等等 * * @param username * @return * @throws UsernameNotFoundException */ @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &amp;#123; UserDetailsImpl userDetailsImpl = new UserDetailsImpl(); userDetailsImpl.setUsername(\"liuzhihang\"); userDetailsImpl.setPassword(new BCryptPasswordEncoder().encode(\"123456789\")); return userDetailsImpl; &amp;#125; &amp;#125; 请求校验过程graph TD; A(请求接口) --&gt; B(JwtPerTokenFilter#doFilterInternal 验证Header中的token); B --&gt; C(DynamicAuthorityService#hasPermission 验证有没有请求url权限); C --&gt; D(处理逻辑); D --&gt; E(返回结果) JWTToken拦截器主要是拦截请求, 验证Header中的token是否正确 package com.liuzhihang.demo.filter; import com.liuzhihang.demo.utils.JwtTokenUtil; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.web.authentication.WebAuthenticationDetailsSource; import org.springframework.stereotype.Component; import org.springframework.web.filter.OncePerRequestFilter; import javax.servlet.FilterChain; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * @author liuzhihang * @date 2019-06-05 09:09 */ @Slf4j @Component public class JwtPerTokenFilter extends OncePerRequestFilter &amp;#123; @Autowired private JwtTokenUtil jwtTokenUtil; /** * 存放Token的Header Key */ private static final String HEADER_STRING = \"token\"; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &amp;#123; String token = request.getHeader(HEADER_STRING); if (null != token &amp;&amp; !jwtTokenUtil.isTokenExpired(token)) &amp;#123; UserDetails userDetails = jwtTokenUtil.getUserDetailsFromToken(token); String username = userDetails.getUsername(); if (username != null &amp;&amp; SecurityContextHolder.getContext().getAuthentication() == null) &amp;#123; // 通过 username 查询数据库 获取token 然后和库中token作比较 if (username.equals(\"liuzhihang\")) &amp;#123; UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities()); authentication.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); SecurityContextHolder.getContext().setAuthentication(authentication); &amp;#125; &amp;#125; &amp;#125; filterChain.doFilter(request, response); &amp;#125; &amp;#125; URI动态校验package com.liuzhihang.demo.service; import lombok.extern.slf4j.Slf4j; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.Authentication; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; import java.util.HashSet; import java.util.Set; /** * 动态权限认证 * * @author liuzhihang * @date 2019-06-25 15:51 */ @Slf4j @Component(value = \"dynamicAuthorityService\") public class DynamicAuthorityService &amp;#123; public boolean hasPermission(HttpServletRequest request, Authentication authentication) &amp;#123; try &amp;#123; Object principal = authentication.getPrincipal(); if (principal instanceof UserDetails &amp;&amp; authentication instanceof UsernamePasswordAuthenticationToken) &amp;#123; // 本次请求的uri String uri = request.getRequestURI(); // 获取当前用户 UserDetails userDetails = (UserDetails) principal; String username = userDetails.getUsername(); log.info(\"本次用户请求认证, username:&amp;#123;&amp;#125;, uri:&amp;#123;&amp;#125;\", username, uri); // 从数据库取逻辑 if (username.equals(\"liuzhihang\"))&amp;#123; Set&lt;String> set = new HashSet&lt;>(); set.add(\"/homeInfo\"); set.add(\"/getAllUser\"); set.add(\"/editUserInfo\"); if (set.contains(uri)) &amp;#123; return true; &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (Exception e) &amp;#123; log.error(\"用户请求登录, uri:&amp;#123;&amp;#125; error\", request.getRequestURI(), e); return false; &amp;#125; return false; &amp;#125; &amp;#125; 测试脚本在 httpclient脚本 POST localhost:8080/login Content-Type: application/json &amp;#123; \"username\": \"liuzhihang\", \"password\": \"123456789\" &amp;#125; ### 请求接口脚本 POST localhost:8080/homeInfo Content-Type: application/json token: eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJsaXV6aGloYW5nIiwiaWF0IjoxNTY5MDI1NjY4LCJleHAiOjE1Njk2MzA0Njh9.Kot_uLnwtcq-t5o4x3V-xBnpf-mKEi7OV2eAfgMCKLk ### 返回: &amp;#123; \"resultCode\": \"0000\", \"resultMsg\": \"登录成功\", \"resultTime\": \"20190920191038\", \"token\": \"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJsaXV6aGloYW5nIiwiaWF0IjoxNTY4OTc3ODM4LCJleHAiOjE1Njk1ODI2Mzh9.MAS9VkFdCF3agkCgTtc0VzPMFjY42vFyIvAEzkSeAfs\" &amp;#125; 参考前后端分离 SpringBoot + SpringSecurity + JWT + RBAC 实现用户无状态请求验证","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"https://liuzhihang.com/tags/JWT/"},{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"https://liuzhihang.com/tags/SpringSecurity/"}]},{"title":"Gitalk使用MD5生成Id","slug":"hexo/Gitalk使用MD5生成Id","date":"2019-07-20T07:43:07.000Z","updated":"2020-04-07T11:58:47.380Z","comments":true,"path":"2019/07/20/gitalk-uses-md5-to-generate-an-id.html","link":"","permalink":"https://liuzhihang.com/2019/07/20/gitalk-uses-md5-to-generate-an-id.html","excerpt":"","text":"Gitalk默认使用: location.pathname 作为 gitalk 的id, 但是location.path必须小于50位切换主题时, 每个主题使用的处理方式都不相同, 有可能会导致换了主题, 发现之前的评论不见了, 下面介绍使用MD5作为id, 同时在换主题时一定要修改这个id的规则. Gitalk使用使用Gitalk方法: var gitalk = new Gitalk(&amp;#123; clientID: 'GitHub Application Client ID', clientSecret: 'GitHub Application Client Secret', repo: 'GitHub repo', owner: 'GitHub repo owner', admin: ['GitHub repo owner and collaborators, only these guys can initialize github issues'], id: location.pathname, // Ensure uniqueness and length less than 50 distractionFreeMode: false // Facebook-like distraction free mode &amp;#125;) gitalk.render('gitalk-container') 使用MD5生成id 引入js MD5 js 下载地址 &lt;script src=\"js/md5.min.js\">&lt;/script> 修改js &lt;script> var gitalk_id = md5(location.pathname) if (&lt;%- page.comments_type == '404' %>) &amp;#123; gitalk_id = md5('https://liuzhihang.com/404') &amp;#125; let gitalk = new Gitalk(&amp;#123; clientID: '&lt;%- theme.gitalk.oauth.clientId %>', clientSecret: '&lt;%- theme.gitalk.oauth.clientSecret %>', repo: '&lt;%- theme.gitalk.repo %>', owner: '&lt;%- theme.gitalk.owner %>', admin: &lt;%- JSON.stringify(theme.gitalk.admin) %>, id: gitalk_id, distractionFreeMode: false // Facebook-like distraction free mode &amp;#125;); gitalk.render('gitalk-container'); &lt;/script>","categories":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/tags/hexo/"}]},{"title":"IDEA插件--Toolkit","slug":"plugin/tookit","date":"2019-05-11T06:50:48.000Z","updated":"2020-09-12T17:22:04.156Z","comments":true,"path":"2019/05/11/idea-plugin-toolkit.html","link":"","permalink":"https://liuzhihang.com/2019/05/11/idea-plugin-toolkit.html","excerpt":"","text":"Toolkit 一个小工具包, 暂时还有很多功能需要扩展. 特征 Mybatis 通过侧栏箭头在 MyBatis XML文件和 Mapper文件之间相互跳转 mapper文件id简单检查 Json JavaBean复制为Json字符串 Json字符串格式化 Json字符串转换为JavaBean Json压缩 XML: Xml格式化 演示 文末演示 安装 在线安装: File -&gt; Setting -&gt; Plugins -&gt; 搜索 Toolkit 手动安装: 下载插件 -&gt; File -&gt; Setting -&gt; Plugins -&gt; Install Plugin from Disk... 使用 右键菜单选择 Tookit 更新v1.0.7 (2020-02-27) 修改使用包装类型 查看更多历史更新记录 感谢MyBatis:&emsp;mybatis support: https://github.com/zhaoqin102/mybatis-support &emsp;free-idea-mybatis: https://github.com/wuzhizhan/free-idea-mybatis Json:&emsp;GsonFormat: https://github.com/zzz40500/GsonFormat 本工具使用 JetBrains IDEA 进行开发 演示","categories":[{"name":"IDEA","slug":"IDEA","permalink":"https://liuzhihang.com/categories/IDEA/"}],"tags":[{"name":"plugin","slug":"plugin","permalink":"https://liuzhihang.com/tags/plugin/"}]},{"title":"elasticsearch cat API","slug":"elk/es-cat","date":"2019-03-14T14:01:00.000Z","updated":"2020-04-04T06:17:45.542Z","comments":true,"path":"2019/03/14/elasticsearch-cat-api.html","link":"","permalink":"https://liuzhihang.com/2019/03/14/elasticsearch-cat-api.html","excerpt":"cat API官方地址 GET /_cat/XXX?vGET /_cat/XXX?v&amp;format=json v 是指带着列信息 支持指定返回内容的格式 默认为text ?format=text(json/smile/yaml/cbor)","text":"cat API官方地址 GET /_cat/XXX?vGET /_cat/XXX?v&amp;format=json v 是指带着列信息 支持指定返回内容的格式 默认为text ?format=text(json/smile/yaml/cbor) 查看节点别名 GET /_cat/aliases?vcurl -X GET “192.168.xxx.xxx:9200/_cat/aliases?v” 每个节点分配了几个shard，对磁盘的占用空间大小，使用率 GET /_cat/allocation?vcurl -X GET “192.168.xxx.xxx:9200/_cat/allocation?v” 群集或单个索引的document计数 GET /_cat/count?vcurl -X GET “192.168.xxx.xxx:9200/_cat/count?v GET /_cat/count/index_name?vcurl -X GET “192.168.xxx.xxx:9200/_cat/count/index_name?v” 显示集群中每个数据节点上fielddata当前正在使用的堆内存量 GET /_cat/fielddata?vcurl -X GET “192.168.xxx.xxx:9200/_cat/fielddata?v” 查看集群健康情况 GET /_cat/health?vcurl -X GET “192.168.xxx.xxx:9200/_cat/health?v” 查看索引的信息 GET _cat/indices?vGET _cat/indices/index_name?vcurl -X GET “192.168.xxx.xxx:9200/_cat/indices/twi*?v&amp;s=index” 查看master信息 GET /_cat/master?vcurl -X GET “192.168.xxx.xxx:9200/_cat/master?v” 查看node信息 GET /_cat/nodes?vcurl -X GET “192.168.xxx.xxx:9200/_cat/nodes?v” 当前pending没执行完的task的具体情况，执行的是什么操作 创建索引，更新映射，分配或失败分片的列表GET /_cat/pending_tasks?vcurl -X GET “192.168.xxx.xxx:9200/_cat/pending_tasks?v” 查看安装的插件 GET /_cat/plugins?v&amp;s=component&amp;h=name,component,version,descriptioncurl -X GET “192.168.xxx.xxx:9200/_cat/plugins?v&amp;s=component&amp;h=name,component,version,description” shard recovery恢复的过程情况 GET /_cat/recovery?vcurl -X GET “192.168.xxx.xxx:9200/_cat/recovery?v” 查看在群集中注册的快照存储库 GET /_cat/repositories?vcurl -X GET “192.168.xxx.xxx:9200/_cat/repositories?v 查看线程池使用 GET /_cat/thread_poolcurl -X GET “192.168.xxx.xxx:9200/_cat/thread_pool” 查看shard情况 GET _cat/shards?vGET _cat/shards/index_name?vcurl -X GET “192.168.xxx.xxx:9200/_cat/shards/index_name?v 索引segment文件的情况，在哪个node上，有多少个document，占用了多少磁盘空间，有多少数据在内存中，是否可以搜索 GET /_cat/segments?vGET _cat/segments/index_name?vcurl -X GET “192.168.xxx.xxx:9200/_cat/segments/index_name?v 查看tempalte GET /_cat/templates?v&amp;s=namecurl -X GET “192.168.xxx.xxx:9200/_cat/templates?v&amp;s=name”","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"为什么es集群至少需要三个节点","slug":"elk/es集群至少三个节点","date":"2019-03-13T13:01:04.000Z","updated":"2020-06-18T08:23:00.411Z","comments":true,"path":"2019/03/13/why-does-the-es-cluster-require-at-least-three-nodes.html","link":"","permalink":"https://liuzhihang.com/2019/03/13/why-does-the-es-cluster-require-at-least-three-nodes.html","excerpt":"elasticsearch集群graph LR; A(Master Node) --- B(Data Node); A --- C(Data Node); B --- C; Master: 在Elasticsearch中Master仅仅负责维护集群的状态 创建或删除索引 跟踪哪些节点是集群的一部分 决定将哪些碎片分配给哪个节点 等集群范围的操作 上面的一些集群信息, 是由Master节点进行维护, 但是 Master也会把节点信息, 同步给其他节点, 但是只有master节点可以修改.","text":"elasticsearch集群graph LR; A(Master Node) --- B(Data Node); A --- C(Data Node); B --- C; Master: 在Elasticsearch中Master仅仅负责维护集群的状态 创建或删除索引 跟踪哪些节点是集群的一部分 决定将哪些碎片分配给哪个节点 等集群范围的操作 上面的一些集群信息, 是由Master节点进行维护, 但是 Master也会把节点信息, 同步给其他节点, 但是只有master节点可以修改. 点击查看Elasticsearch节点介绍 为什么要至少三个节点首先查看 Elasticsearch 的配置文件, 如下:Zen Discovery 官方介绍 # 传递初始主机列表，以便在启动新节点时执行发现 discovery.zen.ping.unicast.hosts: [\"192.168.xxx.xxx:9300\", \"192.168.xxx.xxx:9300\"] # 选举Maste时需要的节点数 (total number of master-eligible nodes / 2 + 1) 防止“防止脑裂” discovery.zen.minimum_master_nodes: 2 # 一个节点多久ping一次，默认1s discovery.zen.fd.ping_interval: 1s # 等待ping返回时间，默认30s discovery.zen.fd.ping_timeout: 30s # ping超时重试次数，默认3次 discovery.zen.fd.ping_retries: 3 discovery.zen.minimum_master_nodes: 2 其中 minimum_master_nodes 配置是为了防止脑裂 假设 Elasticsearch 有两个节点graph LR; A(Master Node) --- B(Data Node); graph LR; A(Master Node) -.X.- B(Data Node); discovery.zen.minimum_master_nodes: 1 此时出现网络波动, 导致 A—B 之间短暂断开连接, 根据选举规则, B将自己选举为 Master, 当网络波动结束, 就会出现两个Master的情况. graph LR; A(Master Node 宕机) --- B(Data Node); discovery.zen.minimum_master_nodes: 2 Master 出现故障, 则 B 将永远不可能将自己选择为 Master Elasticsearch 有三个节点三节点配置: discovery.zen.minimum_master_nodes: 2 graph LR; A(Master Node) -.X.- B(Data Node); A -.X.- C(Data Node); B --- C; 出现网络波动 A 节点 和 别的节点短暂断开连接 graph LR; A(Master Node -&gt; Data Node) -.X.- B(Data Node -&gt; Master Node); A -.X.- C(Data Node); B --- C; A节点降级, B和C 进行选举, 此处模拟选举B为 Master Node graph LR; A(Data Node) --- B(Master Node); A --- C(Data Node); B --- C; 网络恢复后的节点状况. 总结以上可以看出, 通过配置 minimum_master_nodes 来防止出现脑裂同时在生产过程中, 为了尽量保持集群高可用, 至少需要三台机器搭建集群","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"Elasticsearch 数据写入流程","slug":"elk/es数据写入过程","date":"2019-03-12T06:25:59.000Z","updated":"2020-04-04T06:49:14.257Z","comments":true,"path":"2019/03/12/elasticsearch-data-writing-process.html","link":"","permalink":"https://liuzhihang.com/2019/03/12/elasticsearch-data-writing-process.html","excerpt":"简单流程 客户端随机选择一个node发送数据, 此时该node为协调节点(coordinating node) 1.1. coordinating node 通过 _id计算出该document在哪个shard上, 假设为shard0, 计算方式如下: hash(_id) % number_of_primary_shards 1.2. node 根据 cluster state 获取到 shard0 在 node1 上","text":"简单流程 客户端随机选择一个node发送数据, 此时该node为协调节点(coordinating node) 1.1. coordinating node 通过 _id计算出该document在哪个shard上, 假设为shard0, 计算方式如下: hash(_id) % number_of_primary_shards 1.2. node 根据 cluster state 获取到 shard0 在 node1 上 将消息发送到 node1 的 P0 上 P0 收到数据后, 将数据同步到 自己的 replica shard R0上 P0 和 R0 都处理完毕, 才会返回客户端成功 Px 为 primary shardRx 为 replica shard当客户端请求为查询时, 路由到任意 shard(primary shard 或者 replica shard) 查询到数据即可返回. 详细流程 P0收到document, 同时将数据写入到 内存buffer和translog中 每隔1s或buffer满时, buffer中的数据会 refresh 到segment中, 而后进入os cache, 一旦segment进入到 cache中,其中的数据, 则可以被搜索到 refresh 时间可以手动设置, 也可以手动触发 refresh 清空buffer, translog不处理 重复1-3操作, translog不断增大, translog每隔30分钟,或大到一定量时, 会触发commit操作 将buffer中内容刷新到segment中, 并清空buffer 将一个commit point 写入到磁盘文件中, 标识此次commit 对应的 segment 执行 fsync 将 os cache 中的数据强制刷新到磁盘文件中 删除 translog 文件 删除和更新操作 在commit时, 如果操作为删除, 生成一个 .del文件, 其中将该document标记位deleted, 并不是真正的物理删除, 此时如果有查询请求, 会先查询 .del文件中是否有该记录, 如果有, 则回复不存在.在commit时, 如果为更新操作, 则是将原document标记位deleted, 同时写入一条新数据 服务宕机重启, translog 日志作用 translog是先写入到 os cache中, 然后每隔5s写入到磁盘文件中, 假如服务宕掉, 可能会失去5s数据, 也可以修改写入磁盘的时机, 但是可能会影响性能translog中记录的是数据操作信息, 在服务宕机重启时, 会读取translog磁盘文件, 然后将translog中的数据重新恢复到 segment中, 然后进行后续操作 segment merge 过程 segment 持续生成, 会导致 segment不断变多, 占用文件句柄, cpu资源等等es后台有一个专门的程序负责合并segment, 将小的 segment 合成大的segment, 同时写一个commit point, 标识 新的segment file.打开新的segment供查询使用, 删除旧的 segmentsegment 合并过程中, 被标记位 deleted 的document 不会被合并. 即: 在合并 segment时, 才将 document 真正物理删除合并的segment 可以使磁盘上已经commit的索引 也可以是内存中还未commit的索引","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"logstash input多个kafka异常","slug":"issue/logstash-kafka-error","date":"2019-03-04T11:09:06.000Z","updated":"2020-06-18T08:21:30.033Z","comments":true,"path":"2019/03/04/logstash-input-multiple-kafka-exceptions.html","link":"","permalink":"https://liuzhihang.com/2019/03/04/logstash-input-multiple-kafka-exceptions.html","excerpt":"问题描述graph LR; filebeat --&gt; logstash; log4j --&gt; logstash; logstash --&gt; es; filebeat 和 log4j appender 同时到 kafka, logstash在启动时报错, 错误如下: javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=logstash-0","text":"问题描述graph LR; filebeat --&gt; logstash; log4j --&gt; logstash; logstash --&gt; es; filebeat 和 log4j appender 同时到 kafka, logstash在启动时报错, 错误如下: javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=logstash-0 问题原因及解决input 消费kafka时, 分别指定不同的 client_id. kafka &#123; bootstrap_servers =&gt; [&quot;192.168.103.43:9092&quot;] # 注意这里配置的kafka的broker地址不是zk的地址 client_id =&gt; &quot;kafka_client_1&quot; group_id =&gt; &quot;logstash&quot; topics =&gt; [&quot;ipaynow_log&quot;] # kafka topic 名称 consumer_threads =&gt; 5 decorate_events =&gt; true type =&gt; &quot;string&quot; codec =&gt; &quot;json&quot; &#125; kafka &#123; bootstrap_servers =&gt; [&quot;192.168.103.43:9092&quot;] # 注意这里配置的kafka的broker地址不是zk的地址 client_id =&gt; &quot;kafka_client_2&quot; group_id =&gt; &quot;logstash&quot; topics =&gt; [&quot;ipaynow-hunter&quot;] # kafka topic 名称 consumer_threads =&gt; 5 decorate_events =&gt; true type =&gt; &quot;string&quot; codec =&gt; plain &#123; charset=&gt;&quot;UTF-8&quot; &#125; &#125;","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"程序无异常中断","slug":"issue/程序无异常中断","date":"2019-02-15T02:46:48.000Z","updated":"2020-04-04T06:23:27.483Z","comments":true,"path":"2019/02/15/no-abnormal-interruption-of-the-program.html","link":"","permalink":"https://liuzhihang.com/2019/02/15/no-abnormal-interruption-of-the-program.html","excerpt":"问题描述 程序执行到某一处之后停顿, 不能继续执行, 不抛出异常, 无返回值 本地测试正常 debug可以正常执行 操作为入库之前, 创建对象, 是一个很简单的set操作 payInfoExtra.setToAccType(agPayReqDto.getToAccType().getValue()); 其中get操作获取的为一个枚举, 主要操作为从枚举中获取value set到另一个对象中","text":"问题描述 程序执行到某一处之后停顿, 不能继续执行, 不抛出异常, 无返回值 本地测试正常 debug可以正常执行 操作为入库之前, 创建对象, 是一个很简单的set操作 payInfoExtra.setToAccType(agPayReqDto.getToAccType().getValue()); 其中get操作获取的为一个枚举, 主要操作为从枚举中获取value set到另一个对象中 public AccTypeEnum getToAccType() &amp;#123; return toAccType; &amp;#125; 问题原因及解决小伙伴在他们项目中复用本项目中的枚举类, 没有修改包名类名, 但是把枚举中value字段从 byte改成了String, 同时放在了依赖中, 提供给我们使用.解决方案就很简单了, 让小伙伴修改包名类名就可以了.原枚举类如下: public enum AccTypeEnum &amp;#123; PRI((byte) 0, \"对私\"), PUB((byte) 1, \"对公\"); private byte value; private String desc; &amp;#125;","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"}]},{"title":"skywalking5集群部署","slug":"skywalking/skywalking5集群部署","date":"2018-12-27T03:27:37.000Z","updated":"2020-04-04T06:25:19.101Z","comments":true,"path":"2018/12/27/skywalking5-cluster-deployment.html","link":"","permalink":"https://liuzhihang.com/2018/12/27/skywalking5-cluster-deployment.html","excerpt":"准备环境 skywalking-5.0.0-GA zookeeper-3.4.10 elasticsearch-5.6.14 下载地址如下: skywalking: http://skywalking.apache.org/downloads/ zookeeper: http://mirrors.hust.edu.cn/apache/zookeeper/ elasticsearch: https://www.elastic.co/downloads/past-releases","text":"准备环境 skywalking-5.0.0-GA zookeeper-3.4.10 elasticsearch-5.6.14 下载地址如下: skywalking: http://skywalking.apache.org/downloads/ zookeeper: http://mirrors.hust.edu.cn/apache/zookeeper/ elasticsearch: https://www.elastic.co/downloads/past-releases 安装zk集群 下载并解压zkwget http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz tar -xvf zookeeper-3.4.10.tar.gz 修改配置文件cd zookeeper-3.4.10/conf/ cp zoo_sample.cfg zoo.cfg vim zoo.cfg 内容如下tickTime=2000 initLimit=10 syncLimit=5 dataDir=/opt/export/app/zookeeper-3.4.10/data clientPort=2181 server.1=192.168.***.236:2888:3888 server.2=192.168.***.237:2888:3888 写入集群myidecho 1 > /opt/export/app/zookeeper-3.4.10/data/myid # 另一台机器则写入2 zk基本命令# 在zk的bin目录下 # 启动 ./zkServer.sh start # 停止 ./zkServer.sh stop # 查看状态 ./zkServer.sh status # 查看zk的节点 ./zkCli.sh # 连接后使用 ls / 命令查看 ls /skywalking 安装es集群 下载并解压eswget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.14.tar.gz tar -xvf elasticsearch-5.6.14.tar.gz 修改配置文件cd elasticsearch-5.6.14/config/ vim elasticsearch.yml 内容如下cluster.name: CollectorDBCluster node.name: node-1 path.data: /opt/export/app/elasticsearch-5.6.14/data path.logs: /opt/export/app/elasticsearch-5.6.14/logs network.host: 192.168.***.234 discovery.zen.ping.unicast.hosts: [\"192.168.***.234:9300\", \"192.168.***.235:9300\"] discovery.zen.minimum_master_nodes: 2 bootstrap.memory_lock: false bootstrap.system_call_filter: false # 修改上报数据线程池大小 thread_pool.bulk.queue_size: 1000 常用命令# 后台启动 bin/elasticsearch -d # 删除所有索引 curl -XDELETE 192.168.***.234:9200/* 安装skywalking☞ 官方地址 下载并解压wget http://mirrors.shu.edu.cn/apache/incubator/skywalking/5.0.0-GA/apache-skywalking-apm-incubating-5.0.0-GA.tar.gz tar -xvf apache-skywalking-apm-incubating-5.0.0-GA.tar.gz mv apache-skywalking-apm-incubating-5.0.0-GA skywalking-5.0.0-GA 修改配置cd skywalking-5.0.0-GA/config/ vim application.yml 修改内容如下 集群配置cluster: zookeeper: hostPort: 192.168.***.236:2181,192.168.***.237:2181 sessionTimeout: 100000 es配置storage: elasticsearch: clusterName: CollectorDBCluster clusterTransportSniffer: true clusterNodes: 192.168.***.234:9300,192.168.***.235:9300 # 其他配置 其他配置# host配置修改 host: 192.168.***.236 修改webapp配置vim webapp/webapp.yml collector: path: /graphql ribbon: ReadTimeout: 10000 listOfServers: 192.168.**.236:10800,192.168.**.237:10800 常用命令# 启动collector+webUI bin/startup.sh # 只启动collector或webUI bin/collectorService.sh bin/webappService.sh 探针使用 ☞ 官方地址 java -javaagent:/path/to/skywalking-agent/skywalking-agent.jar -jar yourApp.jar","categories":[{"name":"skywalking","slug":"skywalking","permalink":"https://liuzhihang.com/categories/skywalking/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"},{"name":"skywalking","slug":"skywalking","permalink":"https://liuzhihang.com/tags/skywalking/"}]},{"title":"logstash时间戳差8个小时","slug":"issue/处理logstash时间戳差8个小时","date":"2018-12-20T07:11:16.000Z","updated":"2020-04-04T06:23:27.485Z","comments":true,"path":"2018/12/20/logstash-timestamp-difference-8-hours.html","link":"","permalink":"https://liuzhihang.com/2018/12/20/logstash-timestamp-difference-8-hours.html","excerpt":"问题说明原始配置: elasticsearch &#123; # manage_template =&gt; false template_overwrite =&gt; true template =&gt; &quot;/opt/export/app/logstash-6.4.2/bin/dynamic_templates.json&quot; user =&gt; xxxxxxx password =&gt; xxxxxxx index =&gt; &quot;%&#123;sys_name&#125;-%&#123;+YYYY.MM.dd&#125;&quot; hosts =&gt; [&quot;172.19.3.51:9200&quot;,&quot;172.19.3.52:9200&quot;] &#125; 在使用logstash输出内容要es中时, 指定index为系统名称+时间(年月日), 时间会自动匹配‘@timestamp’字段并格式化, 但是在实际使用过程中, 发现在上午八点之前的消息会被创建到昨天的索引里面.查阅相关资料, 有介绍在时间戳上面增加8个小时的方式, 也可以使用. 这里结合自己业务使用的其他方式.","text":"问题说明原始配置: elasticsearch &#123; # manage_template => false template_overwrite => true template => \"/opt/export/app/logstash-6.4.2/bin/dynamic_templates.json\" user => xxxxxxx password => xxxxxxx index => \"%&#123;sys_name&#125;-%&#123;+YYYY.MM.dd&#125;\" hosts => [\"172.19.3.51:9200\",\"172.19.3.52:9200\"] &#125; 在使用logstash输出内容要es中时, 指定index为系统名称+时间(年月日), 时间会自动匹配‘@timestamp’字段并格式化, 但是在实际使用过程中, 发现在上午八点之前的消息会被创建到昨天的索引里面.查阅相关资料, 有介绍在时间戳上面增加8个小时的方式, 也可以使用. 这里结合自己业务使用的其他方式. 解决方案 主要报送内容为filebeat的日志信息, 日志统一有时间戳, 格式如下: [trans-mediapay]-[2018-12-19 02:00:00:187]-[queryThreadPool-14]-[]-[WeBankServiceImpl.java:101]-[INFO ]-[测试2点的日志] 解析时间戳的时间 先匹配整体日志, 获取’log_time’字段 匹配’log_time’字段 生成元数据 ‘[@metadata][index_suffix]’ filter &amp;#123; # 日志聚合使用全量配置 grok &amp;#123; match => &amp;#123; \"message\" => \"\\[%&amp;#123;DATA:sys_name&amp;#125;\\]-\\[%&amp;#123;DATA:log_time&amp;#125;\\]-\\[%&amp;#123;DATA:thread_name&amp;#125;\\]-\\[%&amp;#123;DATA:trace_id&amp;#125;\\]-\\[%&amp;#123;DATA:class_name&amp;#125;\\]-\\[%&amp;#123;DATA:log_level&amp;#125;\\]-%&amp;#123;GREEDYDATA:log_msg&amp;#125;\" &amp;#125; &amp;#125; grok&amp;#123; match => &amp;#123; \"log_time\" => [\"%&amp;#123;INT:index_year&amp;#125;-%&amp;#123;INT:index_mouth&amp;#125;-%&amp;#123;INT:index_day&amp;#125;\"]&amp;#125; &amp;#125; mutate &amp;#123; # 使用元数据 [@metadata][index_suffix] add_field => &amp;#123; \"[@metadata][index_suffix]\" => \"%&amp;#123;index_year&amp;#125;.%&amp;#123;index_mouth&amp;#125;.%&amp;#123;index_day&amp;#125;\" &amp;#125; remove_field => [\"host\",\"beat\",\"tags\",\"[beat][name]\",\"[beat][version]\",\"prospector\",\"@version\",\"offset\",\"input\",\"y_index\",\"M_index\",\"d_index\"] &amp;#125; } 3. 输出时使用元数据, 该字段不会出现在es的字段中 ```bash elasticsearch &#123; # manage_template =&gt; false template_overwrite =&gt; true template =&gt; &quot;/opt/export/app/logstash-6.4.2/bin/dynamic_templates.json&quot; user =&gt; xxxxxxx password =&gt; xxxxxxx index =&gt; &quot;%&#123;sys_name&#125;-%&#123;[@metadata][index_suffix]&#125;&quot; hosts =&gt; [&quot;xxxx:9200&quot;,&quot;xxxx:9200&quot;] &#125;","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"获取IP和byte转long遇到的小问题","slug":"issue/获取IP&byte转long","date":"2018-12-10T11:46:01.000Z","updated":"2020-04-04T06:23:27.488Z","comments":true,"path":"2018/12/10/get-the-small-problem-encountered-by-ip-and-byte-to-long.html","link":"","permalink":"https://liuzhihang.com/2018/12/10/get-the-small-problem-encountered-by-ip-and-byte-to-long.html","excerpt":"介绍因为业务需求新项目的流水号系统从 ‘数据库自增步长+分段式锁’ 换成使用 雪花流水号, 修改机器标识和数据中心字段为自动获取ip后三位, 人工保证ip后三位不相同 示例雪花流水号 - 改造版 修改内容如下:删除构造, 修改数据位数, 添加静态代码块","text":"介绍因为业务需求新项目的流水号系统从 ‘数据库自增步长+分段式锁’ 换成使用 雪花流水号, 修改机器标识和数据中心字段为自动获取ip后三位, 人工保证ip后三位不相同 示例雪花流水号 - 改造版 修改内容如下:删除构造, 修改数据位数, 添加静态代码块 private final static long MACHINE_BIT = 8; private final static long DATA_CENTER_BIT = 2; static &amp;#123; try &amp;#123; InetAddress localHost = InetAddress.getLocalHost(); address = localHost.getAddress()[3] &amp; 0xff; System.out.println(\"当前系统的 address 为: \" + address); &amp;#125; catch (UnknownHostException e) &amp;#123; throw new IllegalArgumentException(\"DATA_CENTER_ID can't be greater than MAX_DATA_CENTER_NUM or less than 0\"); &amp;#125; &amp;#125; 注意点服务器配置host服务器对应的 hostname 需要配置ip地址 cat /etc/hosts byte 转换 long需要 &amp; 0xff当获取ip大于127时转换出来为负值, 所以需要 &amp; 0xff","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"ip","slug":"ip","permalink":"https://liuzhihang.com/tags/ip/"}]},{"title":"基于LinkHashMap的LRU缓存淘汰","slug":"redis/LRULinkedHashMap","date":"2018-11-19T13:24:52.000Z","updated":"2020-04-04T06:24:26.301Z","comments":true,"path":"2018/11/19/elimination-of-lru-cache-based-on-linkhashmap.html","link":"","permalink":"https://liuzhihang.com/2018/11/19/elimination-of-lru-cache-based-on-linkhashmap.html","excerpt":"","text":"LRU缓存淘汰LRU缓存淘汰是redis中的一种淘汰策略, 当内存大小不足以存放数据时, 此时存入新数据, 将删除较早存入的数据.在dubbo中使用LRU来缓存 hostName.在mysql中使用LRU来缓存 serverSideStatementCheckCache 和 serverSideStatementCache. 代码实现package com.ipaynow.tool.lru; import java.util.LinkedHashMap; import java.util.Map; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * 基于LinkedHashMap LRU 缓存淘汰, 以下框架中都有使用 * dubbo com.alibaba.dubbo.common.utils.LRUCache * com.mysql.jdbc.util.LRUCache * * @author liuzhihang * @date 2018/11/20 10:43 */ public class LRULinkedHashMap&lt;K, V> extends LinkedHashMap&lt;K, V> &amp;#123; /** * 设置最大容量 */ private volatile int maxCapacity; private static final int DEFAULT_MAX_CAPACITY = 1000; private static final float DEFAULT_LOAD_FACTOR = 0.75f; private final Lock lock = new ReentrantLock(); public LRULinkedHashMap() &amp;#123; this.maxCapacity = DEFAULT_MAX_CAPACITY; &amp;#125; public LRULinkedHashMap(int maxCapacity) &amp;#123; // accessOrder设置为true 按照时间排序 super(maxCapacity, DEFAULT_LOAD_FACTOR, true); this.maxCapacity = maxCapacity; &amp;#125; /** * 当链表长度大于最大容量时 删除最旧的元素 */ @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V> eldest) &amp;#123; return size() > maxCapacity; &amp;#125; @Override public boolean containsKey(Object key) &amp;#123; try &amp;#123; lock.lock(); return super.containsKey(key); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; @Override public V get(Object key) &amp;#123; try &amp;#123; lock.lock(); return super.get(key); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; @Override public V put(K key, V value) &amp;#123; try &amp;#123; lock.lock(); return super.put(key, value); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; @Override public V remove(Object key) &amp;#123; try &amp;#123; lock.lock(); return super.remove(key); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; @Override public int size() &amp;#123; try &amp;#123; lock.lock(); return super.size(); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; @Override public void clear() &amp;#123; try &amp;#123; lock.lock(); super.clear(); &amp;#125; finally &amp;#123; lock.unlock(); &amp;#125; &amp;#125; public int getMaxCapacity() &amp;#123; return maxCapacity; &amp;#125; public void setMaxCapacity(int maxCapacity) &amp;#123; this.maxCapacity = maxCapacity; &amp;#125; &amp;#125; 测试代码及结果package com.ipaynow.tool.lru; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.util.Iterator; import java.util.Map; /** * @author liuzhihang * @date 2018/11/20 10:58 */ public class LRUTest &amp;#123; public static void main(String[] args) throws InterruptedException &amp;#123; LRULinkedHashMap&lt;String, String> map = new LRULinkedHashMap&lt;>(5); for (int i = 0; i &lt; 10; i++) &amp;#123; Thread.sleep(1000); map.put(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss SSS\")), \"value\" + i); &amp;#125; for (Iterator&lt;Map.Entry&lt;String, String>> iterator = map.entrySet().iterator(); iterator.hasNext(); ) &amp;#123; Map.Entry&lt;String, String> entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); System.out.println(key + \"------------\" + value); &amp;#125; &amp;#125; &amp;#125; 控制台输出结果: 2018-11-20 11:13:21 398------------value5 2018-11-20 11:13:22 399------------value6 2018-11-20 11:13:23 400------------value7 2018-11-20 11:13:24 400------------value8 2018-11-20 11:13:25 400------------value9 Process finished with exit code 0","categories":[{"name":"Redis","slug":"Redis","permalink":"https://liuzhihang.com/categories/Redis/"},{"name":"cache","slug":"Redis/cache","permalink":"https://liuzhihang.com/categories/Redis/cache/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://liuzhihang.com/tags/Redis/"},{"name":"cache","slug":"cache","permalink":"https://liuzhihang.com/tags/cache/"}]},{"title":"ELK常用启动命令","slug":"elk/elk-start-command","date":"2018-10-29T09:03:38.000Z","updated":"2020-04-04T06:11:20.190Z","comments":true,"path":"2018/10/29/elk-common-start-command.html","link":"","permalink":"https://liuzhihang.com/2018/10/29/elk-common-start-command.html","excerpt":"elasticsearch启动命令# 前台启动 关闭窗口连接后自动退出 ./bin/elasticsearch # 后台启动 ./bin/elasticsearch -d","text":"elasticsearch启动命令# 前台启动 关闭窗口连接后自动退出 ./bin/elasticsearch # 后台启动 ./bin/elasticsearch -d logstash启动命令# 前台启动 -f 后面为配置文件 ./logstash -f logstash.conf # 后台启动 nohup ./logstash -f logstash.conf &amp; kibana启动命令# 前台启动 ./bin/kibana # 后台启动 ./bin/kibana &amp; kibana停止命令当ps -ef | grep kibana 查不到时 可以lsof -i:5601kill -9 线程 filebeat启动命令# 前台启动 ./filebeat -e -c filebeat.yml # 后台启动 不输出日志/输出日志 nohup ./filebeat -e -c filebeat.yml >/dev/null 2>&amp;1 &amp; nohup ./filebeat -e -c filebeat.yml > filebeat.log &amp; jar包启动命令# 前台启动 java -jar server.ja # 后台启动 nohup java -jar server.jar &amp;","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"search-guard-6 配置用户","slug":"elk/search-guard-6-config-user","date":"2018-10-24T09:13:45.000Z","updated":"2020-04-04T06:18:21.574Z","comments":true,"path":"2018/10/24/searchguard6-configuration-user.html","link":"","permalink":"https://liuzhihang.com/2018/10/24/searchguard6-configuration-user.html","excerpt":"search-guard 配置用户路径: /opt/export/app/elasticsearch-6.4.2/plugins/search-guard-6/sgconfig 生成密码执行以下命令, 输入明文 plugins/search-guard-6/tools/hasher.sh -p mycleartextpassword","text":"search-guard 配置用户路径: /opt/export/app/elasticsearch-6.4.2/plugins/search-guard-6/sgconfig 生成密码执行以下命令, 输入明文 plugins/search-guard-6/tools/hasher.sh -p mycleartextpassword 1. 配置用户及密码文件: sg_internal_users.yml zhangsan: hash: $2y$12$yKXk785zSTtB3kE7g.XnbOPrc690g9JE50Znwum924i2M/xYGG4qq roles: - trans_group 格式: 姓名: 密码: XXXX(明文的hash, 使用search-guard的工具生成) 角色: - 角色名称 2. 配置权限文件: sg_roles.xml 配置’?kibana’ 及’?kibana-6’ 权限是为了保证用户在kibana中能够正常使用kibana sg_trans_group: cluster: - cluster:monitor/nodes - cluster:monitor/health indices: 'log-system': '*': - indices:admin/mappings/fields/get - indices:admin/validate/query - indices:data/read/search - indices:data/read/msearch - indices:admin/get - indices:data/read/field_stats '?kibana': '*': - MANAGE - INDEX - READ - DELETE '?kibana-6': '*': - MANAGE - INDEX - READ - DELETE 格式: 权限名称: 集群: - 集群名称:权限 索引: '索引名称': '类型': - 权限 3. 配置角色映射文件: sg_roles_mapping.yml 配置完用户的账户密码, 以及相应角色权限之后, 需要将用户和权限进行关联, 关联之后即可使用 sg_trans_group: backendroles: - trans_group 格式: 映射名称: 角色: - 用户的角色 也可以使用以下方式进行关联: sg_trans_group: users: - zhangsan - lisi # 即 映射名称: 用户名称: - 用户名 4. 使配置生效使用以下命令 ./sgadmin.sh -cn 集群名称 -cd ../sgconfig -ks ../../../config/sgadmin-keystore.jks -kspass changeit -ts ../../../config/truststore.jks -tspass changeit -nhnv","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"search-guard-6 安装","slug":"elk/search-guard-6-install","date":"2018-10-23T11:19:45.000Z","updated":"2020-04-04T06:18:30.040Z","comments":true,"path":"2018/10/23/searchguard6-installation.html","link":"","permalink":"https://liuzhihang.com/2018/10/23/searchguard6-installation.html","excerpt":"ES 安装 search-guard-6安装插件☞ 官方网站在ES目录下执行命令 bin/elasticsearch-plugin install -b com.floragunn:search-guard-6:6.4.2-23.1 注: 安装版本需要和Elasticsearch版本相对应. 查看版本 这里不使用官方的快速构建方法","text":"ES 安装 search-guard-6安装插件☞ 官方网站在ES目录下执行命令 bin/elasticsearch-plugin install -b com.floragunn:search-guard-6:6.4.2-23.1 注: 安装版本需要和Elasticsearch版本相对应. 查看版本 这里不使用官方的快速构建方法 生成证书 下载脚本 git clone https://github.com/floragunncom/search-guard-ssl.git 证书配置 路径 **/elasticsearch-6.4.2/search-guard-ssl/example-pki-scripts 目录内容 etc下可对证书进行配置 修改example.sh #!/bin/bash OPENSSL_VER=\"$(openssl version)\" if [[ $OPENSSL_VER == *\"0.9\"* ]]; then echo \"Your OpenSSL version is too old: $OPENSSL_VER\" echo \"Please install version 1.0.1 or later\" exit -1 else echo \"Your OpenSSL version is: $OPENSSL_VER\" fi set -e ./clean.sh # 第一个参数为CA根证书密码，第二个参数为TS密码(truststore，信任证书密码) ./gen_root_ca.sh capass changeit # 生成节点证书： 第一个参数为节点编号，第二个参数为keystore文件密码，第三个参数为CA根证书密码。 # 此处我们只生成两个节点证书 ./gen_node_cert.sh 0 changeit capass &amp;&amp; ./gen_node_cert.sh 1 changeit capass # 生成客户端证书： 第一个参数为客户端名称, 第二个参数为keystore文件名称，第三个参数为CA根证书名称。 ./gen_client_node_cert.sh spock changeit capass ./gen_client_node_cert.sh kirk changeit capass ./gen_client_node_cert.sh logstash changeit capass ./gen_client_node_cert.sh filebeat changeit capass ./gen_client_node_cert.sh kibana changeit capass # 生成一个sgadmin客户端证书，用于配置管理 ./gen_client_node_cert.sh sgadmin changeit capass # 生成一个javaapi访问的客户端证书 ./gen_client_node_cert.sh javaapi changeit capass rm -f ./*tmp* 生成证书移动到elasticsearch config 在ES目录下 ./example.sh cp node-0-keystore.jks sgadmin-keystore.jks truststore.jks /opt/export/app/elasticsearch-6.4.2/config/ 配置elasticsearch.yml, 增加以下配置 # 配置节点间通信证书，节点间通信使用TLS是强制的 searchguard.ssl.transport.keystore_filepath: node-0-keystore.jks searchguard.ssl.transport.keystore_password: changeit searchguard.ssl.transport.truststore_filepath: truststore.jks searchguard.ssl.transport.truststore_password: changeit # 设置不校验hostname searchguard.ssl.transport.enforce_hostname_verification: false searchguard.ssl.transport.resolve_hostname: false # 配置管理员证书DN searchguard.authcz.admin_dn: - CN=sgadmin,OU=client,O=client,L=Test, C=DE bootstrap.memory_lock: false bootstrap.system_call_filter: false xpack.security.enabled: false 启动访问需要权限 添加脚本权限并初始化用户cd /opt/export/app/elasticsearch-6.4.2/plugins/search-guard-6/tools chmod +x *.sh ./sgadmin.sh -cn cluster-es -cd ../sgconfig -ks ../../../config/sgadmin-keystore.jks -kspass changeit -ts ../../../config/truststore.jks -tspass changeit -nhnv 每次更新用户权限或者新增修改用户, 只需要重新执行第三条命令, 更新用户信息即可 Kibana安装参照官方网站安装配置即可. 官方网站, 或者按照以下步骤. 在kibana安装目录下执行一下吗命令 bin/kibana-plugin install https://search.maven.org/remotecontent?filepath=com/floragunn/search-guard-kibana-plugin/6.4.2-15/search-guard-kibana-plugin-6.4.2-15.zip 修改kibana.yml # Use HTTPS instead of HTTP # elasticsearch.url: \"https://localhost:9200\" elasticsearch.url: \"http://localhost:9200\" # Configure the Kibana internal server user elasticsearch.username: \"kibanaserver\" elasticsearch.password: \"kibanaserver\" # Disable SSL verification because we use self-signed demo certificates elasticsearch.ssl.verificationMode: none # Whitelist the Search Guard Multi Tenancy Header elasticsearch.requestHeadersWhitelist: [ \"Authorization\", \"sgtenant\" ] 打开对应域名登录http://localhost:5601/ 注:以上内容为参考自M醉逍遥, 并搭建成功后总结记录, 以作备忘. 链接如下:https://www.jianshu.com/p/319913a944af","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"hexo搭建博客","slug":"hexo/hexo-blog","date":"2018-10-08T12:17:11.000Z","updated":"2020-04-04T04:12:06.986Z","comments":true,"path":"2018/10/08/hexo-build-blog.html","link":"","permalink":"https://liuzhihang.com/2018/10/08/hexo-build-blog.html","excerpt":"安装node下载地址: https://nodejs.org 查看当前版本: node -v 安装hexonpm install 也可以使用淘宝镜像 npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install hexo","text":"安装node下载地址: https://nodejs.org 查看当前版本: node -v 安装hexonpm install 也可以使用淘宝镜像 npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install hexo hexo常用命令初始化hexo init 清除缓存hexo clean 生成静态文件hexo g hexo generate 启动hexo s hexo server 部署hexo d hexo deploy 生成并部署hexo g -d","categories":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/tags/hexo/"}]},{"title":"服务器cpu占用率高","slug":"issue/cpu-high-occupancy-rate","date":"2018-09-25T10:38:31.000Z","updated":"2020-04-04T06:23:27.480Z","comments":true,"path":"2018/09/25/server-cpu-occupancy-rate-is-high.html","link":"","permalink":"https://liuzhihang.com/2018/09/25/server-cpu-occupancy-rate-is-high.html","excerpt":"1. top 命令找到占用cpu最高的进程top - 14:37:14 up 34 days, 13:27, 2 users, load average: 0.21, 0.29, 0.29 Tasks: 151 total, 1 running, 150 sleeping, 0 stopped, 0 zombie Cpu(s): 4.4%us, 2.7%sy, 0.0%ni, 90.9%id, 0.5%wa, 0.0%hi, 0.2%si, 1.3%st Mem: 16334064k total, 16171240k used, 162824k free, 16716k buffers Swap: 16383996k total, 4470816k used, 11913180k free, 539788k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1818 tomcat 20 0 3643m 983m 7548 S 0.7 24.8 190:40.13 java","text":"1. top 命令找到占用cpu最高的进程top - 14:37:14 up 34 days, 13:27, 2 users, load average: 0.21, 0.29, 0.29 Tasks: 151 total, 1 running, 150 sleeping, 0 stopped, 0 zombie Cpu(s): 4.4%us, 2.7%sy, 0.0%ni, 90.9%id, 0.5%wa, 0.0%hi, 0.2%si, 1.3%st Mem: 16334064k total, 16171240k used, 162824k free, 16716k buffers Swap: 16383996k total, 4470816k used, 11913180k free, 539788k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1818 tomcat 20 0 3643m 983m 7548 S 0.7 24.8 190:40.13 java 字段解释:top - 时间 运行时间 用户 系统负载Tasks: 进程相关信息Cpu(s): cpu相关信息Mem: 内存相关Swap: 交换区相关信息 进程相关信息PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2. 使用top -H -p 查看该进程内所有线程top -H -p 1818 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 6656 tomcat 20 0 4193m 608m 11m R 21.0 3.8 1419:44 java 3. printf “%x\\n” 将10进制线程号转换为16进制结果[liuzhihang@test08 ~]$ printf \"%x\\n\" 1876 754 [liuzhihang@test08 ~]$ 4. jstack |grep jstack 1818 | grep 754 -A 30 pid 为第一次执行top命令时的 pidtid 为将第二次的pid进行十六进制转换后的结果 \"catalina-8180-89\" #1842 daemon prio=5 os_prio=0 tid=0x00007f4ec4096000 nid=0x5d96 waiting on condition [0x00007f4e87545000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000f418f898> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:104) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:32) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) \"catalina-8180-88\" #1841 daemon prio=5 os_prio=0 tid=0x00007f4eb848e800 nid=0x5d94 waiting on condition [0x00007f4e8bd8b000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method)","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"}]},{"title":"final finally finalize区别","slug":"source-code/java/final-finally-finalize","date":"2018-09-06T09:58:38.000Z","updated":"2020-04-04T06:21:20.355Z","comments":true,"path":"2018/09/06/final-finally-finalize-difference.html","link":"","permalink":"https://liuzhihang.com/2018/09/06/final-finally-finalize-difference.html","excerpt":"finalfinal为java关键字, 可以作用于成员变量、方法、类上1.作用于成员变量上, 基本类型则值不可修改, 如果成员变量为对象, 则该对象的引用不可修改.2.作用于方法, 该方法不可被重写3.作用于类, 该类不可继承","text":"finalfinal为java关键字, 可以作用于成员变量、方法、类上1.作用于成员变量上, 基本类型则值不可修改, 如果成员变量为对象, 则该对象的引用不可修改.2.作用于方法, 该方法不可被重写3.作用于类, 该类不可继承 finally异常处理的关键字, 无论异常是否发生, finally内逻辑总会执行. finally 和 return 的执行顺序1.一般使用逻辑, return在try-catch-finally之后, 证明, 无论是否异常, finally都会执行 public class MainTest &amp;#123; public static void main(String[] args) &amp;#123; System.out.println(finallyTest()); &amp;#125; private static String finallyTest() &amp;#123; try &amp;#123; System.out.println(\"处理逻辑\"); // int i = 1 / 0; &amp;#125; catch (Exception e) &amp;#123; System.out.println(\"异常逻辑\"); &amp;#125; finally &amp;#123; System.out.println(\"finally执行了\"); &amp;#125; return \"最终return返回\"; &amp;#125; &amp;#125; 2.在try/catch内添加returntry/catch内的return执行完后会继续执行finally, 但是从打印结果来开, finally的语句先打印, 原因是因为 return的 public class MainTest &amp;#123; public static void main(String[] args) &amp;#123; System.out.println(finallyTest()); &amp;#125; private static String finallyTest() &amp;#123; try &amp;#123; System.out.println(\"处理逻辑\"); // int i = 1 / 0; return \"try - return返回\"; &amp;#125; catch (Exception e) &amp;#123; System.out.println(\"异常逻辑\"); // return \"catch - return返回\"; &amp;#125; finally &amp;#123; System.out.println(\"finally执行了\"); &amp;#125; return \"最终return返回\"; &amp;#125; &amp;#125; 输出结果 处理逻辑 finally执行了 try - return返回 3.finally里面添加return语句finally里面return执行完后会直接返回, 不会再执行try块中的return语句 public class MainTest &amp;#123; public static void main(String[] args) &amp;#123; System.out.println(finallyTest()); &amp;#125; private static String finallyTest() &amp;#123; try &amp;#123; System.out.println(\"处理逻辑\"); // int i = 1 / 0; return \"try - return返回\"; &amp;#125; catch (Exception e) &amp;#123; System.out.println(\"异常逻辑\"); // return \"catch - return返回\"; &amp;#125; finally &amp;#123; System.out.println(\"finally执行了\"); return \"finally - return返回\"; &amp;#125; // return \"最终return返回\"; &amp;#125; &amp;#125; 执行结果 处理逻辑 finally执行了 finally - return返回 4.finally内添加逻辑改变变量值1).try中的return值只是暂时放在栈中, 所以最终返回的还是 10, finally中并没有改变其值2).try中的return值如果是对象, 栈中存放的是对象的引用, 对象属性值还是可以通过finally修改 public class MainTest &amp;#123; public static void main(String[] args) &amp;#123; System.out.println(finallyTest()); &amp;#125; private static String finallyTest() &amp;#123; int temp = 10; try &amp;#123; System.out.println(\"处理逻辑\"); return \"try - return返回: \" + temp; &amp;#125; catch (Exception e) &amp;#123; System.out.println(\"异常逻辑\"); // return \"catch - return返回\"; &amp;#125; finally &amp;#123; temp = 100; System.out.println(\"finally执行了\"); &amp;#125; return \"最终return返回: \" + temp; &amp;#125; &amp;#125; 输出结果 处理逻辑 finally执行了 try - return返回: 10 public class MainTest &amp;#123; public static void main(String[] args) &amp;#123; Temp temp = new Temp(); temp.temp = 1; System.out.println(finallyTest(temp).toString()); &amp;#125; private static Temp finallyTest(Temp temp) &amp;#123; try &amp;#123; System.out.println(\"处理逻辑\"); return temp; &amp;#125; catch (Exception e) &amp;#123; System.out.println(\"异常逻辑\"); // return \"catch - return返回\"; &amp;#125; finally &amp;#123; temp.temp = 100; System.out.println(\"finally执行了\"); &amp;#125; return temp; &amp;#125; &amp;#125; class Temp &amp;#123; int temp; @Override public String toString() &amp;#123; return \"Temp&amp;#123;\" + \"temp=\" + temp + '&amp;#125;'; &amp;#125; &amp;#125; 打印结果 处理逻辑 finally执行了 Temp&amp;#123;temp=100&amp;#125; finalize方法Object类的方法, 子类可重写, 主要是垃圾回收时使用.","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}]},{"title":"线程池原理及源码解析","slug":"concurrent/thread-pool","date":"2018-09-05T08:40:35.000Z","updated":"2020-04-04T06:49:14.278Z","comments":true,"path":"2018/09/05/thread-pool-principle-and-source-code-analysis.html","link":"","permalink":"https://liuzhihang.com/2018/09/05/thread-pool-principle-and-source-code-analysis.html","excerpt":"线程池处理流程 判断核心线程池是否已满, 不满则创建新线程执行任务 等待队列如果有界, 判断等待队列是否已满, 不满, 则添加任务到等待队列 判断最大线程数是否已满, 不满则创建新线程执行任务 最大线程数已满, 按照既定策略处理新任务","text":"线程池处理流程 判断核心线程池是否已满, 不满则创建新线程执行任务 等待队列如果有界, 判断等待队列是否已满, 不满, 则添加任务到等待队列 判断最大线程数是否已满, 不满则创建新线程执行任务 最大线程数已满, 按照既定策略处理新任务 全参构造及各参数含义public class ThreadPoolExecutor extends AbstractExecutorService &amp;#123; public ThreadPoolExecutor(int corePoolSize, // 核心线程数 int maximumPoolSize, // 最大线程数 long keepAliveTime, // 核心线程外线程的存活时间 TimeUnit unit, // 存活时间的单位 BlockingQueue&lt;Runnable> workQueue, // 保存等待执行的线程的阻塞队列 ThreadFactory threadFactory, // 线程工厂 RejectedExecutionHandler handler) &amp;#123; // 线程拒绝策略 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &amp;#125; // 省略 . . . &amp;#125; workQueue阻塞队列ArrayBlockingQueue: 是一个基于数组结构的有界阻塞队列, 此队列按 FIFO(先进先出) 原则对元素进行排序.LinkedBlockingQueue: 一个基于链表结构的阻塞队列,此队列按 FIFO(先进先出) 排序元素, 吞吐量通常要高于ArrayBlockingQueue. 静态工厂方法Executors.newFixedThreadPool()使用了这个队列SynchronousQueue: 一个不存储元素的阻塞队列. 每个插入操作必须等到另一个线程调用移除操作, 否则插入操作一直处于阻塞状态, 吞吐量通常要高于LinkedBlockingQueue, 静态工厂方法Executors.newCachedThreadPool使用了这个队列.PriorityBlockingQueue: 一个具有优先级的无限阻塞队列. 2.threadFactory线程工厂可以使用默认的工厂也可以自定义工厂, 或者使用 google guava 提供的工厂, 可以为线程命名和设置是否为守护线程 // 默认工厂 ThreadFactory threadFactory = Executors.defaultThreadFactory(); // google guava工具提供 ThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(\"demo-pool-%d\").build(); 3.handler线程拒绝策略当线程池达到最大线程数, 并且队列满了, 新的线程要采取的处理策略.1.AbortPolicy 拒绝新任务并抛出RejectedExecutionException异常2.CallerRunsPolicy 直接在调用程序的线程中运行3.DiscardOldestPolicy 放弃最早的任务, 即队列最前面的任务4.DiscardPolicy 丢弃, 不处理 Executors初始化线程池的四种方式这四种初始化线程池的方式, 前三种都是调用 ThreadPoolExecutor 类的构造创建的线程池, 只不过使用的阻塞队列方式不同. newFixedThreadPool() public class Executors &amp;#123; /** * 固定线程池 * 核心线程数 = 最大线程数 * 超时时间为0 * LinkedBlockingQueue无界队列, 会持续等待 * 使用默认拒绝策略 AbortPolicy */ public static ExecutorService newFixedThreadPool(int nThreads) &amp;#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>()); &amp;#125; &amp;#125; newCachedThreadPool() public class Executors &amp;#123; /** * 无界线程池 * 核心线程数0 最大线程数 (2³¹ -1) * 超时时间 60秒 * SynchronousQueue不存储元素的阻塞队列 * 线程空闲时间超过60秒, 会自动释放资源, 提交任务如果没有空闲线程, 则会创建新线程 */ public static ExecutorService newCachedThreadPool() &amp;#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable>()); &amp;#125; &amp;#125; 3.newSingleThreadExecutor() public class Executors &amp;#123; /** * 创建只有 1个线程的线程池 * 如果线程异常, 则创建一个新的线程继续执行任务 * */ public static ExecutorService newSingleThreadExecutor() &amp;#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>())); &amp;#125; &amp;#125; 4.newSingleThreadExecutor() public class Executors &amp;#123; /** * ScheduledThreadPoolExecutor 继承 ThreadPoolExecutor 类 * 可以在指定时间周期内执行任务 * */ public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &amp;#123; return new ScheduledThreadPoolExecutor(corePoolSize); &amp;#125; &amp;#125; 源码解析变量public class ThreadPoolExecutor extends AbstractExecutorService &amp;#123; /** * ctx 为原子类型的变量, 有两个概念 * workerCount, 表示有效的线程数 * runState, 表示线程状态, 是否正在运行, 关闭等 */ private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // 29 private static final int COUNT_BITS = Integer.SIZE - 3; // 容量 2²⁹-1 private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits 线程池的五中状态 // 即高3位为111, 接受新任务并处理排队任务 private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 即高3位为000, 不接受新任务, 但处理排队任务 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 即高3位为001, 不接受新任务, 不处理排队任务, 并中断正在进行的任务 private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 即高3位为010, 所有任务都已终止, 工作线程为0, 线程转换到状态TIDYING, 将运行terminate()钩子方法 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 即高3位为011, 标识terminate（）已经完成 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl 用来计算线程的方法 private static int runStateOf(int c) &amp;#123; return c &amp; ~CAPACITY; &amp;#125; private static int workerCountOf(int c) &amp;#123; return c &amp; CAPACITY; &amp;#125; private static int ctlOf(int rs, int wc) &amp;#123; return rs | wc; &amp;#125; &amp;#125; execute方法public class ThreadPoolExecutor extends AbstractExecutorService &amp;#123; public void execute(Runnable command) &amp;#123; // 空则抛出异常 if (command == null) throw new NullPointerException(); // 获取当前线程池的状态 int c = ctl.get(); // 计算工作线程数 并判断是否小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) &amp;#123; // addWorker提交任务, 提交成功则结束 if (addWorker(command, true)) return; // 提交失败再次获取当前状态 c = ctl.get(); &amp;#125; // 判断线程状态, 并插入队列, 失败则移除 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &amp;#123; // 再次获取状态 int recheck = ctl.get(); // 如果状态不是RUNNING, 并移除失败 if (! isRunning(recheck) &amp;&amp; remove(command)) // 调用拒绝策略 reject(command); // 如果工作线程为0 则调用 addWorker else if (workerCountOf(recheck) == 0) addWorker(null, false); &amp;#125; // 提交任务失败 走拒绝策略 else if (!addWorker(command, false)) reject(command); &amp;#125; &amp;#125; addWorker方法public class ThreadPoolExecutor extends AbstractExecutorService &amp;#123; /** * 检查任务是否可以提交 * */ private boolean addWorker(Runnable firstTask, boolean core) &amp;#123; retry: // 外层循环 for (;;) &amp;#123; // 获取当前状态 int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. 检查线程池是否关闭 if (rs >= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; // 内层循环 for (;;) &amp;#123; int wc = workerCountOf(c); // 工作线程大于容量 或者大于 核心或最大线程数 if (wc >= CAPACITY || wc >= (core ? corePoolSize : maximumPoolSize)) return false; // CAS 线程数增加, 成功则调到外层循环 if (compareAndIncrementWorkerCount(c)) break retry; // 失败则再次获取线程状态 c = ctl.get(); // Re-read ctl // 不相等则重新走外层循环 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &amp;#125; &amp;#125; /** * 创建新worker 开始新线程 */ boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &amp;#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &amp;#123; final ReentrantLock mainLock = this.mainLock; // 加锁 mainLock.lock(); try &amp;#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &amp;#123; // 判断线程是否存活, 已存活抛出非法异常 if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 设置包含池中的所有工作线程。仅在持有mainLock时访问 workers是 HashSet 集合 // private final HashSet&lt;Worker> workers = new HashSet&lt;Worker>(); workers.add(w); int s = workers.size(); // 设置池最大大小, 并将 workerAdded设置为 true if (s > largestPoolSize) largestPoolSize = s; workerAdded = true; &amp;#125; &amp;#125; finally &amp;#123; // 解锁 mainLock.unlock(); &amp;#125; // 添加成功 开始启动线程 并将 workerStarted 设置为 true if (workerAdded) &amp;#123; t.start(); workerStarted = true; &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; // 启动线程失败 if (! workerStarted) addWorkerFailed(w); &amp;#125; return workerStarted; &amp;#125; /** * 启动线程失败, 加锁 * 移除线程, 并减少线程总数 * 转换状态 */ private void addWorkerFailed(Worker w) &amp;#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &amp;#123; if (w != null) workers.remove(w); decrementWorkerCount(); tryTerminate(); &amp;#125; finally &amp;#123; mainLock.unlock(); &amp;#125; &amp;#125; &amp;#125;","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"https://liuzhihang.com/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"多线程相关","slug":"concurrent/multi-thread","date":"2018-09-04T11:08:03.000Z","updated":"2020-04-04T06:16:02.599Z","comments":true,"path":"2018/09/04/multithreaded-correlation.html","link":"","permalink":"https://liuzhihang.com/2018/09/04/multithreaded-correlation.html","excerpt":"多线程多个线程同时或交替运行, 单核CPU为顺序执行(交替执行), 多核情况下, 每个CPU有自己的运算器, 所以在多个CPU中可以同时运行.","text":"多线程多个线程同时或交替运行, 单核CPU为顺序执行(交替执行), 多核情况下, 每个CPU有自己的运算器, 所以在多个CPU中可以同时运行. 创建线程的方式1.继承Thread public class MyThread extends Thread &amp;#123; @Override public void run() &amp;#123; super.run(); System.out.println(Thread.currentThread().getName() + \"执行完毕\"); &amp;#125; &amp;#125; public class ThreadTest &amp;#123; public static void main(String[] args) &amp;#123; MyThread myThread = new MyThread(); myThread.setName(\"测试\"); myThread.start(); System.out.println(Thread.currentThread().getName() + \"执行完毕\"); &amp;#125; &amp;#125; 开始线程, 可以看出main线程和测试线程是两个独立的线程调用myThread.run();方法相当于直接在主线程运行run方法, 而不是开启一个新的线程去执行 2.实现Runnable接口 public class MyRunable implements Runnable &amp;#123; @Override public void run() &amp;#123; System.out.println(Thread.currentThread().getName() + \"执行完毕\"); &amp;#125; &amp;#125; public class ThreadTest &amp;#123; public static void main(String[] args) &amp;#123; MyRunable runable = new MyRunable(); Thread thread = new Thread(runable); thread.start(); System.out.println(Thread.currentThread().getName() + \"执行完毕\"); &amp;#125; &amp;#125; 3.使用线程池3.1 可以在spring中配置相关线程池, 使用时从容器取出即可, 也可以自己声明线程池 &lt;bean id=\"threadPool\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\"> &lt;!-- 核心线程数，默认为1 --> &lt;property name=\"corePoolSize\" value=\"5\"/> &lt;!-- 最大线程数，默认为Integer.MAX_VALUE --> &lt;property name=\"maxPoolSize\" value=\"20\"/> &lt;!-- 队列最大长度，一般需要设置值>=notifyScheduledMainExecutor.maxNum；默认为Integer.MAX_VALUE &lt;property name=\"queueCapacity\" value=\"1000\" /> --> &lt;!-- 线程池维护线程所允许的空闲时间，默认为60s --> &lt;property name=\"keepAliveSeconds\" value=\"300\"/> &lt;!-- 队列最大长度 --> &lt;property name=\"queueCapacity\" value=\"2000\"/> &lt;!-- 线程池对拒绝任务（无线程可用）的处理策略，目前只支持AbortPolicy、CallerRunsPolicy；默认为后者 --> &lt;property name=\"rejectedExecutionHandler\"> &lt;!-- AbortPolicy:直接抛出java.utils.concurrent.RejectedExecutionException异常 --> &lt;!-- CallerRunsPolicy:主线程直接执行该任务，执行完之后尝试添加下一个任务到线程池中，可以有效降低向线程池内添加任务的速度 --> &lt;!-- DiscardOldestPolicy:抛弃旧的任务、暂不支持；会导致被丢弃的任务无法再次被执行 --> &lt;!-- DiscardPolicy:抛弃当前任务、暂不支持；会导致被丢弃的任务无法再次被执行 --> &lt;bean class=\"java.util.concurrent.ThreadPoolExecutor$CallerRunsPolicy\"/> &lt;/property> &lt;/bean> 3.2 Executors 创建线程池 public class ThreadTest &amp;#123; public static void main(String[] args) &amp;#123; ExecutorService threadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) &amp;#123; threadPool.execute(new MyRunable()); &amp;#125; &amp;#125; &amp;#125; 当手动创建线程池时, 如果IDEA安装阿里 P3C 插件后会报错提示以下内容, 建议 线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明： Executors 返回的线程池对象的弊端如下： 1） FixedThreadPool 和 SingleThreadPool: 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 2） CachedThreadPool 和 ScheduledThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE， 可能会创建大量的线程，从而导致 OOM。 建议使用如下方式: public class ThreadTest &amp;#123; public static void main(String[] args) &amp;#123; // 定时任务 建议为线程起名 ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(3, new BasicThreadFactory.Builder().namingPattern(\"example-schedule-pool-%d\").build()); executorService.scheduleAtFixedRate(new MyRunable(), 0, 1, TimeUnit.SECONDS); &amp;#125; &amp;#125; public class ThreadTest &amp;#123; public static void main(String[] args) &amp;#123; // 线程工厂 ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(\"demo-pool-%d\").build(); //Common Thread Pool ExecutorService pool = new ThreadPoolExecutor(5, 20, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;>(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); pool.execute(()-> System.out.println(Thread.currentThread().getName())); pool.shutdown();//gracefully shutdown &amp;#125; &amp;#125; 线程优先级1.myThread.setPriority(1);设置优先级2.优先级从低到高为 1-10, Thread类提供 Thread.MIN_PRIORITY=1, Thread.NORM_PRIORITY=5, Thread.MAX_PRIORITY=103.默认优先级为 5 即 NORM_PRIORITY4.优先级高的仅代表获取进入运行机会的几率大, 并不代表一定会比优先级低的先执行 sleep()和wait()1.sleep()线程未释放锁, 时间结束后线程继续执行2.wait线程释放锁, 需要使用notify或notifyAll3.wait常用于线程之间的交互 package com.liuzhihang.tool.alternate; /** * 交替打印奇偶数 * * @author liuzhihang * @date 2018/9/4 18:39 */ public class AlternateNum &amp;#123; public static void main(String[] args) &amp;#123; Num num = new Num(); Thread thread1 = new Thread(new Odd(num)); Thread thread2 = new Thread(new Even(num)); thread1.start(); thread2.start(); &amp;#125; &amp;#125; class Num &amp;#123; int anInt = 1; boolean flag = true; &amp;#125; class Odd implements Runnable &amp;#123; private Num num; public Odd(Num num) &amp;#123; this.num = num; &amp;#125; @Override public void run() &amp;#123; while (num.anInt &lt; 1000) &amp;#123; // 使用同一把锁 synchronized (num) &amp;#123; if (num.flag) &amp;#123; System.out.println(\"奇数 -> \" + num.anInt); num.anInt++; num.flag = false; num.notify(); &amp;#125; else &amp;#123; try &amp;#123; num.wait(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; class Even implements Runnable &amp;#123; private Num num; public Even(Num num) &amp;#123; this.num = num; &amp;#125; @Override public void run() &amp;#123; while (num.anInt &lt; 1000) &amp;#123; // 使用同一把锁 synchronized (num) &amp;#123; if (!num.flag) &amp;#123; System.out.println(\"偶数 -> \" + num.anInt); num.anInt++; num.flag = true; num.notify(); &amp;#125; else &amp;#123; try &amp;#123; num.wait(); &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125;","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"反射和序列化破解单例","slug":"source-code/java/ReflectSingleton","date":"2018-08-27T09:31:23.000Z","updated":"2020-04-04T06:55:36.741Z","comments":true,"path":"2018/08/27/reflection-and-serialization-cracking-singleton.html","link":"","permalink":"https://liuzhihang.com/2018/08/27/reflection-and-serialization-cracking-singleton.html","excerpt":"介绍主要介绍通过反射的方式获取单例对象, 验证单例模式的安全性.主要从以下几个角度来介绍反射下的单例饿汉式双重锁检查枚举单例","text":"介绍主要介绍通过反射的方式获取单例对象, 验证单例模式的安全性.主要从以下几个角度来介绍反射下的单例饿汉式双重锁检查枚举单例 饿汉式饿汉式直接使用反射即可破解单例模式 public class ReflectTest &amp;#123; public static void main(String[] args) &amp;#123; try &amp;#123; HungerPattern hungerPattern = HungerPattern.getHungerPattern(); Class&lt;HungerPattern> hungerPatternClass = HungerPattern.class; Constructor&lt;HungerPattern> conA = hungerPatternClass.getDeclaredConstructor(); Constructor&lt;HungerPattern> conB = hungerPatternClass.getDeclaredConstructor(); conA.setAccessible(true); conB.setAccessible(true); HungerPattern instanceA = conA.newInstance(); HungerPattern instanceB = conB.newInstance(); // instanceA 和 instanceB 不是同一对象 System.out.println(hungerPattern.hashCode()); System.out.println(instanceA.hashCode()); System.out.println(instanceB.hashCode()); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 输出结果 D:\\jdk1.8\\bin\\java.exe . . . 713338599 168423058 821270929 Process finished with exit code 0 双重锁检查双重锁检查同样存在相同的情况 直接使用public class ReflectTest &amp;#123; public static void main(String[] args) &#123; try &#123; DoubleCheckLockLazyPattern pattern = DoubleCheckLockLazyPattern.getDoubleCheckLockLazyPattern(); Class&lt;DoubleCheckLockLazyPattern&gt; patternClass = DoubleCheckLockLazyPattern.class; Constructor&lt;DoubleCheckLockLazyPattern&gt; conA = patternClass.getDeclaredConstructor(); Constructor&lt;DoubleCheckLockLazyPattern&gt; conB = patternClass.getDeclaredConstructor(); conA.setAccessible(true); conB.setAccessible(true); DoubleCheckLockLazyPattern patternA = conA.newInstance(); DoubleCheckLockLazyPattern patternB = conA.newInstance(); System.out.println(pattern.hashCode()); System.out.println(patternA.hashCode()); System.out.println(patternB.hashCode()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; } 输出结果 ```bash D:\\jdk1.8\\bin\\java.exe . . . 713338599 168423058 821270929 Process finished with exit code 0 在双重锁检查私有构造内加入异常 public class DoubleCheckLockLazyPattern &amp;#123; private DoubleCheckLockLazyPattern() &amp;#123; // 加入异常判断, 防止反射 if (doubleCheckLockLazyPattern != null) &amp;#123; throw new RuntimeException(); &amp;#125; &amp;#125; private static volatile DoubleCheckLockLazyPattern doubleCheckLockLazyPattern = null; public static DoubleCheckLockLazyPattern getDoubleCheckLockLazyPattern() &amp;#123; try &amp;#123; if (doubleCheckLockLazyPattern == null) &amp;#123; // 一系列操作 Thread.sleep(100); synchronized (DoubleCheckLockLazyPattern.class) &amp;#123; // 二次检查 if (doubleCheckLockLazyPattern == null) &amp;#123; doubleCheckLockLazyPattern = new DoubleCheckLockLazyPattern(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; return doubleCheckLockLazyPattern; &amp;#125; &amp;#125; 输出结果 D:\\jdk1.8\\bin\\java.exe . . . java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.liuzhihang.demo.singleton.ReflectTest.main(ReflectTest.java:24) Caused by: java.lang.RuntimeException at com.liuzhihang.demo.singleton.DoubleCheckLockLazyPattern.&lt;init>(DoubleCheckLockLazyPattern.java:15) ... 5 more 通过序列化反序列化获取对象 DoubleCheckLockLazyPattern 实现序列化 public class ReflectTest &amp;#123; public static void main(String[] args) &amp;#123; try &amp;#123; DoubleCheckLockLazyPattern pattern = DoubleCheckLockLazyPattern.getDoubleCheckLockLazyPattern(); FileOutputStream fos= new FileOutputStream(\"C:/Users/liuzhihang/desktop/pattern.txt\"); ObjectOutputStream oos = new ObjectOutputStream(fos); oos.writeObject(pattern); oos.close(); fos.close(); ObjectInputStream oisA = new ObjectInputStream(new FileInputStream(\"C:/Users/liuzhihang/desktop/pattern.txt\")); DoubleCheckLockLazyPattern patternA= (DoubleCheckLockLazyPattern) oisA.readObject(); ObjectInputStream oisB = new ObjectInputStream(new FileInputStream(\"C:/Users/liuzhihang/desktop/pattern.txt\")); DoubleCheckLockLazyPattern patternB= (DoubleCheckLockLazyPattern) oisB.readObject(); System.out.println(pattern.hashCode()); System.out.println(patternA.hashCode()); System.out.println(patternB.hashCode()); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 输出结果 D:\\jdk1.8\\bin\\java.exe . . . 258952499 1702297201 1996181658 Process finished with exit code 0 修改反序列化方法, 可以防止反序列化 添加以下方法 private Object readResolve() &amp;#123; return doubleCheckLockLazyPattern; &amp;#125; 输出结果 D:\\jdk1.8\\bin\\java.exe . . . 258952499 258952499 258952499 Process finished with exit code 0 枚举单例public enum SingletonEnum &amp;#123; /** * 单例 */ INSTANCE; private Resource resource; SingletonEnum() &amp;#123; this.resource = new Resource(); &amp;#125; public Resource getResource() &amp;#123; return resource; &amp;#125; &amp;#125; class Resource &amp;#123; &amp;#125; 枚举单例分析在枚举反射获取对象时抛出异常, 通过 Constructor类 源码可以看出, 在反射创建对象时会判断是否是枚举修饰, 是则抛出异常 @CallerSensitive public T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException &amp;#123; if (!override) &amp;#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &amp;#123; Class&lt;?> caller = Reflection.getCallerClass(); checkAccess(caller, clazz, null, modifiers); &amp;#125; &amp;#125; if ((clazz.getModifiers() &amp; Modifier.ENUM) != 0) throw new IllegalArgumentException(\"Cannot reflectively create enum objects\"); ConstructorAccessor ca = constructorAccessor; // read volatile if (ca == null) &amp;#123; ca = acquireConstructorAccessor(); &amp;#125; @SuppressWarnings(\"unchecked\") T inst = (T) ca.newInstance(initargs); return inst; &amp;#125; 同时在父类 Enum类 中重写了 readObject方法, 所以枚举也可以避免反序列化 /** * prevent default deserialization */ private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &amp;#123; throw new InvalidObjectException(\"can't deserialize enum\"); &amp;#125;","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"反射","slug":"反射","permalink":"https://liuzhihang.com/tags/%E5%8F%8D%E5%B0%84/"}]},{"title":"反射","slug":"utils/reflection/Reflect","date":"2018-08-24T11:24:38.000Z","updated":"2020-04-04T07:33:24.454Z","comments":true,"path":"2018/08/24/reflection.html","link":"","permalink":"https://liuzhihang.com/2018/08/24/reflection.html","excerpt":"介绍java反射可以在运行时获取对象的成员和属性, 并且可以动态的创建对象并调用对象的属性.反射一般编程中很少使用,但是在很多框架中都使用了反射, 比如配置Spring的Xml配置文件中, 就使用全类名配置方式, 其实就是反射的一种使用方式. 同时反射对单例模式有一定的影响, 可以参考反射获取单例对象","text":"介绍java反射可以在运行时获取对象的成员和属性, 并且可以动态的创建对象并调用对象的属性.反射一般编程中很少使用,但是在很多框架中都使用了反射, 比如配置Spring的Xml配置文件中, 就使用全类名配置方式, 其实就是反射的一种使用方式. 同时反射对单例模式有一定的影响, 可以参考反射获取单例对象 获取反射对象获取反射Class对象一共三种方式 // 1. 使用实例获取 User user = new User(); Class&lt;? extends User> aClass = user.getClass(); // 2. 使用类获取 Class&lt;User> userClass = User.class; // 3. 全类名获取, 可能会抛出 ClassNotFoundException 异常 Class&lt;?> aClass1 = Class.forName(\"com.liuzhihang.tool.reflect.User\"); 获取属性 获取字段// 获取所有公有字段 (public) Field[] fields = aClass.getFields(); // 获取所有字段 (public 缺省, protected, private) Field[] fields = aClass.getDeclaredFields() // 获取指定公共字段 Field age = aClass.getField(\"age\"); // 获取指定字段 (public 缺省, protected, private) Field userName = aClass.getDeclaredField(\"userName\"); 获取构造 获取构造// 获取所有构造 不能获取私有 Constructor&lt;?>[] constructors = aClass.getConstructors(); // 获取指定参数类型的构造 不能获取私有 空则获取空参构造 getConstructor(Class&lt;?&gt;… parameterTypes)Constructor constructor = aClass.getConstructor(String.class); // 获取所有构造 包含私有Constructor&lt;?&gt;[] declaredConstructors = aClass.getDeclaredConstructors(); // 获取指定参数类型的构造 可以获取私有 空则获取空参构造 getDeclaredConstructor(Class&lt;?&gt;… parameterTypes)Constructor declaredConstructor = aClass.getDeclaredConstructor(String.class); 2. 使用构造创建对象 可以通过 constructor.setAccessible(true); 暴力破解忽略访问修饰符, 来使用私有构造参数 ```bash Constructor&lt;User&gt; constructor = aClass.getDeclaredConstructor(String.class); // 暴力破解 constructor.setAccessible(true); User test = constructor.newInstance(&quot;test&quot;); 获取方法 获取方法// 获取所有公共方法(包含父类) Method[] methods = aClass.getMethods(); // 获取所有方法 Method[] methods = aClass.getDeclaredMethods(); // 获取私有方法 第一个参数填方法名称 Method address = aClass.getDeclaredMethod(\"setAddress\", String.class); // 获取公共方法 Method address = aClass.getMethod(\"setAddress\", String.class); 2. 使用方法 ```bash Class&lt;?&gt; aClass = Class.forName(&quot;com.liuzhihang.tool.reflect.User&quot;) Method address = aClass.getDeclaredMethod(&quot;setAddress&quot;, String.class); User user = aClass.getConstructor().newInstance(); System.out.println(user.toString()); // 解除私有限制 address.setAccessible(true); // 使用invoke来调用方法 address.invoke(user, &quot;北京&quot;); System.out.println(user.toString()); 获取其他属性还可以获取类实现的接口, 父类, 注解, 以及判断类的类型等多种使用方式.","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"反射","slug":"反射","permalink":"https://liuzhihang.com/tags/%E5%8F%8D%E5%B0%84/"}]},{"title":"LinkList相关学习","slug":"source-code/java/LinkList","date":"2018-08-23T09:56:29.000Z","updated":"2020-04-04T06:54:14.566Z","comments":true,"path":"2018/08/23/linklist-related-learning.html","link":"","permalink":"https://liuzhihang.com/2018/08/23/linklist-related-learning.html","excerpt":"介绍 LinkList也是工作中常见的集合, 底层使用双向链表结构比较适合新增和删除, 查询和修改需要遍历相对ArrayList比较消耗性能","text":"介绍 LinkList也是工作中常见的集合, 底层使用双向链表结构比较适合新增和删除, 查询和修改需要遍历相对ArrayList比较消耗性能 内部类 Nodeprivate static class Node&lt;E> &amp;#123; // 元素值 E item; // 下一个节点 Node&lt;E> next; // 上一个几点 Node&lt;E> prev; // 构造一个新节点 指向上一个节点和下一个节点 Node(Node&lt;E> prev, E element, Node&lt;E> next) &amp;#123; this.item = element; this.next = next; this.prev = prev; &amp;#125; &amp;#125; add 新增通过代码可以看出, 在新增元素时只需要创建一个新节点 Node, 并将原始链表最后一个Node的next指向新Node public boolean add(E e) &amp;#123; linkLast(e); return true; &amp;#125; /** * Links e as last element. */ void linkLast(E e) &amp;#123; // 声明 l 为最后一个节点 final Node&lt;E> l = last; // 创建新节点, 指向上一个节点, 下一个节点为空 final Node&lt;E> newNode = new Node&lt;>(l, e, null); // 最后一个节点为新创建的节点 last = newNode; // 判断是否为第一个元素, 否则将 新创建的 Node加入链表 if (l == null) first = newNode; else l.next = newNode; size++; modCount++; &amp;#125; remove 删除1.删除操作需要遍历链表找到相应元素, 然后移动指针即可2.删除首尾元素直接移动指针即可 removeFirst()/removeLast() 方法 public boolean remove(Object o) &amp;#123; if (o == null) &amp;#123; // 遍历链表 for (Node&lt;E> x = first; x != null; x = x.next) &amp;#123; if (x.item == null) &amp;#123; unlink(x); return true; &amp;#125; &amp;#125; &amp;#125; else &amp;#123; for (Node&lt;E> x = first; x != null; x = x.next) &amp;#123; if (o.equals(x.item)) &amp;#123; unlink(x); return true; &amp;#125; &amp;#125; &amp;#125; return false; &amp;#125; /** * 删除元素 */ E unlink(Node&lt;E> x) &amp;#123; // assert x != null; final E element = x.item; final Node&lt;E> next = x.next; final Node&lt;E> prev = x.prev; // 判断上一个Node是否为空 if (prev == null) &amp;#123; // 空, 该节点为链表头, 将下一个节点设置为链表头 first = next; &amp;#125; else &amp;#123; // 不为空, 将上一个节点的next 指向当前节点的 next, 并将当前节点的 prev置为空 prev.next = next; x.prev = null; &amp;#125; // 判断下一个Node是否为空 if (next == null) &amp;#123; // 空, 该节点为链表尾, 将链表尾设置为当前节点的上一个节点 last = prev; &amp;#125; else &amp;#123; // 不为空, 将下一个节点的prev, 设置为上一个节点, 并将当前节点的 next置为空 next.prev = prev; x.next = null; &amp;#125; x.item = null; size--; modCount++; return element; &amp;#125; get/setget/set时都需要获取指定索引的元素, 使用二分法查找, 然后进行遍历查找, 所以此处相较于ArrayList多了遍历查询, 虽然使用了二分法进行优化, 但是get/set操作相比ArrayList来说性能还是相对较差 public E get(int index) &amp;#123; // 校验索引 checkElementIndex(index); // 二分法遍历查找节点 return node(index).item; &amp;#125; public E set(int index, E element) &amp;#123; // 校验索引 checkElementIndex(index); // 二分法遍历查找节点 Node&lt;E> x = node(index); // 修改Node节点的 item值 E oldVal = x.item; x.item = element; return oldVal; &amp;#125; /** * 返回指定索引处非null节点. */ Node&lt;E> node(int index) &amp;#123; // assert isElementIndex(index); // 判断索引是否小于长度的一半 (二分法) 然后遍历查找 if (index &lt; (size >> 1)) &amp;#123; Node&lt;E> x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &amp;#125; else &amp;#123; Node&lt;E> x = last; for (int i = size - 1; i > index; i--) x = x.prev; return x; &amp;#125; &amp;#125;","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"LinkList","slug":"LinkList","permalink":"https://liuzhihang.com/tags/LinkList/"}]},{"title":"ArrayList相关学习","slug":"source-code/java/ArrayList","date":"2018-08-23T07:17:40.000Z","updated":"2020-04-04T06:20:52.869Z","comments":true,"path":"2018/08/23/arraylist-related-learning.html","link":"","permalink":"https://liuzhihang.com/2018/08/23/arraylist-related-learning.html","excerpt":"ArrayList是工作中常用的集合, 基于数组实现, 可以插入空数据, 也支持随机访问.ArrayList比较适合 get/set操作, 因为 add/remove需要移动数据, 相对来说比较消耗性能. 默认初始长度1.默认初始长度为 102.底层结构为Object[] 数组","text":"ArrayList是工作中常用的集合, 基于数组实现, 可以插入空数据, 也支持随机访问.ArrayList比较适合 get/set操作, 因为 add/remove需要移动数据, 相对来说比较消耗性能. 默认初始长度1.默认初始长度为 102.底层结构为Object[] 数组 private static final int DEFAULT_CAPACITY = 10; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &amp;#123;&amp;#125;; /** * 构造一个初始容量为10的空列表 */ public ArrayList() &amp;#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &amp;#125; 添加方法 add() 向数组中添加元素, 流程如下 /** * 将指定的元素追加到此列表的末尾. */ public boolean add(E e) &amp;#123; // 扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 添加元素 elementData[size++] = e; return true; &amp;#125; 2.扩容过程 transient Object[] elementData; // 扩容 private void ensureCapacityInternal(int minCapacity) &amp;#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); &amp;#125; // 计算容量, elementData为空 则使用默认容量 10, 指定容量 private static int calculateCapacity(Object[] elementData, int minCapacity) &amp;#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &amp;#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &amp;#125; return minCapacity; &amp;#125; // 修改次数自增, 并且如果 新的长度-原长度>0 则使用 grow(minCapacity)方法进行扩容 private void ensureExplicitCapacity(int minCapacity) &amp;#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length > 0) grow(minCapacity); &amp;#125; 添加元素赋值elementData[size++] = e; 扩容流程 grow(minCapacity)通过扩容流程可以看出扩容过程中, 是将创建一个原数组1.5倍大小的新数组, 同时将数组元素复制到新数组, 所以一般使用中, 尽量指定数组大小, 从而避免数组的复制. /** * 增加容量确保能容纳 minCapacity 数量的元素 */ private void grow(int minCapacity) &amp;#123; // overflow-conscious code // 获取当前 elementData 的长度 int oldCapacity = elementData.length; // 获取新的长度 为当前长度的 1.5倍 int newCapacity = oldCapacity + (oldCapacity >> 1); // 比较并交换 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 防止超出最大长度 if (newCapacity - MAX_ARRAY_SIZE > 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 数组复制 elementData = Arrays.copyOf(elementData, newCapacity); &amp;#125; 删除 remove 方法删除过程中使用 System.arraycopy 本地方法, 对数组进行复制, 所以 ArrayList的 新增和删除方法性能不如, LinkList, 但是 get和set方法, 则直接根据索引修改数据, 比较适合对数据进行修改的操作. /** * 删除指定位置的元素, 后面的元素将前移 */ public E remove(int index) &amp;#123; // 检查索引 否则抛出 IndexOutOfBoundsException(outOfBoundsMsg(index)) rangeCheck(index); // 修改次数自增 modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved > 0) // 数组复制 System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; &amp;#125; /** * 删除指定元素 */ public boolean remove(Object o) &amp;#123; if (o == null) &amp;#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &amp;#123; fastRemove(index); return true; &amp;#125; &amp;#125; else &amp;#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &amp;#123; fastRemove(index); return true; &amp;#125; &amp;#125; return false; &amp;#125; /** * System.arraycopy 方法拷贝 删除 */ private void fastRemove(int index) &amp;#123; modCount++; int numMoved = size - index - 1; if (numMoved > 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &amp;#125;","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}]},{"title":"@Value注入属性的小bug","slug":"issue/inject-bean","date":"2018-08-21T06:47:41.000Z","updated":"2020-04-04T06:23:27.471Z","comments":true,"path":"2018/08/21/value-injects-a-small-bug-in-the-property.html","link":"","permalink":"https://liuzhihang.com/2018/08/21/value-injects-a-small-bug-in-the-property.html","excerpt":"@Value注入属性工作中一些公共属性, 一般通过@Value注入的对象的属性中, 使用方式如下 @Configuration public class WeChatConfig &#123; /** * 微信支付参数 */ @Value(&quot;$&#123;wx.appId&#125;&quot;) public String WX_APP_ID; &#125; 通过@Value注解, 将配置文件中的值注入到对象属性中, 在使用时只需要注入WeChatConfig对象然后调用即可, 而实际工作中, 往往用静态属性, 方便使用, 于是可以写成如下方式","text":"@Value注入属性工作中一些公共属性, 一般通过@Value注入的对象的属性中, 使用方式如下 @Configuration public class WeChatConfig &amp;#123; /** * 微信支付参数 */ @Value(\"$&amp;#123;wx.appId&amp;#125;\") public String WX_APP_ID; &amp;#125; 通过@Value注解, 将配置文件中的值注入到对象属性中, 在使用时只需要注入WeChatConfig对象然后调用即可, 而实际工作中, 往往用静态属性, 方便使用, 于是可以写成如下方式 @Configuration public class WeChatConfig &amp;#123; /** * 微信支付参数 */ @Value(\"$&amp;#123;wx.appId&amp;#125;\") public static String WX_APP_ID; &amp;#125; 使用此方式不会报错, 但是却取不到属性值, 并且不会报错. 变通方式可以如下: @Configuration public class WeChatConfig &amp;#123; /** * 微信支付参数 */ @Value(\"$&amp;#123;wx.appId&amp;#125;\") public static String WX_APP_ID; @Value(\"$&amp;#123;wx.app.id&amp;#125;\") private void setWxAppId(String wxAppId) &amp;#123; WX_APP_ID = wxAppId; &amp;#125; &amp;#125; 注意: 此处的 set方法不可以设置为静态, 否则同样不能注入属性","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"}]},{"title":"使用枚举实现单例","slug":"design-patterns/单例模式-枚举实现","date":"2018-08-17T12:05:10.000Z","updated":"2020-04-04T04:12:06.877Z","comments":true,"path":"2018/08/17/use-enumeration-to-implement-a-singleton.html","link":"","permalink":"https://liuzhihang.com/2018/08/17/use-enumeration-to-implement-a-singleton.html","excerpt":"简介介绍使用枚举的方式创建单例, 其他方式可以参考单例模式","text":"简介介绍使用枚举的方式创建单例, 其他方式可以参考单例模式 代码 /** * 使用枚举单例 * * @author liuzhihang * @date 2018/8/17 17:34 */ public class SingletonPattern &amp;#123; private SingletonPattern() &amp;#123; &amp;#125; public static SingletonPattern getInstance() &amp;#123; return SingleEnum.INSTANCE.getSingletonPattern(); &amp;#125; private enum SingleEnum &amp;#123; /** * 单例 */ INSTANCE; private SingletonPattern singletonPattern; SingleEnum() &amp;#123; this.singletonPattern = new SingletonPattern(); &amp;#125; public SingletonPattern getSingletonPattern() &amp;#123; return singletonPattern; &amp;#125; &amp;#125; &amp;#125; 优点1.比双重锁检查相对简洁2.线程安全3.自动处理序列化4.防止反射","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","permalink":"https://liuzhihang.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"Elasticsearch基本语句","slug":"elk/es-query","date":"2018-06-26T13:30:29.000Z","updated":"2020-04-04T06:17:49.305Z","comments":true,"path":"2018/06/26/elasticsearch-basic-statement.html","link":"","permalink":"https://liuzhihang.com/2018/06/26/elasticsearch-basic-statement.html","excerpt":"查看集群1. 查看集群健康curl -X GET &quot;localhost:9200/_cat/health?v&quot; 2. 查看集群节点curl -X GET &quot;localhost:9200/_cat/nodes?v&quot;","text":"查看集群1. 查看集群健康curl -X GET \"localhost:9200/_cat/health?v\" 2. 查看集群节点curl -X GET \"localhost:9200/_cat/nodes?v\" 3. 查看集群所有索引curl -X GET \"localhost:9200/_cat/indices?v\" get 获取指定数据1. 直接获取数据curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK?pretty\" 格式为 /{index}/{type}/{id} 字段 含义 monitor_log_mch_order_out 索引 (_index) logs 索引的类型 (_type), 不知道类型可以用 _all 匹配 AWSudIFgTuj3oZBEhyxK id (_id) pretty json格式显示数据, 可省略 2. 屏蔽或只查看 _sourcecurl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK?pretty&amp;_source=false\" 添加 _source=false 即可 curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK/_source?pretty\" 3. 过滤字段curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK?pretty&amp;_source_include=log*&amp;_source_exclude=logType\" 获取包含 log* 且不为 logType 的字段 curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK?pretty&amp;_source=logType,logLevel\" 只查询指定字段的简易写法 mget 多条件匹配查询 匹配多个索引, 同时查询多个id的数据 curl -X GET \"localhost:9200/_mget?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"docs\" : [ &amp;#123; \"_index\" : \"monitor_log_mch_order_out\", \"_type\" : \"logs\", \"_id\" : \"AWSudIFgTuj3oZBEhyxK\" &amp;#125;, &amp;#123; \"_index\" : \"monitor_log_mch_order_out\", \"_type\" : \"logs\", \"_id\" : \"AWSuXewETuj3oZBEhywS\" &amp;#125; ] &amp;#125; ' 可以将索引写在host后面, 代表查询的都为同一索引下的数据 curl -X GET \"localhost:9200/monitor_log_mch_order_out/_mget?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"docs\" : [ &amp;#123; \"_type\" : \"logs\", \"_id\" : \"AWSudIFgTuj3oZBEhyxK\" &amp;#125;, &amp;#123; \"_type\" : \"logs\", \"_id\" : \"AWSuXewETuj3oZBEhywS\" &amp;#125; ] &amp;#125; ' 合并index和type, 代表查询的都为同一索引下type也相同的数据 curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_mget?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"docs\" : [ &amp;#123; \"_id\" : \"AWSudIFgTuj3oZBEhyxK\" &amp;#125;, &amp;#123; \"_id\" : \"AWSuXewETuj3oZBEhywS\" &amp;#125; ] &amp;#125; ' 简化后如下: curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_mget?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"ids\" : [\"AWSudIFgTuj3oZBEhyxK\", \"AWSuXewETuj3oZBEhywS\"] &amp;#125; ' 注: 当多个条件的 _type 相同时 可以使用 _all 或者省略 过滤字段, 每个Id分别对 _source进行过滤curl -X GET \"localhost:9200/monitor_log_mch_order_out/_mget?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"docs\" : [ &amp;#123; \"_id\" : \"AWSudIFgTuj3oZBEhyxK\", \"_source\" : false &amp;#125;, &amp;#123; \"_id\" : \"AWSuXewETuj3oZBEhywS\", \"_source\" : [\"bizId\", \"method\"] &amp;#125;, &amp;#123; \"_id\" : \"AWSuLAYqTuj3oZBEhysH\", \"_source\" : &amp;#123; \"include\": [\"log*\"], \"exclude\": [\"logLevel\"] &amp;#125; &amp;#125; ] &amp;#125; ' _search 搜索1. 匹配bizId 查询curl -X GET \"localhost:9200/monitor_log_mch_order_out/_search?pretty&amp;q=bizId:2009011201807190133430748068\" 2. 同时指定类型同时指定类型, 多个类型用 ‘,’ 隔开, 也支持多个索引勇士搜索, 多个索引用 ‘,’ 隔开, 或者模糊搜索 curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_search?pretty&amp;q=bizId:2009011201807190133430748068\" 3. 占位符 _all 匹配所有索引curl -X GET \"localhost:9200/_all/logs/_search?pretty&amp;q=bizId:2009011201807190133430748068\" 4. 匹配所有索引所有类型curl -X GET \"localhost:9200/_search?pretty&amp;q=bizId:2009011201807190133430748068\" 注: q 代表映射query_string 5. 请求体的方式curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_search?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"query\" : &amp;#123; \"term\" : &amp;#123; \"bizId\" : \"2009011201807190133430748068\" &amp;#125; &amp;#125; &amp;#125; ' 6. 分页查询 from/sizecurl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_search?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"from\" : 0, \"size\" : 1, \"query\" : &amp;#123; \"term\" : &amp;#123; \"bizId\" : \"2009011201807190133430748068\" &amp;#125; &amp;#125; &amp;#125; ' 7. 查询并过滤字段根据字段查询并筛选掉指定字段 curl -X GET \"localhost:9200/_search?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"_source\": &amp;#123; \"includes\": [ \"costTime\", \"bizId\" ], \"excludes\": [ \"logLevel\" ] &amp;#125;, \"query\" : &amp;#123; \"term\" : &amp;#123; \"bizId\" : \"2009011201807190133430748068\" &amp;#125; &amp;#125; &amp;#125; ' 范围查询1. 按照时间范围查询可以省略索引查询全部 curl -X GET \"localhost:9200/monitor_log_mch_order_out/_search?pretty\" -H 'Content-Type: application/json' -d' &amp;#123; \"query\": &amp;#123; \"range\" : &amp;#123; \"time\" : &amp;#123; \"gte\": \"2018-07-19 00:14:25:000\", \"lte\": \"2018-07-19 00:14:30:000\", \"format\": \"yyyy-MM-dd HH:mm:ss:SSS\" &amp;#125; &amp;#125; &amp;#125; &amp;#125; '","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"logstash配置","slug":"elk/logstash-config","date":"2018-06-20T14:28:02.000Z","updated":"2020-04-04T06:18:05.805Z","comments":true,"path":"2018/06/20/logstash-configuration.html","link":"","permalink":"https://liuzhihang.com/2018/06/20/logstash-configuration.html","excerpt":"输入input &#123; beats &#123; port =&gt; &quot;5043&quot; &#125; &#125; 配置日志输入方式为 filebeat, 并配置端口","text":"输入input &amp;#123; beats &amp;#123; port => \"5043\" &amp;#125; &amp;#125; 配置日志输入方式为 filebeat, 并配置端口 过滤filter &amp;#123; grok &amp;#123; match => &amp;#123; \"message\" => \"\\[%&amp;#123;DATA:time&amp;#125;\\]-\\[%&amp;#123;DATA:method&amp;#125;\\] - \\[%&amp;#123;DATA:catalina&amp;#125;\\] -\\[%&amp;#123;DATA:logLevel&amp;#125;\\] - \\[%&amp;#123;DATA:index_prefix&amp;#125;\\|%&amp;#123;WORD:logType&amp;#125;\\|%&amp;#123;WORD:sysNo&amp;#125;\\|%&amp;#123;WORD:objType&amp;#125;\\|%&amp;#123;DATA:funcode&amp;#125;\\|%&amp;#123;WORD:monitorObjNo&amp;#125;\\|%&amp;#123;WORD:bizId&amp;#125;\\|%&amp;#123;WORD:respCode&amp;#125;\\|%&amp;#123;DATA:respMsg&amp;#125;\\|%&amp;#123;WORD:costTime&amp;#125;|%&amp;#123;DATA:exField&amp;#125;\\]\" &amp;#125; &amp;#125; grok&amp;#123; match => &amp;#123; \"time\" => [\"%&amp;#123;INT:y_index&amp;#125;-%&amp;#123;INT:M_index&amp;#125;-%&amp;#123;INT:d_index&amp;#125;\"]&amp;#125; &amp;#125; mutate &amp;#123; add_field => &amp;#123; \"[@metadata][index_suffix]\" => \"%&amp;#123;y_index&amp;#125;%&amp;#123;M_index&amp;#125;%&amp;#123;d_index&amp;#125;\" &amp;#125; remove_field => [\"beat\",\"host\",\"thread\",\"class\",\"source\",\"tags\",\"type\",\"y_index\",\"M_index\",\"d_index\"] lowercase => [ \"index_prefix\" ] lowercase => [ \"funcode\" ] lowercase => [ \"objType\" ] lowercase => [ \"monitorObjNo\" ] &amp;#125; &amp;#125; 使用gork过滤器对日志进行筛选, 并对部分字段赋值. 使用mutate插件对字段进行转换, add_field 为添加字段 [@metadata][index_suffix] 意思是添加临时字段, 该字段不会输出到es中 输出output &amp;#123; if [logType] == \"info\" &amp;#123; elasticsearch &amp;#123; hosts => [ \"xxx.xxx.xxx.xxx:9200\" ] index => \"%&amp;#123;index_prefix&amp;#125;_%&amp;#123;objType&amp;#125;_%&amp;#123;funcode&amp;#125;_%&amp;#123;[@metadata][index_suffix]&amp;#125;\" user => elastic password => xxx &amp;#125; &amp;#125; if [logType] == \"error\" &amp;#123; redis &amp;#123; data_type => \"list\" db => 0 #key => \"%&amp;#123;index_prefix&amp;#125;_%&amp;#123;sysNo&amp;#125;_%&amp;#123;objType&amp;#125;_%&amp;#123;funcode&amp;#125;_%&amp;#123;[@metadata][index_suffix]&amp;#125;\" key => \"%&amp;#123;index_prefix&amp;#125;_%&amp;#123;sysNo&amp;#125;_%&amp;#123;objType&amp;#125;_%&amp;#123;monitorObjNo&amp;#125;\" host => \"xxx.xxx.xxx.xxx\" port => \"6379\" password => \"xxx\" &amp;#125; &amp;#125; &amp;#125; 将过滤后的字段按照类型输出到Es或者redis队列中 启动命令 ./bin/logstash -f first-pipelines.yml nohup ./logstash -f ../first-pipelines.yml &gt;/dev/null 2&gt;&amp;1 &amp; 其他配置# 输出到控制台 stdout &amp;#123; codec => rubydebug &amp;#125;","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"filebeat配置","slug":"elk/filebeat-config","date":"2018-06-20T13:30:29.000Z","updated":"2020-04-04T06:17:59.180Z","comments":true,"path":"2018/06/20/filebeat-configuration.html","link":"","permalink":"https://liuzhihang.com/2018/06/20/filebeat-configuration.html","excerpt":"","text":"filebeat配置filebeat.prospectors: - input_type: log #读取日志的路径 paths: - /opt/export/log/info-xxx.log fields: log_type: \"monitor_log\" fields_under_root: true #过滤部分日志 include_lines: ['Monitor_log'] #----------------------------- Logstash output -------------------------------- output.logstash: # The Logstash hosts hosts: [\"xxx.xxx.xxx.xxx:5043\",\"xxx.xxx.xxx.xxx:5043\"] loadbalance: true #================================ Logging ===================================== logging.level: info logging.to_files: true logging.to_syslog: false logging.files: path: /opt/export/app/filebeat/logs name: mybeat.log keepfiles: 5 过滤不包含指定字段的日志, 并仅仅输出到logstash, 也可以直接输出到Elasticsearch 启动命令 前台启动：关闭窗口连接后自动退出 ./filebeat -e -c filebeat.yml 后台启动: nohup ./filebeat -e -c filebeat.yml >/dev/null 2>&amp;1 &amp; 关闭: kill -9 xxxx","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"监控系统架构","slug":"elk/framework","date":"2018-06-20T12:25:29.000Z","updated":"2020-04-04T06:18:02.309Z","comments":true,"path":"2018/06/20/monitoring-system-architecture.html","link":"","permalink":"https://liuzhihang.com/2018/06/20/monitoring-system-architecture.html","excerpt":"监控系统基本框架","text":"监控系统基本框架 解释 各业务系统按照指定格式打印日志 filebeat自动读取日志信息, 并进行过滤, 输出到logstash logstash进行二次处理, 将日志内容格式化, 并将 info日志和error日志分别存放到Elasticsearch和redis队列中 监控系统定时从Es和redis中获取数据, 存放到mysql并进行报警分析 使用EChart图形化展示信息…","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"线程的生命周期","slug":"concurrent/thread-life-cycle","date":"2018-06-15T11:31:00.000Z","updated":"2020-04-04T06:16:51.741Z","comments":true,"path":"2018/06/15/thread-life-cycle.html","link":"","permalink":"https://liuzhihang.com/2018/06/15/thread-life-cycle.html","excerpt":"线程的生命周期","text":"线程的生命周期 图解析1.一般情况下线程主要经历: 准备, 就绪, 运行, 死亡四种状态.2.准备:即创建线程, 包括集成Thread, 线程池, spring方式等等3.就绪:线程创建并调用start()方法并不代表线程将立即获得资源, 而是进入到就绪状态进行资源分配4.运行:抢占到资源的线程将执行, 执行过程可能会含有一些别的操作&emsp;1).线程等待, 直到调用 notify()或notifyAll()方法被唤醒, 这里唤醒后不会立即继续执行线程, 而是进入就绪状态重新抢占资源&emsp;2).线程休眠, 直到休眠时间结束, 同样结束后不会立即继续执行线程, 而是进入就绪状态重新抢占资源&emsp;3).线程阻塞, IO资源阻塞, 锁等方式使线程进入阻塞队列, 释放锁将继续执行5.死亡: 调用stop()方法, 线程中断, 或线程执行完毕则线程死亡","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"synchronized锁的介绍","slug":"concurrent/synchronized-thread","date":"2018-06-13T12:25:00.000Z","updated":"2020-04-04T06:16:28.556Z","comments":true,"path":"2018/06/13/introduction-of-synchronized-lock.html","link":"","permalink":"https://liuzhihang.com/2018/06/13/introduction-of-synchronized-lock.html","excerpt":"synchronized锁的使用synchronized可以使用在方法和代码块中, 使用的方式不同锁代表的含义不同, 下面将从几个方面进行介绍. 普通方法 静态方法 代码块synchronized(this) 代码块synchronized(*.class)","text":"synchronized锁的使用synchronized可以使用在方法和代码块中, 使用的方式不同锁代表的含义不同, 下面将从几个方面进行介绍. 普通方法 静态方法 代码块synchronized(this) 代码块synchronized(*.class) 结论 在使用synchronized关键字中锁主要分为两类, 一种是对象锁, 另一种类锁 普通加锁方法和synchronized(this)都是对象锁, 静态加锁方法和synchronized(*.class)都是类锁 对象锁: 同一对象持有锁, 相同对象等待, 其他对象不受影响; 不同对象持有锁, 互不影响. 类锁: 类锁时, 只要该类的对象持有锁, 无论是否为同一对象访问静态同步方法时都等待, 访问非静态同步方法不受影响. 对象锁和类锁互相不影响 测试代码及过程package com.liuzhihang.tool.sync; /** * @author liuzhihang * @date 2018/7/11 16:25 */ public class SyncMainTest &amp;#123; public static void main(String[] args) &amp;#123; SyncTest syncTest1 = new SyncTest(); // SyncTest syncTest2 = new SyncTest(); new Thread(() -> syncTest1.methodA(), \"线程 01 \").start(); new Thread(() -> syncTest1.methodB(), \"线程 02 \").start(); &amp;#125; &amp;#125; class SyncTest &amp;#123; void methodA() &amp;#123; System.out.println(Thread.currentThread().getName() + \"start\"); try &amp;#123; System.out.println(Thread.currentThread().getName() + \"sleep\"); Thread.sleep(500); &amp;#125; catch (InterruptedException e) &amp;#123; &amp;#125; System.out.println(Thread.currentThread().getName() + \"end\"); &amp;#125; void methodB() &amp;#123; System.out.println(Thread.currentThread().getName() + \"start\"); try &amp;#123; System.out.println(Thread.currentThread().getName() + \"sleep\"); Thread.sleep(300); &amp;#125; catch (InterruptedException e) &amp;#123; &amp;#125; System.out.println(Thread.currentThread().getName() + \"end\"); &amp;#125; &amp;#125; 以上为一个简单的测试代码, 指使用两个线程分别调用两个方法, 通过打印结果可以看出顺序是乱序的, 其中线程的 start() 顺序并不代表线程的执行顺序, 在下面测试中假设是 “线程01” 先执行. 1.A B 方法分别添加synchronized关键字 + 同一对象class SyncTest &amp;#123; synchronized void methodA() &amp;#123; // ... &amp;#125; synchronized void methodB() &amp;#123; // ... &amp;#125; &amp;#125; 结论: 方法 A 阻塞, 方法 B 等待 A 执行完毕后才继续执行. 2.A B 方法分别添加synchronized关键字 + 不同对象public class SyncMainTest &amp;#123; public static void main(String[] args) &amp;#123; SyncTest syncTest1 = new SyncTest(); SyncTest syncTest2 = new SyncTest(); new Thread(() -> syncTest1.methodA(), \"线程 01 \").start(); new Thread(() -> syncTest2.methodB(), \"线程 02 \").start(); &amp;#125; &amp;#125; class SyncTest &amp;#123; synchronized void methodA() &amp;#123; // ... &amp;#125; synchronized void methodB() &amp;#123; // ... &amp;#125; &amp;#125; 结论: 方法 A 阻塞, 方法 B 不受影响. 3.A 方法分别添加synchronized关键字 B方法不添加class SyncTest &amp;#123; synchronized void methodA() &amp;#123; // ... &amp;#125; void methodB() &amp;#123; // ... &amp;#125; &amp;#125; 结论: 方法 A 阻塞, 方法 B 不受影响. 4.A B 方法分别添加 static synchronized + 不同对象public class SyncMainTest &amp;#123; public static void main(String[] args) &amp;#123; SyncTest syncTest1 = new SyncTest(); SyncTest syncTest2 = new SyncTest(); new Thread(() -> syncTest1.methodA(), \"线程 01 \").start(); new Thread(() -> syncTest2.methodB(), \"线程 02 \").start(); &amp;#125; &amp;#125; class SyncTest &amp;#123; static synchronized void methodA() &amp;#123; // ... &amp;#125; static synchronized void methodB() &amp;#123; // ... &amp;#125; &amp;#125; 结论: 方法 A 阻塞, 方法 B 等待 A结束后继续执行. 5.A 方法添加 static synchronized, B 方法添加 synchronized + 不同对象public class SyncMainTest &amp;#123; public static void main(String[] args) &amp;#123; SyncTest syncTest1 = new SyncTest(); SyncTest syncTest2 = new SyncTest(); new Thread(() -> syncTest1.methodA(), \"线程 01 \").start(); new Thread(() -> syncTest2.methodB(), \"线程 02 \").start(); &amp;#125; &amp;#125; class SyncTest &amp;#123; static synchronized void methodA() &amp;#123; // ... &amp;#125; synchronized void methodB() &amp;#123; // ... &amp;#125; &amp;#125; 结论: 方法 A 阻塞, 方法 B 不受影响. 6.A B 方法内添加 synchronized(this)class SyncTest &amp;#123; void methodA() &amp;#123; synchronized (this) &amp;#123; // ... &amp;#125; &amp;#125; void methodB() &amp;#123; synchronized (this) &amp;#123; // ... &amp;#125; &amp;#125; &amp;#125; 结论: 同一对象 A 阻塞 B等待, 不同对象 A阻塞 B不受影响 7.A B 方法内添加 synchronized(SyncTest.class)class SyncTest &amp;#123; void methodA() &amp;#123; synchronized (SyncTest.class) &amp;#123; // ... &amp;#125; &amp;#125; void methodB() &amp;#123; synchronized (SyncTest.class) &amp;#123; // ... &amp;#125; &amp;#125; &amp;#125; 结论: 同一/不同对象 A 阻塞 B等待 8.A 方法内添加 synchronized(SyncTest.class), B 方法内添加 synchronized(this)class SyncTest &amp;#123; void methodA() &amp;#123; synchronized (SyncTest.class) &amp;#123; // ... &amp;#125; &amp;#125; void methodB() &amp;#123; synchronized (this) &amp;#123; // ... &amp;#125; &amp;#125; &amp;#125; 结论: 同一/不同对象 A 阻塞 B不受影响 9.A 方法内添加 synchronized(SyncTest.class), B 方法内添加 synchronized(OtherObj)class SyncTest &amp;#123; private String string = \"lock\"; void methodA() &amp;#123; synchronized (SyncTest.class) &amp;#123; // ... &amp;#125; &amp;#125; void methodB() &amp;#123; synchronized (string) &amp;#123; // ... &amp;#125; &amp;#125; &amp;#125; 结论: 同一/不同对象 A 阻塞 B不受影响","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"synchronized同步锁原理","slug":"concurrent/synchronized","date":"2018-06-11T12:25:29.000Z","updated":"2020-04-04T06:16:09.670Z","comments":true,"path":"2018/06/11/synchronized-synchronous-lock-principle.html","link":"","permalink":"https://liuzhihang.com/2018/06/11/synchronized-synchronous-lock-principle.html","excerpt":"介绍 在多线程操作中volatile关键字可以保证共享变量的内存可见性, 但是并不能保证操作的原子性, 这时候就需要用到锁, synchronized同步锁是java关键字, 是内置的语言实现. synchronized加锁和线程结束或异常锁的释放过程由JVM进行控制 synchronized关键字可以使用在方法和同步代码块中, 不同的使用方式, 锁的结果是不同的 重量级锁 + 可重入","text":"介绍 在多线程操作中volatile关键字可以保证共享变量的内存可见性, 但是并不能保证操作的原子性, 这时候就需要用到锁, synchronized同步锁是java关键字, 是内置的语言实现. synchronized加锁和线程结束或异常锁的释放过程由JVM进行控制 synchronized关键字可以使用在方法和同步代码块中, 不同的使用方式, 锁的结果是不同的 重量级锁 + 可重入 synchronized底层原理1.代码示例 package com.liuzhihang.tool.java; /** * @author liuzhihang * @date 2018/06/11 16:05 */ public class SynchronizedTest &amp;#123; private int i; private int j; public void syncTest1() &amp;#123; synchronized (this) &amp;#123; i++; &amp;#125; &amp;#125; public synchronized void syncTest2() &amp;#123; j++; &amp;#125; &amp;#125; 2.使用 javap -v SynchronizedTest.class 查看代码的对应字节码如下: $ javap -v SynchronizedTest.class Classfile /C:/Users/liuzhihang/Desktop/SynchronizedTest.class Last modified 2018-7-10; size 518 bytes MD5 checksum ba48def77b226e7b9ac28121ec423c16 Compiled from &quot;SynchronizedTest.java&quot; public class com.liuzhihang.tool.java.SynchronizedTest minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: // 常量池省略 &#123; // 构造方法省略 public void syncTest1(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: aload_0 5: dup 6: getfield #2 // Field i:I 9: iconst_1 10: iadd 11: putfield #2 // Field i:I 14: aload_1 15: monitorexit 16: goto 24 19: astore_2 20: aload_1 21: monitorexit 22: aload_2 23: athrow 24: return Exception table: // 省略代码 public synchronized void syncTest2(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #3 // Field j:I 5: iconst_1 6: iadd 7: putfield #3 // Field j:I 10: return LineNumberTable: line 22: 0 line 23: 10 &#125; SourceFile: &quot;SynchronizedTest.java&quot; 3.结论 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令, 其中有两个 monitorexit 因为不能确保是正常结束还是异常结束, 所以另一个是用来确保异常结束时释放 monitor指令. 同步方法时使用的是 flags中的 ACC_SYNCHRONIZED 来标识该方法为同步方法, JVM在调用该方法时便会执行相应的同步调用. 每个线程都维护自己的监视器(monitor), 只要是同步调用进行相关操作时要先获得 monitor, 否则将被阻塞","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"volatile关键字","slug":"concurrent/volatile","date":"2018-06-09T14:31:29.000Z","updated":"2020-04-04T06:49:14.260Z","comments":true,"path":"2018/06/09/volatile-keyword.html","link":"","permalink":"https://liuzhihang.com/2018/06/09/volatile-keyword.html","excerpt":"介绍在多线程操作共享变量时, 会使用volatile修饰共享变量, 比如单例模式的双重锁检查中, 并且在concurrent包下也大量使用了volatile关键字;volatile可以对类属性进行修饰, 从而确保线程每次都是从主存中获取属性, 操作完毕后写回主存.","text":"介绍在多线程操作共享变量时, 会使用volatile修饰共享变量, 比如单例模式的双重锁检查中, 并且在concurrent包下也大量使用了volatile关键字;volatile可以对类属性进行修饰, 从而确保线程每次都是从主存中获取属性, 操作完毕后写回主存. java内存模型 在多线程同时对共享变量进行操作过程中, 每个线程会拷贝一份共享变量到自己的工作内存中进行相关操作, 操作完毕后会将结果写入到主存中. 而volatile关键字可以保证操作的可见性和有序性, 但是却不能保证原子性. 扩展原子性指一个操作或者多个操作要么全部执行要么全部都不执行, 操作过程整体是一个原子, 不被分割打断. 可见性当多个线程访问同一个变量时, 一个线程修改了这个变量的值, 其他线程能够立即看得到修改的值. 有序性即程序执行的顺序按照代码的先后顺序执行主要原因是因为处理器在处理程序时会进行指令重排, 对代码进行优化, 指令重排在单线程中得到的结果是一致的, 但是在多线程中就会造成各种错误. volatile关键字作用1.使用volatile关键字修饰的变量,会强制将修改的值写入到主存中2.volatile不保证原子性, 在多线程操作下仅能保证操作别的线程可见, 在多线程情况下同时操作共享变量依然会有数据不正确的情况.3.volatile会防止指令重排","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"volatile","slug":"volatile","permalink":"https://liuzhihang.com/tags/volatile/"}]},{"title":"SpringAop代理的选择","slug":"spring/springAop","date":"2018-05-21T06:50:13.000Z","updated":"2020-04-04T04:12:06.927Z","comments":true,"path":"2018/05/21/springaop-agent-selection.html","link":"","permalink":"https://liuzhihang.com/2018/05/21/springaop-agent-selection.html","excerpt":"介绍Spring动态创建bean过程, 是如何进行选择使用 jdk还是cglib进行代理的, 可以通过源码进行解析 执行过程通过断点进行跟踪主要执行过程在 DefaultAopProxyFactory, 通过判断条件是使用Cglib还是Jdk","text":"介绍Spring动态创建bean过程, 是如何进行选择使用 jdk还是cglib进行代理的, 可以通过源码进行解析 执行过程通过断点进行跟踪主要执行过程在 DefaultAopProxyFactory, 通过判断条件是使用Cglib还是Jdk 相关源码解析public class DefaultAopProxyFactory implements AopProxyFactory, Serializable &amp;#123; @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &amp;#123; //判断条件 是否优化, 返回是否直接代理目标类以及任何接口或者没有用户提供的代理接口 if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &amp;#123; Class&lt;?> targetClass = config.getTargetClass(); if (targetClass == null) &amp;#123; throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); &amp;#125; //判断是否是接口, 和已经使用jdk代理 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &amp;#123; return new JdkDynamicAopProxy(config); &amp;#125; return new ObjenesisCglibAopProxy(config); &amp;#125; else &amp;#123; return new JdkDynamicAopProxy(config); &amp;#125; &amp;#125; /** * Determine whether the supplied &amp;#123;@link AdvisedSupport&amp;#125; has only the * &amp;#123;@link org.springframework.aop.SpringProxy&amp;#125; interface specified * (or no proxy interfaces specified at all). */ private boolean hasNoUserSuppliedProxyInterfaces(AdvisedSupport config) &amp;#123; Class&lt;?>[] ifcs = config.getProxiedInterfaces(); return (ifcs.length == 0 || (ifcs.length == 1 &amp;&amp; SpringProxy.class.isAssignableFrom(ifcs[0]))); &amp;#125; &amp;#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"aop","slug":"aop","permalink":"https://liuzhihang.com/tags/aop/"}]},{"title":"cglib动态代理","slug":"spring/CglibProxy","date":"2018-05-18T11:55:01.000Z","updated":"2020-04-04T06:26:10.822Z","comments":true,"path":"2018/05/18/cglib-dynamic-proxy.html","link":"","permalink":"https://liuzhihang.com/2018/05/18/cglib-dynamic-proxy.html","excerpt":"介绍Spring动态代理可以选择使用jdk动态代理, 或者cglib动态代理, cglib动态代理位于 net.sf.cglib.proxy 包下. 使用时涉及接口: net.sf.cglib.proxy.MethodInterceptor用来生成动态子类的类类: net.sf.cglib.proxy.Enhancer 注意: cglib 动态代理是基于类的代理, 是通过对指定的业务类生成一个子类, 并覆盖其中业务方法实现代理. 因为使用继承, 所以被代理类不能使 final 修饰","text":"介绍Spring动态代理可以选择使用jdk动态代理, 或者cglib动态代理, cglib动态代理位于 net.sf.cglib.proxy 包下. 使用时涉及接口: net.sf.cglib.proxy.MethodInterceptor用来生成动态子类的类类: net.sf.cglib.proxy.Enhancer 注意: cglib 动态代理是基于类的代理, 是通过对指定的业务类生成一个子类, 并覆盖其中业务方法实现代理. 因为使用继承, 所以被代理类不能使 final 修饰 使用步骤1.创建MethodInterceptor接口的实现类, 并编写intercept方法的实现2.通过methodProxy.invokeSuper(o, objects);调用父类的方法3.创建Enhancer, 通过 setSuperclass(Class superclass)方法指定父类(被代理类), 通过 setCallback(final Callback callback)方法指定代理4.enhancer.create() 生成代理, 调用被代理类的方法 代码演示按照步骤编写简易逻辑代码. 创建MethodInterceptor接口的实现类/** * 基于类的代理 即使类没有实现接口也可以被代理 * 主要是基于类生成一个继承的子类 所以 类和方法不要声明为 final * * * @author liuzhihang * @date 2018/5/18 10:10 */ public class MyMethodInterceptor implements MethodInterceptor &amp;#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &amp;#123; System.out.println(\"cglib动态代理 before . . .\"); Object invoke = null; try &amp;#123; invoke = methodProxy.invokeSuper(o, objects); &amp;#125; catch (Throwable throwable) &amp;#123; throwable.printStackTrace(); System.err.println(\"cglib动态代理 error: \" + throwable.getMessage()); &amp;#125; finally &amp;#123; System.out.println(\"cglib动态代理 after . . .\"); &amp;#125; return invoke; &amp;#125; &amp;#125; 创建Enhancer创建Enhancer, 通过 setSuperclass(Class superclass)方法指定父类(被代理类), 通过 setCallback(final Callback callback)方法指定代理 public class CglibMainTest &amp;#123; public static void main(String[] args) &amp;#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SubjectCglib.class); enhancer.setCallback(new MyMethodInterceptor()); SubjectCglib subjectCglib = (SubjectCglib) enhancer.create(); System.err.println(subjectCglib.getAge(\"liuzhihang\")); &amp;#125; &amp;#125; 可以将二者合并到MyInterceptor中/** * 基于类的代理 即使类没有实现接口也可以被代理 * * * @author liuzhihang * @date 2018/5/18 10:10 */ public class MyCglibInterceptor implements MethodInterceptor &amp;#123; private Object object; public Object getInstance(Object object) &amp;#123; this.object = object; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(object.getClass()); enhancer.setCallback(this); return enhancer.create(); &amp;#125; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &amp;#123; System.out.println(\"cglib动态代理 before . . .\"); Object invoke = null; try &amp;#123; invoke = methodProxy.invokeSuper(o, objects); &amp;#125; catch (Throwable throwable) &amp;#123; throwable.printStackTrace(); System.err.println(\"cglib动态代理 error: \" + throwable.getMessage()); &amp;#125; finally &amp;#123; System.out.println(\"cglib动态代理 after . . .\"); &amp;#125; return invoke; &amp;#125; &amp;#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"动态代理","slug":"动态代理","permalink":"https://liuzhihang.com/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"jdk动态代理及源码解析","slug":"spring/JDKProxy","date":"2018-05-17T11:55:01.000Z","updated":"2020-04-04T06:27:13.047Z","comments":true,"path":"2018/05/17/jdk-dynamic-proxy-and-source-code-analysis.html","link":"","permalink":"https://liuzhihang.com/2018/05/17/jdk-dynamic-proxy-and-source-code-analysis.html","excerpt":"介绍Spring动态代理可以选择使用jdk动态代理, 或者cglib动态代理, jdk动态代理位于 java.lang.reflect 包下. 使用时涉及接口: java.lang.reflect.InvocationHandler动态代理类: java.lang.reflect.Proxy 注意: JDK 动态代理是基于接口的代理, 只能对实现接口的类生成代理, 不能对类进行代理","text":"介绍Spring动态代理可以选择使用jdk动态代理, 或者cglib动态代理, jdk动态代理位于 java.lang.reflect 包下. 使用时涉及接口: java.lang.reflect.InvocationHandler动态代理类: java.lang.reflect.Proxy 注意: JDK 动态代理是基于接口的代理, 只能对实现接口的类生成代理, 不能对类进行代理 使用步骤1.创建InvocationHandler接口的实现类, 并编写invoke方法的实现2.创建被代理类的接口及实现类3.使用动态代理类Proxy的静态方法生成代理类实例4.使用实例调用方法 代码演示按照步骤编写简易逻辑代码. 创建InvocationHandler接口的实现类/** * JDK 动态代理 * 基于接口的代理, 只能对实现接口的类生成代理, 不能对类进行代理 * * @author liuzhihang * @date 2018/5/17 10:36 */ public class MyInvocationHandler implements InvocationHandler &amp;#123; /** * 目标对象 */ private Object target; public MyInvocationHandler(Object target) &amp;#123; this.target = target; &amp;#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; System.out.println(\"jdk 动态代理 before . . . \"); System.out.println(\"当前代理方法为:\" + method); Object invoke = method.invoke(target, args); System.out.println(\"jdk 动态代理 after . . . \"); return invoke; &amp;#125; &amp;#125; 创建被代理类的接口及实现类/** * 被代理类的接口 * @author liuzhihang * @date 2018/5/17 10:47 */ public interface Subject &amp;#123; /** * 获取名字 * @return */ String getName(); /** * 获取年龄 * @param name * @return */ String getAge(String name); &amp;#125; /** * 被代理类 * * @author liuzhihang * @date 2018/5/17 10:48 */ public class SubjectImpl implements Subject &amp;#123; @Override public String getName() &amp;#123; System.out.println(\"SubjectImpl的获取名字方法 . . .\"); return \"liuzhihang\"; &amp;#125; @Override public String getAge(String name) &amp;#123; System.out.println(name + \"开始获取年龄 . . .\"); return \"25\"; &amp;#125; &amp;#125; 使用动态代理类Proxy的静态方法生成代理类实例获取代理类实例有以下两种方式, 一种是通过Proxy.newProxyInstance(..)获取, 一种是通过 Proxy.getProxyClass(..) 方式获取1.Proxy.newProxyInstance(..) /** * 当代理类实例调用方法时, 会自动跳转到代理类关联的 handler 对象, 通过 method.invoke(target, args) 进行调用 * * * @author liuzhihang * @date 2018/5/17 10:49 */ public class ProxyMainTest &amp;#123; public static void main(String[] args) &amp;#123; Subject subject = new SubjectImpl(); ClassLoader classLoader = subject.getClass().getClassLoader(); Class&lt;?>[] interfaces = subject.getClass().getInterfaces(); MyInvocationHandler handler = new MyInvocationHandler(subject); // 生成代理类实例 Subject proxyInstance = (Subject) Proxy.newProxyInstance(classLoader, interfaces, handler); String name = proxyInstance.getName(); String instanceAge = proxyInstance.getAge(\"liuzhihang\"); System.err.println(name + \" \" + instanceAge); &amp;#125; &amp;#125; 2.Proxy.getProxyClass(..) /** * 当代理类实例调用方法时, 会自动跳转到代理类关联的 handler 对象, 通过 method.invoke(target, args) 进行调用 * 此方式有异常抛出 * * @author liuzhihang * @date 2018/5/17 10:49 */ public class ProxyMainTest &amp;#123; public static void main(String[] args) &amp;#123; try &amp;#123; Subject subject = new SubjectImpl(); ClassLoader classLoader = subject.getClass().getClassLoader(); Class&lt;?>[] interfaces = subject.getClass().getInterfaces(); MyInvocationHandler handler = new MyInvocationHandler(subject); Class&lt;?> proxyClass = Proxy.getProxyClass(classLoader, interfaces); Constructor&lt;?> constructor = proxyClass.getConstructor(InvocationHandler.class); Subject subject1 = (Subject) constructor.newInstance(handler); String name1 = subject1.getName(); String instanceAge1 = subject1.getAge(\"liuzhihang\"); System.err.println(name1 + \" \" + instanceAge1); &amp;#125; catch (NoSuchMethodException | IllegalAccessException | InvocationTargetException | InstantiationException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; 执行结果D:\\jdk1.8\\bin\\java.exe . . . liuzhihang 25 jdk 动态代理 before . . . 当前代理方法为:public abstract java.lang.String com.liuzhihang.tool.proxy.jdk.Subject.getName() SubjectImpl的获取名字方法 . . . jdk 动态代理 after . . . jdk 动态代理 before . . . 当前代理方法为:public abstract java.lang.String com.liuzhihang.tool.proxy.jdk.Subject.getAge(java.lang.String) liuzhihang开始获取年龄 . . . jdk 动态代理 after . . . Process finished with exit code 0 结论: 代理实例在每次调用方法是都会通过代理类进行调用 相关源码解析完整注释可自己查看相关源码, 源码过程应当DeBug多走走.1.调用 Proxy.newProxyInstance 方法 /** * 返回指定接口的代理类实例，该接口将方法调用分派给指定的调用处理程序 */ @CallerSensitive public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; // 非空校验 Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); // 获取系统安全接口 final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; // 校验权限 checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * 从缓存中获取代理类 或者 生成新的代理类 */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * 通过反射获取构造函数对象并生成代理类实例 */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; // 获取构造 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; // 验证代理类的修饰符 if (!Modifier.isPublic(cl.getModifiers())) &#123; // 修改访问权限 AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; // 将此对象的可访问标志设置为指定的布尔值, true表示反射对象在使用时应禁止Java语言访问检查, false表示反射对象应强制执行Java语言访问检查 cons.setAccessible(true); return null; &#125; &#125;); &#125; //生成实例, 并将参数传入构造 return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException | InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125; 可以看出获取代理类是在 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); 处, 继续相关逻辑2.获取代理类相关逻辑 /** * 生成代理类, 之前必须进行权限检查 */ private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(&quot;interface limit exceeded&quot;); &#125; //如果由实现给定接口的给定加载器定义的代理类存在，则它将简单地返回缓存副本; 否则，它将通过Proxy Class Factory创建代理类 return proxyClassCache.get(loader, interfaces); &#125; 3.proxyClassCache.get(loader, interfaces);java.lang.reflect.WeakCache#get(..) 介绍 /** * 通过缓存查找值, 如果缓存中没有给定的（key，sub Key）对的条目或条目已被清除，则它总是评估&#123;Key sub Key Factory&#125;函数并可选择评估&#123;Factory value&#125;函数 */ public V get(K key, P parameter) &#123; // 非空校验 Objects.requireNonNull(parameter); // 判断移除队列 expungeStaleEntries(); // 缓存key Object cacheKey = CacheKey.valueOf(key, refQueue); // 延迟加载使用二级map ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey); if (valuesMap == null) &#123; ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey, valuesMap = new ConcurrentHashMap&lt;&gt;()); if (oldValuesMap != null) &#123; valuesMap = oldValuesMap; &#125; &#125; // 创建子key 并根据key 检索supplier Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); // 根据key获取supplier Supplier&lt;V&gt; supplier = valuesMap.get(subKey); Factory factory = null; while (true) &#123; if (supplier != null) &#123; // supplier 可能为 Factory 或者 CacheValue&lt;V&gt; 的实例, 从缓存中获取到则直接返回 V value = supplier.get(); if (value != null) &#123; return value; &#125; &#125; // factory不存在则创建 if (factory == null) &#123; factory = new Factory(key, parameter, subKey, valuesMap); &#125; // supplier 为null if (supplier == null) &#123; // 从valuesMap获取supplier supplier = valuesMap.putIfAbsent(subKey, factory); if (supplier == null) &#123; // successfully installed Factory supplier = factory; &#125; // else retry with winning supplier &#125; else &#123; if (valuesMap.replace(subKey, supplier, factory)) &#123; // successfully replaced // cleared CacheEntry / unsuccessful Factory // with our Factory supplier = factory; &#125; else &#123; // retry with current supplier supplier = valuesMap.get(subKey); &#125; &#125; &#125; &#125; 可以发现重点在 Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); 获取 subKey 的过程中.4.subKeyFactory.apply(key, parameter)Debug发现在此处调用的是 java.lang.reflect.Proxy.ProxyClassFactory 静态内部类,此处根据接口的数量生成二级缓存 /** * 一个工厂函数, 用于生成, 定义并返回给定ClassLoader和接口数组的代理类 */ private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?>[], Class&lt;?>> &amp;#123; // 所有代理类的前缀 private static final String proxyClassNamePrefix = \"$Proxy\"; // next number to use for generation of unique proxy class names private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?> apply(ClassLoader loader, Class&lt;?>[] interfaces) &amp;#123; // 在IdentityHashMap中, 当且仅当两个key严格相等（key1==key2）时，IdentityHashMap才认为两个key相等 Map&lt;Class&lt;?>, Boolean> interfaceSet = new IdentityHashMap&lt;>(interfaces.length); // 循环接口数组 for (Class&lt;?> intf : interfaces) &amp;#123; /* * 验证类加载器是否将此接口的名称解析为同一个Class对象 */ Class&lt;?> interfaceClass = null; try &amp;#123; // 获取接口的 class interfaceClass = Class.forName(intf.getName(), false, loader); &amp;#125; catch (ClassNotFoundException e) &amp;#123; &amp;#125; if (interfaceClass != intf) &amp;#123; throw new IllegalArgumentException( intf + \" is not visible from class loader\"); &amp;#125; /* * 验证interfaceClass是否为接口 */ if (!interfaceClass.isInterface()) &amp;#123; throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); &amp;#125; /* * 验证接口是否重复 */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &amp;#123; throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); &amp;#125; &amp;#125; String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * 验证所有非公开代理接口是否在同一个包中 */ for (Class&lt;?> intf : interfaces) &amp;#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &amp;#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) &amp;#123; proxyPkg = pkg; &amp;#125; else if (!pkg.equals(proxyPkg)) &amp;#123; throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &amp;#125; &amp;#125; &amp;#125; if (proxyPkg == null) &amp;#123; // 如果没有非公开的代理接口，使用 com.sun.proxy package proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; &amp;#125; /* * 为要生成的代理类选择一个名称 */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * 生成代理类 */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); try &amp;#123; return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &amp;#125; catch (ClassFormatError e) &amp;#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &amp;#125; &amp;#125; &amp;#125; 5.生辰给代理类byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags);可以在测试类中添加以下内容打印出代理类: System.setProperty(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;); 代理类内容如下: // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package com.sun.proxy; import com.liuzhihang.tool.proxy.jdk.Subject; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; public final class $Proxy0 extends Proxy implements Subject &amp;#123; private static Method m1; private static Method m3; private static Method m2; private static Method m4; private static Method m0; public $Proxy0(InvocationHandler var1) throws &amp;#123; super(var1); &amp;#125; public final boolean equals(Object var1) throws &amp;#123; try &amp;#123; return (Boolean)super.h.invoke(this, m1, new Object[]&amp;#123;var1&amp;#125;); &amp;#125; catch (RuntimeException | Error var3) &amp;#123; throw var3; &amp;#125; catch (Throwable var4) &amp;#123; throw new UndeclaredThrowableException(var4); &amp;#125; &amp;#125; public final String getName() throws &amp;#123; try &amp;#123; return (String)super.h.invoke(this, m3, (Object[])null); &amp;#125; catch (RuntimeException | Error var2) &amp;#123; throw var2; &amp;#125; catch (Throwable var3) &amp;#123; throw new UndeclaredThrowableException(var3); &amp;#125; &amp;#125; public final String toString() throws &amp;#123; try &amp;#123; return (String)super.h.invoke(this, m2, (Object[])null); &amp;#125; catch (RuntimeException | Error var2) &amp;#123; throw var2; &amp;#125; catch (Throwable var3) &amp;#123; throw new UndeclaredThrowableException(var3); &amp;#125; &amp;#125; public final String getAge(String var1) throws &amp;#123; try &amp;#123; return (String)super.h.invoke(this, m4, new Object[]&amp;#123;var1&amp;#125;); &amp;#125; catch (RuntimeException | Error var3) &amp;#123; throw var3; &amp;#125; catch (Throwable var4) &amp;#123; throw new UndeclaredThrowableException(var4); &amp;#125; &amp;#125; public final int hashCode() throws &amp;#123; try &amp;#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &amp;#125; catch (RuntimeException | Error var2) &amp;#123; throw var2; &amp;#125; catch (Throwable var3) &amp;#123; throw new UndeclaredThrowableException(var3); &amp;#125; &amp;#125; static &amp;#123; try &amp;#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m3 = Class.forName(\"com.liuzhihang.tool.proxy.jdk.Subject\").getMethod(\"getName\"); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m4 = Class.forName(\"com.liuzhihang.tool.proxy.jdk.Subject\").getMethod(\"getAge\", Class.forName(\"java.lang.String\")); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &amp;#125; catch (NoSuchMethodException var2) &amp;#123; throw new NoSuchMethodError(var2.getMessage()); &amp;#125; catch (ClassNotFoundException var3) &amp;#123; throw new NoClassDefFoundError(var3.getMessage()); &amp;#125; &amp;#125; &amp;#125; 可以看出生成的$Proxy0类继承Proxy动态代理类并实现了Subject被代理接口, 实现所有方法通过 super.h.invoke(this, m1, new Object[]{var1}) 内部调用了 InvocationHandler.invoke(…)方法, 通过反射调用代理实例的方法","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"动态代理","slug":"动态代理","permalink":"https://liuzhihang.com/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"懒汉单例模式线程安全","slug":"design-patterns/单例模式","date":"2018-02-21T09:15:29.000Z","updated":"2020-04-04T04:12:06.880Z","comments":true,"path":"2018/02/21/lazy-singleton-mode-thread-safe.html","link":"","permalink":"https://liuzhihang.com/2018/02/21/lazy-singleton-mode-thread-safe.html","excerpt":"一个类中只有一个实例, 且能够自行实例化提供这个实例, 同时提供全局访问的方法. 结构1.构造私有化: 确保外部不能使用new直接创建对象2.内部静态属性创建实例3.对外公共静态获取对象方法","text":"一个类中只有一个实例, 且能够自行实例化提供这个实例, 同时提供全局访问的方法. 结构1.构造私有化: 确保外部不能使用new直接创建对象2.内部静态属性创建实例3.对外公共静态获取对象方法 demo/** * 单例模式 * 1. 构造私有化: 确保外部不能使用new直接创建对象 * 2. 内部静态属性创建实例 * 3. 对外公共静态获取对象方法 * * @author liuzhihang * @date 2018/3/27 17:45 */ public class SingletonPattern &amp;#123; private SingletonPattern() &amp;#123; &amp;#125; private static SingletonPattern singletonPattern = null; public static SingletonPattern getSingletonPattern() &amp;#123; if (singletonPattern == null) &amp;#123; singletonPattern = new SingletonPattern(); &amp;#125; return singletonPattern; &amp;#125; &amp;#125; 分类1.懒汉式: 懒汉模式, 项目启动时不生成对象, 而是在首次创建该对象的时候生成唯一实例 /** * 懒汉模式, 项目启动时不生成对象, 而是在首次创建该对象的时候生成唯一实例 * * @author liuzhihang * @date 2018/4/2 16:24 */ public class LazyPattern &amp;#123; private LazyPattern() &amp;#123; &amp;#125; private static LazyPattern lazyPattern = null; public static LazyPattern getLazyPattern() &amp;#123; try &amp;#123; if (lazyPattern == null) &amp;#123; // 模拟一系列耗时操作 Thread.sleep(50); lazyPattern = new LazyPattern(); &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; return lazyPattern; &amp;#125; &amp;#125; 2.饿汉式: 项目启动时, 进行加载, 会导致项目启动较慢, 并且无论后面是否用到都会进行加载 /** * * 饿汉式单例模式 * 项目启动时, 进行加载, 会导致项目启动较慢, 并且无论后面是否用到都会进行加载 * * @author liuzhihang * @date 2018/4/2 18:44 */ public class HungerPattern &amp;#123; private HungerPattern() &amp;#123; &amp;#125; private static HungerPattern hungerPattern = new HungerPattern(); public static HungerPattern getHungerPattern() &amp;#123; return hungerPattern; &amp;#125; &amp;#125; 测试用例在多线程情况下对单例模式进行测试: /** * @author liuzhihang * @date 2018/3/27 19:02 */ public class SingletonTest &amp;#123; public static void main(String[] args) &amp;#123; ThreadTest[] threadTests = new ThreadTest[10]; for (int i = 0; i &lt; threadTests.length; i++) &amp;#123; threadTests[i] = new ThreadTest(); &amp;#125; for (int i = 0; i &lt; threadTests.length; i++) &amp;#123; threadTests[i].start(); &amp;#125; &amp;#125; &amp;#125; class ThreadTest extends Thread &amp;#123; @Override public void run() &amp;#123; // 懒汉模式 System.out.println(LazyPattern.getLazyPattern().hashCode()); // 饿汉模式 // System.out.println(HungerPattern.getHungerPattern().hashCode()); &amp;#125; &amp;#125; 结果: 1.饿汉模式 D:\\jdk1.8\\bin\\java.exe . . . 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 Process finished with exit code 0 2.懒汉模式 D:\\jdk1.8\\bin\\java.exe . . . 140919816 1359128134 1385166630 924507082 67641385 508832262 574926395 140919816 1442414714 896298396 Process finished with exit code 0 结论: 在懒汉单例模式下不能保证线程的安全性 懒汉模式的线程安全优化饿汉模式会造成资源浪费, 启动慢等结果, 下面对懒汉模式进行线程安全优化. synchronized 锁住静态方法锁住静态方法 类级锁 影响范围较大, 导致效率相对较低 /** * 懒汉式 * 在方法上添加 synchronized 关键字 锁类 * 同步方法的方式, 导致效率相对较低 * * @author liuzhihang * @date 2018/4/3 14:27 */ public class SyncLazyPattern &amp;#123; private SyncLazyPattern() &amp;#123; &amp;#125; private static SyncLazyPattern syncLazyPattern = null; public static synchronized SyncLazyPattern getSyncLazyPattern() &amp;#123; try &amp;#123; if (syncLazyPattern == null) &amp;#123; Thread.sleep(100); syncLazyPattern = new SyncLazyPattern(); &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; return syncLazyPattern; &amp;#125; &amp;#125; synchronized 锁住代码块package com.liuzhihang.demo.singleton; /** * 锁代码块的方式虽然可以保证结果一致性 * 但锁住很多操作, 同样会导致效率低下 * * @author liuzhihang * @date 2018/4/3 15:22 */ public class SyncCodeBlockLazyPattern &amp;#123; private SyncCodeBlockLazyPattern() &amp;#123; &amp;#125; private static SyncCodeBlockLazyPattern syncCodeBlockLazyPattern = null; public static SyncCodeBlockLazyPattern getSyncCodeBlockLazyPattern() &amp;#123; try &amp;#123; // 锁住具体执行业务逻辑的代码 synchronized (SyncCodeBlockLazyPattern.class) &amp;#123; if (syncCodeBlockLazyPattern == null) &amp;#123; Thread.sleep(100); syncCodeBlockLazyPattern = new SyncCodeBlockLazyPattern(); &amp;#125; &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; return syncCodeBlockLazyPattern; &amp;#125; &amp;#125; 双重检查锁机制(推荐)package com.liuzhihang.demo.singleton; /** * 双重锁检查机制, 仅锁住创建对象的部分代码 * 注意: 在对象前 添加 volatile 关键字 确保可见性, 即 每次获取值从主内存中获取, 同时防止指令重排序 * * @author liuzhihang * @date 2018/4/3 15:29 */ public class DubboCheckLockLazyPattern &amp;#123; private DubboCheckLockLazyPattern() &amp;#123; &amp;#125; private static volatile DubboCheckLockLazyPattern dubboCheckLockLazyPattern = null; public static DubboCheckLockLazyPattern getDubboCheckLockLazyPattern() &amp;#123; try &amp;#123; if (dubboCheckLockLazyPattern == null) &amp;#123; // 一系列操作 Thread.sleep(100); synchronized (DubboCheckLockLazyPattern.class) &amp;#123; // 二次检查 if (dubboCheckLockLazyPattern == null) &amp;#123; dubboCheckLockLazyPattern = new DubboCheckLockLazyPattern(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; catch (InterruptedException e) &amp;#123; e.printStackTrace(); &amp;#125; return dubboCheckLockLazyPattern; &amp;#125; &amp;#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","permalink":"https://liuzhihang.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"poi读写Excel简单介绍","slug":"utils/excel/poiForExcel","date":"2018-02-15T10:12:20.000Z","updated":"2020-04-04T07:33:24.451Z","comments":true,"path":"2018/02/15/poi-read-and-write-excel-brief-introduction.html","link":"","permalink":"https://liuzhihang.com/2018/02/15/poi-read-and-write-excel-brief-introduction.html","excerpt":"Apache POI 可以对Microsoft Office 进行操作, 下面是工作中使用的对Excel进行读写操作的常用方式. 引入依赖 &lt;!-- excel poi --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.17&lt;/version&gt; &lt;/dependency&gt;","text":"Apache POI 可以对Microsoft Office 进行操作, 下面是工作中使用的对Excel进行读写操作的常用方式. 引入依赖 &lt;!-- excel poi --> &lt;dependency> &lt;groupId>org.apache.poi&lt;/groupId> &lt;artifactId>poi&lt;/artifactId> &lt;version>3.17&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.poi&lt;/groupId> &lt;artifactId>poi-ooxml&lt;/artifactId> &lt;version>3.17&lt;/version> &lt;/dependency> 简单使用主要介绍读写时, 分别常用到的一些对象及其含义, 方便自己编写util. package com.liuzhihang.tool.excel.poi; import org.apache.poi.hssf.usermodel.HSSFWorkbook; import org.apache.poi.ss.usermodel.Row; import org.apache.poi.ss.usermodel.Sheet; import org.apache.poi.ss.usermodel.Workbook; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import java.io.OutputStream; /** * @author liuzhihang * @date 2018/4/20 16:12 */ public class ExcelTest &amp;#123; public static void main(String[] args) throws Exception &amp;#123; // readerTest(); writerTest(); &amp;#125; private static void writerTest() throws IOException &amp;#123; File file = new File(\"c:Users/liuzhihang/Desktop/test.xlsx\"); if (file.exists()) &amp;#123; System.out.println(\"读取的文件存在!\"); file.delete(); &amp;#125; file.createNewFile(); // 操作 .xls 的 workbook Workbook hssfWorkbook = new HSSFWorkbook(); // 操作 .xlsx 的 workbook XSSFWorkbook xssfWorkbook = new XSSFWorkbook(); // 创建 sheet 页 XSSFSheet sheet = xssfWorkbook.createSheet(); // 创建 0 行 操作对象 Row row0 = sheet.createRow(0); // 创建单元格并赋值 row0.createCell(0).setCellValue(\"序号\"); OutputStream outputStream = new FileOutputStream(file); // 写入文件 xssfWorkbook.write(outputStream); &amp;#125; private static void readerTest() throws Exception &amp;#123; File file = new File(\"c:Users/liuzhihang/Desktop/parkingLotTempLate.xlsx\"); Workbook workBook = ExcelUtil.getWorkBook(file); // 获取 excel 页 // Sheet sheetByIndex = workBook.getSheetAt(0); // Sheet sheetByName = workBook.getSheet(\"Sheet0\"); // 操作 sheet Sheet sheet = workBook.getSheetAt(0); // 获取最后一行行数 从 0 开始 int lastRowNum = sheet.getLastRowNum(); // 获取总行数 int physicalNumberOfRows = sheet.getPhysicalNumberOfRows(); // 操作行 获取第0行 Row row = sheet.getRow(0); String value = row.getCell(0).getStringCellValue(); &amp;#125; &amp;#125; ExcelUtil 简单工具poi读写 excel 的简单工具 ExcelUtil, 实际工作中可结合javaBean使用并重新编写util. package com.liuzhihang.tool.excel.poi; import lombok.extern.log4j.Log4j2; import org.apache.commons.lang.StringUtils; import org.apache.poi.hssf.usermodel.HSSFWorkbook; import org.apache.poi.ss.usermodel.Cell; import org.apache.poi.ss.usermodel.Row; import org.apache.poi.ss.usermodel.Sheet; import org.apache.poi.ss.usermodel.Workbook; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.*; import java.util.ArrayList; import java.util.List; /** * @author liuzhihang * @date 2018/4/20 12:02 */ @Log4j2 public class ExcelUtil &amp;#123; /** * 读取两列excel 返回第二列的集合 * * @param workbook * @return */ public static List&lt;String> readExcelForTwoColumns(Workbook workbook) &amp;#123; if (workbook == null) &amp;#123; log.info(\"获取 workbook 为null\"); return null; &amp;#125; List&lt;String> list = new ArrayList&lt;>(); try &amp;#123; Sheet sheet = workbook.getSheetAt(0); //获取总行数 int rowNum = sheet.getLastRowNum(); //正文内容应该从第二行开始，第一行为文件的标头的标题 for (int i = 0; i &lt; rowNum; i++) &amp;#123; Row row = sheet.getRow(i + 1); String value = getCellValue(row.getCell(1)).toString(); if (StringUtils.isNotBlank(value)) &amp;#123; list.add(value); &amp;#125; &amp;#125; &amp;#125; catch (Exception e) &amp;#123; log.error(e.getMessage()); &amp;#125; return list; &amp;#125; /** * 写 excel * * @param excelFile * @param list */ public static void writerExcelForTwoColumns(File excelFile, List&lt;String> list) &amp;#123; OutputStream outputStream = null; try &amp;#123; outputStream = new FileOutputStream(excelFile); Workbook workBook = null; String fileName = excelFile.getName(); if (fileName.endsWith(\".xls\")) &amp;#123; workBook = new HSSFWorkbook(); &amp;#125; else if (fileName.endsWith(\".xlsx\")) &amp;#123; workBook = new XSSFWorkbook(); &amp;#125; else &amp;#123; log.info(\"文件格式不正确!, 当前文件名:&amp;#123;&amp;#125;\", fileName); throw new Exception(\"文件格式不正确\"); &amp;#125; // 创建第 0 页 Sheet sheet = workBook.createSheet(); Row row1 = sheet.createRow(0); row1.createCell(0).setCellValue(\"序号\"); row1.createCell(1).setCellValue(\"编号\"); for (int i = 0; i &lt; list.size(); i++) &amp;#123; Row row = sheet.createRow(i + 1); row.createCell(0).setCellValue(i + 1); row.createCell(1).setCellValue(list.get(i)); &amp;#125; workBook.write(outputStream); &amp;#125; catch (Exception e) &amp;#123; log.error(\"写excel失败\", e); &amp;#125; finally &amp;#123; try &amp;#123; outputStream.close(); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; /** * 获取工作表 * * @param file * @return */ public static Workbook getWorkBook(File file) throws Exception &amp;#123; String fileName = file.getName(); Workbook workbook = null; try &amp;#123; InputStream inputStream = new FileInputStream(file); if (fileName.endsWith(\".xls\")) &amp;#123; workbook = new HSSFWorkbook(inputStream); &amp;#125; else if (fileName.endsWith(\".xlsx\")) &amp;#123; workbook = new XSSFWorkbook(inputStream); &amp;#125; else &amp;#123; log.info(\"文件格式不正确!, 当前文件名:&amp;#123;&amp;#125;\", fileName); throw new Exception(\"文件格式不正确\"); &amp;#125; &amp;#125; catch (Exception e) &amp;#123; throw e; &amp;#125; return workbook; &amp;#125; /** * 获取单元格的数据 * * @param cell * @return */ public static Object getCellValue(Cell cell) &amp;#123; if (cell != null) &amp;#123; switch (cell.getCellTypeEnum()) &amp;#123; // 数字 case NUMERIC: return cell.getNumericCellValue(); // 字符串 case STRING: return cell.getStringCellValue(); // 公式 case FORMULA: return cell.getCellFormula(); // 布尔 case BOOLEAN: return cell.getBooleanCellValue(); case ERROR: return cell.getErrorCellValue(); // 空 default: return \"\"; &amp;#125; &amp;#125; return \"\"; &amp;#125; &amp;#125;","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"poi","slug":"poi","permalink":"https://liuzhihang.com/tags/poi/"},{"name":"excel","slug":"excel","permalink":"https://liuzhihang.com/tags/excel/"}]},{"title":"protostuff序列化工具","slug":"utils/serialize/protostuff","date":"2018-02-05T12:12:20.000Z","updated":"2020-04-04T07:33:24.448Z","comments":true,"path":"2018/02/05/protostuff-serialization-tool.html","link":"","permalink":"https://liuzhihang.com/2018/02/05/protostuff-serialization-tool.html","excerpt":"介绍在很多地方都需要用到序列化, 比如在使用redis缓存对象时, 一般情况是实现java Serializable接口. 简单介绍下在慕课网学习到的一个新的序列化工具 —- protostuff. 在学习中介绍使用该工具可以大大减少对象序列化后字节所占空间, 并提高序列化时间等. 1.慕课网课程地址2.序列化相关工具比较","text":"介绍在很多地方都需要用到序列化, 比如在使用redis缓存对象时, 一般情况是实现java Serializable接口. 简单介绍下在慕课网学习到的一个新的序列化工具 —- protostuff. 在学习中介绍使用该工具可以大大减少对象序列化后字节所占空间, 并提高序列化时间等. 1.慕课网课程地址2.序列化相关工具比较 引入依赖 &lt;!-- protostuff 序列化工具 --> &lt;dependency> &lt;groupId>com.dyuproject.protostuff&lt;/groupId> &lt;artifactId>protostuff-core&lt;/artifactId> &lt;version>1.1.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.dyuproject.protostuff&lt;/groupId> &lt;artifactId>protostuff-runtime&lt;/artifactId> &lt;version>1.1.3&lt;/version> &lt;/dependency> 相关使用import com.dyuproject.protostuff.LinkedBuffer; import com.dyuproject.protostuff.ProtostuffIOUtil; import com.dyuproject.protostuff.runtime.RuntimeSchema; /** * @author liuzhihang * @date 2018/4/18 15:04 */ public class ProtostuffUtil &amp;#123; public static &lt;T> byte[] serialize(T t, Class&lt;T> cls) &amp;#123; RuntimeSchema&lt;T> schema = RuntimeSchema.createFrom(cls); return ProtostuffIOUtil.toByteArray(t, schema, LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE)); &amp;#125; public static &lt;T> T unSerialize(byte[] bytes, Class&lt;T> cls) &amp;#123; RuntimeSchema&lt;T> schema = RuntimeSchema.createFrom(cls); T message = schema.newMessage(); ProtostuffIOUtil.mergeFrom(bytes, message, schema); return message; &amp;#125; &amp;#125; 测试import lombok.Data; /** * @author liuzhihang * @date 2018/4/17 19:01 */ @Data public class User &amp;#123; private String id; private String userName; &amp;#125; import com.alibaba.fastjson.JSON; /** * @author liuzhihang * @date 2018/4/17 19:02 */ public class ProtostuffTest &amp;#123; public static void main(String[] args) &amp;#123; User user = new User(); user.setId(\"test0001\"); user.setUserName(\"测试用户0001\"); System.out.println(JSON.toJSONString(user)); byte[] serialize = ProtostuffUtil.serialize(user, User.class); User unSerialize = ProtostuffUtil.unSerialize(serialize, User.class); System.err.println(JSON.toJSONString(unSerialize)); &amp;#125; &amp;#125; 结果: &amp;#123;\"id\":\"test0001\",\"userName\":\"测试用户0001\"&amp;#125; &amp;#123;\"id\":\"test0001\",\"userName\":\"测试用户0001\"&amp;#125;","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"serialize","slug":"serialize","permalink":"https://liuzhihang.com/tags/serialize/"}]},{"title":"Transactional声明式事务","slug":"spring/Transactional","date":"2018-01-27T03:50:13.000Z","updated":"2020-04-04T04:12:06.921Z","comments":true,"path":"2018/01/27/transactional-declarative-transaction.html","link":"","permalink":"https://liuzhihang.com/2018/01/27/transactional-declarative-transaction.html","excerpt":"介绍1.声明式事务管理建立在AOP之上的. 其本质是对方法前后进行拦截, 然后在目标方法开始之前创建或者加入一个事务, 在执行完目标方法之后根据执行情况提交或者回滚事务.2.声明式事务最大的优点就是不需要通过编程的方式管理事务, 这样就不需要在业务逻辑代码中掺杂事务管理的代码, 只需在配置文件中做相关的事务规则声明(或通过基于@Transactional注解的方式), 便可以将事务规则应用到业务逻辑中.3.声明式事务不足的地方在于, 与编程式事务相比, 只能作用到方法级别, 无法像编程式事务那样可以作用到代码块级别. xml配置1.添加命名空间","text":"介绍1.声明式事务管理建立在AOP之上的. 其本质是对方法前后进行拦截, 然后在目标方法开始之前创建或者加入一个事务, 在执行完目标方法之后根据执行情况提交或者回滚事务.2.声明式事务最大的优点就是不需要通过编程的方式管理事务, 这样就不需要在业务逻辑代码中掺杂事务管理的代码, 只需在配置文件中做相关的事务规则声明(或通过基于@Transactional注解的方式), 便可以将事务规则应用到业务逻辑中.3.声明式事务不足的地方在于, 与编程式事务相比, 只能作用到方法级别, 无法像编程式事务那样可以作用到代码块级别. xml配置1.添加命名空间 &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" . . . xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\" . . . http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd\"> 2.添加相关事务支持 &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"> &lt;!-- 指向数据源 --> &lt;property name=\"dataSource\" ref=\"masterDataSource\"/> &lt;/bean> &lt;!-- 开启事务的Annotation支持 --> &lt;tx:annotation-driven transaction-manager=\"transactionManager\"/> @Transactional注解 使用@Transactional 可以作用于接口,接口方法,类以及类方法上. 只需要在相应接口,类或方法上加上@Transactional注解即可. @Transactional 注解介绍package org.springframework.transaction.annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Inherited; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; import org.springframework.core.annotation.AliasFor; import org.springframework.transaction.TransactionDefinition; import org.springframework.transaction.annotation.Isolation; import org.springframework.transaction.annotation.Propagation; /** * @Target(&amp;#123;ElementType.METHOD, ElementType.TYPE&amp;#125;) : 可用于接口, 类, 枚举, 注解, 方法 * @Retention(RetentionPolicy.RUNTIME) : 注解会在class字节码文件中存在，在运行时可以通过反射获取到 * @Inherited : 子类可以继承父类中的注解 * @Documented : 注解将被包含在javadoc中 */ @Target(&amp;#123;ElementType.METHOD, ElementType.TYPE&amp;#125;) @Retention(RetentionPolicy.RUNTIME) @Inherited @Documented public @interface Transactional &amp;#123; /** * 事务管理器的别名 * 系统指定多个事务管理器时可通过别名进行区分 */ @AliasFor(\"transactionManager\") String value() default \"\"; /** * 可通过在 transactionManager 中设置 &lt;qualifier value=\"managerOne\"/> 属性类指定名称 * 可用于确定目标事务管理器，匹配特定的限定符值（或bean名称） */ @AliasFor(\"value\") String transactionManager() default \"\"; /** * 事务的传播机制 * 默认 Propagation.REQUIRED */ Propagation propagation() default Propagation.REQUIRED; /** * 事务的隔离级别 * 默认 Isolation.DEFAULT */ Isolation isolation() default Isolation.DEFAULT; /** * 事务超时时间 * 默认 TransactionDefinition.TIMEOUT_DEFAULT 即 -1 */ int timeout() default TransactionDefinition.TIMEOUT_DEFAULT; /** * 设置事务只读 */ boolean readOnly() default false; /** * 设置需要进行回滚的异常类数组，当方法中抛出指定异常数组中的异常时，则进行事务回滚 * rollbackFor = Exception.class 或 rollbackFor = &amp;#123;RuntimeException.class, Exception.class&amp;#125; */ Class&lt;? extends Throwable>[] rollbackFor() default &amp;#123;&amp;#125;; /** * 设置需要进行回滚的异常类名称数组，当方法中抛出指定异常名称数组中的异常时, 事务进行回滚 */ String[] rollbackForClassName() default &amp;#123;&amp;#125;; /** * 设置不需要进行回滚的异常类数组，当方法中抛出指定异常数组中的异常时，则不进行事务回滚 */ Class&lt;? extends Throwable>[] noRollbackFor() default &amp;#123;&amp;#125;; /** * 设置不需要进行回滚的异常类名称数组，当方法中抛出指定异常名称数组中的异常时, 事务不进行回滚 */ String[] noRollbackForClassName() default &amp;#123;&amp;#125;; &amp;#125; 传播行为介绍事务的传播行为, 一共 7 种1.枚举介绍 package org.springframework.transaction.annotation; import org.springframework.transaction.TransactionDefinition; public enum Propagation &amp;#123; /** * 支持当前事务, 如果不存在, 则创建一个新事务 * 事务的默认设置 */ REQUIRED(TransactionDefinition.PROPAGATION_REQUIRED), /** * 支持当前事务, 如果不存在, 则以非事务方式执行 */ SUPPORTS(TransactionDefinition.PROPAGATION_SUPPORTS), /** * 支持当前事务, 如果不存在则抛出异常 */ MANDATORY(TransactionDefinition.PROPAGATION_MANDATORY), /** * 开始一个新的事务, 并暂停当前事务(如果存在) */ REQUIRES_NEW(TransactionDefinition.PROPAGATION_REQUIRES_NEW), /** * 以非事务方式执行, 暂停当前事务(如果存在) */ NOT_SUPPORTED(TransactionDefinition.PROPAGATION_NOT_SUPPORTED), /** * 以非事务方式执行, 如果存在则抛出异常 */ NEVER(TransactionDefinition.PROPAGATION_NEVER), /** * 如果当前事务存在, 则在嵌套事务中执行. * 如果事务不存在, 则等同于 PROPAGATION_REQUIRED */ NESTED(TransactionDefinition.PROPAGATION_NESTED); private final int value; Propagation(int value) &amp;#123; this.value = value; &amp;#125; public int value() &amp;#123; return this.value; &amp;#125; &amp;#125; 2.列表 Propagation 含义 REQUIRED 支持当前事务, 如果不存在, 则创建一个新事务 SUPPORTS 支持当前事务, 如果不存在, 则以非事务方式执行 MANDATORY 支持当前事务, 如果不存在则抛出异常 REQUIRES_NEW 开始一个新的事务, 并暂停当前事务(如果存在) NOT_SUPPORTED 以非事务方式执行, 暂停当前事务(如果存在) NEVER 以非事务方式执行, 如果存在则抛出异常 NESTED 如果当前事务存在, 则在嵌套事务中执行. 如果事务不存在, 则等同于 PROPAGATION_REQUIRED 隔离级别介绍1.枚举介绍 package org.springframework.transaction.annotation; import org.springframework.transaction.TransactionDefinition; public enum Isolation &amp;#123; /** * 使用底层数据存储默认的隔离级别 * 一般存储底层默认为: READ_COMMITTED */ DEFAULT(TransactionDefinition.ISOLATION_DEFAULT), /** * 读未提交 * 会出现脏读和不可重复读, 一般不使用 */ READ_UNCOMMITTED(TransactionDefinition.ISOLATION_READ_UNCOMMITTED), /** * 读已提交 * 该级别仅禁止事务读取其中未提交更改的行 * 可能会出现不可重复读取和幻像读取 */ READ_COMMITTED(TransactionDefinition.ISOLATION_READ_COMMITTED), /** * 可重复读 * 禁止事务读取其中有未提交更改的行, 并且还禁止一个事务读取一行, 第二个事务更改该行. 并且第一个事务重新读取该行, 第二次获取不同值的情况 * 即 禁止 读未提交, 不可重复读 * 会出现幻读 */ REPEATABLE_READ(TransactionDefinition.ISOLATION_REPEATABLE_READ), /** * 串行 * 所有事物依次执行, 不会影响别的事务, 所以会防止 不可重复读 脏读 幻读 * 会影响性能 */ SERIALIZABLE(TransactionDefinition.ISOLATION_SERIALIZABLE); private final int value; Isolation(int value) &amp;#123; this.value = value; &amp;#125; public int value() &amp;#123; return this.value; &amp;#125; &amp;#125; 2.列表 Isolation 含义 DEFAULT 使用底层数据存储默认的隔离级别, 一般存储底层默认为: READ_COMMITTED READ_UNCOMMITTED 读未提交, 会出现脏读和不可重复读, 一般不使用 READ_COMMITTED 该级别仅禁止事务读取其中未提交更改的行. 可能会出现不可重复读取和幻像读取 REPEATABLE_READ 可重复读, 禁止事务读取其中有未提交更改的行, 并且还禁止一个事务读取一行, 第二个事务更改该行. 并且第一个事务重新读取该行, 第二次获取不同值的情况. 即 禁止 读未提交, 不可重复读. 会出现幻读 SERIALIZABLE 串行, 所有事物依次执行, 不会影响别的事务, 所以会防止 不可重复读 脏读 幻读. 会影响性能 3.脏读 幻读 不可重复读 脏读 当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 幻读 事务读取时不存在该数据, 读取后发现该数据存在. 中间因为别的事务在进行插入操作 不可重复读 一个事务在读取该数据时另一个事务在修改该数据, 导致多次读取数据内容不一致","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"transactional","slug":"transactional","permalink":"https://liuzhihang.com/tags/transactional/"}]},{"title":"整数包装类型的缓存","slug":"source-code/java/IntegerCache","date":"2018-01-15T12:12:20.000Z","updated":"2020-04-04T06:53:41.581Z","comments":true,"path":"2018/01/15/integer-wrapper-type-cache.html","link":"","permalink":"https://liuzhihang.com/2018/01/15/integer-wrapper-type-cache.html","excerpt":"部分包装类型存在缓存机制, 会在JVM启动时, 缓存一定数量的对象, 有助于节省内存, 提高性能. 缓存区间 类型 范围 是否修改 Integer -128 到 127 true : -XX:AutoBoxCacheMax=size 修改 ByteCache -128 到 127 false ShortCache -128 到 127 false LongCache -128 到 127 false CharacterCache 0 到 127 false","text":"部分包装类型存在缓存机制, 会在JVM启动时, 缓存一定数量的对象, 有助于节省内存, 提高性能. 缓存区间 类型 范围 是否修改 Integer -128 到 127 true : -XX:AutoBoxCacheMax=size 修改 ByteCache -128 到 127 false ShortCache -128 到 127 false LongCache -128 到 127 false CharacterCache 0 到 127 false 举例 Integer a = 100; Integer b = 100; Integer c = 1000; Integer d = 1000; Integer e = new Integer(100); Integer f = Integer.valueOf(100); System.out.println(a == b); // true System.out.println(c == d); // false System.out.println(a == e); // false System.out.println(f == e); // false System.out.println(a == f); // true 分析== 在比较对象时, 判断是否指向同一地址 a b f 都是从缓存中取出数据, 所以地址是相同的 c d 不在缓存范围内, 所以是新的对象 e 是新对象 IntegerCacheprivate static class IntegerCache &amp;#123; static final int low = -128; static final int high; static final Integer cache[]; static &amp;#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) &amp;#123; try &amp;#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &amp;#125; catch( NumberFormatException nfe) &amp;#123; // If the property cannot be parsed into an int, ignore it. &amp;#125; &amp;#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high >= 127; &amp;#125; private IntegerCache() &amp;#123;&amp;#125; &amp;#125; 可以通过设置 java.lang.Integer.IntegerCache.high 来修改缓存的值. 方法为修改 JVM 的启动参数 -XX:AutoBoxCacheMax=size","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}]},{"title":"Interceptor拦截器","slug":"spring/Interceptor","date":"2018-01-10T06:50:13.000Z","updated":"2020-04-04T04:12:06.923Z","comments":true,"path":"2018/01/10/interceptor.html","link":"","permalink":"https://liuzhihang.com/2018/01/10/interceptor.html","excerpt":"介绍Interceptor: 拦截器，作用类似 Filter, 主要作用是拦截用户请求, 在 Action 执行的前后各执行一段代码, 进行相应的业务处理. 作用权限认证统一逻辑处理日志监控等","text":"介绍Interceptor: 拦截器，作用类似 Filter, 主要作用是拦截用户请求, 在 Action 执行的前后各执行一段代码, 进行相应的业务处理. 作用权限认证统一逻辑处理日志监控等 使用方式及方法介绍使用方式分为两种, 一种为: 实现HandlerInterceptor接口或者是继承实现了HandlerInterceptor接口的类, 另一种为: 实现Spring的WebRequestInterceptor接口, 或者是继承实现了WebRequestInterceptor的类.1.HandlerInterceptor 介绍 package org.springframework.web.servlet; import org.springframework.web.servlet.ModelAndView; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public interface HandlerInterceptor &amp;#123; /** * 请求处理之前调用 链式 会按照声明顺序依次执行 * 返回 true 则继续执行下一个 Interceptor 无则执行 Controller * 返回 false 请求结束 */ boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; /** * 在请求处理之后，DispatcherServlet进行视图返回渲染之前进行调用，可以在这个方法中对Controller 处理之后的ModelAndView 对象进行操作。 * 调度程序Servlet在执行链中处理一个处理程序，由任意数量的拦截器组成，处理器本身在最后。 使用这种方法，每个拦截器可以后处理一个执行，并按照执行链的相反顺序进行应用 */ void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception; /** * 请求处理完成后的回调，即渲染视图后的回调。 将被调用处理程序执行的任何结果，从而允许适当的资源清理。 * 注意：只有当这个拦截器的预处理方法已经成功完成并返回时才会被调用 * 与postHandle方法一样，该方法将以相反的顺序在链中的每个拦截器上调用，因此第一个拦截器将成为最后被调用的拦截器 */ void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception; &amp;#125; 2.WebRequestInterceptor 介绍 package org.springframework.web.context.request; import org.springframework.ui.ModelMap; import org.springframework.web.context.request.WebRequest; public interface WebRequestInterceptor &amp;#123; /** * 在调用之前拦截请求处理程序的执行。 允许准备上下文资源（如Hibernate Session）并将它们公开为请求属性或线程本地对象. * 即 准备一些需要的资源, 例如, 将请求属性放置到 WebRequest 中 * 无返回对象 */ void preHandle(WebRequest request) throws Exception; /** * 在视图呈现前（如果有的话）在成功调用之后拦截请求处理程序的执行。 * 允许在成功处理程序执行后修改上下文资源（例如，刷新休眠会话） * 可以通过修改 ModelMap 的属性来改变你返回的试图模型 */ void postHandle(WebRequest request, ModelMap model) throws Exception; /** * 求处理完成后的回调，即渲染视图后的回调。 将被调用处理程序执行的任何结果，从而允许适当的资源清理。 * 注意：只有在拦截器的预处理方法成功完成时才会调用 */ void afterCompletion(WebRequest request, Exception ex) throws Exception; &amp;#125; xml 配置1.在 *-servlet.xml 中添加 MVC schema xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\" http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd\" 2.配置 mvc:interceptors 标签 &lt;mvc:interceptors> &lt;mvc:interceptor> &lt;!-- 拦截路径 --> &lt;mvc:mapping path=\"/**\"/> &lt;!-- 指定拦截器 --> &lt;bean class=\"com.liuzhihang.myprojext.controller.interceptor.RequestInterceptor\"/> &lt;/mvc:interceptor> &lt;/mvc:interceptors> 使用示例package com.liuzhihang.myprojext.controller.interceptor; import org.springframework.web.servlet.HandlerInterceptor; import org.springframework.web.servlet.ModelAndView; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class RequestInterceptor implements HandlerInterceptor &amp;#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &amp;#123; // 处理逻辑 return true; &amp;#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &amp;#123; &amp;#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &amp;#123; &amp;#125; &amp;#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"interceptor","slug":"interceptor","permalink":"https://liuzhihang.com/tags/interceptor/"},{"name":"servlet","slug":"servlet","permalink":"https://liuzhihang.com/tags/servlet/"}]},{"title":"utils工具--ValidationUtil 参数校验","slug":"utils/validation/ValidationUtil","date":"2017-12-30T13:20:20.000Z","updated":"2020-04-04T07:33:24.457Z","comments":true,"path":"2017/12/30/utils-tool-validationutil-parameter-check.html","link":"","permalink":"https://liuzhihang.com/2017/12/30/utils-tool-validationutil-parameter-check.html","excerpt":"在工作中不可避免的要面对很多参数校验, 比如写新接口时需要对传入VO的必要字段进行校验, String 是否为空, Integer 最小值, 对象是否为null, 等等.而使用 hibernate的validator工具对参数进行校验, 可以极大的简化流程, 当然不可避免的就是需要在被校验字段上加上注解信息. 1. 相关依赖 &lt;!-- 参数校验工具 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.4.2.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.web&lt;/groupId&gt; &lt;artifactId&gt;el-impl&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/dependency&gt;","text":"在工作中不可避免的要面对很多参数校验, 比如写新接口时需要对传入VO的必要字段进行校验, String 是否为空, Integer 最小值, 对象是否为null, 等等.而使用 hibernate的validator工具对参数进行校验, 可以极大的简化流程, 当然不可避免的就是需要在被校验字段上加上注解信息. 1. 相关依赖 &lt;!-- 参数校验工具 --> &lt;dependency> &lt;groupId>org.hibernate&lt;/groupId> &lt;artifactId>hibernate-validator&lt;/artifactId> &lt;version>5.4.2.Final&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.glassfish.web&lt;/groupId> &lt;artifactId>el-impl&lt;/artifactId> &lt;version>2.2&lt;/version> &lt;/dependency> 2. ValidationUtil对加上相关注解字段进行校验, 使用到 ValidationUtil.java和ValidationResult.java两个文件, 也可在工具中直接抛出异常. ValidationUtil 内容如下: package com.liuzhihang.tool.validate; import org.apache.commons.collections.CollectionUtils; import javax.validation.ConstraintViolation; import javax.validation.Validation; import javax.validation.Validator; import java.beans.IntrospectionException; import java.beans.Introspector; import java.beans.PropertyDescriptor; import java.util.Set; /** * 对添加 hibernate.validator 注解的字段进行校验 * * 使用前 需要引入 hibernate-validator 依赖 * * @author liuzhihang * @date 2017/11/22 11:08 */ public class ValidationUtil &amp;#123; private static Validator validator = Validation.buildDefaultValidatorFactory().getValidator(); /** * 会 验证 所有字段 * * @param obj * @param &lt;T> * @return 返回所有不符合的信息 */ public static &lt;T> ValidationResult validateAllField(T obj) &amp;#123; ValidationResult result = new ValidationResult(true); StringBuilder errorMsg = new StringBuilder(); if (obj == null) &amp;#123; result.setHasPass(false); result.setErrorMsg(\"The class is null!\"); return result; &amp;#125; Set&lt;ConstraintViolation&lt;T>> violationSet = validator.validate(obj); if (CollectionUtils.isNotEmpty(violationSet)) &amp;#123; for (ConstraintViolation&lt;T> violation : violationSet) &amp;#123; errorMsg.append(violation.getMessage()); &amp;#125; result.setHasPass(false); result.setErrorMsg(errorMsg.toString()); &amp;#125; return result; &amp;#125; /** * 验证指定字段 是否符合信息 * * @param obj * @param fieldName * @param &lt;T> * @return */ public static &lt;T> ValidationResult validateOneField(T obj, String fieldName) &amp;#123; ValidationResult result = new ValidationResult(true); if (obj == null) &amp;#123; result.setHasPass(false); result.setErrorMsg(\"The class is null!\"); return result; &amp;#125; Set&lt;ConstraintViolation&lt;T>> violationSet = validator.validateProperty(obj, fieldName); if (CollectionUtils.isNotEmpty(violationSet)) &amp;#123; for (ConstraintViolation&lt;T> violation : violationSet) &amp;#123; result.setHasPass(false); result.setErrorMsg(violation.getMessage()); &amp;#125; &amp;#125; return result; &amp;#125; /** * 验证 所有字段, 当第一个不符合时 则直接返回信息 * * @param obj * @param &lt;T> * @return */ public static &lt;T> ValidationResult validateAllFieldForOneBack(T obj) &amp;#123; ValidationResult result = new ValidationResult(true); if (obj == null) &amp;#123; result.setHasPass(false); result.setErrorMsg(\"The class is null!\"); return result; &amp;#125; try &amp;#123; PropertyDescriptor[] propertyDescriptors = Introspector.getBeanInfo(obj.getClass()).getPropertyDescriptors(); for (PropertyDescriptor propertyDescriptor : propertyDescriptors) &amp;#123; result = validateOneField(obj, propertyDescriptor.getName()); if (result.getHasPass()) &amp;#123; return result; &amp;#125; &amp;#125; &amp;#125; catch (IntrospectionException e) &amp;#123; result.setHasPass(false); result.setErrorMsg(\"This validate has error : \" + e); &amp;#125; return result; &amp;#125; &amp;#125; ValidationResult 内容如下: package com.liuzhihang.tool.validate; /** * @Description: * @Author: liuzhihang * @Date: 2018/1/6 17:57 */ public class ValidationResult &amp;#123; private Boolean hasPass; private String errorMsg; public ValidationResult(Boolean hasPass) &amp;#123; this.hasPass = hasPass; &amp;#125; public Boolean getHasPass() &amp;#123; return hasPass; &amp;#125; public void setHasPass(Boolean hasPass) &amp;#123; this.hasPass = hasPass; &amp;#125; public String getErrorMsg() &amp;#123; return errorMsg; &amp;#125; public void setErrorMsg(String errorMsg) &amp;#123; this.errorMsg = errorMsg; &amp;#125; @Override public String toString() &amp;#123; return \"ValidationResult&amp;#123;\" + \"hasPass=\" + hasPass + \", errorMsg='\" + errorMsg + '\\'' + '&amp;#125;'; &amp;#125; &amp;#125; 3. 常用注解Bean Validation 中内置的 constraint @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 附加的 constraint @NotBlank(message =) 验证字符串非null，且长度必须大于0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内 4 测试示例代码: package com.liuzhihang.tool.validate; import lombok.Data; import org.hibernate.validator.constraints.NotBlank; import org.hibernate.validator.constraints.NotEmpty; import javax.validation.constraints.Min; import javax.validation.constraints.NotNull; /** * @author liuzhihang * @date 2017/11/22 18:25 */ @Data public class ValidationVo &amp;#123; @NotBlank(message = \"The name must notEmpty!\") private String name; @NotNull(message = \"The age must notNull!\") @Min(value = 1, message = \"The age must greater than 0!\") private Integer age; public static void main(String[] args) &amp;#123; ValidationVo validationVo = new ValidationVo(); System.out.println(ValidationUtil.validateAllField(validationVo).toString()); validationVo.setAge(1); System.out.println(ValidationUtil.validateAllField(validationVo).toString()); validationVo.setName(\"二蛋\"); System.out.println(ValidationUtil.validateAllField(validationVo).toString()); &amp;#125; &amp;#125; 输出结果: ValidationResult&#123;hasPass=false, errorMsg=&#39;The name must notEmpty!The age must notNull!&#39;&#125; ValidationResult&#123;hasPass=false, errorMsg=&#39;The name must notEmpty!&#39;&#125; ValidationResult&#123;hasPass=true, errorMsg=&#39;null&#39;&#125;","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"validation","slug":"validation","permalink":"https://liuzhihang.com/tags/validation/"}]},{"title":"xml解析--dom4j","slug":"utils/xml/xml-dom4j","date":"2017-12-30T12:12:20.000Z","updated":"2020-04-04T07:33:24.442Z","comments":true,"path":"2017/12/30/xml-parsing-dom4j.html","link":"","permalink":"https://liuzhihang.com/2017/12/30/xml-parsing-dom4j.html","excerpt":"在工作中有时候会用到dom4j对xml文件或者字符串进行解析, 以下内容为随手笔记, 防止以后遗忘. 1. 相关依赖 &lt;!-- dom4j --&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt;","text":"在工作中有时候会用到dom4j对xml文件或者字符串进行解析, 以下内容为随手笔记, 防止以后遗忘. 1. 相关依赖 &lt;!-- dom4j --> &lt;dependency> &lt;groupId>dom4j&lt;/groupId> &lt;artifactId>dom4j&lt;/artifactId> &lt;version>1.6.1&lt;/version> &lt;/dependency> 2. 获取dom对象获取dom对象方式主要以下几种: // 读取 xml 文件 方式 SAXReader reader = new SAXReader(); Document doc1 = reader.read(new File(\"src/main/java/com/liuzhihang/tool/xml/alipay.xml\")); // 解析 xml 文本 方式 String aliPayStr = XmlTest.getAliPayStr(); Document doc2 = DocumentHelper.parseText(aliPayStr); // 主动创建 Document doc3 = DocumentHelper.createDocument(); Element element = doc3.addElement(\"Test\"); 3. 操作dom对象当获取到dom对象后便可以通过以下方式对dom进行操作 // 获取根节点 Element rootElement = dom.getRootElement(); // System.out.println(rootElement.getName()); // 获取子节点 Element element = rootElement.element(\"response\").element(\"alipay\"); // System.out.println(element.asXML()); // 获取节点的文字 String text = element.element(\"alipay_buyer_login_id\").getText(); // System.out.println(text); // 获取节点下的所有节点 快捷键 iter / itco List elements = element.elements(); // for (Object o : elements) &amp;#123; // Element tempElement = (Element) o; // System.out.println(tempElement.getName() + \"\\t\" + tempElement.getText()); // &amp;#125; // for (Iterator iterator = elements.iterator(); iterator.hasNext(); ) &amp;#123; // Element next = (Element)iterator.next(); // System.out.println(next.getName() + \"\\t\" + next.getText()); // &amp;#125; // 获取节点下所有节点 Iterator对象 快捷键 itit Iterator iterator = element.elementIterator(); // while (iterator.hasNext()) &amp;#123; // Element next = (Element)iterator.next(); // System.out.println(next.getName() + \"\\t\" + next.getText()); // &amp;#125; // 添加节点 Element testElement = element.addElement(\"testElement\"); // 指定添加文字 testElement.setText(\"测试添加文字\"); System.out.println(element.asXML()); // 删除节点 boolean remove = element.remove(testElement); System.out.println(remove + \"\\n\" + element.asXML()); 4. 详细代码Dom4jTest.java","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"xml","slug":"xml","permalink":"https://liuzhihang.com/tags/xml/"}]},{"title":"xml解析--JaxbUtil","slug":"utils/xml/xml-jaxb","date":"2017-12-17T12:12:20.000Z","updated":"2020-04-04T07:33:24.445Z","comments":true,"path":"2017/12/17/xml-parsing-jaxbutil.html","link":"","permalink":"https://liuzhihang.com/2017/12/17/xml-parsing-jaxbutil.html","excerpt":"主要介绍使用jaxb对xml进行解析, 互转. jaxb 是相对较多的xml工具, 只需要在javaBean的属性上添加相应注解, 就可以使用工具进行解析. 具体使用过程如下: 1. 编写javaBean并添加注解使用过程中一般常用@XmlRootElement, @XmlAccessorType, @XmlElement, @XmlAttribute四个注解, 其余使用方式可以再自行深入研究. @XmlRootElement: 根元素 @XmlAccessorType: java对象生成xml文件时对java对象属性的访问方式 属性为XmlAccessType.FIELD 指java所有成员变量 @XmlElement: 子节点, name 可指定节点名 @XmlAttribute: 映射为xml文件的属性, name 可指定属性名","text":"主要介绍使用jaxb对xml进行解析, 互转. jaxb 是相对较多的xml工具, 只需要在javaBean的属性上添加相应注解, 就可以使用工具进行解析. 具体使用过程如下: 1. 编写javaBean并添加注解使用过程中一般常用@XmlRootElement, @XmlAccessorType, @XmlElement, @XmlAttribute四个注解, 其余使用方式可以再自行深入研究. @XmlRootElement: 根元素 @XmlAccessorType: java对象生成xml文件时对java对象属性的访问方式 属性为XmlAccessType.FIELD 指java所有成员变量 @XmlElement: 子节点, name 可指定节点名 @XmlAttribute: 映射为xml文件的属性, name 可指定属性名 javaBean: @Data @XmlRootElement(name = \"alipay\") @XmlAccessorType(XmlAccessType.FIELD) class AliPayXml &amp;#123; @XmlElement(name = \"alipay_buyer_login_id\" ) private String buyerLoginId; @XmlElement(name = \"alipay_buyer_user_id\") private String buyerUserId; &amp;#125; 2. 使用 JaxbUtilJaxbUtil代码 package com.liuzhihang.tool.xml; import javax.xml.bind.JAXBContext; import javax.xml.bind.JAXBException; import javax.xml.bind.Marshaller; import javax.xml.bind.Unmarshaller; import java.io.StringReader; import java.io.StringWriter; /** * Jaxb 工具 * * @author liuzhihang * @date 2017/11/28 19:13 */ public class JaxbUtil &amp;#123; private static final String CHARTSET = \"UTF-8\"; public static String bean2Xml(Object obj) throws JAXBException &amp;#123; return bean2Xml(obj, CHARTSET); &amp;#125; public static String bean2Xml(Object obj, String chartset) throws JAXBException &amp;#123; JAXBContext jaxbContext = JAXBContext.newInstance(obj.getClass()); Marshaller marshaller = jaxbContext.createMarshaller(); marshaller.setProperty(Marshaller.JAXB_FORMATTED_OUTPUT, true); marshaller.setProperty(Marshaller.JAXB_ENCODING, chartset); StringWriter writer = new StringWriter(); marshaller.marshal(obj, writer); return writer.getBuffer().toString(); &amp;#125; public static &lt;T> T xml2Bean(String xmlString, Class&lt;T> clazz) throws JAXBException &amp;#123; JAXBContext jaxbContext = JAXBContext.newInstance(clazz); Unmarshaller unmarshaller = jaxbContext.createUnmarshaller(); T t = (T) unmarshaller.unmarshal(new StringReader(xmlString)); return t; &amp;#125; &amp;#125; 3. 测试代码待测试字符串: xmlStr &lt;alipay> &lt;alipay_buyer_login_id>176****3035&lt;/alipay_buyer_login_id> &lt;alipay_buyer_user_id>2088912868994947&lt;/alipay_buyer_user_id> &lt;/alipay> 测试代码: /** * @Description: * @Author: liuzhihang * @Date: 2017/12/17 23:11 */ public class JaxbTest &amp;#123; public static void main(String[] args) throws JAXBException &amp;#123; String aliPayXmlStr = \"&lt;alipay>\\n\" + \" &lt;alipay_buyer_login_id>176****3035&lt;/alipay_buyer_login_id>\\n\" + \" &lt;alipay_buyer_user_id>2088912868994947&lt;/alipay_buyer_user_id>\\n\" + \"&lt;/alipay>\"; AliPayXml aliPayXml = JaxbUtil.xml2Bean(aliPayXmlStr, AliPayXml.class); System.out.println(JSON.toJSONString(aliPayXml)); &amp;#125; &amp;#125; 测试结果: 打印的为json格式结果, 可debugger查看. 同样也可以将javaBean转换为xmlStr &#123;&quot;buyerLoginId&quot;:&quot;176****3035&quot;,&quot;buyerUserId&quot;:&quot;2088912868994947&quot;&#125;","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"xml","slug":"xml","permalink":"https://liuzhihang.com/tags/xml/"}]}],"categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"链路追踪","slug":"工作笔记/链路追踪","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"},{"name":"工具册","slug":"工具册","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E5%85%B7%E5%86%8C/"},{"name":"ELK","slug":"工作笔记/ELK","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/ELK/"},{"name":"IDEA","slug":"IDEA","permalink":"https://liuzhihang.com/categories/IDEA/"},{"name":"IDEA","slug":"工具册/IDEA","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E5%85%B7%E5%86%8C/IDEA/"},{"name":"Archetype","slug":"工作笔记/Archetype","permalink":"https://liuzhihang.com/categories/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/Archetype/"},{"name":"markdown","slug":"markdown","permalink":"https://liuzhihang.com/categories/markdown/"},{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"},{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/categories/hexo/"},{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"},{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"},{"name":"skywalking","slug":"skywalking","permalink":"https://liuzhihang.com/categories/skywalking/"},{"name":"Redis","slug":"Redis","permalink":"https://liuzhihang.com/categories/Redis/"},{"name":"cache","slug":"Redis/cache","permalink":"https://liuzhihang.com/categories/Redis/cache/"},{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"},{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"},{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"},{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E4%BD%9C%E7%AC%94%E8%AE%B0/"},{"name":"链路追踪","slug":"链路追踪","permalink":"https://liuzhihang.com/tags/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"},{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"},{"name":"工具册","slug":"工具册","permalink":"https://liuzhihang.com/tags/%E5%B7%A5%E5%85%B7%E5%86%8C/"},{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"},{"name":"plugin","slug":"plugin","permalink":"https://liuzhihang.com/tags/plugin/"},{"name":"IDEA","slug":"IDEA","permalink":"https://liuzhihang.com/tags/IDEA/"},{"name":"Archetype","slug":"Archetype","permalink":"https://liuzhihang.com/tags/Archetype/"},{"name":"markdown","slug":"markdown","permalink":"https://liuzhihang.com/tags/markdown/"},{"name":"小技巧","slug":"小技巧","permalink":"https://liuzhihang.com/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"流水号","slug":"流水号","permalink":"https://liuzhihang.com/tags/%E6%B5%81%E6%B0%B4%E5%8F%B7/"},{"name":"雪花算法","slug":"雪花算法","permalink":"https://liuzhihang.com/tags/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95/"},{"name":"error","slug":"error","permalink":"https://liuzhihang.com/tags/error/"},{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"},{"name":"mac","slug":"mac","permalink":"https://liuzhihang.com/tags/mac/"},{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/tags/hexo/"},{"name":"JWT","slug":"JWT","permalink":"https://liuzhihang.com/tags/JWT/"},{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"https://liuzhihang.com/tags/SpringSecurity/"},{"name":"skywalking","slug":"skywalking","permalink":"https://liuzhihang.com/tags/skywalking/"},{"name":"ip","slug":"ip","permalink":"https://liuzhihang.com/tags/ip/"},{"name":"Redis","slug":"Redis","permalink":"https://liuzhihang.com/tags/Redis/"},{"name":"cache","slug":"cache","permalink":"https://liuzhihang.com/tags/cache/"},{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"线程池","slug":"线程池","permalink":"https://liuzhihang.com/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"反射","slug":"反射","permalink":"https://liuzhihang.com/tags/%E5%8F%8D%E5%B0%84/"},{"name":"LinkList","slug":"LinkList","permalink":"https://liuzhihang.com/tags/LinkList/"},{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","permalink":"https://liuzhihang.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"volatile","slug":"volatile","permalink":"https://liuzhihang.com/tags/volatile/"},{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"aop","slug":"aop","permalink":"https://liuzhihang.com/tags/aop/"},{"name":"动态代理","slug":"动态代理","permalink":"https://liuzhihang.com/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"poi","slug":"poi","permalink":"https://liuzhihang.com/tags/poi/"},{"name":"excel","slug":"excel","permalink":"https://liuzhihang.com/tags/excel/"},{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"serialize","slug":"serialize","permalink":"https://liuzhihang.com/tags/serialize/"},{"name":"transactional","slug":"transactional","permalink":"https://liuzhihang.com/tags/transactional/"},{"name":"interceptor","slug":"interceptor","permalink":"https://liuzhihang.com/tags/interceptor/"},{"name":"servlet","slug":"servlet","permalink":"https://liuzhihang.com/tags/servlet/"},{"name":"validation","slug":"validation","permalink":"https://liuzhihang.com/tags/validation/"},{"name":"xml","slug":"xml","permalink":"https://liuzhihang.com/tags/xml/"}]}