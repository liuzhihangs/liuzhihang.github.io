{"meta":{"title":"Notes","subtitle":"Notes","description":"学，然后知不足；教，然后知困。","author":"liuzhihang","url":"https://liuzhihang.com","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-01-22T03:34:04.288Z","updated":"2020-01-22T03:34:04.288Z","comments":true,"path":"/404.html","permalink":"https://liuzhihang.com/404.html","excerpt":"","text":"啊~哦~ 您要查看的页面不存在或已删除！ 请检查您输入的网址是否正确，或者点击链接继续浏览空间 您可以在下方留言 返回上级 回到首页"},{"title":"关于我","date":"2020-06-18T07:45:45.195Z","updated":"2020-06-18T07:45:45.195Z","comments":true,"path":"about/index.html","permalink":"https://liuzhihang.com/about/index.html","excerpt":"","text":"Java开发, 热爱互联网, 闲暇时间会看看视频, 教程, 看书. 写写学习笔记.喜欢跑步 (这家伙很懒, 已经很久没跑步了~)偶尔打打王者 (混分大王~)更多的时间是比较宅! Label:java 后端 支付 开发 程序猿 coder Experience 2019-12 - 至今 北京欧非科技有限公司(Opay) 2017.04 - 2019-12 现在支付股份有限公司 Other欢迎通过以下方式了解我 Blog: https://liuzhihang.com/GitHub: https://github.com/liuzhihangsLeetCode: https://leetcode-cn.com/u/liuzhihang/CSDN: https://blog.csdn.net/qq_36535538知乎: https://www.zhihu.com/people/liuzhihang 公众号 扫码关注 视频号 扫码关注"},{"title":"分类","date":"2020-04-04T04:12:06.732Z","updated":"2020-04-04T04:12:06.732Z","comments":true,"path":"categories/index.html","permalink":"https://liuzhihang.com/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2019-12-23T06:35:08.831Z","updated":"2019-09-17T04:59:28.759Z","comments":true,"path":"contact/index.html","permalink":"https://liuzhihang.com/contact/index.html","excerpt":"","text":"欢迎留言大家有什么问题都可以给我留言, 非常欢迎和大家沟通交流. 博客内容为个人学习笔记, 肯定有理解的不到位的地方, 非常欢迎大家指正."},{"title":"friends","date":"2020-01-04T15:20:32.041Z","updated":"2020-01-04T15:20:32.041Z","comments":true,"path":"friends/index.html","permalink":"https://liuzhihang.com/friends/index.html","excerpt":"","text":"欢迎交换友链！格式1: 博客名字: liuzhihang博客地址: https://liuzhihang.com/博客头像: https://liuzhihang.com/medias/avatar.jpg博客简介: Work study notes about java programmers … 格式2: { \"name\": \"liuzhihang\", \"url\": \"https://liuzhihang.com/\", \"avatar\": \"https://liuzhihang.com/medias/avatar.jpg\", \"introduction\": \"Work study notes about java programmers ...\", \"title\": \"前去学习\" }"},{"title":"友情链接","date":"2020-04-04T05:30:59.681Z","updated":"2020-04-04T05:30:59.681Z","comments":true,"path":"link/index.html","permalink":"https://liuzhihang.com/link/index.html","excerpt":"","text":"请按照以下格式留言 name: 姓名 link: 链接地址 avatar: 头像 descr: 介绍"},{"title":"友情链接","date":"2019-12-23T06:35:09.231Z","updated":"2019-09-08T04:25:25.184Z","comments":true,"path":"links/index.html","permalink":"https://liuzhihang.com/links/index.html","excerpt":"","text":""},{"title":"跨境支付系统总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:11:31.222Z","comments":true,"path":"project/crossborder-pay.html","permalink":"https://liuzhihang.com/project/crossborder-pay.html","excerpt":"","text":"简述 来到这边接触的第一个项目, 很久之前了, 已经记得不是很清楚了. 项目描述跨境支付, 系统主要分为四块: 交易系统, 定时系统, 商户后台, 运营后台交易系统: 对接各个渠道(微信卡牌, 微信公众号, 支付宝等), 支持一码多付, 实时汇率等定时系统: 业务系统相关的各个定时任务商户后台: 商户查看交易记录, 发起退款等操作中心运营后台: 商户进件, 配置费率等 责任描述 和小伙伴一起重构代码+熟悉项目 对接支付宝跨境支付 对接商户 其他 暂时想不起来了"},{"title":"国内聚合支付","date":"2017-11-19T09:42:43.000Z","updated":"2019-10-01T09:07:11.366Z","comments":true,"path":"project/aggregate-pay.html","permalink":"https://liuzhihang.com/project/aggregate-pay.html","excerpt":"","text":"系统架构 聚合支付项目, 维护和迭代, 对接商户和渠道.参与项目: 公众号, 卡牌, 小程序 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构Spring + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper + RabbitMQ 开发时间2017.11 - 至今 项目介绍聚合支付系统一共涉及到 API系统, 公众号, 卡牌, 小程序, H5等交易系统, 应用中心, 清结算, 计费中心, 数据中心等其他支持系统, 这里仅仅介绍交易相关系统, 并且以公众号系统为例. API系统: 相当于网关, 对外提供统一接口, 负责统一加签验签, 根据参数路由到各个子系统, 过滤请求等等. 公众号系统: 聚合微信公众号, 支付宝服务窗, 手Q公众号等多种支付方式, 为商户提供统一接口, 如原生微信、 原生支付宝、 微众银行、 地方银商行等, 支持通道一键切换. 定时系统: 定时批处理, 补单等任务发起服务. 高峰时期日均800w笔交易. 责任描述系统代码维护和重构, 对接商户和渠道, 使用各种加签验签方式和渠道交互, 线上生产问题排查, 版本迭代, 及新需求新功能开发. 总结主要是对接银行等各个渠道, 银行之间的加密加签方式各不相同, 需要多进行测试.涉及到交易, 要保证交易金额正确, 防止资损.发生问题时要及时定位问题, 马上排查. 公众号:0模式: 服务商模式, 商户将应用挂在我方app下, 由我方拉起支付1模式: 商户下单, 我方返回支付要素 2.0 拆分对接渠道项目为渠道组件, 公众号、H5、SDK等各个渠道只需要引入渠道组件, 对接渠道组件即可. 即渠道组件负责将各个渠道的接口模型转换为固定的模型."},{"title":"卡+系统","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.534Z","comments":true,"path":"project/go-card.html","permalink":"https://liuzhihang.com/project/go-card.html","excerpt":"","text":"基本逻辑 仅仅代表大致逻辑, 并不是流程图 会员通过小程序以八折购买某店铺的会员卡–go卡 普通用户消费, 通过二维码卡牌进行消费 后台通过算法, 计算出扣除 go卡编号, 扣除该卡面相同金额 金额以比例分润给用户和我司 好友在店铺消费可以指定使用哪张会员卡 – 还有消费 95折 收益点: 用户八折购买会员卡, 当卡面金额被消费完(自己消费和他人消费), 自身所获得收益远大于购买卡的金额风险点: 会员购卡金额存放, 如果直接给商户, 商户可能存在跑路风险 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构SpringBoot + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper 开发时间2017.06 - 2017.11 项目介绍购卡项目: 该系统分为 卡+金融, 会员中心, 商户后台, 定时系统, 前端系统, 这有卡算法核心等前端系统: 通过公众号/小程序展示商户信息, 卡收益率等信息, 负责和后台系统进行交互; 卡+金融: 项目核心, 分为有卡消费和无卡消费, 主要进行用户消费, 买单交易, 修改账户, 分红交易, 转账交易等操作; 会员中心: 验证会员登录, 维持登录态, 存储会员信息以及会员卡信息等; 商户后台: 商户实时查看卡销售和订单交易情况, 进行退款等操作的平台; 定时系统: 负责定时任务统一请求调度; 这有卡: 算法核心, 卡+金融请求这有卡, 这有卡通过算法计算出商户和用户实时收益率等卡信息, 消费时获取需要扣除金额卡的卡号; 责任描述参与架构设计, 流程梳理, 表结构设计等工作, 负责卡+金融系统 无卡消费, 分红结算, 异步通知, 同步清算交易, 上报数据中心等逻辑实现, 及定时任务编写实现; 负责商户后台 分红信息的查询和导出, 交易列表及详情的展示, 卡信息编辑展示; 总结 结合C端用户和商家的第一次尝试, 同时可以利用到公司的支付资源 本次使用的是公众号内进行卡销售, 后面这有卡单独开发 ‘卡拼拼’ 小程序来进行相关拼卡业务, 相当于是对本项目的迭代"},{"title":"喜茶总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.552Z","comments":true,"path":"project/heytea.html","permalink":"https://liuzhihang.com/project/heytea.html","excerpt":"","text":"系统架构 独立负责喜茶交易系统开发, 熟悉整体业务 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构SpringBoot + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper + RabbitMQ 开发时间2018.07 - 2019.03 项目介绍项目包括: API系统, 订单系统, 定时系统, 通知系统, 账户系统, 数据中心等几大系统API系统: 统一加签验签, 是外部请求的统一入口; 订单系统: 充值, 退款, 线上消费, 线下消费, 冲正等业务核心; 定时系统: 各系统定时任务触发的系统; 通知系统: 从mq中消费数据, 按照通知地址通知商户; 责任描述参与系统的设计与架构讨论, 并负责搭建开发 API系统, 订单系统, 定时系统 和通知系统.API系统, 统一加签验签, 和喜茶对接相关接口. 订单系统: 对接微信小程序支付, 微信退款, 开发账户充值, 消费, 冲正, 补单等业务逻辑, 其中流水号系统撤销, 使用雪花算法方式代替流水号系统; 定时系统: 设定合理的调度区间, 定时补单, 和查询交易状态, 补发通知状态; 通知系统: 消费MQ, 并通知商户, 同时存入数据库, 如果通知失败, 在指定时间间隔内, 补发通知. 总结 独立开发整个项目, 从API系统到业务系统, 通知系统 流水号系统使用雪花算法 使用阿里云MQ, 同时熟悉通知系统整体业务"},{"title":"现在支付","date":"2019-12-20T11:00:00.000Z","updated":"2020-04-22T09:25:54.889Z","comments":true,"path":"project/ipaynow.html","permalink":"https://liuzhihang.com/project/ipaynow.html","excerpt":"","text":"2017.04 - 2019-12 现在支付股份有限公司, 简称ipaynow做三方支付相关业务, 先后参与跨境支付, 付款平台, 监控系统等项目的开发. Project 长期运维, 不断迭代 跨境支付: 微信公众号 卡牌 支付宝, 后移交给别的组 国内聚合支付: 公众号 卡牌 小程序 付款平台&amp;渠道系统: 代扣业务 独立负责项目开发 喜茶钱包: 二类户 + 喜茶 合作项目 麦当劳Arch Card: 麦当劳钱包充值消费, 卡券消费 内部运维, 从头开始 日志系统: 统一日志系统, 方便查询问题 监控系统: 对各系统进行监控, 从商户和渠道两个方面对交易数据进行监控 skywalking应用监控: 实时查看各系统情况, 接口耗时 转换思路, 不断尝试 卡+: 会员卡的重新定义, 达到闲置会员卡充分利用, 真正可以赚钱的会员卡 停车管家: 一个相对比较糟糕的项目 摇钱树: 和二类户合作, 开户获取分红 内部活动, 临时小项目 定时抢: 一个临时小创意, 设置游戏规则, 按照排名领取红包"},{"title":"日志系统总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.539Z","comments":true,"path":"project/log-system.html","permalink":"https://liuzhihang.com/project/log-system.html","excerpt":"","text":"软件架构Filebeat + Logstash + Elasticsearch + Kibana + Search-Guard 项目介绍日志系统基于ELK, 使用filebeat从各个系统取指定格式的日志, 通过logstash将日志清洗然后上报到ES; Kibana使用Search-Guard进行权限控制 责任描述前期对ELK进行调研和搭建, 调研Search-Guard插件, 并测试使用效果, 评估可用性. 统一日志格式, 并通过logstash进行过滤. 对es进行相关系统学习, 了解底层原理及如何优化. 编写相关操作文档, 及日志系统接入文档, 帮助各个系统对接日志系统. 总结前期使用ELK+Search-Gurad, 后期小伙伴开发日志组件日志组件: 所有项目排掉日志模块, 统一依赖日志组件; 规范日志格式; 同时日志组件可以使用 log4j appender 直接上报数据到kafka 方便监控系统监控; 日志组件使用skywalking traceId, 可以进行全链路追踪;"},{"title":"麦当劳 Arch Card总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.536Z","comments":true,"path":"project/mcd-arch-card.html","permalink":"https://liuzhihang.com/project/mcd-arch-card.html","excerpt":"","text":"系统架构 使用了 SpringCloud, Feign, Apollo配置中心, CMQ 等 开发环境IDEA、JDK1.8、Tomcat 7、TDB、Git、Maven 软件架构SpringBoot + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper + SpringCloud + Apollo + CMQ 开发时间2018.07 - 至今 项目介绍项目包括: API系统, 订单系统, 定时系统, 通知系统, 账户系统, 数据中心等几大系统API系统: 统一加签验签, 是外部请求的统一入口; 订单系统: 充值, 退款, 线上消费, 线下消费, 卡券充值, 卡券消费, 冲正等业务核心; 定时系统: 各系统定时任务触发的系统; 通知系统: 从mq中消费数据, 按照通知地址通知商户;卡券系统: 负责卡券生成及核销; 商户后台: 查看交易统计数据以及发起退款. 责任描述参与系统的架构讨论和设计, 并搭建交易系统和定时系统交易系统: 对接微信充值, 开发钱包卡券充值, 卡券消费, 线上消费, 线下消费, 退款, 冲正等业务逻辑; 定时系统: 负责统一批处理调度; 和商户联调, 同时对接其他系统; 总结初始使用Dubbo+Zookeeper的方式, 后期改成 SpringCloud+Feign统一配置中心, Apollo 使用起来比较方便. (近期搭建了下 Nacos 感觉也挺不错)"},{"title":"监控系统项目总结","date":"2018-10-04T09:42:43.000Z","updated":"2019-09-30T13:08:23.531Z","comments":true,"path":"project/monitor-system.html","permalink":"https://liuzhihang.com/project/monitor-system.html","excerpt":"","text":"基本逻辑 v0.0.1 还未加入 Kafka后期为迭代以及ELK版本更新, 在Filebeat 和 Logstash 中间加入 MQ(Kafka)使用 Skywalking + ES 对应用进行监控 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构SpringBoot + SpringMVC + MyBatis + ELK(Elasticsearch、Logstash、Kibana) + Redis + Bootstrap + Thymeleaf 开发时间一期: 2018.05 一一 2018.07二期: 未启动 项目介绍基于ELK, 对各交易系统从渠道和商户的维度对下单、查询、支付、通知的TPS/QPS以及成功率、支付率进行监控, 确保一旦符合报警规则, 立即报警.报警方式: 短信、邮件、微信 ☞ 相关架构 责任描述1、参与系统架构, 表结构设计, 实现流程的讨论2、监控规则的制定3、商户维度监控逻辑实现4、系统的更新维护及版本迭代 技术描述1、基于Elasticsearch和MySql的CRUD2、使用Springboot Scheduled定时,监控指定区间内的数据变化3、使用Redis队列对Error信息立即报警4、使用Bootstrap+EChart模版展示监控数据信息 后期规划1、对接微信渠道, 支持公众号报警方式2、前端页面进行优化(后端程序员表示…)3、统一日志模块优化4、后台权限, 监控规则可配置(手动改库总是不太好.)"},{"title":"摇贝总结","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.550Z","comments":true,"path":"project/money-tree.html","permalink":"https://liuzhihang.com/project/money-tree.html","excerpt":"","text":"系统架构开发环境软件架构开发时间项目介绍责任描述技术描述总结"},{"title":"付款平台和渠道系统","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.545Z","comments":true,"path":"project/pay-platform.html","permalink":"https://liuzhihang.com/project/pay-platform.html","excerpt":"","text":"系统架构 参与对原代付系统进行重构, 同时也了解相关业务 开发环境IDEA、JDK1.8、Tomcat 7、MySQL、Git、Maven 软件架构Spring + SpringMVC + MyBatis + Redis + Dubbo + Zookeeper + RabbitMQ 开发时间2017.11 - 至今 项目介绍商户与自己的客户签订代收协议, 委托现在支付对已签约客户发起银行卡扣款, 并将资金划入商户在我司开通的余额账户, T+1 日结算到结算账户. 商户将资金冲入在我司开通的余额账户, 并委托我司将业务资金转账到指定的客户银行卡中.高峰时期日均流水近1亿元.代付系统: 包括 付款平台, 渠道系统, 定时系统付款平台: 主要负责对接商户, 校验参数, 风控, 和应用中心交互等业务; 渠道系统: 负责和银行对接, 包含大部分加签验签工具, 以及接收渠道异步通知. 责任描述参与对原代付系统进行重构, 负责退票逻辑实现, 运营后台查单, 发起退票等功能实现. 对接银行, 排查线上问题. 以及对项目进行维护. 总结和银行进行交互, 加解密验签方式比较复杂认识到代付业务: 补单, 查单, 压单, 窗口期了解到整体架构: 和 风控系统, 应用中心, 通知系统, 流水号系统, 清结算, 数据中心, 运营后台等系统的交互"},{"title":"现在支付","date":"2019-12-20T11:00:00.000Z","updated":"2020-04-22T09:47:55.364Z","comments":true,"path":"project/operapay.html","permalink":"https://liuzhihang.com/project/operapay.html","excerpt":"","text":"2019-12 - 至今 北京欧非科技有限公司, 简称opay支付,及支付场景相关业务 这里啥也没有开始写~"},{"title":"国内聚合支付","date":"2017-11-19T09:42:43.000Z","updated":"2019-09-30T13:08:23.542Z","comments":true,"path":"project/timing.html","permalink":"https://liuzhihang.com/project/timing.html","excerpt":"","text":"展示 总结周五周六两天时间, 设计+开发学习使用墨刀对接公司小程序支付并能够拉起支付页面"},{"title":"Repositories","date":"2019-12-23T06:35:08.828Z","updated":"2019-09-08T04:26:22.862Z","comments":true,"path":"repository/index.html","permalink":"https://liuzhihang.com/repository/index.html","excerpt":"","text":""},{"title":"recommend-course","date":"2020-04-01T11:50:25.425Z","updated":"2020-04-01T11:50:25.425Z","comments":true,"path":"recommend-course/index.html","permalink":"https://liuzhihang.com/recommend-course/index.html","excerpt":"","text":"中华石杉老师课程很多课程都可以搜索的到, 下面是别的小伙伴整理的 👉 中华石杉老师课程汇总 石杉老师的课程还是很不错的, 推荐看Java面试突击第一季, 无论是用来平时知识点扫盲还是用来面试突击, 都很有用处. Java面试突击第一季 链接：https://pan.baidu.com/s/1EKi9DkkiEFZRqQM0R_PNsA提取码：buha 列表"},{"title":"标签","date":"2020-04-04T04:12:07.018Z","updated":"2020-04-04T04:12:07.018Z","comments":true,"path":"tags/index.html","permalink":"https://liuzhihang.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2020-06-19T03:48:58.605Z","updated":"2020-06-19T02:42:28.773Z","comments":true,"path":"resources/highlight/atom-one-light.css","permalink":"https://liuzhihang.com/resources/highlight/atom-one-light.css","excerpt":"","text":"/* Atom One Light by Daniel Gamage Original One Light Syntax theme from https://github.com/atom/one-light-syntax base: #fafafa mono-1: #383a42 mono-2: #686b77 mono-3: #a0a1a7 hue-1: #0184bb hue-2: #4078f2 hue-3: #a626a4 hue-4: #50a14f hue-5: #e45649 hue-5-2: #c91243 hue-6: #986801 hue-6-2: #c18401 */ .hljs { display: block; overflow-x: auto; padding: 0.5em; color: #383a42; background: #fafafa; } .hljs-comment, .hljs-quote { color: #a0a1a7; font-style: italic; } .hljs-doctag, .hljs-keyword, .hljs-formula { color: #a626a4; } .hljs-section, .hljs-name, .hljs-selector-tag, .hljs-deletion, .hljs-subst { color: #e45649; } .hljs-literal { color: #0184bb; } .hljs-string, .hljs-regexp, .hljs-addition, .hljs-attribute, .hljs-meta-string { color: #50a14f; } .hljs-built_in, .hljs-class .hljs-title { color: #c18401; } .hljs-attr, .hljs-variable, .hljs-template-variable, .hljs-type, .hljs-selector-class, .hljs-selector-attr, .hljs-selector-pseudo, .hljs-number { color: #986801; } .hljs-symbol, .hljs-bullet, .hljs-link, .hljs-meta, .hljs-selector-id, .hljs-title { color: #4078f2; } .hljs-emphasis { font-style: italic; } .hljs-strong { font-weight: bold; } .hljs-link { text-decoration: underline; }"},{"title":"","date":"2020-06-19T03:34:52.113Z","updated":"2020-06-19T03:34:52.113Z","comments":true,"path":"resources/highlight/atom-one-dark.css","permalink":"https://liuzhihang.com/resources/highlight/atom-one-dark.css","excerpt":"","text":"/* 代碼框背景色和字體顔色,與hljs一樣就行 */ /* 必須配置(把下面.hljs的color和background複製到這裏來) */ #article-container pre, #article-container figure.highlight { color: #abb2bf; background: #282c34; } /* 代碼框工具欄 (如果你關掉了copy、lang和shrink,可不用配置這個 */ #article-container figure.highlight .highlight-tools { color: #5c6370; background: #282c34; } /* 代碼框行數(如果已經關掉line_number,可以不用配置這個) */ #article-container figure.highlight .gutter pre { color: #5c6370; background: #282c34; } /* 代碼塊figcaption配置(hexo自帶標簽https://hexo.io/zh-tw/docs/tag-plugins.html#Code-Block) */ /* 不需要可以不用配置這個 */ #article-container figure.highlight figcaption a { color: #282c34 !important } /* Atom One Dark by Daniel Gamage Original One Dark Syntax theme from https://github.com/atom/one-dark-syntax base: #282c34 mono-1: #abb2bf mono-2: #818896 mono-3: #5c6370 hue-1: #56b6c2 hue-2: #61aeee hue-3: #c678dd hue-4: #98c379 hue-5: #e06c75 hue-5-2: #be5046 hue-6: #d19a66 hue-6-2: #e6c07b */ #article-container figure.highlight .hljs { display: block; overflow-x: auto; padding: 0.5em; color: #abb2bf; background: #282c34; } .hljs-comment, .hljs-quote { color: #5c6370; font-style: italic; } .hljs-doctag, .hljs-keyword, .hljs-formula { color: #c678dd; } .hljs-section, .hljs-name, .hljs-selector-tag, .hljs-deletion, .hljs-subst { color: #e06c75; } .hljs-literal { color: #56b6c2; } .hljs-string, .hljs-regexp, .hljs-addition, .hljs-attribute, .hljs-meta-string { color: #98c379; } .hljs-built_in, .hljs-class .hljs-title { color: #e6c07b; } .hljs-attr, .hljs-variable, .hljs-template-variable, .hljs-type, .hljs-selector-class, .hljs-selector-attr, .hljs-selector-pseudo, .hljs-number { color: #d19a66; } .hljs-symbol, .hljs-bullet, .hljs-link, .hljs-meta, .hljs-selector-id, .hljs-title { color: #61aeee; } .hljs-emphasis { font-style: italic; } .hljs-strong { font-weight: bold; } .hljs-link { text-decoration: underline; }"},{"title":"后端架构师技术图谱","date":"2019-12-23T06:35:09.228Z","updated":"2019-09-08T04:25:46.473Z","comments":true,"path":"map/index.html","permalink":"https://liuzhihang.com/map/index.html","excerpt":"","text":"《后端架构师技术图谱》 数据结构 队列 集合 链表、数组 字典、关联数组 栈 树 二叉树 完全二叉树 平衡二叉树 二叉查找树（BST） 红黑树 B，B+，B*树 LSM 树 BitSet 常用算法 排序、查找算法 选择排序 冒泡排序 插入排序 快速排序 归并排序 希尔排序 堆排序 计数排序 桶排序 基数排序 二分查找 Java 中的排序工具 布隆过滤器 字符串比较 KMP 算法 深度优先、广度优先 贪心算法 回溯算法 剪枝算法 动态规划 朴素贝叶斯 推荐算法 最小生成树算法 最短路径算法 并发 Java 并发 多线程 线程安全 一致性、事务 事务 ACID 特性 事务的隔离级别 MVCC 锁 Java中的锁和同步类 公平锁 &amp; 非公平锁 悲观锁 乐观锁 &amp; CAS ABA 问题 CopyOnWrite容器 RingBuffer 可重入锁 &amp; 不可重入锁 互斥锁 &amp; 共享锁 死锁 操作系统 计算机原理 CPU 多级缓存 进程 线程 协程 Linux 设计模式 设计模式的六大原则 23种常见设计模式 应用场景 单例模式 责任链模式 MVC IOC AOP UML 微服务思想 康威定律 运维 &amp; 统计 &amp; 技术支持 常规监控 APM 统计分析 持续集成(CI/CD) Jenkins 环境分离 自动化运维 Ansible puppet chef 测试 TDD 理论 单元测试 压力测试 全链路压测 A/B 、灰度、蓝绿测试 虚拟化 KVM Xen OpenVZ 容器技术 Docker 云技术 OpenStack DevOps 文档管理 中间件 Web Server Nginx OpenResty Tengine Apache Httpd Tomcat 架构原理 调优方案 Jetty 缓存 本地缓存 客户端缓存 服务端缓存 Web缓存 Memcached Redis 架构 回收策略 Tair 消息队列 消息总线 消息的顺序 RabbitMQ RocketMQ ActiveMQ Kafka Redis 消息推送 ZeroMQ 定时调度 单机定时调度 分布式定时调度 RPC Dubbo Thrift gRPC 数据库中间件 Sharding Jdbc 日志系统 日志搜集 配置中心 API 网关 网络 协议 OSI 七层协议 TCP/IP HTTP HTTP2.0 HTTPS 网络模型 Epoll Java NIO kqueue 连接和短连接 框架 零拷贝（Zero-copy） 序列化(二进制协议) Hessian Protobuf 数据库 基础理论 数据库设计的三大范式 MySQL 原理 InnoDB 优化 索引 聚集索引, 非聚集索引 复合索引 自适应哈希索引(AHI) explain NoSQL MongoDB Hbase 搜索引擎 搜索引擎原理 Lucene Elasticsearch Solr sphinx 性能 性能优化方法论 容量评估 CDN 网络 连接池 性能调优 大数据 流式计算 Storm Flink Kafka Stream 应用场景 Hadoop HDFS MapReduce Yarn Spark 安全 web 安全 XSS CSRF SQL 注入 Hash Dos 脚本注入 漏洞扫描工具 验证码 DDoS 防范 用户隐私信息保护 序列化漏洞 加密解密 对称加密 哈希算法 非对称加密 服务器安全 数据安全 数据备份 网络隔离 内外网分离 登录跳板机 授权、认证 RBAC OAuth2.0 双因素认证（2FA） 单点登录(SSO) 常用开源框架 开源协议 日志框架 Log4j、Log4j2 Logback ORM 网络框架 Web 框架 Spring 家族 工具框架 分布式设计 扩展性设计 稳定性 &amp; 高可用 硬件负载均衡 软件负载均衡 限流 应用层容灾 跨机房容灾 容灾演练流程 平滑启动 数据库扩展 读写分离模式 分片模式 服务治理 服务注册与发现 服务路由控制 分布式一致 CAP 与 BASE 理论 分布式锁 分布式一致性算法 PAXOS Zab Raft Gossip 两阶段提交、多阶段提交 幂等 分布式一致方案 分布式 Leader 节点选举 TCC(Try/Confirm/Cancel) 柔性事务 分布式文件系统 唯一ID 生成 全局唯一ID 一致性Hash算法 设计思想 &amp; 开发模式 DDD(Domain-driven Design - 领域驱动设计) 命令查询职责分离(CQRS) 贫血，充血模型 Actor 模式 响应式编程 Reactor RxJava Vert.x DODAF2.0 Serverless Service Mesh 项目管理 架构评审 重构 代码规范 代码 Review RUP 看板管理 SCRUM 敏捷开发 极限编程（XP） 结对编程 PDCA 循环质量管理 FMEA管理模式 通用业务术语 技术趋势 政策、法规 法律 严格遵守刑法253法条 架构师素质 团队管理 招聘 资讯 行业资讯 公众号列表 博客 团队博客 个人博客 综合门户、社区 问答、讨论类社区 行业数据分析 专项网站 其他类 推荐参考书 在线电子书 纸质书 开发方面 架构方面 技术管理方面 基础理论 工具方面 大数据方面 技术资源 开源资源 手册、文档、教程 在线课堂 会议、活动 常用APP 找工作 工具 代码托管 文件服务 综合云服务商 VPS （Toc generated by simple-php-github-toc ） 数据结构队列 《java队列——queue详细分析》 非阻塞队列：ConcurrentLinkedQueue(无界线程安全)，采用CAS机制（compareAndSwapObject原子操作）。 阻塞队列：ArrayBlockingQueue(有界)、LinkedBlockingQueue（无界）、DelayQueue、PriorityBlockingQueue，采用锁机制；使用 ReentrantLock 锁。 《LinkedList、ConcurrentLinkedQueue、LinkedBlockingQueue对比分析》 集合 《Java Set集合的详解》 链表、数组 《Java集合详解–什么是List》 字典、关联数组 《Java map 详解 - 用法、遍历、排序、常用API等》 栈 《java数据结构与算法之栈（Stack）设计与实现》 《Java Stack 类》 《java stack的详细实现分析》 Stack 是线程安全的。 内部使用数组保存数据，不够时翻倍。 树二叉树每个节点最多有两个叶子节点。 《二叉树》 完全二叉树 《完全二叉树》 叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 平衡二叉树左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 《浅谈数据结构-平衡二叉树》 《浅谈算法和数据结构: 八 平衡查找树之2-3树》 二叉查找树（BST）二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree）。 《浅谈算法和数据结构: 七 二叉查找树》 红黑树 《最容易懂得红黑树》 添加阶段后，左旋或者右旋从而再次达到平衡。 《浅谈算法和数据结构: 九 平衡查找树之红黑树》 B，B+，B*树MySQL是基于B+树聚集索引组织表 《B-树，B+树，B*树详解》 《B-树，B+树与B*树的优缺点比较》 B+树的叶子节点链表结构相比于 B-树便于扫库，和范围检索。LSM 树 LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的。Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引。 《LSM树 VS B+树》 B+ 树读性能好，但由于需要有序结构，当key比较分散时，磁盘寻道频繁，造成写性能。 LSM 是将一个大树拆分成N棵小树，先写到内存（无寻道问题，性能高），在内存中构建一颗有序小树（有序树），随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历（二分查找）所有的小树，但在每颗小树内部数据是有序的。 《LSM树（Log-Structured Merge Tree）存储引擎》 极端的说，基于LSM树实现的HBase的写性能比MySQL高了一个数量级，读性能低了一个数量级。 优化方式：Bloom filter 替代二分查找；compact 小数位大树，提高查询性能。 Hbase 中，内存中达到一定阈值后，整体flush到磁盘上、形成一个文件（B+数），HDFS不支持update操作，所以Hbase做整体flush而不是merge update。flush到磁盘上的小树，定期会合并成一个大树。 BitSet经常用于大规模数据的排重检查。 《Java Bitset类》 《Java BitSet（位集）》 常用算法 《常见排序算法及对应的时间复杂度和空间复杂度》 排序、查找算法 《常见排序算法及对应的时间复杂度和空间复杂度》 选择排序 《Java中的经典算法之选择排序（SelectionSort）》 每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕。 冒泡排序 《冒泡排序的2种写法》 相邻元素前后交换、把最大的排到最后。 时间复杂度 O(n²) 插入排序 《排序算法总结之插入排序》 快速排序 《坐在马桶上看算法：快速排序》 一侧比另外一次都大或小。归并排序 《图解排序算法(四)之归并排序》 分而治之，分成小份排序，在合并(重建一个新空间进行复制)。 希尔排序TODO 堆排序 《图解排序算法(三)之堆排序》 排序过程就是构建最大堆的过程，最大堆：每个结点的值都大于或等于其左右孩子结点的值，堆顶元素是最大值。 计数排序 《计数排序和桶排序》 和桶排序过程比较像，差别在于桶的数量。 桶排序 《【啊哈！算法】最快最简单的排序——桶排序》 《排序算法（三）：计数排序与桶排序》 桶排序将[0,1)区间划分为n个相同的大小的子区间，这些子区间被称为桶。 每个桶单独进行排序，然后再遍历每个桶。 基数排序按照个位、十位、百位、…依次来排。 《排序算法系列：基数排序》 《基数排序》 二分查找 《二分查找(java实现)》 要求待查找的序列有序。 时间复杂度 O(logN)。 《java实现二分查找-两种方式》 while + 递归。Java 中的排序工具 《Arrays.sort和Collections.sort实现原理解析》 Collections.sort算法调用的是合并排序。 Arrays.sort() 采用了2种排序算法 – 基本类型数据使用快速排序法，对象数组使用归并排序。 布隆过滤器常用于大数据的排重，比如email，url 等。核心原理：将每条数据通过计算产生一个指纹（一个字节或多个字节，但一定比原始数据要少很多），其中每一位都是通过随机计算获得，在将指纹映射到一个大的按位存储的空间中。注意：会有一定的错误率。优点：空间和时间效率都很高。缺点：随着存入的元素数量增加，误算率随之增加。 《布隆过滤器 – 空间效率很高的数据结构》 《大量数据去重：Bitmap和布隆过滤器(Bloom Filter)》 《基于Redis的布隆过滤器的实现》 基于 Redis 的 Bitmap 数据结构。 《网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用》 使用Java中的 BitSet 类 和 加权和hash算法。 字符串比较KMP 算法KMP：Knuth-Morris-Pratt算法（简称KMP）核心原理是利用一个“部分匹配表”，跳过已经匹配过的元素。 《字符串匹配的KMP算法》 深度优先、广度优先 《广度优先搜索BFS和深度优先搜索DFS》 贪心算法 《算法：贪婪算法基础》 《常见算法及问题场景——贪心算法》 回溯算法 《 五大常用算法之四：回溯法》 剪枝算法 《α-β剪枝算法》 动态规划 《详解动态规划——邹博讲动态规划》 《动态规划算法的个人理解》 朴素贝叶斯 《带你搞懂朴素贝叶斯分类算法》 P(B|A)=P(A|B)P(B)/P(A) 《贝叶斯推断及其互联网应用1》 《贝叶斯推断及其互联网应用2》 推荐算法 《推荐算法综述》 《TOP 10 开源的推荐系统简介》 最小生成树算法 《算法导论–最小生成树（Kruskal和Prim算法）》 最短路径算法 《Dijkstra算法详解》 并发Java 并发 Java 并发知识合集 JAVA并发知识图谱 多线程 《40个Java多线程问题总结》 线程安全 《Java并发编程——线程安全及解决机制简介》 一致性、事务事务 ACID 特性 《数据库事务ACID特性》 事务的隔离级别 未提交读：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。 读提交：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。 可重复读： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。 序列化：所有事物串行处理（牺牲了效率） 《理解事务的4种隔离级别》 数据库事务的四大特性及事务隔离级别 《MySQL的InnoDB的幻读问题 》 幻读的例子非常清楚。 通过 SELECT … FOR UPDATE 解决。 《一篇文章带你读懂MySQL和InnoDB》 图解脏读、不可重复读、幻读问题。 MVCC 《【mysql】关于innodb中MVCC的一些理解》 innodb 中 MVCC 用在 Repeatable-Read 隔离级别。 MVCC 会产生幻读问题（更新时异常。） 《轻松理解MYSQL MVCC 实现机制》 通过隐藏版本列来实现 MVCC 控制，一列记录创建时间、一列记录删除时间，这里的时间 每次只操作比当前版本小（或等于）的 行。 锁Java中的锁和同步类 《Java中的锁分类》 主要包括 synchronized、ReentrantLock、和 ReadWriteLock。 《Java并发之AQS详解》 《Java中信号量 Semaphore》 有数量控制 申请用 acquire，申请不要则阻塞；释放用 release。 《java开发中的Mutex vs Semaphore》 简单的说 就是Mutex是排它的，只有一个可以获取到资源， Semaphore也具有排它性，但可以定义多个可以获取的资源的对象。 公平锁 &amp; 非公平锁公平锁的作用就是严格按照线程启动的顺序来执行的，不允许其他线程插队执行的；而非公平锁是允许插队的。 《公平锁与非公平锁》 默认情况下 ReentrantLock 和 synchronized 都是非公平锁。ReentrantLock 可以设置成公平锁。 悲观锁悲观锁如果使用不当（锁的条数过多），会引起服务大面积等待。推荐优先使用乐观锁+重试。 《【MySQL】悲观锁&amp;乐观锁》 乐观锁的方式：版本号+重试方式 悲观锁：通过 select … for update 进行行锁(不可读、不可写，share 锁可读不可写)。 《Mysql查询语句使用select.. for update导致的数据库死锁分析》 mysql的innodb存储引擎实务锁虽然是锁行，但它内部是锁索引的。 锁相同数据的不同索引条件可能会引起死锁。 《Mysql并发时经典常见的死锁原因及解决方法》 乐观锁 &amp; CAS 《乐观锁的一种实现方式——CAS》 和MySQL乐观锁方式相似，只不过是通过和原值进行比较。 ABA 问题由于高并发，在CAS下，更新后可能此A非彼A。通过版本号可以解决，类似于上文Mysql 中提到的的乐观锁。 《Java CAS 和ABA问题》 《Java 中 ABA问题及避免》 AtomicStampedReference 和 AtomicStampedReference。 CopyOnWrite容器可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。 《JAVA中写时复制(Copy-On-Write)Map实现》 实现读写分离，读取发生在原始数据上，写入发生在副本上。 不用加锁，通过最终一致实现一致性。 《聊聊并发-Java中的Copy-On-Write容器》 RingBuffer 《线程安全的无锁RingBuffer的实现【一个读线程，一个写线程】》 可重入锁 &amp; 不可重入锁 《可重入锁和不可重入锁》 通过简单代码举例说明可重入锁和不可重入锁。 可重入锁指同一个线程可以再次获得之前已经获得的锁。 可重入锁可以用户避免死锁。 Java中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock 《ReenTrantLock可重入锁（和synchronized的区别）总结》 synchronized 使用方便，编译器来加锁，是非公平锁。 ReenTrantLock 使用灵活，锁的公平性可以定制。 相同加锁场景下，推荐使用 synchronized。 互斥锁 &amp; 共享锁互斥锁：同时只能有一个线程获得锁。比如，ReentrantLock 是互斥锁，ReadWriteLock 中的写锁是互斥锁。共享锁：可以有多个线程同时或的锁。比如，Semaphore、CountDownLatch 是共享锁，ReadWriteLock 中的读锁是共享锁。 《ReadWriteLock场景应用》 死锁 《“死锁”四个必要条件的合理解释》 互斥、持有、不可剥夺、环形等待。 Java如何查看死锁？ JConsole 可以识别死锁。 java多线程系列：死锁及检测 jstack 可以显示死锁。 操作系统计算机原理 《操作系统基础知识——操作系统的原理，类型和结构》 CPU多级缓存典型的 CPU 有三级缓存，距离核心越近，速度越快，空间越小。L1 一般 32k，L2 一般 256k，L3 一般12M。内存速度需要200个 CPU 周期，CPU 缓存需要1个CPU周期。 《从Java视角理解CPU缓存和伪共享》 进程TODO 线程 《线程的生命周期及状态转换详解》 协程 《终结python协程—-从yield到actor模型的实现》 线程的调度是由操作系统负责，协程调度是程序自行负责 与线程相比，协程减少了无谓的操作系统切换. 实际上当遇到IO操作时做切换才更有意义，（因为IO操作不用占用CPU），如果没遇到IO操作，按照时间片切换. Linux 《Linux 命令大全》 设计模式设计模式的六大原则 《设计模式的六大原则》 开闭原则：对扩展开放,对修改关闭，多使用抽象类和接口。 里氏替换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。 依赖倒转原则：要依赖于抽象,不要依赖于具体，针对接口编程,不针对实现编程。 接口隔离原则：使用多个隔离的接口,比使用单个接口好，建立最小的接口。 迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。 合成复用原则：尽量使用合成/聚合,而不是使用继承。 23种常见设计模式 《设计模式》 《23种设计模式全解析》 《设计模式类图与示例》 应用场景 《细数JDK里的设计模式》 结构型模式： 适配器：用来把一个接口转化成另一个接口，如 java.util.Arrays#asList()。 桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC； 组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 Map.putAll，List.addAll、Set.addAll。 装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap。 享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。 代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 java.lang.reflect.Proxy 创建模式: 抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 java.util.Calendar#getInstance()。 建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：java.lang.StringBuilder#append()。 工厂方法：就是 一个返* 回具体对象的方法，而不是多个，如 java.lang.Object#toString()、java.lang.Class#newInstance()。 原型模式：使得类的实例能够生成自身的拷贝、如：java.lang.Object#clone()。 单例模式：全局只有一个实例，如 java.lang.Runtime#getRuntime()。 行为模式： 责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 javax.servlet.Filter#doFilter()。 命令模式：将操作封装到对象内，以便存储，传递和返回，如：java.lang.Runnable。 解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，java.text.Format，java.text.Normalizer。 迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 java.util.Iterator。 中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，java.lang.reflect.Method#invoke()。 空对象模式：如 java.util.Collections#emptyList()。 观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 java.util.EventListener。 模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 java.util.Collections#sort()。 《Spring-涉及到的设计模式汇总》 《Mybatis使用的设计模式》 单例模式 《单例模式的三种实现 以及各自的优缺点》 《单例模式－－反射－－防止序列化破坏单例模式》 使用枚举类型。 责任链模式TODO MVC 《MVC 模式》 模型(model)－视图(view)－控制器(controller) IOC 《理解 IOC》 《IOC 的理解与解释》 正向控制：传统通过new的方式。反向控制，通过容器注入对象。 作用：用于模块解耦。 DI：Dependency Injection，即依赖注入，只关心资源使用，不关心资源来源。 AOP 《轻松理解AOP(面向切面编程)》 《Spring AOP详解》 《Spring AOP的实现原理》 Spring AOP使用的动态代理，主要有两种方式：JDK动态代理和CGLIB动态代理。 《Spring AOP 实现原理与 CGLIB 应用》 Spring AOP 框架对 AOP 代理类的处理原则是：如果目标对象的实现类实现了接口，Spring AOP 将会采用 JDK 动态代理来生成 AOP 代理类；如果目标对象的实现类没有实现接口，Spring AOP 将会采用 CGLIB 来生成 AOP 代理类 UML 《UML教程》 微服务思想 《微服务架构设计》 《微服务架构技术栈选型手册》 康威定律 《微服务架构的理论基础 - 康威定律》 定律一：组织沟通方式会通过系统设计表达出来，就是说架构的布局和组织结构会有相似。 定律二：时间再多一件事情也不可能做的完美，但总有时间做完一件事情。一口气吃不成胖子，先搞定能搞定的。 定律三：线型系统和线型组织架构间有潜在的异质同态特性。种瓜得瓜，做独立自治的子系统减少沟通成本。 定律四：大的系统组织总是比小系统更倾向于分解。合久必分，分而治之。 《微服务架构核⼼20讲》 运维 &amp; 统计 &amp; 技术支持常规监控 《腾讯业务系统监控的修炼之路》 监控的方式：主动、被动、旁路(比如舆情监控) 监控类型： 基础监控、服务端监控、客户端监控、监控、用户端监控 监控的目标：全、块、准 核心指标：请求量、成功率、耗时 《开源还是商用？十大云运维监控工具横评》 Zabbix、Nagios、Ganglia、Zenoss、Open-falcon、监控宝、 360网站服务监控、阿里云监控、百度云观测、小蜜蜂网站监测等。 《监控报警系统搭建及二次开发经验》 命令行监控工具 《常用命令行监控工具》 top、sar、tsar、nload 《20个命令行工具监控 Linux 系统性能》 《JVM性能调优监控工具jps、jstack、jmap、jhat、jstat、hprof使用详解》 APMAPM — Application Performance Management 《Dapper，大规模分布式系统的跟踪系统》 CNCF OpenTracing，中文版 主要开源软件，按字母排序 Apache SkyWalking CAT CNCF jaeger Pinpoint Zipkin 《开源APM技术选型与实战》 主要基于 Google的Dapper（大规模分布式系统的跟踪系统） 思想。 统计分析 《流量统计的基础：埋点》 常用指标：访问与访客、停留时长、跳出率、退出率、转化率、参与度 《APP埋点常用的统计工具、埋点目标和埋点内容》 第三方统计：友盟、百度移动、魔方、App Annie、talking data、神策数据等。 《美团点评前端无痕埋点实践》 所谓无痕、即通过可视化工具配置采集节点，在前端自动解析配置并上报埋点数据，而非硬编码。 持续集成(CI/CD) 《持续集成是什么？》 《8个流行的持续集成工具》 Jenkins 《使用Jenkins进行持续集成》 环境分离开发、测试、生成环境分离。 《开发环境、生产环境、测试环境的基本理解和区》 自动化运维Ansible 《Ansible中文权威指南》 《Ansible基础配置和企业级项目实用案例》 puppet 《自动化运维工具——puppet详解》 chef 《Chef 的安装与使用》 测试TDD 理论 《深度解读 - TDD（测试驱动开发）》 基于测试用例编码功能代码，XP（Extreme Programming）的核心实践. 好处：一次关注一个点，降低思维负担；迎接需求变化或改善代码的设计；提前澄清需求；快速反馈； 单元测试 《Java单元测试之JUnit篇》 《JUnit 4 与 TestNG 对比》 TestNG 覆盖 JUnit 功能，适用于更复杂的场景。 《单元测试主要的测试功能点》 模块接口测试、局部数据结构测试、路径测试 、错误处理测试、边界条件测试 。 压力测试 《Apache ab 测试使用指南》 《大型网站压力测试及优化方案》 《10大主流压力/负载/性能测试工具推荐》 《真实流量压测工具 tcpcopy应用浅析》 《nGrinder 简易使用教程》 全链路压测 《京东618：升级全链路压测方案，打造军演机器人ForceBot》 《饿了么全链路压测的探索与实践》 《四大语言，八大框架｜滴滴全链路压测解决之道》 《全链路压测经验》 A/B 、灰度、蓝绿测试 《技术干货 | AB 测试和灰度发布探索及实践》 《nginx 根据IP 进行灰度发布》 《蓝绿部署、A/B 测试以及灰度发布》 虚拟化 《VPS的三种虚拟技术OpenVZ、Xen、KVM优缺点比较》 KVM 《KVM详解，太详细太深入了，经典》 《【图文】KVM 虚拟机安装详解》 Xen 《Xen虚拟化基本原理详解》 OpenVZ 《开源Linux容器 OpenVZ 快速上手指南》 容器技术Docker 《几张图帮你理解 docker 基本原理及快速入门》 《Docker 核心技术与实现原理》 《Docker 教程》 云技术OpenStack 《OpenStack构架知识梳理》 DevOps 《一分钟告诉你究竟DevOps是什么鬼？》 《DevOps详解》 文档管理 Confluence-收费文档管理系统 GitLab? Wiki 中间件Web ServerNginx 《Ngnix的基本学习-多进程和Apache的比较》 Nginx 通过异步非阻塞的事件处理机制实现高并发。Apache 每个请求独占一个线程，非常消耗系统资源。 事件驱动适合于IO密集型服务(Nginx)，多进程或线程适合于CPU密集型服务(Apache)，所以Nginx适合做反向代理，而非web服务器使用。 《nginx与Apache的对比以及优缺点》 nginx只适合静态和反向代理，不适合处理动态请求。 OpenResty 官方网站 《浅谈 OpenResty》 通过 Lua 模块可以在Nginx上进行开发。 agentzh 的 Nginx 教程 Tengine 官方网站 Apache Httpd 官方网站 Tomcat架构原理 《TOMCAT原理详解及请求过程》 《Tomcat服务器原理详解》 《Tomcat 系统架构与设计模式,第 1 部分: 工作原理》 《四张图带你了解Tomcat系统架构》 《JBoss vs. Tomcat: Choosing A Java Application Server》 Tomcat 是轻量级的 Serverlet 容器，没有实现全部 JEE 特性（比如持久化和事务处理），但可以通过其他组件代替，比如Spring。 Jboss 实现全部了JEE特性，软件开源免费、文档收费。 调优方案 《Tomcat 调优方案》 启动NIO模式（或者APR）；调整线程池；禁用AJP连接器（Nginx+tomcat的架构，不需要AJP）； 《tomcat http协议与ajp协议》 《AJP与HTTP比较和分析》 AJP 协议（8009端口）用于降低和前端Server（如Apache，而且需要支持AJP协议）的连接数(前端)，通过长连接提高性能。 并发高时，AJP协议优于HTTP协议。 Jetty 《Jetty 的工作原理以及与 Tomcat 的比较》 《jetty和tomcat优势比较》 架构比较:Jetty的架构比Tomcat的更为简单。 性能比较：Jetty和Tomcat性能方面差异不大，Jetty默认采用NIO结束在处理I/O请求上更占优势，Tomcat默认采用BIO处理I/O请求，Tomcat适合处理少数非常繁忙的链接，处理静态资源时性能较差。 其他方面：Jetty的应用更加快速，修改简单，对新的Servlet规范的支持较好;Tomcat 对JEE和Servlet 支持更加全面。 缓存 《缓存失效策略（FIFO 、LRU、LFU三种算法的区别）》 本地缓存 《HashMap本地缓存》 《EhCache本地缓存》 堆内、堆外、磁盘三级缓存。 可按照缓存空间容量进行设置。 按照时间、次数等过期策略。 《Guava Cache》 简单轻量、无堆外、磁盘缓存。 《Nginx本地缓存》 《Pagespeed—懒人工具，服务器端加速》 客户端缓存 《浏览器端缓存》 主要是利用 Cache-Control 参数。 《H5 和移动端 WebView 缓存机制解析与实战》 服务端缓存Web缓存 nuster - nuster cache varnish - varnish cache squid - squid cache Memcached 《Memcached 教程》 《深入理解Memcached原理》 采用多路复用技术提高并发性。 slab分配算法： memcached给Slab分配内存空间，默认是1MB。分配给Slab之后 把slab的切分成大小相同的chunk，Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。 《Memcached软件工作原理》 《Memcache技术分享：介绍、使用、存储、算法、优化、命中率》 《memcache 中 add 、 set 、replace 的区别》 区别在于当key存在还是不存在时，返回值是true和false的。 《memcached全面剖析》 Redis 《Redis 教程》 《redis底层原理》 使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。 使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。 《Redis持久化方式》 RDB方式：定期备份快照，常用于灾难恢复。优点：通过fork出的进程进行备份，不影响主进程、RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。缺点：会丢数据。 AOF方式：保存操作日志方式。优点：恢复时数据丢失少，缺点：文件大，回复慢。 也可以两者结合使用。 《分布式缓存–序列3–原子操作与CAS乐观锁》 架构 《Redis单线程架构》 回收策略 《redis的回收策略》 Tair 官方网站 《Tair和Redis的对比》 特点：可以配置备份节点数目，通过异步同步到备份节点 一致性Hash算法。 架构：和Hadoop 的设计思想类似，有Configserver，DataServer，Configserver 通过心跳来检测，Configserver也有主备关系。 几种存储引擎: MDB，完全内存性，可以用来存储Session等数据。 Rdb（类似于Redis），轻量化，去除了aof之类的操作，支持Restfull操作 LDB（LevelDB存储引擎），持久化存储，LDB 作为rdb的持久化，google实现，比较高效，理论基础是LSM(Log-Structured-Merge Tree)算法，现在内存中修改数据，达到一定量时（和内存汇总的旧数据一同写入磁盘）再写入磁盘，存储更加高效，县比喻Hash算法。 Tair采用共享内存来存储数据，如果服务挂掉（非服务器），重启服务之后，数据亦然还在。 消息队列 《消息队列-推/拉模式学习 &amp; ActiveMQ及JMS学习》 RabbitMQ 消费者默认是推模式（也支持拉模式）。 Kafka 默认是拉模式。 Push方式：优点是可以尽可能快地将消息发送给消费者，缺点是如果消费者处理能力跟不上，消费者的缓冲区可能会溢出。 Pull方式：优点是消费端可以按处理能力进行拉去，缺点是会增加消息延迟。 《Kafka、RabbitMQ、RocketMQ等消息中间件的对比 —— 消息发送性能和区别》 消息总线消息总线相当于在消息队列之上做了一层封装，统一入口，统一管控、简化接入成本。 《消息总线VS消息队列》 消息的顺序 《如何保证消费者接收消息的顺序》 RabbitMQ支持事务，推拉模式都是支持、适合需要可靠性消息传输的场景。 《RabbitMQ的应用场景以及基本原理介绍》 《消息队列之 RabbitMQ》 《RabbitMQ之消息确认机制（事务+Confirm）》 RocketMQJava实现，推拉模式都是支持，吞吐量逊于Kafka。可以保证消息顺序。 《RocketMQ 实战之快速入门》 《RocketMQ 源码解析》 ActiveMQ纯Java实现，兼容JMS，可以内嵌于Java应用中。 《ActiveMQ消息队列介绍》 Kafka高吞吐量、采用拉模式。适合高IO场景，比如日志同步。 官方网站 《各消息队列对比，Kafka深度解析，众人推荐，精彩好文！》 《Kafka分区机制介绍与示例》 Redis 消息推送生产者、消费者模式完全是客户端行为，list 和 拉模式实现，阻塞等待采用 blpop 指令。 《Redis学习笔记之十：Redis用作消息队列》 ZeroMQ TODO 定时调度单机定时调度 《linux定时任务cron配置》 《Linux cron运行原理》 fork 进程 + sleep 轮询 《Quartz使用总结》 《Quartz源码解析 —- 触发器按时启动原理》 《quartz原理揭秘和源码解读》 定时调度在 QuartzSchedulerThread 代码中，while()无限循环，每次循环取出时间将到的trigger，触发对应的job，直到调度器线程被关闭。 分布式定时调度 《这些优秀的国产分布式任务调度系统，你用过几个？》 opencron、LTS、XXL-JOB、Elastic-Job、Uncode-Schedule、Antares 《Quartz任务调度的基本实现原理》 Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的 《Elastic-Job-Lite 源码解析》 《Elastic-Job-Cloud 源码解析》 RPC 《从零开始实现RPC框架 - RPC原理及实现》 核心角色：Server: 暴露服务的服务提供方、Client: 调用远程服务的服务消费方、Registry: 服务注册与发现的注册中心。 《分布式RPC框架性能大比拼 dubbo、motan、rpcx、gRPC、thrift的性能比较》 Dubbo 官方网站 dubbo实现原理简单介绍 ** SPI **TODO Thrift 官方网站 《Thrift RPC详解》 支持多语言，通过中间语言定义接口。 gRPC服务端可以认证加密，在外网环境下，可以保证数据安全。 官方网站 《你应该知道的RPC原理》 数据库中间件Sharding Jdbc 官网 源码解析 日志系统日志搜集 《从零开始搭建一个ELKB日志收集系统》 《用ELK搭建简单的日志收集分析系统》 《日志收集系统-探究》 配置中心 Apollo - 携程开源的配置中心应用 Spring Boot 和 Spring Cloud 支持推、拉模式更新配置 支持多种语言 《基于zookeeper实现统一配置管理》 《 Spring Cloud Config 分布式配置中心使用教程》 servlet 3.0 异步特性可用于配置中心的客户端 《servlet3.0 新特性——异步处理》 API 网关主要职责：请求转发、安全认证、协议转换、容灾。 《API网关那些儿》 《谈API网关的背景、架构以及落地方案》 《使用Zuul构建API Gateway》 《Spring Cloud Gateway 源码解析》 《HTTP API网关选择之一Kong介绍》 网络协议OSI 七层协议 《OSI七层协议模型、TCP/IP四层模型学习笔记》 TCP/IP 《深入浅出 TCP/IP 协议》 《TCP协议中的三次握手和四次挥手》 HTTP 《http协议详解(超详细)》 HTTP2.0 《HTTP 2.0 原理详细分析》 《HTTP2.0的基本单位为二进制帧》 利用二进制帧负责传输。 多路复用。 HTTPS 《https原理通俗了解》 使用非对称加密协商加密算法 使用对称加密方式传输数据 使用第三方机构签发的证书，来加密公钥，用于公钥的安全传输、防止被中间人串改。 《八大免费SSL证书-给你的网站免费添加Https安全加密》 网络模型 《web优化必须了解的原理之I/o的五种模型和web的三种工作模式》 五种I/O模型：阻塞I/O，非阻塞I/O，I/O复用、事件(信号)驱动I/O、异步I/O，前四种I/O属于同步操作，I/O的第一阶段不同、第二阶段相同，最后的一种则属于异步操作。 三种 Web Server 工作方式：Prefork(多进程)、Worker方式(线程方式)、Event方式。 《select、poll、epoll之间的区别总结》 select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。 select 有打开文件描述符数量限制，默认1024（2048 for x64），100万并发，就要用1000个进程、切换开销大；poll采用链表结构，没有数量限制。 select，poll “醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，通过回调机制节省大量CPU时间；select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，而epoll只要一次拷贝。 poll会随着并发增加，性能逐渐下降，epoll采用红黑树结构，性能稳定，不会随着连接数增加而降低。 《select，poll，epoll比较 》 在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 《深入理解Java NIO》 NIO 是一种同步非阻塞的 IO 模型。同步是指线程不断轮询 IO 事件是否就绪，非阻塞是指线程在等待 IO 的时候，可以同时做其他任务 《BIO与NIO、AIO的区别》 《两种高效的服务器设计模型：Reactor和Proactor模型》 Epoll 《epoll使用详解（精髓）》 Java NIO 《深入理解Java NIO》 《Java NIO编写Socket服务器的一个例子》 kqueue 《kqueue用法简介》 连接和短连接 《TCP/IP系列——长连接与短连接的区别》 框架 《Netty原理剖析》 Reactor 模式介绍。 Netty 是 Reactor 模式的一种实现。 零拷贝（Zero-copy） 《对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解》 多个物理分离的buffer，通过逻辑上合并成为一个，从而避免了数据在内存之间的拷贝。 序列化(二进制协议)Hessian 《Hessian原理分析》Binary-RPC;不仅仅是序列化 Protobuf 《Protobuf协议的Java应用例子》Goolge出品、占用空间和效率完胜其他序列化类库，如Hessian；需要编写 .proto 文件。 《Protocol Buffers序列化协议及应用》 * 关于协议的解释；缺点：可读性差; 《简单的使用 protobuf 和 protostuff》 protostuff 的好处是不用写 .proto 文件，Java 对象直接就可以序列化。 数据库基础理论数据库设计的三大范式 《数据库的三大范式以及五大约束》 第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性； 第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情； 第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）； MySQL原理 《MySQL的InnoDB索引原理详解》 《MySQL存储引擎－－MyISAM与InnoDB区别》 两种类型最主要的差别就是Innodb 支持事务处理与外键和行级锁 《myisam和innodb索引实现的不同》 InnoDB 《一篇文章带你读懂Mysql和InnoDB》 优化 《MySQL36条军规》 《MYSQL性能优化的最佳20+条经验》 《SQL优化之道》 《mysql数据库死锁的产生原因及解决办法》 《导致索引失效的可能情况》 《 MYSQL分页limit速度太慢优化方法》 原则上就是缩小扫描范围。 索引聚集索引, 非聚集索引 《MySQL 聚集索引/非聚集索引简述》 《MyISAM和InnoDB的索引实现》 MyISAM 是非聚集，InnoDB 是聚集 复合索引 《复合索引的优点和注意事项》 文中有一处错误： 对于复合索引,在查询使用时,最好将条件顺序按找索引的顺序,这样效率最高; select * from table1 where col1=A AND col2=B AND col3=D 如果使用 where col2=B AND col1=A 或者 where col2=B 将不会使用索引 原文中提到索引是按照“col1，col2，col3”的顺序创建的，而mysql在按照最左前缀的索引匹配原则，且会自动优化 where 条件的顺序，当条件中只有 col2=B AND col1=A 时，会自动转化为 col1=A AND col2=B，所以依然会使用索引。 《MySQL查询where条件的顺序对查询效率的影响》 自适应哈希索引(AHI) 《InnoDB存储引擎——自适应哈希索引》 explain 《MySQL 性能优化神器 Explain 使用分析》 NoSQLMongoDB MongoDB 教程 《Mongodb相对于关系型数据库的优缺点》 优点：弱一致性（最终一致），更能保证用户的访问速度；内置GridFS，支持大容量的存储；Schema-less 数据库，不用预先定义结构；内置Sharding；相比于其他NoSQL，第三方支持丰富；性能优越； 缺点：mongodb不支持事务操作；mongodb占用空间过大；MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方； Hbase 《简明 HBase 入门教程（开篇）》 《深入学习HBase架构原理》 《传统的行存储和（HBase）列存储的区别》 《Hbase与传统数据库的区别》 空数据不存储，节省空间，且适用于并发。 《HBase Rowkey设计》 rowkey 按照字典顺序排列，便于批量扫描。 通过散列可以避免热点。 搜索引擎搜索引擎原理 《倒排索引–搜索引擎入门》 Lucene 《Lucene入门简介》 Elasticsearch 《Elasticsearch学习，请先看这一篇！》 《Elasticsearch索引原理》 Solr 《 Apache Solr入门教程》 《elasticsearch与solr比较》 sphinx 《Sphinx 的介绍和原理探索》 性能性能优化方法论 《15天的性能优化工作，5方面的调优经验》 代码层面、业务层面、数据库层面、服务器层面、前端优化。 《系统性能优化的几个方面》 容量评估 《联网性能与容量评估的方法论和典型案例》 《互联网架构，如何进行容量设计？》 评估总访问量、评估平均访问量QPS、评估高峰QPS、评估系统、单机极限QPS CDN 网络 《CDN加速原理》 《国内有哪些比较好的 CDN？》 连接池 《主流Java数据库连接池比较与开发配置实战》 性能调优 《九大Java性能调试工具，必备至少一款》 大数据流式计算Storm 官方网站 《最详细的Storm入门教程》 Flink 《Flink之一 Flink基本原理介绍》 Kafka Stream 《Kafka Stream调研：一种轻量级流计算模式》 应用场景例如： 广告相关实时统计； 推荐系统用户画像标签实时更新； 线上服务健康状况实时监测； 实时榜单； 实时数据统计。 Hadoop 《用通俗易懂的话说下hadoop是什么,能做什么》 《史上最详细的Hadoop环境搭建》 HDFS 《【Hadoop学习】HDFS基本原理》 MapReduce 《用通俗易懂的大白话讲解Map/Reduce原理》 《 简单的map-reduce的java例子》 Yarn 《初步掌握Yarn的架构及原理》 Spark 《Spark(一): 基本架构及原理》 安全web 安全XSS 《xss攻击原理与解决方法》CSRF 《CSRF原理及防范》 SQL 注入 《SQL注入》 Hash Dos 《邪恶的JAVA HASH DOS攻击》 利用JsonObject 上传大Json，JsonObject 底层使用HashMap；不同的数据产生相同的hash值，使得构建Hash速度变慢，耗尽CPU。 《一种高级的DoS攻击-Hash碰撞攻击》 《关于Hash Collision DoS漏洞：解析与解决方案》 脚本注入 《上传文件漏洞原理及防范》 漏洞扫描工具 《DVWA》 W3af OpenVAS详解 验证码 《验证码原理分析及实现》 《详解滑动验证码的实现原理》 滑动验证码是根据人在滑动滑块的响应时间，拖拽速度，时间，位置，轨迹，重试次数等来评估风险。 《淘宝滑动验证码研究》 DDoS 防范 《学习手册：DDoS的攻击方式及防御手段》 《免费DDoS攻击测试工具大合集》 用户隐私信息保护 用户密码非明文保存，加动态salt。 身份证号，手机号如果要显示，用 “*” 替代部分字符。 联系方式在的显示与否由用户自己控制。 TODO 《个人隐私包括哪些》 《在互联网上，隐私的范围包括哪些？》 《用户密码保存》 序列化漏洞 《Lib之过？Java反序列化漏洞通用利用分析》 加密解密对称加密 《常见对称加密算法》 DES、3DES、Blowfish、AES DES 采用 56位秘钥，Blowfish 采用1到448位变长秘钥，AES 128，192和256位长度的秘钥。 DES 秘钥太短（只有56位）算法目前已经被 AES 取代，并且 AES 有硬件加速，性能很好。 哈希算法 《常用的哈希算法》 MD5 和 SHA-1 已经不再安全，已被弃用。 目前 SHA-256 是比较安全的。 《基于Hash摘要签名的公网URL签名验证设计方案》 非对称加密 《常见非对称加密算法》 RSA、DSA、ECDSA(螺旋曲线加密算法) 和 RSA 不同的是 DSA 仅能用于数字签名，不能进行数据加密解密，其安全性和RSA相当，但其性能要比RSA快。 256位的ECC秘钥的安全性等同于3072位的RSA秘钥。 《区块链的加密技术》 服务器安全 《Linux强化论：15步打造一个安全的Linux服务器》 数据安全数据备份TODO 网络隔离内外网分离TODO 登录跳板机在内外环境中通过跳板机登录到线上主机。 《搭建简易堡垒机》 授权、认证RBAC 《基于组织角色的权限设计》 《权限系统与RBAC模型概述》 《Spring整合Shiro做权限控制模块详细案例分析》 OAuth2.0 《理解OAuth 2.0》 《一张图搞定OAuth2.0》 双因素认证（2FA）2FA - Two-factor authentication，用于加强登录验证 常用做法是 登录密码 + 手机验证码（或者令牌Key，类似于与网银的 USB key） 【《双因素认证（2FA）教程》】(http://www.ruanyifeng.com/blog/2017/11/2fa-tutorial.html) 单点登录(SSO) 《单点登录原理与简单实现》 CAS单点登录框架 常用开源框架开源协议 《开源协议的选择》 如何选择一个开源软件协议 日志框架Log4j、Log4j2 《log4j 详细讲解》 《log4j2 实际使用详解》 《Log4j1,Logback以及Log4j2性能测试对比》 Log4J 异步日志性能优异。 Logback 《最全LogBack 详解、含java案例和配置说明》 ORM 《ORM框架使用优缺点》 主要目的是为了提高开发效率。 MyBatis： 《mybatis缓存机制详解》 一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效 二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的；使用 LRU 机制清理缓存，通过 cacheEnabled 参数开启。 《MyBatis学习之代码生成器Generator》 网络框架TODO Web 框架Spring 家族Spring Spring 简明教程 Spring Boot 官方网站 《Spring Boot基础教程》 Spring Cloud Spring Boot 中文索引站 Spring Cloud 中文文档 《Spring Cloud基础教程》 工具框架 《Apache Commons 工具类介绍及简单使用》 《Google guava 中文教程》 分布式设计扩展性设计 《架构师不可不知的十大可扩展架构》 总结下来，通用的套路就是分布、缓存及异步处理。 《可扩展性设计之数据切分》 水平切分+垂直切分 利用中间件进行分片如，MySQL Proxy。 利用分片策略进行切分，如按照ID取模。 《说说如何实现可扩展性的大型网站架构》 分布式服务+消息队列。 《大型网站技术架构（七）–网站的可扩展性架构》 稳定性 &amp; 高可用 《系统设计：关于高可用系统的一些技术方案》 可扩展：水平扩展、垂直扩展。 通过冗余部署，避免单点故障。 隔离：避免单一业务占用全部资源。避免业务之间的相互影响 2. 机房隔离避免单点故障。 解耦：降低维护成本，降低耦合风险。减少依赖，减少相互间的影响。 限流：滑动窗口计数法、漏桶算法、令牌桶算法等算法。遇到突发流量时，保证系统稳定。 降级：紧急情况下释放非核心功能的资源。牺牲非核心业务，保证核心业务的高可用。 熔断：异常情况超出阈值进入熔断状态，快速失败。减少不稳定的外部依赖对核心服务的影响。 自动化测试：通过完善的测试，减少发布引起的故障。 灰度发布：灰度发布是速度与安全性作为妥协，能够有效减少发布故障。 《关于高可用的系统》 设计原则：数据不丢(持久化)；服务高可用(服务副本)；绝对的100%高可用很难，目标是做到尽可能多的9，如99.999%（全年累计只有5分钟）。 硬件负载均衡 《转！！负载均衡器技术Nginx和F5的优缺点对比》 主要是和F5对比。 《软/硬件负载均衡产品 你知多少？》 软件负载均衡 《几种负载均衡算法》 轮寻、权重、负载、最少连接、QoS 《DNS负载均衡》 配置简单，更新速度慢。 《Nginx负载均衡》 简单轻量、学习成本低；主要适用于web应用。 《借助LVS+Keepalived实现负载均衡 》 配置比较负载、只支持到4层，性能较高。 《HAProxy用法详解 全网最详细中文文档》 支持到七层（比如HTTP）、功能比较全面，性能也不错。 《Haproxy+Keepalived+MySQL实现读均衡负载》 主要是用户读请求的负载均衡。 《rabbitmq+haproxy+keepalived实现高可用集群搭建》 限流 《谈谈高并发系统的限流》 计数器：通过滑动窗口计数器，控制单位时间内的请求次数，简单粗暴。 漏桶算法：固定容量的漏桶，漏桶满了就丢弃请求，比较常用。 令牌桶算法：固定容量的令牌桶，按照一定速率添加令牌，处理请求前需要拿到令牌，拿不到令牌则丢弃请求，或进入丢队列，可以通过控制添加令牌的速率，来控制整体速度。Guava 中的 RateLimiter 是令牌桶的实现。 Nginx 限流：通过 limit_req 等模块限制并发连接数。 应用层容灾 《防雪崩利器：熔断器 Hystrix 的原理与使用》 雪崩效应原因：硬件故障、硬件故障、程序Bug、重试加大流量、用户大量请求。 雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。 Hystrix设计原则： 资源隔离：Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩。 熔断开关：服务的健康状况 = 请求失败数 / 请求总数，通过阈值设定和滑动窗口控制开关。 命令模式：通过继承 HystrixCommand 来包装服务调用逻辑。 《缓存穿透，缓存击穿，缓存雪崩解决方案分析》 《缓存击穿、失效以及热点key问题》 主要策略：失效瞬间：单机使用锁；使用分布式锁；不过期； 热点数据：热点数据单独存储；使用本地缓存；分成多个子key； 跨机房容灾 《“异地多活”多机房部署经验谈》 通过自研中间件进行数据同步。 《异地多活（异地双活）实践经验》 注意延迟问题，多次跨机房调用会将延时放大数倍。 建房间专线很大概率会出现问题，做好运维和程序层面的容错。 不能依赖于程序端数据双写，要有自动同步方案。 数据永不在高延迟和较差网络质量下，考虑同步质量问题。 核心业务和次要业务分而治之，甚至只考虑核心业务。 异地多活监控部署、测试也要跟上。 业务允许的情况下考虑用户分区，尤其是游戏、邮箱业务。 控制跨机房消息体大小，越小越好。 考虑使用docker容器虚拟化技术，提高动态调度能力。 容灾技术及建设经验介绍 容灾演练流程 《依赖治理、灰度发布、故障演练，阿里电商故障演练系统的设计与实战经验》 常见故障画像 案例：预案有效性、预案有效性、故障复现、架构容灾测试、参数调优、参数调优、故障突袭、联合演练。 平滑启动 平滑重启应用思路 1.端流量（如vip层）、2. flush 数据(如果有)、3, 重启应用 《JVM安全退出（如何优雅的关闭java服务）》推荐推出方式：System.exit，Kill SIGTERM；不推荐 kill-9；用 Runtime.addShutdownHook 注册钩子。 《常见Java应用如何优雅关闭》Java、Spring、Dubbo 优雅关闭方式。 数据库扩展读写分离模式 《Mysql主从方案的实现》 《搭建MySQL主从复制经典架构》 《Haproxy+多台MySQL从服务器(Slave) 实现负载均衡》 《DRBD+Heartbeat+Mysql高可用读写分离架构》 DRDB 进行磁盘复制，避免单点问题。 《MySQL Cluster 方式》 分片模式 《分库分表需要考虑的问题及方案》 中间件： 轻量级：sharding-jdbc、TSharding；重量级：Atlas、MyCAT、Vitess等。 问题：事务、Join、迁移、扩容、ID、分页等。 事务补偿：对数据进行对帐检查;基于日志进行比对;定期同标准数据来源进行同步等。 分库策略：数值范围；取模；日期等。 分库数量：通常 MySQL 单库 5千万条、Oracle 单库一亿条需要分库。 《MySql分表和表分区详解》 分区：是MySQL内部机制，对客户端透明，数据存储在不同文件中，表面上看是同一个表。 分表：物理上创建不同的表、客户端需要管理分表路由。 服务治理服务注册与发现 《永不失联！如何实现微服务架构中的服务发现？》 客户端服务发现模式：客户端直接查询注册表，同时自己负责负载均衡。Eureka 采用这种方式。 服务器端服务发现模式：客户端通过负载均衡查询服务实例。 《SpringCloud服务注册中心比较:Consul vs Zookeeper vs Etcd vs Eureka》 CAP支持：Consul（CA）、zookeeper（cp）、etcd（cp） 、euerka（ap） 作者认为目前 Consul 对 Spring cloud 的支持比较好。 《基于Zookeeper的服务注册与发现》 优点：API简单、Pinterest，Airbnb 在用、多语言、通过watcher机制来实现配置PUSH，能快速响应配置变化。 服务路由控制 《分布式服务框架学习笔记4 服务路由》 原则：透明化路由 负载均衡策略：随机、轮询、服务调用延迟、一致性哈希、粘滞连接 本地路由有限策略：injvm(优先调用jvm内部的服务)，innative(优先使用相同物理机的服务),原则上找距离最近的服务。 配置方式：统一注册表；本地配置；动态下发。 分布式一致CAP 与 BASE 理论 《从分布式一致性谈到CAP理论、BASE理论》 一致性分类：强一致(立即一致)；弱一致(可在单位时间内实现一致，比如秒级)；最终一致(弱一致的一种，一定时间内最终一致) CAP：一致性、可用性、分区容错性(网络故障引起) BASE：Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性） BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 分布式锁 《分布式锁的几种实现方式》 基于数据库的分布式锁：优点：操作简单、容易理解。缺点：存在单点问题、数据库性能够开销较大、不可重入； 基于缓存的分布式锁：优点：非阻塞、性能好。缺点：操作不好容易造成锁无法释放的情况。 Zookeeper 分布式锁：通过有序临时节点实现锁机制，自己对应的节点需要最小，则被认为是获得了锁。优点：集群可以透明解决单点问题，避免锁不被释放问题，同时锁可以重入。缺点：性能不如缓存方式，吞吐量会随着zk集群规模变大而下降。 《基于Zookeeper的分布式锁》 清楚的原理描述 + Java 代码示例。 《jedisLock—redis分布式锁实现》 基于 setnx(set if ont exists)，有则返回false，否则返回true。并支持过期时间。 《Memcached 和 Redis 分布式锁方案》 利用 memcached 的 add（有别于set）操作，当key存在时，返回false。 分布式一致性算法PAXOS 《分布式系列文章——Paxos算法原理与推导》 《Paxos–&gt;Fast Paxos–&gt;Zookeeper分析》 《【分布式】Zookeeper与Paxos》 Zab 《Zab：Zookeeper 中的分布式一致性协议介绍》 Raft 《Raft 为什么是更易理解的分布式一致性算法》 三种角色：Leader（领袖）、Follower（群众）、Candidate（候选人） 通过随机等待的方式发出投票，得票多的获胜。 Gossip 《Gossip算法》 两阶段提交、多阶段提交 《关于分布式事务、两阶段提交协议、三阶提交协议》 幂等 《分布式系统—幂等性设计》 幂等特性的作用：该资源具备幂等性，请求方无需担心重复调用会产生错误。 常见保证幂等的手段：MVCC（类似于乐观锁）、去重表(唯一索引)、悲观锁、一次性token、序列号方式。 分布式一致方案 《分布式系统事务一致性解决方案》 《保证分布式系统数据一致性的6种方案》 分布式 Leader 节点选举 《利用zookeeper实现分布式leader节点选举》 TCC(Try/Confirm/Cancel) 柔性事务 《传统事务与柔性事务》 基于BASE理论：基本可用、柔性状态、最终一致。 解决方案：记录日志+补偿（正向补充或者回滚）、消息重试(要求程序要幂等)；“无锁设计”、采用乐观锁机制。 分布式文件系统 说说分布式文件存储系统-基本架构 ？ 《各种分布式文件系统的比较》 ？ HDFS：大批量数据读写，用于高吞吐量的场景，不适合小文件。 FastDFS：轻量级、适合小文件。 唯一ID 生成全局唯一ID 《高并发分布式系统中生成全局唯一Id汇总》 Twitter 方案（Snowflake 算法）：41位时间戳+10位机器标识（比如IP，服务器名称等）+12位序列号(本地计数器) Flicker 方案：MySQL自增ID + “REPLACE INTO XXX:SELECT LAST_INSERT_ID();” UUID：缺点，无序，字符串过长，占用空间，影响检索性能。 MongoDB 方案：利用 ObjectId。缺点：不能自增。 《TDDL 在分布式下的SEQUENCE原理》 在数据库中创建 sequence 表，用于记录，当前已被占用的id最大值。 每台客户端主机取一个id区间（比如 1000~2000）缓存在本地，并更新 sequence 表中的id最大值记录。 客户端主机之间取不同的id区间，用完再取，使用乐观锁机制控制并发。 一致性Hash算法 《一致性哈希算法》 设计思想 &amp; 开发模式DDD(Domain-driven Design - 领域驱动设计) 《浅谈我对DDD领域驱动设计的理解》 概念：DDD 主要对传统软件开发流程(分析-设计-编码)中各阶段的割裂问题而提出，避免由于一开始分析不明或在软件开发过程中的信息流转不一致而造成软件无法交付（和需求方设想不一致）的问题。DDD 强调一切以领域（Domain）为中心，强调领域专家（Domain Expert）的作用，强调先定义好领域模型之后在进行开发，并且领域模型可以指导开发（所谓的驱动）。 过程：理解领域、拆分领域、细化领域，模型的准确性取决于模型的理解深度。 设计：DDD 中提出了建模工具，比如聚合、实体、值对象、工厂、仓储、领域服务、领域事件来帮助领域建模。 《领域驱动设计的基础知识总结》 领域（Doamin）本质上就是问题域，比如一个电商系统，一个论坛系统等。 界限上下文（Bounded Context）：阐述子域之间的关系，可以简单理解成一个子系统或组件模块。 领域模型（Domain Model）：DDD的核心是建立（用通用描述语言、工具—领域通用语言）正确的领域模型；反应业务需求的本质，包括实体和过程；其贯穿软件分析、设计、开发 的整个过程；常用表达领域模型的方式：图、代码或文字； 领域通用语言：领域专家、开发设计人员都能立即的语言或工具。 经典分层架构：用户界面/展示层、应用层、领域层、基础设施层，是四层架构模式。 使用的模式： 关联尽量少，尽量单项，尽量降低整体复杂度。 实体（Entity）：领域中的唯一标示，一个实体的属性尽量少，少则清晰。 值对象（Value Object）：没有唯一标识，且属性值不可变，小二简单的对象，比如Date。 领域服务（Domain Service）： 协调多个领域对象，只有方法没有状态(不存数据)；可以分为应用层服务，领域层服务、基础层服务。 聚合及聚合根（Aggregate，Aggregate Root）：聚合定义了一组具有内聚关系的相关对象的集合；聚合根是对聚合引用的唯一元素；当修改一个聚合时，必须在事务级别；大部分领域模型中，有70%的聚合通常只有一个实体，30%只有2~3个实体；如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，那么我们可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互； 工厂（Factory）：类似于设计模式中的工厂模式。 仓储（Repository）：持久化到DB，管理对象，且只对聚合设计仓储。 《领域驱动设计(DDD)实现之路》 聚合：比如一辆汽车（Car）包含了引擎（Engine）、车轮（Wheel）和油箱（Tank）等组件，缺一不可。 《领域驱动设计系列（2）浅析VO、DTO、DO、PO的概念、区别和用处》 命令查询职责分离(CQRS)CQRS — Command Query Responsibility Seperation 《领域驱动设计系列 (六)：CQRS》 核心思想：读写分离（查询和更新在不同的方法中），不同的流程只是不同的设计方式，CQ代码分离，分布式环境中会有明显体现（有冗余数据的情况下），目的是为了高性能。 《DDD CQRS架构和传统架构的优缺点比较》 最终一致的设计理念；依赖于高可用消息中间件。 《CQRS架构简介》 一个实现 CQRS 的抽象案例。 《深度长文：我对CQRS/EventSourcing架构的思考》 CQRS 模式分析 + 12306 抢票案例 贫血，充血模型 《贫血，充血模型的解释以及一些经验》 失血模型：老子和儿子分别定义，相互不知道，二者实体定义中完全没有业务逻辑，通过外部Service进行关联。 贫血模型：老子知道儿子，儿子也知道老子；部分业务逻辑放到实体中；优点：各层单项依赖，结构清楚，易于维护；缺点：不符合OO思想，相比于充血模式，Service层较为厚重； 充血模型：和贫血模型类似，区别在于如何划分业务逻辑。优点：Service层比较薄，只充当Facade的角色，不和DAO打交道、复合OO思想；缺点：非单项依赖，DO和DAO之间双向依赖、和Service层的逻辑划分容易造成混乱。 肿胀模式：是一种极端情况，取消Service层、全部业务逻辑放在DO中；优点：符合OO思想、简化了分层；缺点：暴露信息过多、很多非DO逻辑也会强行并入DO。这种模式应该避免。 作者主张使用贫血模式。 Actor 模式TODO 响应式编程ReactorTODO RxJavaTODO Vert.xTODO DODAF2.0 《DODAF2.0方法论》 《DODAF2.0之能力视角如何落地》 Serverless无需过多关系服务器的服务架构理念。 《什么是Serverless无服务器架构？》 Serverless 不代表出去服务器，而是去除对服务器运行状态的关心。 Serverless 代表一思维方式的转变，从“构建一套服务在一台服务器上，对对个事件进行响应转变为构建一个为服务器，来响应一个事件”。 Serverless 不代表某个具体的框架。 《如何理解Serverless？》 依赖于 Baas （(Mobile) Backend as a Service） 和 Faas （Functions as a service） Service Mesh 《什么是Service Mesh？》 《初识 Service Mesh》 项目管理架构评审 《架构设计之如何评审架构设计说明书》 《人人都是架构师：非功能性需求》 重构 《架构之重构的12条军规》 代码规范 《阿里巴巴Java开发手册》 代码 Review制度还是制度!另外，每个公司需要根据自己的需求和目标制定自己的 check list 《为什么你做不好 Code Review？》 代码 review 做的好，在于制度建设。 《从零开始Code Review》 《Code Review Checklist》 《Java Code Review Checklist》 《如何用 gitlab 做 code review》 RUP 《运用RUP 4+1视图方法进行软件架构设计》 看板管理 《说说看板在项目中的应用》 SCRUMSCRUM - 争球 3个角色:Product Owner(PO) 产品负责人;Scrum Master（SM），推动Scrum执行;Team 开发团队。 3个工件：Product Backlog 产品TODOLIST，含优先级;Sprint Backlog 功能开发 TODO LIST；燃尽图； 五个价值观：专注、勇气、公开、承诺、尊重。 《敏捷项目管理流程-Scrum框架最全总结！》 《敏捷其实很简单3—敏捷方法之scrum》 敏捷开发TODO 极限编程（XP）XP - eXtreme Programming 《主流敏捷开发方法：极限编程XP》 是一种指导开发人员的方法论。 4大价值： 沟通：鼓励口头沟通，提高效率。 简单：够用就好。 反馈：及时反馈、通知相关人。 勇气：提倡拥抱变化，敢于重构。 5个原则：快速反馈、简单性假设、逐步修改、提倡更改（小步快跑）、优质工作（保证质量的前提下保证小步快跑）。 5个工作：阶段性冲刺；冲刺计划会议；每日站立会议；冲刺后review；回顾会议。 结对编程边写码，边review。能够增强代码质量、减少bug。 《结对编程》 PDCA 循环质量管理P——PLAN 策划，D——DO 实施，C——CHECK 检查，A——ACT 改进 《PDCA》 FMEA管理模式TODO 通用业务术语TODO 技术趋势TODO 政策、法规TODO 法律严格遵守刑法253法条我国刑法第253条之一规定： 国家机关或者金融、电信、交通、教育、医疗等单位的工作人员，违反国家规定，将本单位在履行职责或者提供服务过程中获得的公民个人信息，出售或者非法提供给他人，情节严重的，处3年以下有期徒刑或者拘役，并处或者单处罚金。 窃取或者以其他方法非法获取上述信息，情节严重的，依照前款的规定处罚。 单位犯前两款罪的，对单位判处罚金，并对其直接负责的主管人员和其他直接责任人员，依照各该款的规定处罚。 最高人民法院、最高人民检察院关于执行《中华人民共和国刑法》确定罪名的补充规定（四）规定：触犯刑法第253条之一第1款之规定，构成“出售、非法提供公民个人信息罪”；触犯刑法第253条之一第2款之规定，构成“非法获取公民个人信息罪” 《非法获取公民个人信息罪》 架构师素质 《架构师画像》 业务理解和抽象能力 NB的代码能力 全面：1. 在面对业务问题上，架构师脑海里是否会浮现出多种技术方案；2. 在做系统设计时是否考虑到了足够多的方方面面；3. 在做系统设计时是否考虑到了足够多的方方面面； 全局：是否考虑到了对上下游的系统的影响。 权衡：权衡投入产出比；优先级和节奏控制； 《关于架构优化和设计，架构师必须知道的事情》 要去考虑的细节：模块化、轻耦合、无共享架构；减少各个组件之前的依赖、注意服务之间依赖所有造成的链式失败及影响等。 基础设施、配置、测试、开发、运维综合考虑。 考虑人、团队、和组织的影响。 《如何才能真正的提高自己，成为一名出色的架构师？》 《架构师的必备素质和成长途径》 素质：业务理解、技术广度、技术深度、丰富经验、沟通能力、动手能力、美学素养。 成长路径：2年积累知识、4年积累技能和组内影响力、7年积累部门内影响力、7年以上积累跨部门影响力。 《架构设计师—你在哪层楼？》 第一层的架构师看到的只是产品本身 第二层的架构师不仅看到自己的产品，还看到了整体的方案 第三层的架构师看到的是商业价值 团队管理TODO 招聘资讯行业资讯 36kr Techweb 公众号列表TODO 博客团队博客 阿里中间件博客 美团点评技术团队博客 个人博客 阮一峰的网络日志 酷壳 - COOLSHELL-陈皓 hellojava-阿里毕玄 Cm’s Blog 程序猿DD-翟永超-《Spring Cloud微服务实战》作者 综合门户、社区国内： CSDN 老牌技术社区、不必解释。 51cto.com ITeye 偏 Java 方向 博客园 ChinaUnix 偏 Linux 方向 开源中国社区 深度开源 伯乐在线 涵盖 IT职场、Web前端、后端、移动端、数据库等方面内容，偏技术端。 ITPUB 腾讯云— 云+社区 阿里云— 云栖社区 IBM DeveloperWorks 开发者头条 LinkedKeeper 国外： DZone Reddit 问答、讨论类社区 segmentfault 问答+专栏 知乎 stackoverflow 行业数据分析 艾瑞网 QUEST MOBILE 国家数据 TalkingData 专项网站 测试: 领测国际 测试窝 TesterHome 运维: * [运维派](http://www.yunweipai.com/) * [Abcdocker](https://www.abcdocker.com/) Java: ImportNew 专注于 Java 技术分享 HowToDoInJava 英文博客 安全 红黑联盟 FreeBuf 大数据 中国大数据 其他专题网站： InfoQ 偏重于基础架构、运维方向 DockerInfo 专注于 Docker 应用及咨询、教程的网站 Linux公社 Linux 主题社区 其他类 程序员技能图谱 推荐参考书在线电子书 《深入理解Spring Cloud与微服务构建》 《阿里技术参考图册-研发篇》 《阿里技术参考图册-算法篇》 《2018美团点评技术年货（合辑）》70M InfoQ《架构师》月刊 《架构师之路》 纸质书开发方面 《阿里巴巴Java开发手册》详情 架构方面 《软件架构师的12项修炼：技术技能篇》详情 《架构之美》详情 《分布式服务架构》详情 《聊聊架构》 详情 《云原生应用架构实践》详情 《亿级流量网站架构核心技术》详情 《淘宝技术这十年》详情 《企业IT架构转型之道-中台战略思想与架构实战》 详情 《高可用架构（第1卷）》详情 技术管理方面 《CTO说》详情 《技术管理之巅》详情 《网易一千零一夜：互联网产品项目管理实战》详情 基础理论 《数学之美》详情 《编程珠玑》详情 工具方面TODO 大数据方面技术资源开源资源 github Apache 软件基金会 手册、文档、教程国内： W3Cschool Runoob.com HTML 、 CSS、XML、Java、Python、PHP、设计模式等入门手册。 Love2.io 很多很多中文在线电子书，是一个全新的开源技术文档分享平台。 gitbook.cn 付费电子书。 ApacheCN AI、大数据方面系列中文文档。 国外： Quick Code 免费在线技术教程。 gitbook.com 有部分中文电子书。 Cheatography Cheat Sheets 大全，单页文档网站。 Tutorialspoint 知名教程网站，提供Java、Python、JS、SQL、大数据等高质量入门教程。 在线课堂 学徒无忧 极客时间 segmentfault 斯达克学院 牛客网 极客学院 51CTO学院 会议、活动 QCon ArchSummit GITC全球互联网技术大会 活动发布平台: 活动行 常用APP 极客时间 得到 找工作 Boss直聘 拉勾网 猎聘 100Offer 工具 极客搜索 技术文章搜索引擎。 代码托管 Coding 码云 文件服务 七牛 又拍云 综合云服务商 阿里云 腾讯云 百度云 新浪云 金山云 亚马逊云(AWS) 谷歌云 微软云 VPS Linode DigitalOcean Vultr"},{"title":"","date":"2020-06-19T03:21:26.567Z","updated":"2020-06-19T03:21:26.567Z","comments":true,"path":"resources/highlight/github.css","permalink":"https://liuzhihang.com/resources/highlight/github.css","excerpt":"","text":"/* 代碼框背景色和字體顔色,與hljs一樣就行 */ /* 必須配置(把下面.hljs的color和background複製到這裏來) */ #article-container pre, #article-container figure.highlight { color: #333; background: #f8f8f8; } /* 代碼框工具欄 (如果你關掉了copy、lang和shrink,可不用配置這個 */ #article-container figure.highlight .highlight-tools { color: #333; background: #f8f8f8; } /* 代碼框行數(如果已經關掉line_number,可以不用配置這個) */ /*#article-container figure.highlight .gutter pre {*/ /* background-color: xxx;*/ /* color: xxx*/ /*}*/ /* 代碼塊figcaption配置(hexo自帶標簽https://hexo.io/zh-tw/docs/tag-plugins.html#Code-Block) */ /* 不需要可以不用配置這個 */ /*#article-container figure.highlight figcaption a {*/ /* color: xxx !important*/ /*}*/ /* github.com style (c) Vasily Polovnyov */ #article-container figure.highlight .hljs { display: block; overflow-x: auto; padding: 0.5em; color: #333; background: #f8f8f8; } .hljs-comment, .hljs-quote { color: #998; font-style: italic; } .hljs-keyword, .hljs-selector-tag, .hljs-subst { color: #333; font-weight: bold; } .hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr { color: #008080; } .hljs-string, .hljs-doctag { color: #d14; } .hljs-title, .hljs-section, .hljs-selector-id { color: #900; font-weight: bold; } .hljs-subst { font-weight: normal; } .hljs-type, .hljs-class .hljs-title { color: #458; font-weight: bold; } .hljs-tag, .hljs-name, .hljs-attribute { color: #000080; font-weight: normal; } .hljs-regexp, .hljs-link { color: #009926; } .hljs-symbol, .hljs-bullet { color: #990073; } .hljs-built_in, .hljs-builtin-name { color: #0086b3; } .hljs-meta { color: #999; font-weight: bold; } .hljs-deletion { background: #fdd; } .hljs-addition { background: #dfd; } .hljs-emphasis { font-style: italic; } .hljs-strong { font-weight: bold; }"},{"title":"","date":"2019-12-23T06:35:09.080Z","updated":"2019-09-08T10:04:27.884Z","comments":true,"path":"resources/js/generator.js","permalink":"https://liuzhihang.com/resources/js/generator.js","excerpt":"","text":"function generator(locals) { var comparer, extractName, fileUtil, generateCategoriesJson, generatePostsJson, generateTagsJson, pathUtil; pathUtil = require('path'); generatePostsJson = function(posts) { var postsMeta; postsMeta = { posts: posts.map(function(post) { return { title: post.title, url: encodeURI(post.permalink), date: post.updated.toDate().toISOString() || post.date.toDate().toISOString() }; }) }; return { path: 'posts.json', data: JSON.stringify(postsMeta) }; }; comparer = function(a, b) { return b.length - a.length; }; extractName = function(obj) { return obj.name; }; generateCategoriesJson = function(categories) { var categoriesMeta; categoriesMeta = { categories: categories.sort(comparer).map(extractName) }; return { path: 'categories.json', data: JSON.stringify(categoriesMeta) }; }; generateTagsJson = function(tags) { var tagsMeta; tagsMeta = { tags: tags.sort(comparer).map(extractName) }; return { path: 'tags.json', data: JSON.stringify(tagsMeta) }; }; var jsons = new Array(); jsons.push(generatePostsJson(locals.posts.toArray())); jsons.push(generateCategoriesJson(locals.categories.toArray())); jsons.push(generateTagsJson(locals.tags.toArray())); return jsons; } module.exports = generator;"}],"posts":[{"title":"【JDK源码笔记】- 别走！这里有个笔记：图文讲解 AQS ，一起看看 AQS 的源码……(图文较长)","slug":"source-code/java/AQS","date":"2020-07-12T05:00:00.000Z","updated":"2020-07-12T05:34:10.034Z","comments":true,"path":"2020/07/12/source-code-aqs.html","link":"","permalink":"https://liuzhihang.com/2020/07/12/source-code-aqs.html","excerpt":"","text":"AbstractQueuedSynchronizer 抽象队列同步器，简称 AQS 。是在 JUC 包下面一个非常重要的基础组件，JUC 包下面的并发锁 ReentrantLock CountDownLatch 等都是基于 AQS 实现的。所以想进一步研究锁的底层原理，非常有必要先了解 AQS 的原理。 介绍先看下 AQS 的类图结构，以及源码注释，有一定的大概了解之后再从源码入手，一步一步研究它的底层原理。 “ 源码注释 提供了实现阻塞锁和相关同步器依靠先入先出（FIFO）等待队列（信号量，事件等）的框架。 此类中设计了一个对大多数基于 AQS 的同步器有用的原子变量来表示状态（state）。 子类必须定义 protected 方法来修改这个 state，并且定义 state 值在对象中的具体含义是 acquired 或 released。 考虑到这些，在这个类中的其他方法可以实现所有排队和阻塞机制。 子类可以保持其他状态字段，但只能使用方法 getState 、setState 和 compareAndSetState 以原子方式更新 state 。 子类应被定义为用于实现其封闭类的同步性能的非公共内部辅助类。 类AbstractQueuedSynchronizer没有实现任何同步接口。 相反，它定义了一些方法，如 acquireInterruptibly 可以通过具体的锁和相关同步器来调用适当履行其公共方法。 此类支持独占模式和共享模式。 在独占模式下，其他线程不能获取成功，共享模式下可以（但不一定）获取成功。 此类不“理解”，在机械意义上这些不同的是，当共享模式获取成功，则下一个等待的线程（如果存在）也必须确定它是否能够获取。 线程在不同模式下的等待共享相同的FIFO队列。 通常情况下，实现子类只支持其中一种模式，但同时使用两种模式也可以，例如ReadWriteLock 。 仅共享模式不需要定义支持未使用的模式的方法的子类。 这个类中定义了嵌套类 AbstractQueuedSynchronizer.ConditionObject ，可用于作为一个 Condition 由子类实现，并使用 isHeldExclusively 方法说明当前线程是否以独占方式进行，release()、 getState() acquire() 方法用于操作 state 原子变量。 此类提供检查和监视内部队列的方法，以及类似方法的条件对象。 根据需要进使用以用于它们的同步机制。 要使用这个类用作同步的基础上，需要重新定义以下方法，如使用，通过检查和或修改 getState 、setState 或 compareAndSetState 方法： tryAcquiretryReleasetryAcquireSharedtryReleaseSharedisHeldExclusively “ 通过上面的注释可以得出大概的印象： 内部依靠先入先出（FIFO） 等待队列。 存在 state 表示状态信息。state 值只能用 getState 、setState 和 compareAndSetState 方法以原子方式更新。 支持独占模式和共享模式，但具体需要子类实现具体支持哪种模式。 嵌套 AbstractQueuedSynchronizer.ConditionObject 可以作为 Condition 由子类实现。 子类需要重新定义 tryAcquire、tryRelease、tryAcquireShared、tryReleaseShared、isHeldExclusively 方法。 队列节点 Node Node节点，包含以下元素： 元素 含义 prev 上一个节点 next 下一个节点 thread 持有线程 waitStatus 节点状态 nextWaiter 下一个处于 CONDITION 状态的节点 组合成等待队列则如下： 下面是等待队列节点的 Node 属性： static final class Node { // 节点正在共享模式下等待的标记 static final Node SHARED = new Node(); // 指示节点正在以独占模式等待的标记 static final Node EXCLUSIVE = null; // 指示线程已取消 static final int CANCELLED = 1; // 指示后续线程需要唤醒 static final int SIGNAL = -1; // 指示线程正在等待条件 static final int CONDITION = -2; // 指示下一次acquireShared应该无条件传播 static final int PROPAGATE = -3; /** * 状态字段，仅使用以下值 * SIGNAL -1 ：当前节点释放或者取消时，必须 unpark 他的后续节点。 * CANCELLED 1 ：由于超时（timeout）或中断（interrupt），该节点被取消。节点永远不会离开此状态。特别是，具有取消节点的线程永远不会再次阻塞。 * CONDITION -2 ：该节点目前在条件队列。 但它不会被用作同步队列节点，直到转移，转移时的状态将被设置为 0 。 * PROPAGATE -3 ：releaseShared 应该被传播到其他节点。 * 0：都不是 * 值以数字表示以简化使用，大多数时候可以检查符号（是否大于0）以简化使用 */ volatile int waitStatus; // 上一个节点 volatile Node prev; // 下一个节点 volatile Node next; // 节点持有线程 volatile Thread thread; // 链接下一个等待条件节点，或特殊值共享 Node nextWaiter; // 节点是否处于 共享状态 是， 返回 true final boolean isShared() { return nextWaiter == SHARED; } // 返回前一个节点， 使用时 前一个节点不能为空 final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } Node() { // Used to establish initial head or SHARED marker } Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread; } Node(Thread thread, int waitStatus) { // Used by Condition this.waitStatus = waitStatus; this.thread = thread; } } 在 Node 节点中需要重点关注 waitStatus 默认状态为 0； waitStatus &gt; 0 (CANCELLED 1) 说明该节点超时或者中断了，需要从队列中移除； waitStatus = -1 SIGNAL 当前线程的前一个节点的状态为 SIGNAL，则当前线程需要阻塞（unpark）； waitStatus = -2 CONDITION -2 ：该节点目前在条件队列； waitStatus = -3 PROPAGATE -3 ：releaseShared 应该被传播到其他节点，在共享锁模式下使用。 了解完 Node 的结构之后，再了解下 AQS 结构，并从常用方法入手，逐步了解具体实现逻辑。 AbstractQueuedSynchronizerpublic abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { // 等待队列的头，延迟初始化。 除了初始化，它是仅经由方法setHead修改。 注意：如果头存在，其waitStatus保证不会是 CANCELLED 状态 private transient volatile Node head; // 等待队列的尾部，延迟初始化。 仅在修改通过方法ENQ添加新节点等待。 private transient volatile Node tail; // 同步状态 private volatile int state; // 获取状态 protected final int getState() { return state; } // 设置状态值 protected final void setState(int newState) { state = newState; } // 原子更新状态值 protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } } 在 AQS 中主要参数为： 参数 含义 head 等待队列头 tail 等待队列尾 state 同步状态 通过注释了解到，在 AQS 里主要分为两种操作模式，分别是：独占模式、共享模式，下面分别从两个不同的角度去分析源码。 操作 含义 acquire 以独占模式获取，忽略中断。 通过调用至少一次实施tryAcquire ，在成功时返回。 否则，线程排队，可能重复查封和解封，调用tryAcquire直到成功为止。 这种方法可以用来实现方法Lock.lock 。 release 以独占模式释放。 通过疏通一个或多个线程，如果实现tryRelease返回true。 这种方法可以用来实现方法Lock.unlock 。 acquireShared 获取在共享模式下，忽略中断。 通过至少一次第一调用实现tryAcquireShared ，在成功时返回。 否则，线程排队，可能重复查封和解封，调用tryAcquireShared直到成功为止。 releaseShared 以共享模式释放。 通过疏通一个或多个线程，如果实现tryReleaseShared返回true。 无论是共享模式还是独占模式在这里面都会用到 addWaiter 方法，将当前线程及模式创建排队节点。 独占模式获取独占资源 acquire public final void acquire(int arg) { // tryAcquire 尝试获取 state，获取失败则会加入到队列 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 在独占模式下会尝试获取 state，当获取失败时会调用 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)。 tryAcquire(arg)，尝试获取 state 这块由子类自己实现，不同的子类逻辑不同，这块在介绍子类代码时会说明。 获取 state 失败后，会进行 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，这块代码可以拆分为两块：addWaiter(Node.EXCLUSIVE)，acquireQueued(node, arg)。 addWaiter(Node.EXCLUSIVE) 返回的是当前新创建的节点。 acquireQueued(node, arg) 线程获取锁失败，使用 addWaiter(Node.EXCLUSIVE) 放入等待队列，而 acquireQueued(node, arg) 使用循环，不断的为队列中的节点去尝试获取资源，直到获取成功或者被中断。 总结获取资源主要分为三步： 尝试获取资源 入队列 出队列 尝试获取资源 tryAcquire(arg)，由子类实现，那下面则着手分别分析 入队列、出队列。 入队列：addWaiter(Node.EXCLUSIVE)使用 addWaiter(Node.EXCLUSIVE) 方法将节点插入到队列中，步骤如下： 根据传入的模式创建节点 判断尾节点是否存在，不存在则需要使用 enq(node) 方法初始化节点，存在则直接尝试插入尾部。 尝试插入尾部时使用 CAS 插入，防止并发情况，如果插入失败，会调用 enq(node) 自旋直到插入。 private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // 定位到队列末尾的 node Node pred = tail; if (pred != null) { // 新节点的上一个节点 指向尾节点 node.prev = pred; // 使用 CAS 设置尾节点，tail 如果等于 pred 则更新为 node if (compareAndSetTail(pred, node)) { // 更新成功则将 pred 的下一个节点指向 node pred.next = node; return node; } } // 尾节点没有初始化，或竞争失败，自旋 enq(node); return node; } /** * tailOffset 也就是成员变量 tail 的值 * 此处相当于：比较 tail 的值和 expect 的值是否相等， 相等则更新为 update */ private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update); } private final boolean compareAndSetHead(Node update) { return unsafe.compareAndSwapObject(this, headOffset, null, update); } private Node enq(final Node node) { for (;;) { Node t = tail; // 尾节点为空 需要初始化头节点，此时头尾节点是一个 if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { // 不为空 循环赋值 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 看完代码和注释肯定还是有点模糊，现在用图一步一步进行说明。 因为根据初始尾节点是否为空分为两种情况，这里使用两幅图： 第一幅为第一次添加节点，此时 head 会延迟初始化； 第二幅图为已经存在队列，进行插入节点； 注意看代码，enq 方法返回的是之前的尾节点； addWaiter 方法 返回的是当前插入的新创建的节点。 节点添加到队列之后，返回当前节点，而下一步则需要调用方法 acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 不断的去获取资源。 出队列：acquireQueued(addWaiter(Node.EXCLUSIVE), arg)方法会通过循环不断尝试获取拿到资源，直到成功。代码如下： final boolean acquireQueued(final Node node, int arg) { // 是否拿到资源 boolean failed = true; try { // 中断状态 boolean interrupted = false; // 无限循环 for (;;) { // 当前节点之前的节点 final Node p = node.predecessor(); // 前一个节点是头节点， 说明当前节点是 头节点的 next 即真实的第一个数据节点 （因为 head 是虚拟节点） // 然后再尝试获取资源 if (p == head &amp;&amp; tryAcquire(arg)) { // 获取成功之后 将头指针指向当前节点 setHead(node); p.next = null; // help GC failed = false; return interrupted; } // p 不是头节点， 或者 头节点未能获取到资源 （非公平情况下被别的节点抢占） // 判断 node 是否要被阻塞， if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 不断获取本节点的上一个节点是否为 head，因为 head 是虚拟节点，如果当前节点的上一个节点是 head 节点，则当前节点为 第一个数据节点； 第一个数据节点不断的去获取资源，获取成功，则将 head 指向当前节点； 当前节点不是头节点，或者 tryAcquire(arg) 失败（失败可能是非公平锁）。这时候需要判断前一个节点状态决定当前节点是否要被阻塞（前一个节点状态是否为 SIGNAL）。 /** * 根据上一个节点的状态，判断当前线程是否应该被阻塞 * SIGNAL -1 ：当前节点释放或者取消时，必须 unpark 他的后续节点。 * CANCELLED 1 ：由于超时（timeout）或中断（interrupt），该节点被取消。节点永远不会离开此状态。特别是，具有取消节点的线程永远不会再次阻塞。 * CONDITION -2 ：该节点目前在条件队列。 但它不会被用作同步队列节点，直到转移，转移时的状态将被设置为 0 。 * PROPAGATE -3 ：releaseShared 应该被传播到其他节点。 * 0：都不是 * */ private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // 前一个节点的等待状态 int ws = pred.waitStatus; // 前一个节点需要 unpark 后续节点 if (ws == Node.SIGNAL) return true; // 当前节点处于取消状态 if (ws > 0) { do { // 将取消的节点从队列中移除 node.prev = pred = pred.prev; } while (pred.waitStatus > 0); pred.next = node; } else { // 设置前一个节点为 SIGNAL 状态 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } 在 shouldParkAfterFailedAcquire 方法中，会判断前一个节点的状态，同时取消在队列中当前节点前面无效的节点。 再继续阅读 出队列 acquireQueued 方法，发现有一个 finally 会判断状态后执行 cancelAcquire(node); ，也就是上面流程图中下面的红色方块。 cancelAcquire(Node node) final boolean acquireQueued(final Node node, int arg) { // 是否拿到资源 boolean failed = true; try { // 省略 // 在 finally 会将当前节点置为取消状态 } finally { if (failed) cancelAcquire(node); } } private void cancelAcquire(Node node) { // 节点不存在 直接返回 if (node == null) return; // 取消节点关联线程 node.thread = null; //跳过已经取消的节点，获取当前节点之前的有效节点 Node pred = node.prev; while (pred.waitStatus > 0) node.prev = pred = pred.prev; // 获取当前节点之前的有效节点的下一个节点 Node predNext = pred.next; // 当前节点设置为取消 node.waitStatus = Node.CANCELLED; // 当前节点如果是尾节点，则将最后一个有效节点设置为尾节点，并将 predNext 设置为空 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) { compareAndSetNext(pred, predNext, null); } else { int ws; // pred 不是头节点(node 的上一个有效节点 不是 head) &amp;&amp; （ pred的状态是 SIGNAL || pred 的状态设置为 SIGNAL 成功 ） &amp;&amp; pred 的绑定线程不为空 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) { // 当前节点的后继节点 Node next = node.next; // 后继节点不为空 且 状态有效 将 pred 的 后继节点设置为 当前节点的后继节点 if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); } else { // node 的上一个有效节点 是 head， 或者其他情况 唤醒当前节点的下一个有效节点 unparkSuccessor(node); } node.next = node; // help GC } } private void unparkSuccessor(Node node) { // 判断当前节点状态 int ws = node.waitStatus; if (ws &lt; 0) // 将节点状态更新为 0 compareAndSetWaitStatus(node, ws, 0); // 下一个节点， 一般是下一个节点应该就是需要唤醒的节点，即颁发证书。 Node s = node.next; // 大于 0 CANCELLED ： 线程已取消 // 但是有可能 后继节点 为空或者被取消了。 if (s == null || s.waitStatus > 0) { s = null; // 从尾节点开始遍历，直到定位到 t.waitStatus &lt;= 0 的节点 // 定位到后并不会停止，会继续执行，相当于找到最开始的那个需要唤醒的节点 // t.waitStatus &lt;= 0 ： SIGNAL（ -1 后续线程需要释放） // CONDITION （ -2 线程正在等待条件） // PROPAGATE （ -3 releaseShared 应该被传播到其他节点） for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } // 定位到需要唤醒的节点后 进行 unpark if (s != null) LockSupport.unpark(s.thread); } 流程分析： 找到当前节点的前一个非无效节点 pred； 当前节点如果是尾节点，则将最后一个有效节点设置为尾节点，并将 predNext 设置为空； pred 不是头节点 &amp;&amp; （ pred的状态是 SIGNAL || pred 的状态设置为 SIGNAL 成功 ） &amp;&amp; pred 的绑定线程不为空； 其他情况。 下面分别画图： Q: 通过图可以看出来，只操作了 next 指针，但是没有操作 prev 指针，这是为什么呢？ A: 在 出队列：acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 方法中，shouldParkAfterFailedAcquire 方法会判断前一个节点的状态，同时取消在队列中当前节点前面无效的节点。这时候会移除之前的无效节点，此处也是为了防止指向一个已经被移除的节点。同时保证 prev 的稳定，有利于从 tail 开始遍历列表，这块在 unparkSuccessor(node); 中也可以看到是从后往前表里列表。 Q: unparkSuccessor(Node node) 为什么从后往前遍历？ A: 在 addWaiter(Node.EXCLUSIVE) 插入新节点时，使用的是 尾插法，看红框部分，此时有可能还未指向next。 Q: node.next = node; 这块导致 head不是指向最新节点，链表不就断了么？A： acquireQueued 方法介绍中，里面有个循环，会不断尝试获取资源，成功之后会设置为 head。并且在 shouldParkAfterFailedAcquire 中也会清除当前节点前的无效节点。 释放独占资源 releasepublic final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } 以独占模式释放。 通过释放一个或多个线程，如果实现tryRelease返回true。 这种方法可以用来实现方法Lock.unlock 。 tryRelease(arg) 操作释放资源，同样是由子类实现，后面介绍子类时会进行说明。返回 true 说明资源现在已经没有线程持有了，其他节点可以尝试获取； 释放成功，且 head != null &amp;&amp; h.waitStatus != 0, 会继续执行 unparkSuccessor(h)； 这块会看到 只要 tryRelease(arg) 操作释放资源成功， 后面无论执行是否成功，都会返回 true，unparkSuccessor(h) 相当于只是附加操作。 共享模式获取共享资源 acquireSharedpublic final void acquireShared(int arg) { // 小于 0 表示获取资源失败 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); } private void doAcquireShared(int arg) { // 添加到节点 此处是共享节点 final Node node = addWaiter(Node.SHARED); // 根据是否拿到资源 判断是否需要取消 boolean failed = true; try { boolean interrupted = false; for (;;) { // 返回前一个节点 final Node p = node.predecessor(); if (p == head) { // 再次尝试获取共享资源 int r = tryAcquireShared(arg); // 表示获取成功 if (r >= 0) { // 设置当前节点为头节点 并尝试唤醒后续节点 setHeadAndPropagate(node, r); // 释放头节点 GC 会回收 p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } tryAcquireShared(arg)，尝试获取资源，这块由子类实现； 返回值分为 3 种： 小于 0: 表示失败； 等于 0: 表示共享模式获取资源成功，但后续的节点不能以共享模式获取成功; 大于 0: 表示共享模式获取资源成功，后续节点在共享模式获取也可能会成功，在这种情况下，后续等待线程必须检查可用性。 在失败后会使用 doAcquireShared(arg); 不断获取资源； final Node node = addWaiter(Node.SHARED); 同样会创建节点； 在循环中不断判断前一个节点如果是 head，则尝试获取资源； 在共享模式下获取到资源后会使用 setHeadAndPropagate(node, r); 设置头节点，同时唤醒后续节点。 设置头节点，并传播唤醒后续节点// node 是当前节点 // propagate 是 前一步 tryAcquireShared 的返回值 进来时 >=0 // 大于 0: 表示共享模式获取资源成功，后续节点在共享模式获取也可能会成功，在这种情况下，后续等待线程必须检查可用性。 private void setHeadAndPropagate(Node node, int propagate) { // 记录下当前头节点 Node h = head; // Record old head for check below // 设置传入 node 为头节点 setHead(node); // 判断条件，唤醒后续节点 // propagate > 0 有后续资源 // h == null 旧的头节点 因为前面 addWaiter， 肯定不会为空，应该是防止 h.waitStatus &lt; 0 空指针的写法 // (h = head) == null 当前的 头节点，再判断状态 // waitStatus &lt; 0 后续节点就需要被唤醒 if (propagate > 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) { Node s = node.next; // 后续节点为共享，则需要唤醒 if (s == null || s.isShared()) doReleaseShared(); } } doReleaseShared() 释放共享资源 private void doReleaseShared() { // 循环 for (;;) { // 从头开始 Node h = head; // 判断队列是否为空，就是刚初始化 if (h != null &amp;&amp; h != tail) { int ws = h.waitStatus; // SIGNAL（ -1 后续线程需要释放） if (ws == Node.SIGNAL) { // 将等待状态更新为 0 如果失败，会循环 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases // 唤醒后续节点， 同时将当前节点设置为 取消 unparkSuccessor(h); } // 如果状态是 0 则会更新状态为 PROPAGATE // PROPAGATE （ -3 releaseShared 应该被传播到其他节点） else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } // 判断头节点有没有变化，有变化 是因为竞争，别的线程获取到了锁，会继续循环 // 没有变化直接结束 if (h == head) // loop if head changed break; } } 从头节点开始进行，如果 h != null &amp;&amp; h != tail 说明队列不是空或者刚初始化； 节点状态为 SIGNAL（ -1 ）说明后续线程需要释放； 会更改当前节点状态，成功后唤醒后续节点，失败则继续循环； 节点状态如果是 0 则更新为 PROPAGATE，会将状态传播。 释放共享资源 releaseSharedpublic final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { // 释放共享资源 doReleaseShared(); return true; } return false; } 以共享模式释放。 通过释放一个或多个线程，如果实现tryReleaseShared返回true。 总结Q: AQS 到底是什么？A: AQS 内部提供了一个先入先出（FIFO）双向等待队列，内部依靠 Node 实现，并提供了在独占模式和共享模式下的出入队列的公共方法。而关于状态信息 state 的定义是由子类实现。tryAcquire、tryRelease、tryAcquireShared、tryReleaseShared等尝试获取资源操作都是由子类进行定义和实现的。而 AQS 中提供了子类获取资源之后的相关操作，包括节点 Node 的出入队列，自旋获取资源等等。 Q: AQS 获取资源失败后会如何操作？A: 线程获取资源失败后，会放到等待队列中，在队列中会不断尝试获取资源（自旋），说明线程只是进入等待状态，后面还是可以再次获取资源的。 Q: AQS 等待队列的数据结构是什么？A: CLH变体的先入先出（FIFO）双向等待队列。（CLH锁是一个自旋锁。能确保无饥饿性。提供先来先服务的公平性。是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。） Q: AQS 等待队列中的节点如何获取获取和释放资源的？A: 可以看下独占模式中的讲述过程，通过代码梳理。 本文分别从 独占模式 和 共享模式介绍的 AQS 基本逻辑，并通过源码和作图理解基本思路。但是并没有对需要子类实现的业务逻辑做介绍。这块会在后面介绍 ReentrantLock、CountDownLatch 等子类的时候做介绍。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- JUC 包下工具类，它的名字叫 LockSupport ！你造么？","slug":"source-code/java/LockSupport","date":"2020-07-05T12:20:20.000Z","updated":"2020-07-05T12:53:57.888Z","comments":true,"path":"2020/07/05/source-code-locksupport.html","link":"","permalink":"https://liuzhihang.com/2020/07/05/source-code-locksupport.html","excerpt":"","text":"LockSupport 是 JUC 中常用的一个工具类，主要作用是挂起和唤醒线程。在阅读 JUC 源码中经常看到，所以很有必要了解一下。 介绍 基本线程阻塞原语创建锁和其他同步类。Basic thread blocking primitives for creating locks and other synchronization classes. LockSupport 类每个使用它的线程关联一个许可（在意义上的Semaphore类）。 如果许可可用，调用 park 将立即返回，并在此过程中消费它; 否则可能阻塞。如果许可不是可用，可以调用 unpark 使得许可可用。（但与Semaphore不同，许可不能累积。最多有一个。） 方法 park 和 unpark 提供了阻塞的有效手段和解锁线程不会遇到死锁问题，而 Thread.suspend 和 Thread.resume 是不能用于这种目的：因为许可的存在，一个线程调用 park 和另一个线程试图 unpark 它之间的竞争将保持活性。 此外，如果调用者线程被中断，park 将返回，并且支持设置超时。 该 park 方法也可能返回在其他任何时间，“毫无理由”，因此通常必须在一个循环中调用的返回后重新检查条件。 在这个意义上park作为“忙碌等待”不会浪费太多的时间自旋的优化，但必须以配对 unpark 使用。 这三种形式的 park 还支持 blocker 对象参数。而线程被阻塞时是允许使用监测和诊断工具，以确定线程被阻塞的原因。（诊断工具可以使用getBlocker(Thread) 方法 。）同时推荐使用带有 blocker 参数的 park方法，通常做法是 blocker 被设置为 this 。 上面的意思总结下来个人理解是： 许可（permit）的上限是1，也就是说只有 0 或 1 。 park: 没有许可的时候，permit 为 0 ，调用 park 会阻塞；有许可的时候，permit 为 1 ， 调用 park 会扣除一个许可，然后返回。 unpark：没有许可的时候，permit 为 0 ，调用 unpark 会增加一个许可，因为许可上限是 1 ， 所以调用多次也只会为 1 个。 线程初始的时候是没有许可的。 park 的当前线程如果被中断，会立即返回，并不会抛出中断异常。 park 方法的调用一般要放在一个循环判断体里面。 大概如图所示： 下面是源码注释中的案例： /** * FIFO 独占锁 */ class FIFOMutex { private final AtomicBoolean locked = new AtomicBoolean(false); private final Queue&lt;Thread> waiters = new ConcurrentLinkedQueue&lt;Thread>(); public void lock() { boolean wasInterrupted = false; Thread current = Thread.currentThread(); waiters.add(current); // Block while not first in queue or cannot acquire lock // 不在队列头，或者锁被占用，则阻塞， 就是只有队列头的可以获得锁 while (waiters.peek() != current || !locked.compareAndSet(false, true)) { LockSupport.park(this); if (Thread.interrupted()) // ignore interrupts while waiting wasInterrupted = true; } waiters.remove(); if (wasInterrupted) // reassert interrupt status on exit current.interrupt(); } public void unlock() { locked.set(false); LockSupport.unpark(waiters.peek()); } } 验证线程初始有没有许可？public class LockSupportTest { public static void main(String[] args) { System.out.println(\"开始执行……\"); LockSupport.park(); System.out.println(\"LockSupport park 之后……\"); } } 执行后会发现，代码在 park 处阻塞。说明，线程初始是没有许可的。 添加许可并消耗许可public class LockSupportTest { public static void main(String[] args) { System.out.println(\"开始执行……\"); LockSupport.unpark(Thread.currentThread()); System.out.println(\"执行 - park\"); LockSupport.park(); System.out.println(\"LockSupport park 之后……\"); } } public class LockSupportTest { public static void main(String[] args) throws InterruptedException { Thread thread = new Thread(new Runnable() { @Override public void run() { System.out.println(\"线程 \" + Thread.currentThread().getName() + \"开始执行 park\"); LockSupport.park(this); System.out.println(\"线程 \" + Thread.currentThread().getName() + \"执行 park 结束\"); } }); thread.start(); // 保证 上面线程先执行，然后再主线程 Thread.sleep(5000); System.out.println(\"开始执行 unpark(thread)\"); LockSupport.unpark(thread); Thread.sleep(5000); System.out.println(\"执行 unpark(thread) 结束\"); } } 通过上面示例可以看出： 执行 unpark 可以进行给予指定线程一个证书。 线程当前被 park 阻塞，此时给予证书之后， park 会消耗证书，然后继续执行。 许可上限为 1 public class LockSupportTest { public static void main(String[] args) { System.out.println(\"unpark 1次\"); LockSupport.unpark(Thread.currentThread()); System.out.println(\"unpark 2次\"); LockSupport.unpark(Thread.currentThread()); System.out.println(\"执行 - park 1 次\"); LockSupport.park(); System.out.println(\"执行 - park 2 次\"); LockSupport.park(); System.out.println(\"LockSupport park 之后……\"); } } 线程阻塞，可以看出 permit 只能有一个 中断可以使 park 继续执行并不会抛出异常public class LockSupportTest { public static void main(String[] args) { Thread thread = new Thread(new Runnable() { @Override public void run() { System.out.println(\"线程 \" + Thread.currentThread().getName() + \"开始执行 park\"); LockSupport.park(this); System.out.println(\"线程 \" + Thread.currentThread().getName() + \"执行 park 结束\"); System.out.println(\"线程 \" + Thread.currentThread().getName() + \"开始执行 park 第二次\"); LockSupport.park(this); System.out.println(\"线程 \" + Thread.currentThread().getName() + \"执行 park 第二次 结束\"); } }); try { thread.start(); // 保证 上面线程先执行，然后再主线程 Thread.sleep(5000); System.out.println(\"开始执行 unpark(thread)\"); // LockSupport.unpark(thread); thread.interrupt(); Thread.sleep(5000); System.out.println(\"执行 unpark(thread) 结束\"); } catch (InterruptedException e) { e.printStackTrace(); } } } 输出结果： /Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home/bin/java ... 线程 Thread-0开始执行 park 开始执行 unpark(thread) 线程 Thread-0执行 park 结束 线程 Thread-0开始执行 park 第二次 线程 Thread-0执行 park 第二次 结束 执行 unpark(thread) 结束 可以看出线程中断，park 会继续执行，并且没有抛出异常。 thread.interrupt(); 调用之后， 设置线程中断标示，unpark 没有清除中断标示，第二个 park 也会继续执行。 使用诊断工具liuzhihang % > jps 76690 LockSupportTest 77130 Jps liuzhihang % > jstack 77265 ... \"main\" #1 prio=5 os_prio=31 tid=0x00007f7f3e80a000 nid=0xe03 waiting on condition [0x000070000dfcd000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304) at com.liuzhihang.source.LockSupportTest.main(LockSupportTest.java:14) 中间省略部分，但是可以看出线程进入 WAITING 状态 源码分析 public class LockSupport { private static final sun.misc.Unsafe UNSAFE; /** * 为线程 thread 设置一个许可 * 无许可，则添加一个许可，有许可，则不添加 * 如果线程因为 park 被阻塞， 添加许可之后，会解除阻塞状态 */ public static void unpark(Thread thread) { if (thread != null) UNSAFE.unpark(thread); } /** * 有许可，则使用该许可 * 没有许可，阻塞线程，直到获得许可 * 传递 blocker 是为了方便使用诊断工具 */ public static void park(Object blocker) { Thread t = Thread.currentThread(); setBlocker(t, blocker); UNSAFE.park(false, 0L); setBlocker(t, null); } /** * 设置线程的 blocker 属性 */ private static void setBlocker(Thread t, Object arg) { // Even though volatile, hotspot doesn't need a write barrier here. UNSAFE.putObject(t, parkBlockerOffset, arg); } } LockSupport 的 park unpark 方法，实际调用的是底层 Unsafe 类的 native 方法。 public final class Unsafe { public native void unpark(Object var1); public native void park(boolean var1, long var2); } 既然调用了 Unsafe 到此处肯定不能善罢甘休。 hotspot 源码这块是下载的官方包中的源码，阅读并查阅资料了解的大概逻辑，不清楚之处，希望指导出来。 也可以直接跳过直接看结论。 查看jdk源码http://hg.openjdk.java.net/jdk8u/jdk8u/hotspot/file/5a83b7215107/src/share/vm/runtime/park.hpp 这块在以 os_linux 代码为例http://hg.openjdk.java.net/jdk8u/jdk8u/hotspot/file/5a83b7215107/src/os/linux/vm/os_linux.cpp 在底层维护了一个 _counter 通过更新 _counter 的值来标示是否有证明。 在 park 时，判断 _counter 为 0，则阻塞等待，为 1 则获得更新为 0 并返回。 在 unpark 时，判断 _counter 为 0，则给予凭证，并唤醒线程，为 1 则直接返回。 总结总结也是和预想的是相同的。 许可（permit）的上限是1，也就是说只有 0 或 1 。 park: 没有许可的时候，permit 为 0 ，调用 park 会阻塞；有许可的时候，permit 为 1 ， 调用 park 会扣除一个许可，然后返回。 unpark：没有许可的时候，permit 为 0 ，调用 unpark 会增加一个许可，因为许可上限是 1 ， 所以调用多次也只会为 1 个。 线程初始的时候是没有许可的。 park 的当前线程如果被中断，会立即返回，并不会抛出中断异常。 扩展 park/unpark 和 wait/notify 区别 park 阻塞当前线程，unpark 唤醒指定线程。 wait() 需要结合锁使用，并释放锁资源，如果没有设置超时时间，则需要 notify() 唤醒。而 notify() 是随机唤醒线程。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- JDK 8 新增的 LongAdder，得过来看一下！","slug":"source-code/java/LongAddr","date":"2020-06-28T15:50:20.000Z","updated":"2020-06-28T15:29:05.376Z","comments":true,"path":"2020/06/28/source-code-longadder.html","link":"","permalink":"https://liuzhihang.com/2020/06/28/source-code-longadder.html","excerpt":"","text":"在介绍 AtomicInteger 时，已经说明在高并发下大量线程去竞争更新同一个原子变量时，因为只有一个线程能够更新成功，其他的线程在竞争失败后，只能一直循环，不断的进行 CAS 尝试，从而浪费了 CPU 资源。而在 JDK 8 中新增了 LongAdder 用来解决高并发下变量的原子操作。下面同样通过阅读源码来了解 LongAdder 。 介绍一个或多个变量共同维持初值为 0 总和。 当跨线程竞争更新时，变量集可以动态增长以减少竞争。 方法 sum 返回当前变量集的总和。 当多个线程更新时，这个类是通常优选 AtomicLong ，比如用于收集统计信息，不用于细粒度同步控制的共同总和。 在低更新竞争，这两个类具有相似的特征。 但在高更新竞争时，使用 LongAdder 性能要高于 AtomicLong，同样要消耗更高的空间为代价。 LongAdder 继承了 Striped64，内部维护一个 Cells 数组，相当于多个 Cell 变量， 每个 Cell 里面都有一个初始值为 0 的 long 型变量。 源码分析Cell 类Cell 类 是 Striped64 的静态内部类。 @sun.misc.Contended static final class Cell { volatile long value; Cell(long x) { value = x; } final boolean cas(long cmp, long val) { return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long valueOffset; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?> ak = Cell.class; valueOffset = UNSAFE.objectFieldOffset (ak.getDeclaredField(\"value\")); } catch (Exception e) { throw new Error(e); } } } Cell 使用 @sun.misc.Contended 注解。 内部维护一个被 volatile 修饰的 long 型 value 。 提供 cas 方法，更新value。 其中 @sun.misc.Contended 注解作用是为了减少缓存争用。什么是缓存争用，这里只做下简要介绍。 伪共享CPU 存在多级缓存，其中最小存储单元是 Cache Line，每个 Cache Line 能存储 64 个字节的数据。在多线程场景下，A B 两个线程数据如果被存储到同一个 Cache Line 上，此时 A B 更新各自的数据，就会发生缓存争用，导致多个线程之间相互牵制，变成了串行程序，降低了并发。@sun.misc.Contended 注解，则可以保证该变量独占一个 Cache Line。详细可参考：http://openjdk.java.net/jeps/142 Striped64 核心属性abstract class Striped64 extends Number { /** CPU 的数量，以限制表大小 */ static final int NCPU = Runtime.getRuntime().availableProcessors(); /** * cell 数组，当非空时，大小是 2 的幂。 */ transient volatile Cell[] cells; /** * Base 值，在无争用时使用，表初始化竞赛期间的后备。使用 CAS 更新 */ transient volatile long base; /** * 调整大小和创建Cells时自旋锁（通过CAS锁定）使用。 */ transient volatile int cellsBusy; } Striped64 类主要提供以下几个属性： NCPU：CPU 的数量，以限制表大小。 cells：Cell[] cell 数组，当非空时，大小是 2 的幂。 base：long 型，Base 值，在无争用时使用，表初始化竞赛期间的后备。使用 CAS 更新。 cellsBusy：调整大小和创建Cells时自旋锁（通过CAS锁定）使用。 下面看是进入核心逻辑： LongAdder#addpublic class LongAdder extends Striped64 implements Serializable { public void add(long x) { Cell[] as; long b, v; int m; Cell a; // cells 是 数组，base 是基础值 if ((as = cells) != null || !casBase(b = base, b + x)) { boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) longAccumulate(x, null, uncontended); } } } abstract class Striped64 extends Number { // 使用 CAS 更新 BASE 的值 final boolean casBase(long cmp, long val) { return UNSAFE.compareAndSwapLong(this, BASE, cmp, val); } // 返回当前线程的探测值。 由于包装限制，从ThreadLocalRandom复制 static final int getProbe() { return UNSAFE.getInt(Thread.currentThread(), PROBE); } } 首先会对 Base 值进行 CAS 更新，当 Base 发生竞争时， 会更新数组内的 Cell 。 数组未初始化，Cell 未初始化， Cell 更新失败，即 Cell 也发生竞争时，会调用 Striped64 的 longAccumulate 方法。 Striped64#longAccumulate abstract class Striped64 extends Number { /** * x 要增加的值 * wasUncontended 有没有发生竞争 */ final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) { int h; // 当前线程有无初始化线程探测值， 给当前线程生成一个 非 0 探测值 if ((h = getProbe()) == 0) { ThreadLocalRandom.current(); // force initialization h = getProbe(); wasUncontended = true; } boolean collide = false; // True if last slot nonempty // 循环 for (;;) { Cell[] as; Cell a; int n; long v; // 数组不为空切数组长度大于 0 if ((as = cells) != null &amp;&amp; (n = as.length) > 0) { // (n - 1) &amp; h 获取到索引，索引处 cell 是否为 null， cell未初始化 if ((a = as[(n - 1) &amp; h]) == null) { // 判断 cellsBusy 是否为 0 if (cellsBusy == 0) { // Try to attach new Cell Cell r = new Cell(x); // Optimistically create // cellsBusy == 0 且 使用 casCellsBusy 方法将其更新为 1，失败会继续循环 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { boolean created = false; try { // Recheck under lock Cell[] rs; int m, j; // 重新检查状态 并创建 if ((rs = cells) != null &amp;&amp; (m = rs.length) > 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) { rs[j] = r; created = true; } } finally { // 创建完成之后， 改回 cellsBusy 值 cellsBusy = 0; } if (created) break; // 未创建继续循环 continue; // Slot is now non-empty } } collide = false; } // 传入的 wasUncontended 为 false 即发生碰撞了， 修改为未碰撞， 此处会继续循环，走到下一步，相当于会一直循环这个 cell else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash // cas 更新 cell 的 value， 成功则返回 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // 数组到最大长度 即大于等于 CPU 数量， 或者 cells 数组被改变， else if (n >= NCPU || cells != as) collide = false; // At max size or stale else if (!collide) collide = true; // 乐观锁 进行扩容 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { try { if (cells == as) { // Expand table unless stale Cell[] rs = new Cell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs; } } finally { cellsBusy = 0; } collide = false; continue; // Retry with expanded table } // 当前探针值不能操作成功，则重新设置一个进行尝试 h = advanceProbe(h); } // 没有加 cellsBusy 乐观锁 且 没有初始化，且获得锁成功（此时 cellsBusy == 1） else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) { boolean init = false; try { // Initialize table if (cells == as) { Cell[] rs = new Cell[2]; rs[h &amp; 1] = new Cell(x); cells = rs; init = true; } } finally { cellsBusy = 0; } if (init) break; } // 尝试在base上累加 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // Fall back on using base } } } longAccumulate 方法一共有三种情况 (as = cells) != null &amp;&amp; (n = as.length) &gt; 0 数组不为空且长度大于 0 。 获取索引处的 cell ， cell 为空则进行初始化。 cell 不为空，使用 cas 更新， 成功 break; 跳出循环， 失败则还在循环内，会一直尝试。 collide 指是否发生冲突，冲突后会进行重试。 冲突后会尝试获得锁并进行扩容，扩容长度为原来的 2 倍，然后继续重试。 获得锁失败（说明其他线程在扩容）会重新进行计算探针值。 cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy() 数组为空，获得乐观锁成功。 直接初始化数组。 初始数组长度为 2 。 casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x))) 获得乐观锁失败。 说明有其他线程在初始化数组，直接 CAS 更新 base 。 LongAdder#sum public class LongAdder extends Striped64 implements Serializable { public long sum() { Cell[] as = cells; Cell a; long sum = base; if (as != null) { for (int i = 0; i &lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum; } } 数组为空，说明没有发生竞争，直接返回 base 。 数组不为空，说明发生竞争，累加 cell 的 value 和 base 的和进行返回。 总结基本流程 LongAdder 继承了 Striped64，内部维护一个 Cells 数组，相当于多个 Cell 变量， 每个 Cell 里面都有一个初始值为 0 的 long 型变量。 未发生竞争时（Cells 数组未初始化），是对 base 变量进行原子操作。 发生竞争时，每个线程对自己的 Cell 变量的 value 进行原子操作。 如何确定哪个线程操作哪个 cell？通过 getProbe() 方法获取该线程的探测值，然后和数组长度 n - 1 做 &amp; 操作 (n - 1) &amp; h 。 static final int getProbe() { return UNSAFE.getInt(Thread.currentThread(), PROBE); } Cells 数组初始化及扩容？初始化扩容时会判断 cellsBusy， cellsBusy 使用 volatile 修饰，保证线程见可见性，同时使用 CAS 进行更新。 0 表示空闲，1 表示正在初始化或扩容。 初始化时会创建长度为 2 的 Cell 数组。扩容是创建一个长度是原数组长度 2 倍的新数组，并循环赋值。 如果线程访问分配的 Cell 元素有冲突后，会使用 advanceProbe() 方法重新获取探测值，再次进行尝试。 使用场景在高并发情况下，需要相对高的性能，同时数据准确性要求不高，可以考虑使用 LongAdder。 当要保证线程安全，并允许一定的性能损耗时，并对数据准确性要求较高，优先使用 AtomicLong。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- 请介绍下你了解的ThreadLocal，它的底层原理！","slug":"source-code/java/ThreadLocal","date":"2020-06-21T02:00:00.000Z","updated":"2020-06-21T03:35:47.932Z","comments":true,"path":"2020/06/21/source-code-threadlocal.html","link":"","permalink":"https://liuzhihang.com/2020/06/21/source-code-threadlocal.html","excerpt":"","text":"前言 业务开发中经常使用 ThreadLocal 来存储用户信息等线程私有对象… ThreadLocal 内部构造是什么样子的？为什么可以线程私有？常说的内存泄露又是怎么回事？ 公众号：liuzhihangs ，记录工作学习中的技术、开发及源码笔记；时不时分享一些生活中的见闻感悟。欢迎大佬来指导！ 介绍 ThreadLocal 类提供了线程局部变量。和正常对象不同的是，每个线程都可以访问 get()、set() 方法，获取独属于自己的副本。 ThreadLocal 实例通常是类中的私有静态字段，并且其状态和线程关联。每个线程都保持对其线程局部变量副本的隐式引用，只要线程是活动的并且 ThreadLocal 实例访问; 一个线程消失之后，所有的线程局部实例的副本都会被垃圾回收（除非存在对这些副本的其他引用）。 使用有这么一种使用场景，收到 web 请求，先进行 token 验证，而这个 token，可以解析出用户 user 的信息。所以我这边一般是这样使用的： 自定义注解， @CheckToken ， 标识该方法需要校验 token。 在 Interceptor（拦截器）中检查，如果方法有 @CheckToken 注解则校验 token。 从Header中获取 Authorization ，请求第三方或者自己的逻辑校验 token ，并解析成 user。 将user放到ThreadLocal中。 controller、service 在后续使用中， 如果需要 user 信息，可以直接从 ThreadLocal 中获取。 使用结束后进行remove。 代码如下： public class LocalUserUtils { /** * 用户信息保存至 ThreadLocal 中 */ private static final ThreadLocal&lt;User> USER_THREAD_LOCAL = new ThreadLocal&lt;>(); public static void set(User user) { USER_THREAD_LOCAL.set(user); } public static User get() { return USER_THREAD_LOCAL.get(); } public static void remove() { USER_THREAD_LOCAL.remove(); } } /** * 1. 加上注解 CheckToken * 只有方法， 类忽略 */ @CheckToken @PostMapping(\"/doXxx\") public Result&lt;Resp> doXxx(@RequestBody Req req) { Resp resp = xxxService.doXxx(req); return result.success(resp); } /** * 2. 3. 4. */ @Component public class TokenInterceptor implements HandlerInterceptor { @Override public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception { LocalUserUtils.remove(); } @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { // 请求方法是否存在注解 boolean assignableFrom = handler.getClass().isAssignableFrom(HandlerMethod.class); if (!assignableFrom) { return true; } CheckToken checkToken = null; if (handler instanceof HandlerMethod) { checkToken = ((HandlerMethod) handler).getMethodAnnotation(CheckToken.class); } // 没有加注解 直接放过 if (checkToken == null) { return true; } // 从Header中获取Authorization String authorization = request.getHeader(\"Authorization\"); log.info(\"header authorization : {}\", authorization); if (StringUtils.isBlank(authorization)) { log.error(\"从Header中获取Authorization失败\"); throw CustomExceptionEnum.NOT_HAVE_TOKEN.throwCustomException(); } User user = xxxUserService.checkAuthorization(authorization); // 放到 LocalUserUtils.set(user); return true; } } /** * 5. 使用 * 只有方法， 类忽略 */ @Override public Resp doXxx(Req req) { User user = LocalUserUtils.get(); // do something ... return resp; } 抛出问题 为什么可以线程私有？ 为什么建议声明为静态？ 为什么强制使用后必须remove？ 图 | 阿里巴巴 - Java开发手册（截图） 图 | 阿里巴巴 - Java开发手册（截图） 源码分析Thread public class Thread implements Runnable { // 省略 ... ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; // 省略 ... } 可以看出 Thread 对象中声明了 ThreadLocal.ThreadLocalMap 对象，每个线程都有自己的工作内存，每个线程都有自己的 ThreadLocal. ThreadLocalMap 对象，所以在线程之间是互相隔离的。 ThreadLocalThreadLocal则是一个泛型类，同时提供 set()、get()、remove() 等静态方法。 public class ThreadLocal&lt;T> { // 线程本地hashCode private final int threadLocalHashCode = nextHashCode(); // 获取此线程局部变量的当前线程副本中的值 public T get() {...} // 设置当前线程的此线程局部变量的复制到指定的值 public void set(T value) {...} // 删除当前线程的此线程局部变量的值 public void remove() {...} // ThreadLocalMap只是用来维持线程本地值的定制Map static class ThreadLocalMap {...} } set(T value)方法 public void set(T value) { // 获取当前线程 Thread t = Thread.currentThread(); // 获取当前线程的 threadLocals 属性 ThreadLocalMap map = getMap(t); if (map != null) // 存在则赋值 map.set(this, value); else // 不存在则直接创建 createMap(t, value); } // 根据线程获取当前线程的ThreadLocalMap ThreadLocalMap getMap(Thread t) { return t.threadLocals; } // 创建ThreadLocalMap 并赋值给当前线程的threadLocals字段 void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); } 1.Thread.currentThread() 先获取到当前线程。2. 获取当前线程的 threadLocals 属性，即 ThreadLocalMap。3. 判断 Map 是否存在，存在则赋值，不存在则创建对象。 get()方法 public T get() { // 获取当前线程 Thread t = Thread.currentThread(); // 获取当前线程的 threadLocals 属性 ThreadLocalMap map = getMap(t); // map不为空 if (map != null) { // 根据当前ThreadLocal获取的ThreadLocalMap的Entry节点 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { // 获取节点的value 并返回 @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; } } // 设置初始值并返回 （null） return setInitialValue(); } 1.Thread.currentThread() 先获取到当前线程。2. 获取当前线程的 threadLocals 属性，即 ThreadLocalMap 。3. 判断 Map 不为空，根据当前 ThreadLocal 对象获取 ThreadLocalMap.Entry 节点, 从节点中获取 value。4.ThreadLocalMap 为空或者 ThreadLocalMap.Entry 为空，则初始化 ThreadLocalMap 并返回。 remove()方法public void remove() { // 获取当前线程的ThreadLocalMap ThreadLocalMap m = getMap(Thread.currentThread()); // 不为空， 从ThreadLocalMap中移除该属性 if (m != null) m.remove(this); } 阅读 set()、get()、remove() 的源码之后发现后面其实是操作的 ThreadLocalMap, 主要还是操作的 ThreadLocalMap 的 set()、getEntry()、remove() 以及构造函数。下面看是看 ThreadLocalMap 的源码。 ThreadLocalMapstatic class ThreadLocalMap { /** * Entry节点继承WeakReference是弱引用 */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?>> { /** 与此ThreadLocal关联的值。 */ Object value; Entry(ThreadLocal&lt;?> k, Object v) { super(k); value = v; } } // 初始容量-必须是2的幂 private static final int INITIAL_CAPACITY = 16; // 表，根据需要调整大小. table.length必须始终为2的幂. private ThreadLocal.ThreadLocalMap.Entry[] table; // 表中的条目数。 private int size = 0; // 扩容阈值 private int threshold; // Default to 0 // 设置阀值为长度的 2/3 private void setThreshold(int len) { threshold = len * 2 / 3; } // 构造函数 ThreadLocalMap(ThreadLocal&lt;?> firstKey, Object firstValue) {...} // 根据ThreadLocal获取节点Entry private ThreadLocal.ThreadLocalMap.Entry getEntry(ThreadLocal&lt;?> key) {...} // set ThreadLocalMap的k-v private void set(ThreadLocal&lt;?> key, Object value) {...} // 移除当前值 private void remove(ThreadLocal&lt;?> key) {...} } Entry 继承了 WeakReference&lt;ThreadLocal&lt;?&gt; 也就意味着， Entry 节点的 key 是弱引用。 Entry 对象的key弱引用，指向的是 ThreadLocal 对象。 线程对象执行完毕，线程对象内实例属性会被回收，此时线程内 ThreadLocal 对象的引用被置为 null ，即 Entry 的 key 为 null, key 会被垃圾回收。 ThreadLocal 对象通常为私有静态变量， 生命周期不会至少不会随着线程技术而结束。 ThreadLocal 对象存在，并且 Entry的 key == null &amp;&amp; value != null ，这时就会造成内存泄漏。 小补充 强引用、软引用、弱引用、虚引用强引用（StrongReference）：最常见，直接 new Object(); 创建的即为强引用。当内存空间不足，Java虚拟机宁愿抛出 OOM，也不愿意随意回收具有强引用的对象来解决内存不足问题。 软引用（SoftReference）：内存足够，垃圾回收器不会回收软引用对象；内存不足时，垃圾回收器会回收。 弱引用（WeakReference）：垃圾回收器线程，发现就会回收。 虚引用（PhantomReference）：任何时候都有可能被垃圾回收，必须引用队列联合使用。 内存泄露：内存泄漏（Memory leak）是在计算机科学中，由于疏忽或错误造成程序未能释放已经不再使用的内存。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，导致在释放该段内存之前就失去了对该段内存的控制，从而造成了内存的浪费。 —— 维基百科 构造函数及hash计算ThreadLocalMap(ThreadLocal&lt;?> firstKey, Object firstValue) { // 初始化Entry数组， 长度为16 table = new Entry[INITIAL_CAPACITY]; // 获取key的hashCode，并计算出在数组中的索引， // 长度是 2的幂的情况下，取模 a % b == a &amp; (b - 1) int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); // 设置数组元素数 size = 1; // 设置扩容阈值 setThreshold(INITIAL_CAPACITY); } threadLocalHashCode 是 ThreadLocal 的静态属性，通过 nextHashCode 方法获取。 private final int threadLocalHashCode = nextHashCode(); // 被赋予了接下来的哈希码。 原子更新。 从零开始。 private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647; private static int nextHashCode() { // 返回下一个hash码，通过步长 0x61c88647 累加生成，这块注释说明是最佳哈希值 return nextHashCode.getAndAdd(HASH_INCREMENT); } 初始化数组，长度16。 计算 key 的 hashCode，对2的幂取模。 设置元素，元素数及扩容阈值。 hashCode 通过步长 0x61c88647 累加生成， 并且使用了 AtomicInteger，保证原子性。 set()方法 private void set(ThreadLocal&lt;?> key, Object value) { Entry[] tab = table; int len = tab.length; // hashcode取模求数组索引 int i = key.threadLocalHashCode &amp; (len-1); // 获取数组中对应的位置， 重点关注 e = tab[i = nextIndex(i, len)] for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { // 获取key ThreadLocal&lt;?> k = e.get(); // key 存在则覆盖 if (k == key) { e.value = value; return; } // key 不存在则赋值 if (k == null) { replaceStaleEntry(key, value, i); return; } } // 此时 e == null 直接执创建节点 tab[i] = new Entry(key, value); int sz = ++size; // cleanSomeSlots 循环数组 查找全部key==null的Entry if (!cleanSomeSlots(i, sz) &amp;&amp; sz >= threshold) rehash(); } 获取循环 Entry 数组，获取 tab[i] 处的 e， e != null 继续循环 此时发现 e 的 key 不存在，并且不是 null （hash冲突了。） 那就通过 e = tab[i = nextIndex(i, len)]) 继续获取下一个 i，并获取新的 tab[i] 处的 e。 赋值替换值结束结束并返回。 e == null 结束循环。 // 下一个index，如果 i + 1 &lt; len 直接返回下一个位置 // 如果 i + 1 >= len 则返回 0， 从头开始。 private static int nextIndex(int i, int len) { return ((i + 1 &lt; len) ? i + 1 : 0); } private static int prevIndex(int i, int len) { return ((i - 1 >= 0) ? i - 1 : len - 1); } 这块利用环形设计，如果长度到达数组长度，则从开头开始继续查找。 int i = key.threadLocalHashCode &amp; (len-1); 求出索引，并不是从0开始的。 /** * staleSlot 为当前索引位置， 并且当前索引位置的 k == null */ private void replaceStaleEntry(ThreadLocal&lt;?> key, Object value, int staleSlot) { Entry[] tab = table; int len = tab.length; Entry e; // 需要清除的 entry 的索引 int slotToExpunge = staleSlot; // 循环获取到上一个 key==null 的节点及其索引，有可能还是自己 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // 继续上一层的循环，查找下一个 k == key 的节点索引 for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal&lt;?> k = e.get(); if (k == key) { // key 相等 则直接赋值 e.value = value; // 并且将 此处的 entry替换为 tab[staleSlot] tab[i] = tab[staleSlot]; tab[staleSlot] = e; // 如果发现要清除的 entry和传入的在一个位置上， 则直接赋值 if (slotToExpunge == staleSlot) slotToExpunge = i; // 清除掉过期的 expungeStaleEntry(slotToExpunge) 会清除 entry的value，将其设置为null并将其设置为null， 并返回下一个需要清除的entry的索引位置 // cleanSomeSlots 循环数组 查找全部key==null的Entry cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; } // 如果向后扫描没有找到，并且已经到第初始传入的索引位置处了 if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; } // 没找到， 直接将旧值 Entry 设置为 null 并指向新创建的Entry tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // 结束之后发现要清楚的 key的索引 不等于当前传入的索引， 说明还有其他需要清除。 if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); } 这里存在三个属性 key， value，以及 staleSlot， staleSlot节点的 Entry != null 但是 k == null。 向前扫描获取到上一个 Entry != null 但是 k == null 的节点及其索引, 赋值给 slotToExpunge， 没有扫描到的话 slotToExpunge 还是等于 staleSlot。 向后扫描 Entry != null 的节点，因为在 set 方法中， 后面还有一段数组没有遍历。 发现 key 相等的Entry节点了， 直接赋值，然后清除其他 Entry != null 但是 k == null 的节点， 并返回。 没有找到key相等的节点，但是找到了下一个 Entry != null 但是 k == null， 且此时 slotToExpunge 未发生变化，还是指向 staleSlot， 则 i 赋值给 slotToExpunge。 向后扫描没有扫描到，则直接对当前节点（索引值为staleSlot）的节点的value设置为null，并指向新value。 结束之后发现 slotToExpunge 被改变了， 说明还有其他的要清除。 getEntry()方法 private Entry getEntry(ThreadLocal&lt;?> key) { // hashcode取模求数组索引 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) // 存在则返回 return e; else // 不存在 return getEntryAfterMiss(key, i, e); } private Entry getEntryAfterMiss(ThreadLocal&lt;?> key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { ThreadLocal&lt;?> k = e.get(); if (k == key) return e; if (k == null) // key 已经 == null 了 清除一下 value expungeStaleEntry(i); else // 继续获取下一个 i = nextIndex(i, len); e = tab[i]; } return null; } hashcode 取模求数组索引。 索引处获取到 Entry 则直接返回。 获取不到或者获取到的 Entry key 不相等时，有可能是因为 hash 冲突，被放到别的地方， 调用 getEntryAfterMiss 方法。 getEntryAfterMiss 方法中。 e == null 返回null。 e != null 判断key， key相等返回 Entry， key == null， 那就需要清除这个节点，然后继续按照 nextIndex(i, len) 方法找下一个节点。 remove()方法 private void remove(ThreadLocal&lt;?> key) { Entry[] tab = table; int len = tab.length; // hashcode 取模求数组索引 int i = key.threadLocalHashCode &amp; (len-1); // 清除当前节点的value for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { if (e.get() == key) { // 清楚对象引用 e.clear(); // value 指向 null expungeStaleEntry(i); return; } } } public void clear() { this.referent = null; } hashcode 取模求数组索引。 循环查找数组，将当前 key 的 Entry 的引用，将 value 设置为 null， 后面会被垃圾回收掉。 总结为什么可以线程私有？ThreadLocal 的 get()、set()、remove()方法中都有 Thread t = Thread.currentThread(); 操作的其实是本线程，获取本线程的ThreadLocalMap。 每个线程都有自己的 ThreadLocal，并且是将 value 存放在一个以 ThreadLocal 为 key 的 ThreadLocalMap 中的。所以线程间隔离。 为什么建议声明为静态？Java开发手册已经给出说明，还有就是，如果 ThreadLocal 设置为非静态，那就是某个线程的实例类，这样的话就会失去了线程共享的本质属性。 为什么强制必须时候后remove()？这块可以和内存泄露一块说明， 通过上面的 ThreadLocalMap 处关于弱引用的讲解已经说明会产生内存泄露。至于如何解决也给出了答案： 1.set() 时清除 Entry != null &amp;&amp; key == null 的节点， 将其 value 设置为 null。2.getEntry() 时清除当前 key 到 nextIndex(i, len)==null 之间的 Entry != null &amp;&amp; key == null 的节点， 将其 value 设置为 null。3.remove() 时清除指定key的 Entry != null &amp;&amp; key == null 的节点， 将其 value 设置为 null。 之所以使用remove()，还是为了解决内存泄露的问题。 Last 使用时注意声明为 private static final。 使用后要 remove()。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- 从JUC源码看CAS，我做了个笔记 ......","slug":"source-code/java/CAS","date":"2020-06-12T15:50:20.000Z","updated":"2020-06-12T15:37:39.802Z","comments":true,"path":"2020/06/12/source-code-cas.html","link":"","permalink":"https://liuzhihang.com/2020/06/12/source-code-cas.html","excerpt":"","text":"前言JUC包下大量使用了CAS，工作和面试中也经常遇到CAS，包括说到乐观锁，也不可避免的想起CAS，那CAS究竟是什么？ 概念说到CAS，基本上都会想到乐观锁、AtomicInteger、Unsafe … 当然也有可能啥也没想到！ 不管你们怎么想， 我第一印象是乐观锁，毕竟做交易更新交易状态经常用到乐观锁，就自然想到这个SQL： update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0; 其实就是 set和where里面都携带order_status。 那什么是CAS？ CAS就是Compare-and-Swap，即比较并替换，在并发算法时常用，并且在JUC（java.util.concurrent）包下很多类都使用了CAS。 非常常见的问题就是多线程操作i++问题。一般解决办法就是添加 synchronized 关键字修饰，当然也可以使用 AtomicInteger 代码举例如下： public class CasTest { private static final CountDownLatch LATCH = new CountDownLatch(10); private static int NUM_I = 0; private static volatile int NUM_J = 0; private static final AtomicInteger NUM_K = new AtomicInteger(0); public static void main(String[] args) throws InterruptedException { ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) { threadPool.execute(new Runnable() { public void run() { for (int j = 0; j &lt; 10000; j++) { NUM_I++; NUM_J++; NUM_K.incrementAndGet(); } LATCH.countDown(); } }); } LATCH.await(); System.out.println(\"NUM_I = \" + NUM_I); System.out.println(\"NUM_J = \" + NUM_J); System.out.println(\"NUM_K = \" + NUM_K.get()); threadPool.shutdown(); } } 下面就从AtomicInteger开始了解CAS。 源码分析public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1; } public final int decrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, -1) - 1; } } 可以看出里面使用了Unsafe类下的getAndAddInt方法，Unsafe类很多方法是本地（native）方法，主要是硬件级别的原子操作。 /** * @param var1 当前对象 * @param var2 当前对象在内存偏移量，Unsafe可以根据内存偏移地址获取数据 * @param var4 操作值 * @return */ public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { // 获取在var1在内存的值 var5 = this.getIntVolatile(var1, var2); // 将var1赋值为var5+var4， 赋值时会判断var1是否为var5 } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } // 原子操作 public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 至于 compareAndSwapInt 的分析就忽略了。 看完代码过程其实就是： 比较var1的值是否为var4，是的话将var1更新为var5。 如果不是的话就一直循环，直到var1是var4。 问题 这要是一直获取不到，岂不是一直循环。线程多的情况下，会自旋很长时间，导致浪费资源。 你更新了， 我又给你更新回去了，你也不知道。ABA问题！比如像这样，A想更新值为a，还未抢到资源，这时候B进行了更新，将对象更新为了b，然后又马上更新回了a， 这时候A是什么都不知道的。 以乐观锁举例： -- 0 -> 1 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0; -- 1 -> 0 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0; -- 0 -> 1 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0; 解决办法可以添加version进行版本号控制。 -- 0 -> 1 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0 and version = 0; -- 1 -> 0 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0 and version = 1; -- 0 -> 1 update trans_order set order_status = 1 where order_no = 'xxxxxxxxxxx' and order_status = 0 and version = 0; 代码中可以看 AtomicStampedReference 类： /** * 以原子方式设置该引用和标志给定的更新值的值， * 如果当前引用==预期的引用，并且当前标志==预期标志。 * * @param expectedReference 预期引用 * @param newReference 更新的值 * @param expectedStamp 预期标志 * @param newStamp 更新的标志 * @return {@code true} if successful */ public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) { Pair&lt;V> current = pair; return expectedReference == current.reference &amp;&amp; expectedStamp == current.stamp &amp;&amp; ((newReference == current.reference &amp;&amp; newStamp == current.stamp) || casPair(current, Pair.of(newReference, newStamp))); } 其实就是额外增加一个标志（stamp）来防止ABA的问题， 类似乐观锁的version。","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- HashMap红黑树","slug":"source-code/java/HashMap红黑数","date":"2020-05-25T12:50:20.000Z","updated":"2020-05-26T07:54:53.710Z","comments":true,"path":"2020/05/25/source-code-hashmap-red-black-tree.html","link":"","permalink":"https://liuzhihang.com/2020/05/25/source-code-hashmap-red-black-tree.html","excerpt":"","text":"前言在阅读HashMap源码时，会发现在HashMap中使用了红黑树，所以需要先了解什么是红黑树，以及其原理。从而再进一步阅读HashMap中的链表到红黑树的转换，红黑树的增删节点等。 什么是红黑树？ 在HashMap中是怎么应用的？ 什么是红黑树？ 红黑树（英语：Red–black tree）是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。它在1972年由鲁道夫·贝尔发明，被称为”对称二叉B树”，它现代的名字源于Leo J. Guibas和Robert Sedgewick于1978年写的一篇论文。红黑树的结构复杂，但它的操作有着良好的最坏情况运行时间，并且在实践中高效：它可以在O(logN)时间内完成查找、插入和删除，这里的n是树中元素的数目。 红黑树的性质红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求： 节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。 红黑树操作左旋、右旋 插入 以二叉查找树的方法增加节点 新插入节点为红色（如果设为黑色，就会导致根到叶子的路径上有一条路上，多一个额外的黑节点，这个是很难调整的。但是设为红色节点后，可能会导致出现两个连续红色节点的冲突，那么可以通过颜色调换（color flips）和树旋转来调整。） 注意： 性质1和性质3是永远保持着的。 性质4只在增加红色节点、重绘黑色节点为红色，或做旋转时受到威胁。 性质5只在增加黑色节点、重绘红色节点为黑色，或做旋转时受到威胁。 插入时会遇到以下五种情形： 情形1：插入第一个节点情形2：插入新节点，父节点是黑色情形3：插入新节点，父节点是红色，叔父节点是红色情形4：插入新节点，父节点是红色，叔父节点是黑色或缺省，新节点是右子节点，父节点又是其父节点的左子节点情形5：插入新节点，父节点是红色，叔父节点是黑色或缺省，新节点是左子节点，父节点又是其父节点的左子节点。 情形1： 操作：插入第一个节点违反性质2：” 根是黑色。 “情形：直接插入红色节点，然后进行染色为黑色 情形2： 操作：插入新节点，父节点是黑色未违反性质情形：直接插入 情形3： 操作：插入新节点，父节点是红色，叔父节点是红色违反性质4：” 每个红色节点必须有两个黑色的子节点。 “情形：将祖父节点染色，祖父节点染色后再进行重新判断进行染色或旋转 情形4： 操作：插入新节点，父节点是红色，叔父节点是黑色或缺省，新节点是右子节点，父节点又是其父节点的左子节点违反性质4：” 每个红色节点必须有两个黑色的子节点。 “情形：进行左旋，旋转后父节点变成左子节点，新节点变成父节点，然后重新判断进行染色或旋转 情形5： 操作：插入新节点，父节点是红色，叔父节点是黑色或缺省，新节点是左子节点，父节点又是其父节点的左子节点。违反性质4：” 每个红色节点必须有两个黑色的子节点。 “情形：父节点染色为黑色，进行右旋，祖父节点变为右子节点，然后重新判断进行染色或旋转 HashMap结构static final class TreeNode&lt;K,V> extends LinkedHashMap.Entry&lt;K,V> { TreeNode&lt;K,V> parent; // red-black tree links TreeNode&lt;K,V> left; TreeNode&lt;K,V> right; TreeNode&lt;K,V> prev; // needed to unlink next upon deletion boolean red; // ... 省略 } 三个参数/** * 链表转为树阈值。 * 大于等于8时，会转换为树。 * 8 是综合性能考虑确定的值 */ static final int TREEIFY_THRESHOLD = 8; /** * 从树转换为链表的阈值 */ static final int UNTREEIFY_THRESHOLD = 6; /** * 最小树形化容量，只有哈希表元素数到达64才会进行树转换 */ static final int MIN_TREEIFY_CAPACITY = 64; 链表转红黑树-treeifyBin 数组（哈希表）长度到达64 当链表长度大于等于8是会将链表转换为红黑树 final void treeifyBin(Node&lt;K,V>[] tab, int hash) { int n, index; Node&lt;K,V> e; // 数组为null或者数组长度小于MIN_TREEIFY_CAPACITY（64）时，进行扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) { // 头尾节点 hd-头 tl-尾 TreeNode&lt;K,V> hd = null, tl = null; do { // 创建树节点 Node -> TreeNode // 循环执行完之后得到的是双向链表 TreeNode&lt;K,V> p = replacementTreeNode(e, null); if (tl == null) hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); // 此时得到的仅仅是双向链表 // 指针指向链表头 if ((tab[index] = hd) != null) // 将双向链表转换为树 hd.treeify(tab); } } final void treeify(Node&lt;K,V>[] tab) { TreeNode&lt;K,V> root = null; for (TreeNode&lt;K,V> x = this, next; x != null; x = next) { next = (TreeNode&lt;K,V>)x.next; x.left = x.right = null; if (root == null) { // 情形1：插入第一个节点 x.parent = null; x.red = false; root = x; } else { // 当前节点的 key 和 hash K k = x.key; int h = x.hash; Class&lt;?> kc = null; // 再次循环 for (TreeNode&lt;K,V> p = root;;) { int dir, ph; // 内层循环的key K pk = p.key; // 当前节点的hash和内层循环的hash值作比较 if ((ph = p.hash) > h) // &lt; 0 left查找 dir = -1; else if (ph &lt; h) // > 0 right 查找 dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) // 比较对象 dir = tieBreakOrder(k, pk); TreeNode&lt;K,V> xp = p; // dir &lt;= 0 则走 left查找 > 0 则走 right查找 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) { x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; // 正式转换为红黑树 root = balanceInsertion(root, x); break; } } } } moveRootToFront(tab, root); } // root 根节点 // x 要操作的节点 static &lt;K,V> TreeNode&lt;K,V> balanceInsertion(TreeNode&lt;K,V> root, TreeNode&lt;K,V> x) { // 默认节点为红色 x.red = true; // xp：x的父节点 // xpp：x的祖父节点 // xppl：x祖父节点的左子节点 // xppr：x祖父节点的右子节点 for (TreeNode&lt;K,V> xp, xpp, xppl, xppr;;) { // 情形1： 父节点为null， 直接置为根 if ((xp = x.parent) == null) { x.red = false; return x; } // 父节点黑色 或者 祖父节点为空，直接返回 // 情形2：插入新节点，父节点是黑色 else if (!xp.red || (xpp = xp.parent) == null) return root; // 父节点是祖父节点的左子节点 if (xp == (xppl = xpp.left)) { // 祖父节点的右子节点不为空且是红色 // 情形3：插入新节点，父节点是红色，叔父节点是红色 if ((xppr = xpp.right) != null &amp;&amp; xppr.red) { xppr.red = false; //祖父节点的右子节点设置为黑色 xp.red = false; // 父节点设置为黑色 xpp.red = true; // 祖父节点设置为红色 x = xpp; // 继续操作祖父节点 } // 旋转 else { // 新插入的是右子节点 if (x == xp.right) { // 插入的x是父节点的右子节点， 进行左旋 root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; } if (xp != null) { // 父节点设置为黑色 xp.red = false; if (xpp != null) { xpp.red = true; // 右旋 root = rotateRight(root, xpp); } } } } // 父节点是祖父节点的右子节点 else { // 祖父节点的左子节点不为空且为红色 if (xppl != null &amp;&amp; xppl.red) { xppl.red = false; // 祖父节点的左子节点设置为黑色 xp.red = false; // 父节点设置为黑色 xpp.red = true; // 祖父节点设置为红色 x = xpp; // 继续操作祖父节点 } // 旋转 else { if (x == xp.left) { root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; } if (xp != null) { xp.red = false; if (xpp != null) { xpp.red = true; root = rotateLeft(root, xpp); } } } } } }","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- HashMap扩容","slug":"source-code/java/HashMap扩容","date":"2020-05-17T12:50:20.000Z","updated":"2020-05-18T06:45:17.866Z","comments":true,"path":"2020/05/17/source-code-hashmap-resize.html","link":"","permalink":"https://liuzhihang.com/2020/05/17/source-code-hashmap-resize.html","excerpt":"","text":"描述下HashMap put(k,v)的流程？它的扩容流程是怎么样的？ HashMap put(k,v)流程 通过hash(key方法)获取到key的hash值 调用put方法, 将value存放到指定的位置 根据hash值确定当前key所在node数组的索引 (n - 1) &amp; hash 如果node[i]==null 则直接创建新数组 如果node[i]!=null 判断 当前node的头结点的 hash和key是否都相等, 相等则需要操作的就是该node 判断当前节点是否为TreeNode，对TreeNode进行操作，并返回结果e 如果是链表则遍历链表，key存在则返回节点e，不存在则赋值 判断节点e有没有被赋值，覆盖旧值 hashMap size进行加1，同时判断v新size是否大于扩容阈值从而判断是否需要扩容 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // 声明Node数组tab, Node节点 Node&lt;K,V>[] tab; Node&lt;K,V> p; int n, i; // 对tab数组赋值为当前HashMap的table, 并判断是否为空, 或者长度为0 // 为0进行则resize()数组, 并对 n赋值为当前tab的长度 // resize() 对HashMap的table扩容, 并返回扩容后的新数组 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 对 node p 进行赋值, 数组所在位置 即 node p 如果是null 则直接赋值 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { // p 不为null, 声明 node e, key k Node&lt;K,V> e; K k; // 如果hash值相等且key相等, 直接将 e 赋值为当前node的头节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) // 如果是红黑树, 则对树进行操作, 返回节点e e = ((TreeNode&lt;K,V>)p).putTreeVal(this, tab, hash, key, value); else { // 对链表进行遍历, 找到对应的节点 for (int binCount = 0; ; ++binCount) { // 将 e 赋值为 头节点p的next, 如果下一个节点为null if ((e = p.next) == null) { // 对节点进行赋值 p.next = newNode(hash, key, value, null); // 如果长度到达数转换阈值, 则需要转换为红黑树 if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // 如果e节点的hash相等, key相等, 则 直接跳出循环 e 已经被赋值为 p.next // 此时e节点的value没有被赋值 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // 指针指向下一个节点, 继续遍历 p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; // 对旧值进行覆盖, 并返回旧值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 是否需要扩容 if (++size > threshold) resize(); afterNodeInsertion(evict); return null; } resize()扩容过程 JDK 1.7 扩容流程, 每次都需要数组扩容后, 链表需要重新计算在新数组的位置 JDK 1.8 不需要重新计算 (优化点) 数组下标: (n - 1) &amp; hash 即数组长度-1 &amp; key的hash 扩容后的数组下标: ((n &lt;&lt; 1) - 1) &amp; hash 相当于在 高位1之前加了个1 如图所示, 真正发生影响的是新增的那一位(红色箭头所指), 所以 oldCap &amp; hash 完全可以判断该值是放在旧索引值的位置还是放在旧索引值+旧数组长度的位置 final Node&lt;K,V>[] resize() { // 旧数组 Node&lt;K,V>[] oldTab = table; // 旧数组长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 旧的扩容阈值 int oldThr = threshold; // 新的数组长度和新扩容阈值 int newCap, newThr = 0; // 旧数组存在 if (oldCap > 0) { if (oldCap >= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 新数组长度为旧数组长度的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap >= DEFAULT_INITIAL_CAPACITY) // 扩容阈值是旧扩容阈值的2倍 newThr = oldThr &lt;&lt; 1; // double threshold } // 旧数组不存在, 相当于首次put(K, V)时, 将数组长度置为扩容阈值 else if (oldThr > 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults // 旧数组不存在, new HashMap()未指定长度, 初次put(K, V), 设置为默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 新的扩容阈值是0, 则将扩容阈值设置为 新数组长度*负载因子 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } // 对全局的扩容阈值进行赋值 threshold = newThr; @SuppressWarnings({\"rawtypes\",\"unchecked\"}) // 创建新数组, 长度为新长度, 即原数组长度的2倍 Node&lt;K,V>[] newTab = (Node&lt;K,V>[])new Node[newCap]; // 将table复制为新数组 table = newTab; if (oldTab != null) { // 对旧数组进行遍历 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V> e; // 旧节点node赋值 if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) // 只有头结点, 直接计算新的位置并赋值 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 树单独处理 ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V> loHead = null, loTail = null; Node&lt;K,V> hiHead = null, hiTail = null; Node&lt;K,V> next; do { // next节点 next = e.next; // 节点hash与旧数组长度 &amp; 的结果来决定元素所在位置, 参考上面图示所讲 if ((e.hash &amp; oldCap) == 0) { // 在元索引出创建新链表 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { // 新索引出创建链表 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; // 索引j处直接赋值 newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; // 索引 j + 老数组长度位置存放hiHead newTab[j + oldCap] = hiHead; } } } } } return newTab; }","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"【JDK源码笔记】- HashMap的初始化","slug":"source-code/java/HashMap初始化","date":"2020-05-11T10:50:20.000Z","updated":"2020-05-18T06:45:00.579Z","comments":true,"path":"2020/05/11/source-code-hashmap-init.html","link":"","permalink":"https://liuzhihang.com/2020/05/11/source-code-hashmap-init.html","excerpt":"","text":"HashMap初始化参数都是什么？默认是多少？为什么建议初始化设置容量？tableSizeFor方法是做什么的？如何获取到一个key的hash值？及计算下标？ HashMap初始化参数都是什么？默认是多少？HashMap初始化参数分别是初始容量和负载因子。 初始容量(threshold)：默认 16， 必须是2的幂， 最大容量为 1 &lt;&lt; 30 负载因子(loadFactor)：是指哈希表的负载因子，当哈希表的长度大于capacity * loadFactor时会进行扩容，默认 0.75f 为什么建议初始化设置容量 这块涉及到HashMap的扩容， 在阿里巴巴Java开发手册中已经说明了原因。主要是为了减少频繁的扩容造成的资源损耗。 tableSizeFor方法是做什么的？初始化HashMap时, 如果传入初始容量, 在初始化时会调用 tableSizeFor(initialCapacity) 方法寻找大于等于当前值的下一个2的幂值. 代码如下： static final int tableSizeFor(int cap) { int n = cap - 1; // -1操作, 防止当cap正好是2的幂时的处理 n |= n >>> 1; // n无符号右移1位, 然后和n做 | 运算, (1|0=1 1|1=1 0|0=0 0|1=1) n |= n >>> 2; // n无符号右移2位, 然后和n做 | 运算, n |= n >>> 4; // n无符号右移4位, 然后和n做 | 运算, n |= n >>> 8; // n无符号右移8位, 然后和n做 | 运算, n |= n >>> 16; // n无符号右移16位, 然后和n做 | 运算, // 最后获得的结果为 cap-1的下一个2的幂值-1, 只需要对n+1即可 return (n &lt; 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } 假设cap值为100, 即0110 0100 cap的下一个2的幂为 0111 1111 即 1000 0000 0000 = 0111 1111 + 1 只需要考虑将 首个为1的最高位之后的值置为1, 然后+1即可 为防止cap本来就是2的幂, 则需要先进行减一操作 如图所示: 最后执行的结果进行加1即可 如何获取到一个key的hash值？static final int hash(Object key) { int h; // key的hashCode ^ 上自己的高16位， 如果是null的话则hash为0 return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } 获取到了hash值， 那如何计算在数组的那个位置呢？ // n为数组长度 数组下标 i = (n - 1) &amp; hash 数组长度都是 2的幂假设 n = 1 &gt;&gt; x则 n - 1 则表示 一个低x位全为1的数 (n - 1) &amp; hash 则相当于 一个低x位全为1的数和hash做&amp;操作. 通过图可以看出, 参与运算的只有低x位, 相当于之前的所有值都不会有效. 所以前面的hash(key) 将key.hashCode()高低16位做^操作, 可以保证, 高低16位都能参与运算.一定程度上避免hash碰撞.在源码注释中已经说明, 是肯定会有碰撞, 但是这是权衡之后的结果.","categories":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"源码笔记/JDK","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/JDK/"}],"tags":[{"name":"源码笔记","slug":"源码笔记","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0/"},{"name":"JDK","slug":"JDK","permalink":"https://liuzhihang.com/tags/JDK/"}]},{"title":"markdown代码折叠","slug":"other/markdown代码折叠","date":"2020-04-20T07:20:20.000Z","updated":"2020-04-22T11:58:05.810Z","comments":true,"path":"2020/04/20/markdown-code-folding.html","link":"","permalink":"https://liuzhihang.com/2020/04/20/markdown-code-folding.html","excerpt":"","text":"效果展示折叠内容 折叠内容 在markdown中折叠一部分内容, 点击可以展开. 折叠代码 折叠代码 public class HelloWorld { public static void main(String[] args) { System.out.println(\"HelloWorld\"); } } 使用方式使用html &lt;details> &lt;summary>折叠内容&lt;/summary> 在markdown中折叠一部分内容, 点击可以展开. &lt;/details> &lt;details> &lt;summary>折叠代码&lt;/summary> 代码块 &lt;/details>","categories":[{"name":"markdown","slug":"markdown","permalink":"https://liuzhihang.com/categories/markdown/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://liuzhihang.com/tags/markdown/"},{"name":"小技巧","slug":"小技巧","permalink":"https://liuzhihang.com/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/"}]},{"title":"雪花算法","slug":"distributed/使用雪花算法生成流水号","date":"2020-04-13T08:03:09.000Z","updated":"2020-06-01T02:20:18.654Z","comments":true,"path":"2020/04/13/snowflake-algorithm.html","link":"","permalink":"https://liuzhihang.com/2020/04/13/snowflake-algorithm.html","excerpt":"","text":"简单介绍下雪花算法, 以及Java版雪花算法的代码.仅仅是一个最简单版本, 更深层次的指针回拨等. 相当于在开发过成功可以先使用.尽量还是使用统一的分布式流水号生成系统, 保证流水号全局唯一. 雪花算法0 0000000000 0000000000 0000000000 0000000000 0 00000 00000 000000000000使用64位long型数字作为全局唯一id1位 无意义 041位 时间戳5位 机房id5位 机器id12位自增序号 表示同一时间同一机房同一机器生成的序列号 第一位为什么无意义 二进制中 第一位代表符号位, 默认 0 表示生成的序列号为正数 41位时间戳 41位最大能表示 2^41-1 的数字. 毫秒值 69.7年 (2^41-1)/1000/60/60/24 当时间大于69.7即时间戳差值大于 2199023255551, 会开始出现负值流水号 10位 机房id+机器id 2^10 1024台机器 // 但是使用中不可能每部署一台机器都改下编号, 所以我做出以下改动 // 8位机器号(最大256) 2位机房号 // 机器号使用IP地址后三位 机房id 默认1 // 只需要确保机器的ip后三位不同即可 private static final long MACHINE_BIT = 8; private static final long DATA_CENTER_BIT = 2; private static final long DATA_CENTER_ID = 1;private static long address;static { InetAddress localIp = IpUtils.getLocalIp(); address = localIp.getAddress()[3] &amp; 0xff; log.info(“当前系统的 address 为: {}”, address);} 4. 12位序列号 表示同一毫秒内生成的id 2^12-1 个正整数 SnowFlake每秒能够产生26万ID左右 优点: 生成ID时不依赖于DB，完全在内存生成，高性能高可用。 ID呈趋势递增，后续插入索引树的时候性能较好。 缺点: 依赖于系统时钟的一致性。如果某台机器的系统时钟回拨，有可能造成ID冲突，或者ID乱序 ### SerialNumber ```java public class SerialNumber { /** * 起始的时间戳 2018-01-01 00:00:00 */ private static final long START_STAMP = 1514736000000L; /** * 每一部分占用的位数 * 序列号 占用位数 12 位 (同一毫秒内生成的id 2^12-1 个正整数) * 机器标识 占用位数 8 位 (一般是使用5位) * 数据中心 占用位数 2 位 (一般是使用5位) * */ private static final long SEQUENCE_BIT = 12; private static final long MACHINE_BIT = 8; private static final long DATA_CENTER_BIT = 2; /** * 每一部分的最大值 */ private static final long MAX_DATA_CENTER_NUM = ~(-1L &lt;&lt; DATA_CENTER_BIT); private static final long MAX_MACHINE_NUM = ~(-1L &lt;&lt; MACHINE_BIT); private static final long MAX_SEQUENCE = ~(-1L &lt;&lt; SEQUENCE_BIT); /** * 每一部分向左的位移 * 机器Id左移12位 (SEQUENCE_BIT = 12) * 数据中心左移20位 (SEQUENCE_BIT + MACHINE_BIT = 12 + 8) * 时间戳左移22位 (DATA_CENTER_LEFT + DATA_CENTER_BIT = 12 + 8 + 2) * */ private static final long MACHINE_LEFT = SEQUENCE_BIT; private static final long DATA_CENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private static final long TIME_STAMP_LEFT = DATA_CENTER_LEFT + DATA_CENTER_BIT; /** * 数据中心 机器标识 序列号 上一次时间戳 * 数据中心标识和机器标识一般是外部传入 */ private static final long DATA_CENTER_ID = 1; private static long address; private long sequence = 0L; private long lastStamp = -1L; private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormatter.ofPattern(&quot;yyMMdd&quot;); static { InetAddress localIp = IpUtils.getLocalIp(); address = localIp.getAddress()[3] &amp; 0xff; log.info(&quot;当前系统的 address 为: {}&quot;, address); } /** * 产生下一个ID * * @return */ private synchronized long nextId() { long currStamp = getNewStamp(); if (currStamp &lt; lastStamp) { throw new RuntimeException(&quot;Clock moved backwards. Refusing to generate id&quot;); } if (currStamp == lastStamp) { // 相同毫秒内，序列号自增 (sequence + 1) &amp; (~(-1L &lt;&lt; SEQUENCE_BIT)) sequence = (sequence + 1) &amp; MAX_SEQUENCE; // 同一毫秒的序列数已经达到最大 if (sequence == 0L) { currStamp = getNextMill(); } } else { // 不同毫秒内，序列号置为0 sequence = 0L; } lastStamp = currStamp; // 时间戳部分 数据中心部分 机器标识部分 序列号部分 return (currStamp - START_STAMP) &lt;&lt; TIME_STAMP_LEFT | DATA_CENTER_ID &lt;&lt; DATA_CENTER_LEFT | address &lt;&lt; MACHINE_LEFT | sequence; } private long getNextMill() { long mill = getNewStamp(); while (mill &lt;= lastStamp) { mill = getNewStamp(); } return mill; } private long getNewStamp() { return System.currentTimeMillis(); } }IpUtilsimport java.net.*; import java.util.Enumeration; /** * @author liuzhihang * @date 2019/12/19 16:03 */ public class IpUtils { public static InetAddress getLocalIp() { try { for (Enumeration&lt;NetworkInterface> e = NetworkInterface.getNetworkInterfaces(); e.hasMoreElements(); ) { NetworkInterface item = e.nextElement(); for (InterfaceAddress address : item.getInterfaceAddresses()) { if (item.isLoopback() || !item.isUp()) { continue; } if (address.getAddress() instanceof Inet4Address) { return address.getAddress(); } } } return InetAddress.getLocalHost(); } catch (SocketException | UnknownHostException e) { throw new RuntimeException(e); } } }","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"流水号","slug":"流水号","permalink":"https://liuzhihang.com/tags/%E6%B5%81%E6%B0%B4%E5%8F%B7/"},{"name":"雪花算法","slug":"雪花算法","permalink":"https://liuzhihang.com/tags/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95/"}]},{"title":"项目启动失败:java.lang.NoClassDefFoundError","slug":"issue/项目启动失败","date":"2020-04-12T05:20:48.000Z","updated":"2020-04-12T05:38:39.467Z","comments":true,"path":"2020/04/12/no-class-def-found-error-rule-configuration.html","link":"","permalink":"https://liuzhihang.com/2020/04/12/no-class-def-found-error-rule-configuration.html","excerpt":"","text":"近期遇到一个很久没有启动过的项目, 然后启动失败, 报 java.lang.NoClassDefFoundError, 现在记录问题排查情况. 错误代码 错误代码较长, 可以收缩, 直接看排查 Error starting ApplicationContext. To display the conditions report re-run your application with &#39;debug&#39; enabled.] [2020-04-10 13:26:11.478]-[main]-[]-[ERROR]-[org.springframework.boot.SpringApplication:821]-[Application run failed] org.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:155) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:742) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:389) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:311) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1213) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1202) [spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at com.opay.im.WebApplication.main(WebApplication.java:32) [classes!/:1.0-SNAPSHOT] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_221] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_221] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_221] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_221] at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [opay-im-web-1.0-SNAPSHOT.jar:1.0-SNAPSHOT] at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [opay-im-web-1.0-SNAPSHOT.jar:1.0-SNAPSHOT] at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [opay-im-web-1.0-SNAPSHOT.jar:1.0-SNAPSHOT] at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:58) [opay-im-web-1.0-SNAPSHOT.jar:1.0-SNAPSHOT] Caused by: org.springframework.boot.web.server.WebServerException: Unable to start embedded Tomcat at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.initialize(TomcatWebServer.java:124) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatWebServer.&lt;init&gt;(TomcatWebServer.java:86) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getTomcatWebServer(TomcatServletWebServerFactory.java:414) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory.getWebServer(TomcatServletWebServerFactory.java:178) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:179) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:152) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] ... 16 more Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;servletEndpointRegistrar&#39; defined in class path resource [org/springframework/boot/actuate/autoconfigure/endpoint/web/ServletEndpointManagementContextConfiguration$WebMvcServletEndpointManagementContextConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.endpoint.web.ServletEndpointRegistrar]: Factory method &#39;servletEndpointRegistrar&#39; threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;healthEndpoint&#39; defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthEndpointConfiguration.class]: Unsatisfied dependency expressed through method &#39;healthEndpoint&#39; parameter 1; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;healthIndicatorRegistry&#39; defined in class path resource [org/springframework/boot/actuate/autoconfigure/health/HealthIndicatorAutoConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.boot.actuate.health.HealthIndicatorRegistry]: Factory method &#39;healthIndicatorRegistry&#39; threw exception; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;org.springframework.boot.actuate.autoconfigure.jdbc.DataSourceHealthIndicatorAutoConfiguration&#39;: Unsatisfied dependency expressed through constructor parameter 0; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;dataSource&#39; defined in class path resource [com/opay/im/config/DatabaseConfig.class]: Unsatisfied dependency expressed through method &#39;dataSource&#39; parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;defaultDataSource&#39; defined in class path resource [com/opay/im/config/DatabaseConfig.class]: Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: org/apache/shardingsphere/api/config/RuleConfiguration at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:627) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:607) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) ~[spring-beans-5.1.8.RELEASE.jar!/:5.1.8.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:211) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.getOrderedBeansOfType(ServletContextInitializerBeans.java:202) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.addServletContextInitializerBeans(ServletContextInitializerBeans.java:96) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.ServletContextInitializerBeans.&lt;init&gt;(ServletContextInitializerBeans.java:85) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getServletContextInitializerBeans(ServletWebServerApplicationContext.java:252) ~[spring-boot-2.1.6.RELEASE.jar!/:2.1.6.RELEASE] 问题定位 开始排查是因为缺少 sharding-core-api-4.0.0-RC2.2-1.8.jar 包下的一个文件, 但是本地是有的 本地可以启动 服务器启动失败, 可能是jar包缺少 最后结果发现 sharding-core-api-4.0.0-RC2.2-1.8.jar 是通过公司封装的一个包传递进来的, 而封装的那个jar包在私服上已经被删除了. 删除原因","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"error","slug":"error","permalink":"https://liuzhihang.com/tags/error/"}]},{"title":"IDEA插件开发常用API","slug":"plugin/idea插件开发常用api","date":"2020-01-22T06:58:16.000Z","updated":"2020-04-04T06:47:05.729Z","comments":true,"path":"2020/01/22/idea-plugin-development-common-api.html","link":"","permalink":"https://liuzhihang.com/2020/01/22/idea-plugin-development-common-api.html","excerpt":"","text":"在开发Toolkit过程中查阅相关资料和阅读其他开源项目总结的一些常用API.整体内容来源于网络, 以及自己使用开发Toolkit过程中使用到的.总结的不到位的地方欢迎指正. 使用Gradle创建插件项目请参考: https://blog.xiaohansong.com/idea-plugin-development.html常用API请参考: https://blog.csdn.net/ExcellentYuXiao/article/details/80273448官方文档请参考: http://www.jetbrains.org/intellij/sdk/docs/welcome.html AnAction操作 创建Action集成AnAction并实现其actionPerformed方法. 在方法中可以获取到AnActionEvent对象. 代码如下: public class JsonFormatAction extends AnAction { @Override public void actionPerformed(AnActionEvent event) { // 获取当前project对象 Project project = event.getData(PlatformDataKeys.PROJECT); // 获取当前编辑的文件, 可以进而获取 PsiClass, PsiField 对象 PsiFile psiFile = event.getData(CommonDataKeys.PSI_FILE); Editor editor = event.getData(CommonDataKeys.EDITOR); // 获取Java类或者接口 PsiClass psiClass = getTargetClass(editor, psiFile); // 创建并调起 DialogWrapper DialogWrapper dialog = new JsonFormat(project, psiFile, editor, psiClass); dialog.show(); } 其他方式 // 获取project. 内部调用 getData(CommonDataKeys.PROJECT) = getDataContext().getData(CommonDataKeys.PROJECT) Project project = e.getProject(); // 获取数据上下文 DataContext dataContext = e.getDataContext(); // context可以也获取到其他信息, 入参为 PlatformDataKeys 定义的字段 Project project1 = dataContext.getData(PlatformDataKeys.PROJECT); Editor editor = dataContext.getData(PlatformDataKeys.EDITOR); PsiFile psiFile = dataContext.getData(PlatformDataKeys.PSI_FILE); PsiElement psiElement = dataContext.getData(PlatformDataKeys.PSI_ELEMENT); // 虚拟文件 VirtualFile virtualFile = dataContext.getData(PlatformDataKeys.VIRTUAL_FILE); 获取PsiClassPsiClass为java类或者接口 @Nullable protected PsiClass getTargetClass(Editor editor, PsiFile file) { int offset = editor.getCaretModel().getOffset(); PsiElement element = file.findElementAt(offset); if (element == null) { return null; } else { PsiClass target = PsiTreeUtil.getParentOfType(element, PsiClass.class); return target instanceof SyntheticElement ? null : target; } } Psixxx操作PsiClass操作API源码有注释且比较清楚, 此处仅记录我用到的一部分 // 获取全类名 String qualifiedName = aClass.getQualifiedName(); // 获取所有字段 PsiField[] fields = aClass.getFields(); PsiField操作// 获取字段名 String name = psiField.getName() PsiElement操作PsiClass和PsiField都实现了PsiElement // 删除 element.delete() // 添加元素, 向一个类中添加方法, 字段等, 也可以调用 addBefore, addAfter add(PsiElement element) PsiType操作PsiType支持常用基本类型, 但是当创建对象时则不支持.需要自己创建 PsiElementFactory psiElementFactory = JavaPsiFacade.getElementFactory(project); // String 类型 PsiType stringPsiType = psiElementFactory.createTypeFromText(\"java.lang.String\", null) // list PsiType listPsiType = psiElementFactory.createTypeFromText(\"java.util.List&lt;String>\", null); // 自定义list PsiType typeFromText = psiElementFactory.createTypeFromText(\"java.util.List&lt;\" + className + \">\", null); 搜索文件// 当前项目的所有元素 mapper, 分别填入类型, 作用域 GlobalSearchScope List&lt;DomFileElement&lt;Mapper>> fileElements = DomService.getInstance().getFileElements(Mapper.class, project, GlobalSearchScope.allScope(project)); 写入文件需要调用WriteCommandAction进行异步写入. WriteCommandAction.runWriteCommandAction(project, () -> { doGenerate(psiClass, jsonObject); }); 其他插件中有一些注释, 可以参考插件的内容. 具体可以参考我的插件Toolkit. 我的插件 Toolkit: https://github.com/liuzhihangs/toolkit copy-as-json: https://github.com/liuzhihangs/copy-as-json 感谢: 开源项目: MyBatis support: https://github.com/zhaoqin102/mybatis-support free-idea-mybatis: https://github.com/wuzhizhan/free-idea-mybatis GsonFormat: https://github.com/zzz40500/GsonFormat 相关资料: 搭建开发环境: https://blog.xiaohansong.com/idea-plugin-development.html 常用API请参考: https://blog.csdn.net/ExcellentYuXiao/article/details/80273448 官方文档请参考: http://www.jetbrains.org/intellij/sdk/docs/welcome.html 其他查询到的资料","categories":[{"name":"IDEA","slug":"IDEA","permalink":"https://liuzhihang.com/categories/IDEA/"}],"tags":[{"name":"plugin","slug":"plugin","permalink":"https://liuzhihang.com/tags/plugin/"}]},{"title":"Mac创建data目录失败","slug":"mac/mac创建data目录失败","date":"2020-01-05T10:30:30.000Z","updated":"2020-04-04T06:49:14.266Z","comments":true,"path":"2020/01/05/mac-create-data-directory-failed.html","link":"","permalink":"https://liuzhihang.com/2020/01/05/mac-create-data-directory-failed.html","excerpt":"","text":"问题描述 部分项目log日志输出路径为 /data/log, 发现无法创建目录错误信息: mkdir: cannot create directory ‘data’: Read-only file system 解决方式关闭SPI 重启 按住CMD+R进入恢复模式 打开终端 终端输入命令：csrutil disable 挂载data 在用户目录(可以自己找一个目录下创建data) ~ % > cd ~ ~ % > mkdir data 执行 sudo mount -uw / 重新挂载根目录 建立软链sudo ln -s /Users/liuzhihang/data /data 之后可以重启再打开spi了","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"},{"name":"mac","slug":"mac","permalink":"https://liuzhihang.com/tags/mac/"}]},{"title":"Hexo中插入Bilibili视频","slug":"hexo/hexo插入bilibili视频","date":"2019-09-14T07:06:54.000Z","updated":"2020-04-04T06:49:14.263Z","comments":true,"path":"2019/09/14/hexo-inserts-bilibili-video.html","link":"","permalink":"https://liuzhihang.com/2019/09/14/hexo-inserts-bilibili-video.html","excerpt":"","text":"修改matery主题首页显示视频为Bilibili视频 在Markdown插入Bilibili视频, 并设置大小. 首先找到分享嵌入代码 &lt;iframe src=\"//player.bilibili.com/player.html?aid=17963687&amp;cid=29326684&amp;page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> &lt;/iframe> 在markdown中使用嵌入代码 调整大小和居中等iframe标签属性设置 &lt;!-- 调整大小: width=\"xxx\" height=\"xxx\" --> &lt;iframe src=\"//player.bilibili.com/player.html?aid=17963687&amp;cid=29326684&amp;page=1\" width=\"600\" height=\"400\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> &lt;/iframe> 设置自适应&lt;div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> &lt;iframe src=\"//player.bilibili.com/player.html?aid=17963687&amp;cid=29326684&amp;page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\">&lt;/iframe> &lt;/div> matery 主题修改首页展示视频找到 /themes/hexo-theme-matery/layout/_widget/video.ejs 将第十一行左右代码改成Bilibili视频即可, 引入的 script 可以删掉. 修改后如下. &lt;div class=\"video-player\"> &lt;% if (theme.video.showTitle) { %> &lt;div class=\"title center-align\"> &lt;i class=\"fas fa-video-camera\">&lt;/i>&amp;nbsp;&amp;nbsp;&lt;%- theme.video.title %> &lt;/div> &lt;% } %> &lt;div class=\"row\"> &lt;div class=\"col l8 offset-l2 m10 offset-m1 s12\"> &lt;div id=\"dplayer\" class=\"dplayer-video\"> &lt;div style=\"position: relative; width: 100%; height: 0; padding-bottom: 75%;\"> &lt;iframe src=\"//player.bilibili.com/player.html?aid=16316393&amp;cid=26620787&amp;page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"position: absolute; width: 100%; height: 100%; left: 0; top: 0;\">&lt;/iframe> &lt;/div> &lt;/div> &lt;/div> &lt;/div> &lt;/div>","categories":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/tags/hexo/"}]},{"title":"Redis分布式锁的生产问题解决方案","slug":"distributed/redis分布式锁的生产问题解决方案","date":"2019-08-18T08:36:20.000Z","updated":"2020-04-04T06:49:14.275Z","comments":true,"path":"2019/08/18/redis-distributed-lock-production-problem-solution.html","link":"","permalink":"https://liuzhihang.com/2019/08/18/redis-distributed-lock-production-problem-solution.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 使用方式SET KEY VALUE TIME NX DEL KEY一般使用 NX, 只有在锁不存在的时候才加锁成功, 设置时间是为了锁永远得不到释放 存在问题及解决方法 A加锁, B释放 方法: Redisson 在tryLock时 long threadId = Thread.currentThread().getId(); protected String getLockName(long threadId) { return id + \":\" + threadId; } // id 为 UUID 会将当前 uuId+线程id写入到锁信息中, unlock时会校验是否是当前线程 A lock锁住之后, 设置了时间, 但是在时间内未完成, 导致锁自动释放, 然后B获取锁同时进行操作 方法: Redisson 在lock时会启动异步线程, 自动延期, 时间为 lockWatchdogTimeout(默认30s) Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() { 省略... }, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS); 看源码是延时 1/3的时间后开始, 就是每次1/3时间的时候延期一次. 这样理解不知道对不对 主从下, A 加锁 Master 成功后未同步给Slave 便宕机, 导致 B发现未加锁 方法: 可以修改源码, 同时加锁Master-Slave 才算加锁成功 集群状态下可以参考RedLock(红锁), 加锁多台机器, 多数成功才算成功(locks.size()/2 + 1) public class RedissonRedLock extends RedissonMultiLock { public RedissonRedLock(RLock... locks) { super(locks); } }","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"如何落地最终一致性事务","slug":"distributed/如何落地最终一致性事务","date":"2019-08-17T07:55:55.000Z","updated":"2020-04-04T06:49:14.284Z","comments":true,"path":"2019/08/17/how-to-land-the-final-consistency-transaction.html","link":"","permalink":"https://liuzhihang.com/2019/08/17/how-to-land-the-final-consistency-transaction.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 作业：如果对自己的系统落地最终一致性事务，如何落地实现？ 首先熟悉自己负责的业务, 熟悉系统间交互流程, 哪些可以异步, 哪些是必须同步 异步的时候要考虑是否需要一致性, 当前系统通知流程如图 如何落地最终一致性事务 根据课程思考最终一致性事务修改: 在收到交易请求, 成功时可以 commit half message 同时 需要实现 check方法, 供RocketMQ回调, 检查本地事务状态 在交易成功或失败时再进行commit或rollback rollback消息 RocketMQ会定期删除 通知系统收到消息存储到本地并通知商户 问题但是考虑到在这边系统完全没有必要增加事务, 因为发送消息到MQ是在交易结束后, 直接用一个字段判断状态, 然后用定时保证投递到MQ即可. RocketMQ的两段提交 half message 执行流程 根据流程结果: commit/rockback可以改成 执行流程 RocketMQ send(普通消息)在这边的使用场景中, 因为提交了 half message 也不会发送消息, 等到流程执行结束了, 然后使用send发送普通消息即可.","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"交易系统架构图","slug":"distributed/交易系统架构图","date":"2019-08-10T03:19:54.000Z","updated":"2020-04-04T06:49:14.248Z","comments":true,"path":"2019/08/10/trading-system-architecture.html","link":"","permalink":"https://liuzhihang.com/2019/08/10/trading-system-architecture.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 交易系统架构 请求流程: 请求首先到SLB(阿里云)经过负载均衡后, 到Nginx Nginx做简单负载均衡后发给交易API系统, 4C8G * 5 ECS(阿里云) 交易会根据请求参数, 路由到各个子系统, 使用dubbo 子系统收到请求, 请求风控系统校验风控 请求应用中心获取应用参数 (appId, appKey等) 拼装报文,请求渠道系统 返回信息 日志报送流程 交易成功报送清结算, 报送数据中心 filebeat拉取日志, 报送kafka, 因filebeat升级 同时存在5.x和6.x 需要加中间一层, 之前是直接报logstash logstash对数据进行过滤然后根据type 分别保送到 elasticsearch和redis 监控系统监控redis队列数据, 满足规则, 报警(发消息到通知系统) 监控系统对es数据进行过滤, 放到mysql, 用来展示商户, 渠道的交易变化等信息 kibana(直接用的kibana)提供给技术支持查询日志. es数据会定期删除, 保留15-30天的数据, 仅仅技术支持用, 不需要效率很高, 所以机器配置相对较差. 扩容方案公司体量较小, QPS高峰期也就500左右, TPS高峰期在100~200, 所以基本没有遇到问题.之前有过一段时间公众号支付交易量较大, 主要做法是增加公众号机器, 同时增加API系统机器.假如交易量提高, 一般应对就是增加机器, 和提高机器配置, 基本上都可以应对. 存在问题定时系统是仅仅通过dubbo发送调用请求, 没有业务逻辑. 所以单体基本没有遇到挂掉. 也在考虑分布式定时任务.","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"SpringCloud架构原理图","slug":"distributed/springcloud架构原理图","date":"2019-08-04T09:01:06.000Z","updated":"2020-04-04T06:49:14.254Z","comments":true,"path":"2019/08/04/springcloud-architecture-schematic.html","link":"","permalink":"https://liuzhihang.com/2019/08/04/springcloud-architecture-schematic.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 springcloud 通信原理 1. Eureka 集群 Eureka启动后, 会向其他节点注册, 相互直接视为 peer, 并互相同步注册信息. 2. 缓存机制Eureka存在三个map: registry、readWriteCacheMap、readOnlyCacheMap registry: CurrentHashMap 实时更新readWriteCacheMap: Guava Cache/LoadingCache 也是实时更新readOnlyCacheMap: CurrentHashMap 30秒同步 readWriteCacheMap一次 3. 服务注册服务注册后每30s发送一次心跳(renew)客户端每30秒请注册中心获取一次配置, 并存到本地内存中 注册中心会定时检查心跳, 连续没有3个回踢掉服务","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Dubbo底层原理架构图","slug":"distributed/dubbo底层原理架构图","date":"2019-08-03T06:33:00.000Z","updated":"2020-04-04T06:49:14.272Z","comments":true,"path":"2019/08/03/dubbo-bottom-structure-diagram.html","link":"","permalink":"https://liuzhihang.com/2019/08/03/dubbo-bottom-structure-diagram.html","excerpt":"","text":"Java进阶训练营学习笔记课程: Java进阶训练营老师: 中华石杉邀请码: 二维码 操作流程图 1. 服务注册, 故障及下线 注册: provider和consumer同时在zk上注册临时节点, 同时consumer订阅zk /dubbo/**/providers provider地址, providers发生变化, zk自动推送给consumer zk上结构如下 ls /dubbo/cn.xxx.xxxService [consumers, routers, providers, configurators] [consumer://机器ip/接口?application=服务名&category=consumers&check=false&default.check=false&default.group=beta&default.timeout=5000&default.version=1.0.0&dubbo=2.6.2&interface=接口&methods=方法1,方法2&pid=7828&revision=0.0.1&side=consumer&timestamp=1556173624632] [dubbo://机器1ip:端口/接口?anyhost=true&application=WalletOrderApplicationConsumer&delay=2000&dubbo=2.5.3&group=beta&heartbeat=10000&interface=接口&methods=方法1,方法2&pid=22419&retries=0&revision=1.0.0&side=provider&timeout=10000&timestamp=1564743170669&version=1.0.0, dubbo://机器2ip:端口/接口?anyhost=true&application=WalletOrderApplicationConsumer&delay=2000&dubbo=2.5.3&group=beta&heartbeat=10000&interface=cn.ipaynow.webank.wallet.order.api.provider.DataCenterTaskService&methods=syncRechargesRefund,syncTrans,syncTransCancel,syncTransRefunds,syncRecharges&pid=16801&retries=0&revision=0.0.1&side=provider&timeout=10000&timestamp=1563792977340&version=1.0.0] 故障: zk自动删除临时节点 下线: 取消注册, 主动删除节点 2. Proxy 动态代理根据配置的接口, 生成动态代理对象, 使用 JDK + JAVAASSIST 方式 在服务提供端，将服务的具体实现类转为Invoker 在消费端，通过 getProxy(Invoker invoker)将invoker转为客户端需要的接口 Invoker封装了Provider地址及Service接口信息 3. Cluster 集群层获取到要调用的Invoker 多个服务端会有多个 Invoker对象, 组合成Directory, Directory在zk推送Provider节点变更时, 会发生变化 Router, 按照路由规则选出本次可以调用的 Directory子集, zk注册中心 routers节点下配置 LoadBalance 从子集中按照负载均衡选出本次调用 Random LoadBalance 随机 RoundRobin LoadBalance 轮询 LeastActive LoadBalance 最少活跃 ConsistentHash LoadBalance 一致性哈希 容错 Failover Cluster 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=”2″ 来设置重试次数(不含第一次)。 Failfast Cluster：快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster：失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster：并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=”2″ 来设置最大并行数。 4. Protocol 远程调用层包含两个接口, 分别是 暴露服务(export) 和 引用服务(refer) 分别对应provider 和 consumer选择通信协议 dubbo, hessian, http等 5. Exchange 数据交换层将请求信息封装为Request, 然后发送给 Transport层, 并将返回信息封装为Response 6. Transport 网络传输层使用netty或mina进行网络通信 7. serialize 序列化层将请求报文和返回报文记性序列化和反序列化 8. provider收到请求后先进行反序列化, 然后在解析请求, 通过动态代理调用相应方法","categories":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://liuzhihang.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"SpringBoot项目中使用SpringSecurity和JWT做权限认证","slug":"spring/springboot项目中使用springsecurity和jwt做权限认证","date":"2019-07-22T05:36:22.000Z","updated":"2020-06-18T08:23:42.361Z","comments":true,"path":"2019/07/22/springsecurity-jwt-springboot-project.html","link":"","permalink":"https://liuzhihang.com/2019/07/22/springsecurity-jwt-springboot-project.html","excerpt":"","text":"背景 前段时间做了一个项目, 因为涉及到权限认证, 所以分别调研了 SpringSecurity 和 Apache Shiro. 最后选择使用了 SpringSecurity + JWT做权限认证, 现在项目已经结束, 总相关笔记.项目下载地址 jwt-demo 使用JWT生成token token存储在数据库中 使用 application/json 登录 使用手机号进行登录 URI动态拦截 配置过程添加依赖 分别添加 SpringSecurity JWT 和 fastjson 依赖 &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-security&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>io.jsonwebtoken&lt;/groupId> &lt;artifactId>jjwt&lt;/artifactId> &lt;version>0.9.0&lt;/version> &lt;/dependency> &lt;!--json--> &lt;dependency> &lt;groupId>com.alibaba&lt;/groupId> &lt;artifactId>fastjson&lt;/artifactId> &lt;version>1.2.60&lt;/version> &lt;/dependency> 基础准备对象 主要是在用户登录成功handle时使用JWT生成Token返回给客户端. 基础使用dto请求返回基类 @Data public class BaseReqDto implements Serializable { private String version; } @Data public class BaseRespDto implements Serializable { private String resultCode; private String resultMsg; private String resultTime; } 登录请求返回对象 @Data public class LoginReqDto { private String username; private String token; } @Data public class LoginRespDto extends BaseRespDto { private String token; } 用于验证的用户package com.liuzhihang.demo.bean; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import java.io.Serializable; import java.util.Collection; /** * 用户信息校验验证码 * * @author liuzhihang */ public class UserDetailsImpl implements UserDetails, Serializable { /** * 用户名 */ private String username; /** * 密码 */ private String password; /** * 权限集合 */ private Collection&lt;? extends GrantedAuthority> authorities; @Override public Collection&lt;? extends GrantedAuthority> getAuthorities() { return this.authorities; } public void setAuthorities(Collection&lt;? extends GrantedAuthority> authorities) { this.authorities = authorities; } @Override public String getPassword() { return this.password; } @Override public String getUsername() { return this.username; } public void setUsername(String username) { this.username = username; } public void setPassword(String password) { this.password = password; } @Override public boolean isAccountNonExpired() { return true; } @Override public boolean isAccountNonLocked() { return true; } @Override public boolean isCredentialsNonExpired() { return true; } @Override public boolean isEnabled() { return true; } } 用户未登录handle /** * 用户登录认证, 未登录返回信息 * * @author liuzhihang * @date 2019-06-04 13:52 */ @Component public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint { private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"); @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException e) throws IOException { response.setContentType(\"application/json;charset=UTF-8\"); LoginRespDto respDto = new LoginRespDto(); respDto.setResultCode(\"0001\"); respDto.setResultMsg(\"用户未登录\"); respDto.setResultTime(LocalDateTime.now().format(FORMATTER)); response.getWriter().write(JSON.toJSONString(respDto)); } } 用户登录验证失败handle/** * 用户登录认证失败返回的信息 * * @author liuzhihang * @date 2019-06-04 13:57 */ @Component public class AuthenticationFailureHandlerImpl implements AuthenticationFailureHandler { private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"); @Override public void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response, AuthenticationException exception) throws IOException { response.setContentType(\"application/json;charset=UTF-8\"); LoginRespDto respDto = new LoginRespDto(); respDto.setResultCode(\"0001\"); respDto.setResultMsg(\"用户登录认证失败\"); respDto.setResultTime(LocalDateTime.now().format(FORMATTER)); response.getWriter().write(JSON.toJSONString(respDto)); } } 用户无权访问handle/** * 当用户访问无权限页面时, 返回信息 * * @author liuzhihang * @date 2019-06-04 14:03 */ @Component public class AccessDeniedHandlerImpl implements AccessDeniedHandler { private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"); @Override public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException { response.setContentType(\"application/json;charset=UTF-8\"); LoginRespDto respDto = new LoginRespDto(); respDto.setResultCode(\"0002\"); respDto.setResultMsg(\"用户无权访问\"); respDto.setResultTime(LocalDateTime.now().format(FORMATTER)); response.getWriter().write(JSON.toJSONString(respDto)); } } 用户登录成功handle /** * 用户登录成功之后的返回信息 * * @author liuzhihang * @date 2019-06-04 14:20 */ @Slf4j @Component public class AuthenticationSuccessHandlerImpl implements AuthenticationSuccessHandler { private static final DateTimeFormatter FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\"); @Resource private JwtTokenUtil jwtTokenUtil; @Override public void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException { UserDetailsImpl userDetails = (UserDetailsImpl) authentication.getPrincipal(); String jwtToken = jwtTokenUtil.generateToken(userDetails); // 把生成的token更新到数据库中 // 更新DB操作 ... response.setContentType(\"application/json;charset=UTF-8\"); LoginRespDto respDto = new LoginRespDto(); respDto.setToken(jwtToken); respDto.setResultCode(\"0000\"); respDto.setResultMsg(\"登录成功\"); respDto.setResultTime(LocalDateTime.now().format(FORMATTER)); response.getWriter().write(JSON.toJSONString(respDto)); } } JwtTokenUtil主要用来生成token和通过token解析对象等操作. package com.liuzhihang.demo.utils; import com.liuzhihang.demo.bean.UserDetailsImpl; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.stereotype.Component; import java.time.Instant; import java.util.Date; /** * 使用 java-jwt jwt类库 * * @author liuzhihang * @date 2019-06-05 09:22 */ @Component public class JwtTokenUtil { private static final SignatureAlgorithm SIGN_TYPE = SignatureAlgorithm.HS256; public static final String SECRET = \"jwt-secret\"; /** * JWT超时时间 */ public static final long EXPIRED_TIME = 7 * 24 * 60 * 60 * 1000L; /** * claims 为自定义的私有声明, 要放在前面 * &lt;p> * 生成token */ public String generateToken(UserDetails userDetails) { long instantNow = Instant.now().toEpochMilli(); Claims claims = Jwts.claims(); claims.put(Claims.SUBJECT, userDetails.getUsername()); return Jwts.builder().setClaims(claims).setIssuedAt(new Date(instantNow)) .setExpiration(new Date(instantNow + EXPIRED_TIME)) .signWith(SIGN_TYPE, SECRET).compact(); } /** * claims 为自定义的私有声明, 要放在前面 * &lt;p> * 生成token */ public String generateToken(String userName) { long instantNow = Instant.now().toEpochMilli(); Claims claims = Jwts.claims(); claims.put(Claims.SUBJECT, userName); return Jwts.builder().setClaims(claims).setIssuedAt(new Date(instantNow)) .setExpiration(new Date(instantNow + EXPIRED_TIME)) .signWith(SIGN_TYPE, SECRET).compact(); } /** * 将token解析, 映射为 UserDetails * * @param jwtToken * @return */ public UserDetails getUserDetailsFromToken(String jwtToken) { Claims claimsFromToken = getClaimsFromToken(jwtToken); String userName = claimsFromToken.get(Claims.SUBJECT, String.class); UserDetailsImpl userDetails = new UserDetailsImpl(); userDetails.setUsername(userName); return userDetails; } /** * 验证token */ public Boolean validateToken(String token, UserDetails userDetails) { UserDetailsImpl user = (UserDetailsImpl) userDetails; String username = getPhoneNoFromToken(token); return (username.equals(user.getUsername()) &amp;&amp; !isTokenExpired(token)); } /** * 刷新令牌 * * @param token 原令牌 * @return 新令牌 */ public String refreshToken(String token) { String refreshedToken; try { Claims claims = getClaimsFromToken(token); long instantNow = Instant.now().toEpochMilli(); refreshedToken = Jwts.builder().setClaims(claims).setIssuedAt(new Date(instantNow)) .setExpiration(new Date(instantNow + EXPIRED_TIME)) .signWith(SIGN_TYPE, SECRET).compact(); } catch (Exception e) { refreshedToken = null; } return refreshedToken; } /** * 获取token是否过期 */ public Boolean isTokenExpired(String token) { Date expiration = getExpirationDateFromToken(token); return expiration.before(new Date()); } /** * 根据token获取username */ public String getPhoneNoFromToken(String token) { return getClaimsFromToken(token).getSubject(); } /** * 获取token的过期时间 */ public Date getExpirationDateFromToken(String token) { return getClaimsFromToken(token).getExpiration(); } /** * 解析JWT */ private Claims getClaimsFromToken(String token) { return Jwts.parser().setSigningKey(SECRET).parseClaimsJws(token).getBody(); } } WebSecurityConfig 核心配置package com.liuzhihang.demo.config; import com.liuzhihang.demo.filter.CustomizeAuthenticationFilter; import com.liuzhihang.demo.filter.JwtPerTokenFilter; import com.liuzhihang.demo.service.UserDetailServiceImpl; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.web.AuthenticationEntryPoint; import org.springframework.security.web.access.AccessDeniedHandler; import org.springframework.security.web.authentication.AuthenticationFailureHandler; import org.springframework.security.web.authentication.AuthenticationSuccessHandler; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import javax.annotation.Resource; /** * @author liuzhihang * @date 2019-06-03 14:25 */ @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private UserDetailServiceImpl userDetailServiceImpl; @Resource private JwtPerTokenFilter jwtPerTokenFilter; @Resource(name = \"authenticationEntryPointImpl\") private AuthenticationEntryPoint authenticationEntryPoint; @Resource(name = \"authenticationSuccessHandlerImpl\") private AuthenticationSuccessHandler authenticationSuccessHandler; @Resource(name = \"authenticationFailureHandlerImpl\") private AuthenticationFailureHandler authenticationFailureHandler; @Resource(name = \"accessDeniedHandlerImpl\") private AccessDeniedHandler accessDeniedHandler; /** * 创建用于认证授权的用户 * * @param auth * @throws Exception */ @Autowired public void configureUserInfo(AuthenticationManagerBuilder auth) throws Exception { // 放入自己的认证授权用户, 内部逻辑需要自己实现 // UserDetailServiceImpl implements UserDetailsService auth.userDetailsService(userDetailServiceImpl); } @Override protected void configure(HttpSecurity http) throws Exception { http // 使用JWT, 关闭session .csrf().disable().sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and().httpBasic().authenticationEntryPoint(authenticationEntryPoint) // 登录的权限, 成功返回信息, 失败返回信息 .and().formLogin().permitAll() .loginProcessingUrl(\"/login\") // 配置url 权限 antMatchers: 匹配url 权限 .and().authorizeRequests() .antMatchers(\"/login\", \"/getVersion\") .permitAll() // 其他需要登录才能访问 .anyRequest().access(\"@dynamicAuthorityService.hasPermission(request,authentication)\") // 访问无权限 location 时 .and().exceptionHandling().accessDeniedHandler(accessDeniedHandler) // 自定义过滤 .and().addFilterAt(customAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class) .addFilterBefore(jwtPerTokenFilter, UsernamePasswordAuthenticationFilter.class) .headers().cacheControl(); } /** * 密码加密器 */ @Bean public PasswordEncoder passwordEncoder() { /** * BCryptPasswordEncoder：相同的密码明文每次生成的密文都不同，安全性更高 */ return new BCryptPasswordEncoder(); } @Bean CustomizeAuthenticationFilter customAuthenticationFilter() throws Exception { CustomizeAuthenticationFilter filter = new CustomizeAuthenticationFilter(); filter.setAuthenticationSuccessHandler(authenticationSuccessHandler); filter.setAuthenticationFailureHandler(authenticationFailureHandler); filter.setAuthenticationManager(authenticationManagerBean()); return filter; } } 登录校验过程 graph TD; A(请求登录) --> B(CustomizeAuthenticationFilter#attemptAuthentication 解析请求的json); B --> C(UserDetailServiceImpl#loadUserByUsername 验证用户名密码); C --> D(AuthenticationSuccessHandlerImpl#onAuthenticationSuccess 构建返回参数 包括token); D --> E(返回结果) 自定义拦截器解析 json 报文前端请求登录报文类型为 application/json 需要后端增加拦截器, 对登录请求报文进行解析 package com.liuzhihang.demo.filter; import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONException; import com.alibaba.fastjson.JSONObject; import lombok.extern.slf4j.Slf4j; import org.springframework.http.MediaType; import org.springframework.security.authentication.AuthenticationServiceException; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.Authentication; import org.springframework.security.core.AuthenticationException; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.BufferedReader; import java.io.IOException; /** * * 自定义拦截器, 重写UsernamePasswordAuthenticationFilter 从而可以处理 application/json 中的json请求报文 * * @author liuzhihang * @date 2019-06-12 19:04 */ @Slf4j public class CustomizeAuthenticationFilter extends UsernamePasswordAuthenticationFilter { @Override public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException { // attempt Authentication when Content-Type is json if (request.getContentType().equalsIgnoreCase(MediaType.APPLICATION_JSON_UTF8_VALUE) || request.getContentType().equalsIgnoreCase(MediaType.APPLICATION_JSON_VALUE)) { try { BufferedReader br = request.getReader(); String str; StringBuilder jsonStr = new StringBuilder(); while ((str = br.readLine()) != null) { jsonStr.append(str); } log.info(\"本次登录请求参数:{}\", jsonStr); JSONObject jsonObject = JSON.parseObject(jsonStr.toString()); UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( jsonObject.getString(\"username\"), jsonObject.getString(\"password\")); setDetails(request, authRequest); return this.getAuthenticationManager().authenticate(authRequest); } catch (IOException e) { log.info(\"用户登录, 请求参数 不正确\"); throw new AuthenticationServiceException(\"获取报文请求参数失败\"); } catch (JSONException e) { log.info(\"用户登录, 请求报文格式 不正确\"); throw new AuthenticationServiceException(\"请求报文, 转换Json失败\"); } } else { log.error(\"用户登录, contentType 不正确\"); throw new AuthenticationServiceException( \"请求 contentType 不正确, 请使用 application/json;charset=UTF-8 或者 application/json;\"); } } } 用户认证模块 根据获取到的username从数据库中查询到密码, 将用户名密码赋值给UserDetails对象, 返回其他的框架会进行校验 这边使用中是使用的手机号+验证码登录, 所以 上面json解析的也是 phoneNo+verificationCode 在这块 username仅仅代指登录名, 可以是手机号可以是别的. 这边使用中验证码是从redis中获取的. 获取不到返回失败, 获取到和传递的不一致也算失败. package com.liuzhihang.demo.service; import com.liuzhihang.demo.bean.UserDetailsImpl; import lombok.extern.slf4j.Slf4j; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.stereotype.Component; /** * @author liuzhihang */ @Slf4j @Component(\"userDetailServiceImpl\") public class UserDetailServiceImpl implements UserDetailsService { /** * 用来验证登录名是否有权限进行登录 * * 可以通过数据库进行校验 也可以通过redis 等等 * * @param username * @return * @throws UsernameNotFoundException */ @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { UserDetailsImpl userDetailsImpl = new UserDetailsImpl(); userDetailsImpl.setUsername(\"liuzhihang\"); userDetailsImpl.setPassword(new BCryptPasswordEncoder().encode(\"123456789\")); return userDetailsImpl; } } 请求校验过程 graph TD; A(请求接口) --> B(JwtPerTokenFilter#doFilterInternal 验证Header中的token); B --> C(DynamicAuthorityService#hasPermission 验证有没有请求url权限); C --> D(处理逻辑); D --> E(返回结果) JWTToken拦截器主要是拦截请求, 验证Header中的token是否正确 package com.liuzhihang.demo.filter; import com.liuzhihang.demo.utils.JwtTokenUtil; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.web.authentication.WebAuthenticationDetailsSource; import org.springframework.stereotype.Component; import org.springframework.web.filter.OncePerRequestFilter; import javax.servlet.FilterChain; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * @author liuzhihang * @date 2019-06-05 09:09 */ @Slf4j @Component public class JwtPerTokenFilter extends OncePerRequestFilter { @Autowired private JwtTokenUtil jwtTokenUtil; /** * 存放Token的Header Key */ private static final String HEADER_STRING = \"token\"; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { String token = request.getHeader(HEADER_STRING); if (null != token &amp;&amp; !jwtTokenUtil.isTokenExpired(token)) { UserDetails userDetails = jwtTokenUtil.getUserDetailsFromToken(token); String username = userDetails.getUsername(); if (username != null &amp;&amp; SecurityContextHolder.getContext().getAuthentication() == null) { // 通过 username 查询数据库 获取token 然后和库中token作比较 if (username.equals(\"liuzhihang\")) { UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities()); authentication.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); SecurityContextHolder.getContext().setAuthentication(authentication); } } } filterChain.doFilter(request, response); } } URI动态校验package com.liuzhihang.demo.service; import lombok.extern.slf4j.Slf4j; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.Authentication; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; import java.util.HashSet; import java.util.Set; /** * 动态权限认证 * * @author liuzhihang * @date 2019-06-25 15:51 */ @Slf4j @Component(value = \"dynamicAuthorityService\") public class DynamicAuthorityService { public boolean hasPermission(HttpServletRequest request, Authentication authentication) { try { Object principal = authentication.getPrincipal(); if (principal instanceof UserDetails &amp;&amp; authentication instanceof UsernamePasswordAuthenticationToken) { // 本次请求的uri String uri = request.getRequestURI(); // 获取当前用户 UserDetails userDetails = (UserDetails) principal; String username = userDetails.getUsername(); log.info(\"本次用户请求认证, username:{}, uri:{}\", username, uri); // 从数据库取逻辑 if (username.equals(\"liuzhihang\")){ Set&lt;String> set = new HashSet&lt;>(); set.add(\"/homeInfo\"); set.add(\"/getAllUser\"); set.add(\"/editUserInfo\"); if (set.contains(uri)) { return true; } } } } catch (Exception e) { log.error(\"用户请求登录, uri:{} error\", request.getRequestURI(), e); return false; } return false; } } 测试脚本在 httpclient脚本 POST localhost:8080/login Content-Type: application/json { \"username\": \"liuzhihang\", \"password\": \"123456789\" } ### 请求接口脚本 POST localhost:8080/homeInfo Content-Type: application/json token: eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJsaXV6aGloYW5nIiwiaWF0IjoxNTY5MDI1NjY4LCJleHAiOjE1Njk2MzA0Njh9.Kot_uLnwtcq-t5o4x3V-xBnpf-mKEi7OV2eAfgMCKLk ### 返回: { \"resultCode\": \"0000\", \"resultMsg\": \"登录成功\", \"resultTime\": \"20190920191038\", \"token\": \"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJsaXV6aGloYW5nIiwiaWF0IjoxNTY4OTc3ODM4LCJleHAiOjE1Njk1ODI2Mzh9.MAS9VkFdCF3agkCgTtc0VzPMFjY42vFyIvAEzkSeAfs\" } 参考前后端分离 SpringBoot + SpringSecurity + JWT + RBAC 实现用户无状态请求验证","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"https://liuzhihang.com/tags/JWT/"},{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"https://liuzhihang.com/tags/SpringSecurity/"}]},{"title":"Gitalk使用MD5生成Id","slug":"hexo/Gitalk使用MD5生成Id","date":"2019-07-20T07:43:07.000Z","updated":"2020-04-07T11:58:47.380Z","comments":true,"path":"2019/07/20/gitalk-uses-md5-to-generate-an-id.html","link":"","permalink":"https://liuzhihang.com/2019/07/20/gitalk-uses-md5-to-generate-an-id.html","excerpt":"","text":"Gitalk默认使用: location.pathname 作为 gitalk 的id, 但是location.path必须小于50位切换主题时, 每个主题使用的处理方式都不相同, 有可能会导致换了主题, 发现之前的评论不见了, 下面介绍使用MD5作为id, 同时在换主题时一定要修改这个id的规则. Gitalk使用使用Gitalk方法: var gitalk = new Gitalk({ clientID: 'GitHub Application Client ID', clientSecret: 'GitHub Application Client Secret', repo: 'GitHub repo', owner: 'GitHub repo owner', admin: ['GitHub repo owner and collaborators, only these guys can initialize github issues'], id: location.pathname, // Ensure uniqueness and length less than 50 distractionFreeMode: false // Facebook-like distraction free mode }) gitalk.render('gitalk-container') 使用MD5生成id 引入js MD5 js 下载地址 &lt;script src=\"js/md5.min.js\">&lt;/script> 修改js &lt;script> var gitalk_id = md5(location.pathname) if (&lt;%- page.comments_type == '404' %>) { gitalk_id = md5('https://liuzhihang.com/404') } let gitalk = new Gitalk({ clientID: '&lt;%- theme.gitalk.oauth.clientId %>', clientSecret: '&lt;%- theme.gitalk.oauth.clientSecret %>', repo: '&lt;%- theme.gitalk.repo %>', owner: '&lt;%- theme.gitalk.owner %>', admin: &lt;%- JSON.stringify(theme.gitalk.admin) %>, id: gitalk_id, distractionFreeMode: false // Facebook-like distraction free mode }); gitalk.render('gitalk-container'); &lt;/script>","categories":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/tags/hexo/"}]},{"title":"IDEA插件--Toolkit","slug":"plugin/tookit","date":"2019-05-11T06:50:48.000Z","updated":"2020-04-20T03:06:54.009Z","comments":true,"path":"2019/05/11/idea-plugin-toolkit.html","link":"","permalink":"https://liuzhihang.com/2019/05/11/idea-plugin-toolkit.html","excerpt":"","text":"Toolkit 一个小工具包, 暂时还有很多功能需要扩展. 特征 Mybatis 通过侧栏箭头在 MyBatis XML文件和 Mapper文件之间相互跳转 mapper文件id简单检查 Json JavaBean复制为Json字符串 Json字符串格式化 Json字符串转换为JavaBean Json压缩 XML: Xml格式化 演示 文末演示 安装 在线安装: File -&gt; Setting -&gt; Plugins -&gt; 搜索 Toolkit 手动安装: 下载插件 -&gt; File -&gt; Setting -&gt; Plugins -&gt; Install Plugin from Disk... 使用 右键菜单选择 Tookit 更新v1.0.7 (2020-02-27) 修改使用包装类型 查看更多历史更新记录 感谢MyBatis:&emsp;mybatis support: https://github.com/zhaoqin102/mybatis-support &emsp;free-idea-mybatis: https://github.com/wuzhizhan/free-idea-mybatis Json:&emsp;GsonFormat: https://github.com/zzz40500/GsonFormat 本工具使用 JetBrains IDEA 进行开发 演示","categories":[{"name":"IDEA","slug":"IDEA","permalink":"https://liuzhihang.com/categories/IDEA/"}],"tags":[{"name":"plugin","slug":"plugin","permalink":"https://liuzhihang.com/tags/plugin/"}]},{"title":"elasticsearch cat API","slug":"elk/es-cat","date":"2019-03-14T14:01:00.000Z","updated":"2020-04-04T06:17:45.542Z","comments":true,"path":"2019/03/14/elasticsearch-cat-api.html","link":"","permalink":"https://liuzhihang.com/2019/03/14/elasticsearch-cat-api.html","excerpt":"cat API官方地址 GET /_cat/XXX?vGET /_cat/XXX?v&amp;format=json v 是指带着列信息 支持指定返回内容的格式 默认为text ?format=text(json/smile/yaml/cbor)","text":"cat API官方地址 GET /_cat/XXX?vGET /_cat/XXX?v&amp;format=json v 是指带着列信息 支持指定返回内容的格式 默认为text ?format=text(json/smile/yaml/cbor) 查看节点别名 GET /_cat/aliases?vcurl -X GET “192.168.xxx.xxx:9200/_cat/aliases?v” 每个节点分配了几个shard，对磁盘的占用空间大小，使用率 GET /_cat/allocation?vcurl -X GET “192.168.xxx.xxx:9200/_cat/allocation?v” 群集或单个索引的document计数 GET /_cat/count?vcurl -X GET “192.168.xxx.xxx:9200/_cat/count?v GET /_cat/count/index_name?vcurl -X GET “192.168.xxx.xxx:9200/_cat/count/index_name?v” 显示集群中每个数据节点上fielddata当前正在使用的堆内存量 GET /_cat/fielddata?vcurl -X GET “192.168.xxx.xxx:9200/_cat/fielddata?v” 查看集群健康情况 GET /_cat/health?vcurl -X GET “192.168.xxx.xxx:9200/_cat/health?v” 查看索引的信息 GET _cat/indices?vGET _cat/indices/index_name?vcurl -X GET “192.168.xxx.xxx:9200/_cat/indices/twi*?v&amp;s=index” 查看master信息 GET /_cat/master?vcurl -X GET “192.168.xxx.xxx:9200/_cat/master?v” 查看node信息 GET /_cat/nodes?vcurl -X GET “192.168.xxx.xxx:9200/_cat/nodes?v” 当前pending没执行完的task的具体情况，执行的是什么操作 创建索引，更新映射，分配或失败分片的列表GET /_cat/pending_tasks?vcurl -X GET “192.168.xxx.xxx:9200/_cat/pending_tasks?v” 查看安装的插件 GET /_cat/plugins?v&amp;s=component&amp;h=name,component,version,descriptioncurl -X GET “192.168.xxx.xxx:9200/_cat/plugins?v&amp;s=component&amp;h=name,component,version,description” shard recovery恢复的过程情况 GET /_cat/recovery?vcurl -X GET “192.168.xxx.xxx:9200/_cat/recovery?v” 查看在群集中注册的快照存储库 GET /_cat/repositories?vcurl -X GET “192.168.xxx.xxx:9200/_cat/repositories?v 查看线程池使用 GET /_cat/thread_poolcurl -X GET “192.168.xxx.xxx:9200/_cat/thread_pool” 查看shard情况 GET _cat/shards?vGET _cat/shards/index_name?vcurl -X GET “192.168.xxx.xxx:9200/_cat/shards/index_name?v 索引segment文件的情况，在哪个node上，有多少个document，占用了多少磁盘空间，有多少数据在内存中，是否可以搜索 GET /_cat/segments?vGET _cat/segments/index_name?vcurl -X GET “192.168.xxx.xxx:9200/_cat/segments/index_name?v 查看tempalte GET /_cat/templates?v&amp;s=namecurl -X GET “192.168.xxx.xxx:9200/_cat/templates?v&amp;s=name”","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"为什么es集群至少需要三个节点","slug":"elk/es集群至少三个节点","date":"2019-03-13T13:01:04.000Z","updated":"2020-06-18T08:23:00.411Z","comments":true,"path":"2019/03/13/why-does-the-es-cluster-require-at-least-three-nodes.html","link":"","permalink":"https://liuzhihang.com/2019/03/13/why-does-the-es-cluster-require-at-least-three-nodes.html","excerpt":"elasticsearch集群 graph LR; A(Master Node) --- B(Data Node); A --- C(Data Node); B --- C; Master: 在Elasticsearch中Master仅仅负责维护集群的状态 创建或删除索引 跟踪哪些节点是集群的一部分 决定将哪些碎片分配给哪个节点 等集群范围的操作 上面的一些集群信息, 是由Master节点进行维护, 但是 Master也会把节点信息, 同步给其他节点, 但是只有master节点可以修改.","text":"elasticsearch集群 graph LR; A(Master Node) --- B(Data Node); A --- C(Data Node); B --- C; Master: 在Elasticsearch中Master仅仅负责维护集群的状态 创建或删除索引 跟踪哪些节点是集群的一部分 决定将哪些碎片分配给哪个节点 等集群范围的操作 上面的一些集群信息, 是由Master节点进行维护, 但是 Master也会把节点信息, 同步给其他节点, 但是只有master节点可以修改. 点击查看Elasticsearch节点介绍 为什么要至少三个节点首先查看 Elasticsearch 的配置文件, 如下:Zen Discovery 官方介绍 # 传递初始主机列表，以便在启动新节点时执行发现 discovery.zen.ping.unicast.hosts: [\"192.168.xxx.xxx:9300\", \"192.168.xxx.xxx:9300\"] # 选举Maste时需要的节点数 (total number of master-eligible nodes / 2 + 1) 防止“防止脑裂” discovery.zen.minimum_master_nodes: 2 # 一个节点多久ping一次，默认1s discovery.zen.fd.ping_interval: 1s # 等待ping返回时间，默认30s discovery.zen.fd.ping_timeout: 30s # ping超时重试次数，默认3次 discovery.zen.fd.ping_retries: 3 discovery.zen.minimum_master_nodes: 2其中 minimum_master_nodes 配置是为了防止脑裂 假设 Elasticsearch 有两个节点 graph LR; A(Master Node) --- B(Data Node); graph LR; A(Master Node) -.X.- B(Data Node); discovery.zen.minimum_master_nodes: 1 此时出现网络波动, 导致 A—B 之间短暂断开连接, 根据选举规则, B将自己选举为 Master, 当网络波动结束, 就会出现两个Master的情况. graph LR; A(Master Node 宕机) --- B(Data Node); discovery.zen.minimum_master_nodes: 2 Master 出现故障, 则 B 将永远不可能将自己选择为 Master Elasticsearch 有三个节点三节点配置: discovery.zen.minimum_master_nodes: 2 graph LR; A(Master Node) -.X.- B(Data Node); A -.X.- C(Data Node); B --- C; 出现网络波动 A 节点 和 别的节点短暂断开连接 graph LR; A(Master Node -> Data Node) -.X.- B(Data Node -> Master Node); A -.X.- C(Data Node); B --- C; A节点降级, B和C 进行选举, 此处模拟选举B为 Master Node graph LR; A(Data Node) --- B(Master Node); A --- C(Data Node); B --- C; 网络恢复后的节点状况. 总结以上可以看出, 通过配置 minimum_master_nodes 来防止出现脑裂同时在生产过程中, 为了尽量保持集群高可用, 至少需要三台机器搭建集群","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"Elasticsearch 数据写入流程","slug":"elk/es数据写入过程","date":"2019-03-12T06:25:59.000Z","updated":"2020-04-04T06:49:14.257Z","comments":true,"path":"2019/03/12/elasticsearch-data-writing-process.html","link":"","permalink":"https://liuzhihang.com/2019/03/12/elasticsearch-data-writing-process.html","excerpt":"简单流程 客户端随机选择一个node发送数据, 此时该node为协调节点(coordinating node) 1.1. coordinating node 通过 _id计算出该document在哪个shard上, 假设为shard0, 计算方式如下: hash(_id) % number_of_primary_shards 1.2. node 根据 cluster state 获取到 shard0 在 node1 上","text":"简单流程 客户端随机选择一个node发送数据, 此时该node为协调节点(coordinating node) 1.1. coordinating node 通过 _id计算出该document在哪个shard上, 假设为shard0, 计算方式如下: hash(_id) % number_of_primary_shards 1.2. node 根据 cluster state 获取到 shard0 在 node1 上 将消息发送到 node1 的 P0 上 P0 收到数据后, 将数据同步到 自己的 replica shard R0上 P0 和 R0 都处理完毕, 才会返回客户端成功 Px 为 primary shardRx 为 replica shard当客户端请求为查询时, 路由到任意 shard(primary shard 或者 replica shard) 查询到数据即可返回. 详细流程 P0收到document, 同时将数据写入到 内存buffer和translog中 每隔1s或buffer满时, buffer中的数据会 refresh 到segment中, 而后进入os cache, 一旦segment进入到 cache中,其中的数据, 则可以被搜索到 refresh 时间可以手动设置, 也可以手动触发 refresh 清空buffer, translog不处理 重复1-3操作, translog不断增大, translog每隔30分钟,或大到一定量时, 会触发commit操作 将buffer中内容刷新到segment中, 并清空buffer 将一个commit point 写入到磁盘文件中, 标识此次commit 对应的 segment 执行 fsync 将 os cache 中的数据强制刷新到磁盘文件中 删除 translog 文件 删除和更新操作 在commit时, 如果操作为删除, 生成一个 .del文件, 其中将该document标记位deleted, 并不是真正的物理删除, 此时如果有查询请求, 会先查询 .del文件中是否有该记录, 如果有, 则回复不存在.在commit时, 如果为更新操作, 则是将原document标记位deleted, 同时写入一条新数据 服务宕机重启, translog 日志作用 translog是先写入到 os cache中, 然后每隔5s写入到磁盘文件中, 假如服务宕掉, 可能会失去5s数据, 也可以修改写入磁盘的时机, 但是可能会影响性能translog中记录的是数据操作信息, 在服务宕机重启时, 会读取translog磁盘文件, 然后将translog中的数据重新恢复到 segment中, 然后进行后续操作 segment merge 过程 segment 持续生成, 会导致 segment不断变多, 占用文件句柄, cpu资源等等es后台有一个专门的程序负责合并segment, 将小的 segment 合成大的segment, 同时写一个commit point, 标识 新的segment file.打开新的segment供查询使用, 删除旧的 segmentsegment 合并过程中, 被标记位 deleted 的document 不会被合并. 即: 在合并 segment时, 才将 document 真正物理删除合并的segment 可以使磁盘上已经commit的索引 也可以是内存中还未commit的索引","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"logstash input多个kafka异常","slug":"issue/logstash-kafka-error","date":"2019-03-04T11:09:06.000Z","updated":"2020-06-18T08:21:30.033Z","comments":true,"path":"2019/03/04/logstash-input-multiple-kafka-exceptions.html","link":"","permalink":"https://liuzhihang.com/2019/03/04/logstash-input-multiple-kafka-exceptions.html","excerpt":"问题描述 graph LR; filebeat --> logstash; log4j --> logstash; logstash --> es; filebeat 和 log4j appender 同时到 kafka, logstash在启动时报错, 错误如下: javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=logstash-0","text":"问题描述 graph LR; filebeat --> logstash; log4j --> logstash; logstash --> es; filebeat 和 log4j appender 同时到 kafka, logstash在启动时报错, 错误如下: javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=logstash-0 问题原因及解决input 消费kafka时, 分别指定不同的 client_id. kafka { bootstrap_servers =&gt; [&quot;192.168.103.43:9092&quot;] # 注意这里配置的kafka的broker地址不是zk的地址 client_id =&gt; &quot;kafka_client_1&quot; group_id =&gt; &quot;logstash&quot; topics =&gt; [&quot;ipaynow_log&quot;] # kafka topic 名称 consumer_threads =&gt; 5 decorate_events =&gt; true type =&gt; &quot;string&quot; codec =&gt; &quot;json&quot; } kafka { bootstrap_servers =&gt; [&quot;192.168.103.43:9092&quot;] # 注意这里配置的kafka的broker地址不是zk的地址 client_id =&gt; &quot;kafka_client_2&quot; group_id =&gt; &quot;logstash&quot; topics =&gt; [&quot;ipaynow-hunter&quot;] # kafka topic 名称 consumer_threads =&gt; 5 decorate_events =&gt; true type =&gt; &quot;string&quot; codec =&gt; plain { charset=&gt;&quot;UTF-8&quot; } }","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"程序无异常中断","slug":"issue/程序无异常中断","date":"2019-02-15T02:46:48.000Z","updated":"2020-04-04T06:23:27.483Z","comments":true,"path":"2019/02/15/no-abnormal-interruption-of-the-program.html","link":"","permalink":"https://liuzhihang.com/2019/02/15/no-abnormal-interruption-of-the-program.html","excerpt":"问题描述 程序执行到某一处之后停顿, 不能继续执行, 不抛出异常, 无返回值 本地测试正常 debug可以正常执行 操作为入库之前, 创建对象, 是一个很简单的set操作 payInfoExtra.setToAccType(agPayReqDto.getToAccType().getValue()); 其中get操作获取的为一个枚举, 主要操作为从枚举中获取value set到另一个对象中","text":"问题描述 程序执行到某一处之后停顿, 不能继续执行, 不抛出异常, 无返回值 本地测试正常 debug可以正常执行 操作为入库之前, 创建对象, 是一个很简单的set操作 payInfoExtra.setToAccType(agPayReqDto.getToAccType().getValue()); 其中get操作获取的为一个枚举, 主要操作为从枚举中获取value set到另一个对象中 public AccTypeEnum getToAccType() { return toAccType; } 问题原因及解决小伙伴在他们项目中复用本项目中的枚举类, 没有修改包名类名, 但是把枚举中value字段从 byte改成了String, 同时放在了依赖中, 提供给我们使用.解决方案就很简单了, 让小伙伴修改包名类名就可以了.原枚举类如下: public enum AccTypeEnum { PRI((byte) 0, \"对私\"), PUB((byte) 1, \"对公\"); private byte value; private String desc; }","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"}]},{"title":"skywalking5集群部署","slug":"skywalking/skywalking5集群部署","date":"2018-12-27T03:27:37.000Z","updated":"2020-04-04T06:25:19.101Z","comments":true,"path":"2018/12/27/skywalking5-cluster-deployment.html","link":"","permalink":"https://liuzhihang.com/2018/12/27/skywalking5-cluster-deployment.html","excerpt":"准备环境 skywalking-5.0.0-GA zookeeper-3.4.10 elasticsearch-5.6.14 下载地址如下: skywalking: http://skywalking.apache.org/downloads/ zookeeper: http://mirrors.hust.edu.cn/apache/zookeeper/ elasticsearch: https://www.elastic.co/downloads/past-releases","text":"准备环境 skywalking-5.0.0-GA zookeeper-3.4.10 elasticsearch-5.6.14 下载地址如下: skywalking: http://skywalking.apache.org/downloads/ zookeeper: http://mirrors.hust.edu.cn/apache/zookeeper/ elasticsearch: https://www.elastic.co/downloads/past-releases 安装zk集群 下载并解压zkwget http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz tar -xvf zookeeper-3.4.10.tar.gz 修改配置文件cd zookeeper-3.4.10/conf/ cp zoo_sample.cfg zoo.cfg vim zoo.cfg 内容如下tickTime=2000 initLimit=10 syncLimit=5 dataDir=/opt/export/app/zookeeper-3.4.10/data clientPort=2181 server.1=192.168.***.236:2888:3888 server.2=192.168.***.237:2888:3888 写入集群myidecho 1 > /opt/export/app/zookeeper-3.4.10/data/myid # 另一台机器则写入2 zk基本命令# 在zk的bin目录下 # 启动 ./zkServer.sh start # 停止 ./zkServer.sh stop # 查看状态 ./zkServer.sh status # 查看zk的节点 ./zkCli.sh # 连接后使用 ls / 命令查看 ls /skywalking 安装es集群 下载并解压eswget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.14.tar.gz tar -xvf elasticsearch-5.6.14.tar.gz 修改配置文件cd elasticsearch-5.6.14/config/ vim elasticsearch.yml 内容如下cluster.name: CollectorDBCluster node.name: node-1 path.data: /opt/export/app/elasticsearch-5.6.14/data path.logs: /opt/export/app/elasticsearch-5.6.14/logs network.host: 192.168.***.234 discovery.zen.ping.unicast.hosts: [\"192.168.***.234:9300\", \"192.168.***.235:9300\"] discovery.zen.minimum_master_nodes: 2 bootstrap.memory_lock: false bootstrap.system_call_filter: false # 修改上报数据线程池大小 thread_pool.bulk.queue_size: 1000 常用命令# 后台启动 bin/elasticsearch -d # 删除所有索引 curl -XDELETE 192.168.***.234:9200/* 安装skywalking☞ 官方地址 下载并解压wget http://mirrors.shu.edu.cn/apache/incubator/skywalking/5.0.0-GA/apache-skywalking-apm-incubating-5.0.0-GA.tar.gz tar -xvf apache-skywalking-apm-incubating-5.0.0-GA.tar.gz mv apache-skywalking-apm-incubating-5.0.0-GA skywalking-5.0.0-GA 修改配置cd skywalking-5.0.0-GA/config/ vim application.yml 修改内容如下 集群配置 cluster: zookeeper: hostPort: 192.168.***.236:2181,192.168.***.237:2181 sessionTimeout: 100000 es配置 storage: elasticsearch: clusterName: CollectorDBCluster clusterTransportSniffer: true clusterNodes: 192.168.***.234:9300,192.168.***.235:9300 # 其他配置 其他配置 # host配置修改 host: 192.168.***.236 修改webapp配置vim webapp/webapp.yml collector: path: /graphql ribbon: ReadTimeout: 10000 listOfServers: 192.168.**.236:10800,192.168.**.237:10800 常用命令# 启动collector+webUI bin/startup.sh # 只启动collector或webUI bin/collectorService.sh bin/webappService.sh 探针使用 ☞ 官方地址 java -javaagent:/path/to/skywalking-agent/skywalking-agent.jar -jar yourApp.jar","categories":[{"name":"skywalking","slug":"skywalking","permalink":"https://liuzhihang.com/categories/skywalking/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"},{"name":"skywalking","slug":"skywalking","permalink":"https://liuzhihang.com/tags/skywalking/"}]},{"title":"logstash时间戳差8个小时","slug":"issue/处理logstash时间戳差8个小时","date":"2018-12-20T07:11:16.000Z","updated":"2020-04-04T06:23:27.485Z","comments":true,"path":"2018/12/20/logstash-timestamp-difference-8-hours.html","link":"","permalink":"https://liuzhihang.com/2018/12/20/logstash-timestamp-difference-8-hours.html","excerpt":"问题说明原始配置: elasticsearch { # manage_template =&gt; false template_overwrite =&gt; true template =&gt; &quot;/opt/export/app/logstash-6.4.2/bin/dynamic_templates.json&quot; user =&gt; xxxxxxx password =&gt; xxxxxxx index =&gt; &quot;%{sys_name}-%{+YYYY.MM.dd}&quot; hosts =&gt; [&quot;172.19.3.51:9200&quot;,&quot;172.19.3.52:9200&quot;] } 在使用logstash输出内容要es中时, 指定index为系统名称+时间(年月日), 时间会自动匹配‘@timestamp’字段并格式化, 但是在实际使用过程中, 发现在上午八点之前的消息会被创建到昨天的索引里面.查阅相关资料, 有介绍在时间戳上面增加8个小时的方式, 也可以使用. 这里结合自己业务使用的其他方式.","text":"问题说明原始配置: elasticsearch { # manage_template => false template_overwrite => true template => \"/opt/export/app/logstash-6.4.2/bin/dynamic_templates.json\" user => xxxxxxx password => xxxxxxx index => \"%{sys_name}-%{+YYYY.MM.dd}\" hosts => [\"172.19.3.51:9200\",\"172.19.3.52:9200\"] } 在使用logstash输出内容要es中时, 指定index为系统名称+时间(年月日), 时间会自动匹配‘@timestamp’字段并格式化, 但是在实际使用过程中, 发现在上午八点之前的消息会被创建到昨天的索引里面.查阅相关资料, 有介绍在时间戳上面增加8个小时的方式, 也可以使用. 这里结合自己业务使用的其他方式. 解决方案 主要报送内容为filebeat的日志信息, 日志统一有时间戳, 格式如下: [trans-mediapay]-[2018-12-19 02:00:00:187]-[queryThreadPool-14]-[]-[WeBankServiceImpl.java:101]-[INFO ]-[测试2点的日志] 解析时间戳的时间 先匹配整体日志, 获取’log_time’字段 匹配’log_time’字段 生成元数据 ‘[@metadata][index_suffix]’ filter { # 日志聚合使用全量配置 grok { match => { \"message\" => \"\\[%{DATA:sys_name}\\]-\\[%{DATA:log_time}\\]-\\[%{DATA:thread_name}\\]-\\[%{DATA:trace_id}\\]-\\[%{DATA:class_name}\\]-\\[%{DATA:log_level}\\]-%{GREEDYDATA:log_msg}\" } } grok{ match => { \"log_time\" => [\"%{INT:index_year}-%{INT:index_mouth}-%{INT:index_day}\"]} } mutate { # 使用元数据 [@metadata][index_suffix] add_field => { \"[@metadata][index_suffix]\" => \"%{index_year}.%{index_mouth}.%{index_day}\" } remove_field => [\"host\",\"beat\",\"tags\",\"[beat][name]\",\"[beat][version]\",\"prospector\",\"@version\",\"offset\",\"input\",\"y_index\",\"M_index\",\"d_index\"] } } 3. 输出时使用元数据, 该字段不会出现在es的字段中 ```bash elasticsearch { # manage_template =&gt; false template_overwrite =&gt; true template =&gt; &quot;/opt/export/app/logstash-6.4.2/bin/dynamic_templates.json&quot; user =&gt; xxxxxxx password =&gt; xxxxxxx index =&gt; &quot;%{sys_name}-%{[@metadata][index_suffix]}&quot; hosts =&gt; [&quot;xxxx:9200&quot;,&quot;xxxx:9200&quot;] }","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"获取IP和byte转long遇到的小问题","slug":"issue/获取IP&byte转long","date":"2018-12-10T11:46:01.000Z","updated":"2020-04-04T06:23:27.488Z","comments":true,"path":"2018/12/10/get-the-small-problem-encountered-by-ip-and-byte-to-long.html","link":"","permalink":"https://liuzhihang.com/2018/12/10/get-the-small-problem-encountered-by-ip-and-byte-to-long.html","excerpt":"介绍因为业务需求新项目的流水号系统从 ‘数据库自增步长+分段式锁’ 换成使用 雪花流水号, 修改机器标识和数据中心字段为自动获取ip后三位, 人工保证ip后三位不相同 示例雪花流水号 - 改造版 修改内容如下:删除构造, 修改数据位数, 添加静态代码块","text":"介绍因为业务需求新项目的流水号系统从 ‘数据库自增步长+分段式锁’ 换成使用 雪花流水号, 修改机器标识和数据中心字段为自动获取ip后三位, 人工保证ip后三位不相同 示例雪花流水号 - 改造版 修改内容如下:删除构造, 修改数据位数, 添加静态代码块 private final static long MACHINE_BIT = 8; private final static long DATA_CENTER_BIT = 2; static { try { InetAddress localHost = InetAddress.getLocalHost(); address = localHost.getAddress()[3] &amp; 0xff; System.out.println(\"当前系统的 address 为: \" + address); } catch (UnknownHostException e) { throw new IllegalArgumentException(\"DATA_CENTER_ID can't be greater than MAX_DATA_CENTER_NUM or less than 0\"); } } 注意点服务器配置host服务器对应的 hostname 需要配置ip地址 cat /etc/hosts byte 转换 long需要 &amp; 0xff当获取ip大于127时转换出来为负值, 所以需要 &amp; 0xff","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"ip","slug":"ip","permalink":"https://liuzhihang.com/tags/ip/"}]},{"title":"基于LinkHashMap的LRU缓存淘汰","slug":"redis/LRULinkedHashMap","date":"2018-11-19T13:24:52.000Z","updated":"2020-04-04T06:24:26.301Z","comments":true,"path":"2018/11/19/elimination-of-lru-cache-based-on-linkhashmap.html","link":"","permalink":"https://liuzhihang.com/2018/11/19/elimination-of-lru-cache-based-on-linkhashmap.html","excerpt":"","text":"LRU缓存淘汰LRU缓存淘汰是redis中的一种淘汰策略, 当内存大小不足以存放数据时, 此时存入新数据, 将删除较早存入的数据.在dubbo中使用LRU来缓存 hostName.在mysql中使用LRU来缓存 serverSideStatementCheckCache 和 serverSideStatementCache. 代码实现package com.ipaynow.tool.lru; import java.util.LinkedHashMap; import java.util.Map; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * 基于LinkedHashMap LRU 缓存淘汰, 以下框架中都有使用 * dubbo com.alibaba.dubbo.common.utils.LRUCache * com.mysql.jdbc.util.LRUCache * * @author liuzhihang * @date 2018/11/20 10:43 */ public class LRULinkedHashMap&lt;K, V> extends LinkedHashMap&lt;K, V> { /** * 设置最大容量 */ private volatile int maxCapacity; private static final int DEFAULT_MAX_CAPACITY = 1000; private static final float DEFAULT_LOAD_FACTOR = 0.75f; private final Lock lock = new ReentrantLock(); public LRULinkedHashMap() { this.maxCapacity = DEFAULT_MAX_CAPACITY; } public LRULinkedHashMap(int maxCapacity) { // accessOrder设置为true 按照时间排序 super(maxCapacity, DEFAULT_LOAD_FACTOR, true); this.maxCapacity = maxCapacity; } /** * 当链表长度大于最大容量时 删除最旧的元素 */ @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V> eldest) { return size() > maxCapacity; } @Override public boolean containsKey(Object key) { try { lock.lock(); return super.containsKey(key); } finally { lock.unlock(); } } @Override public V get(Object key) { try { lock.lock(); return super.get(key); } finally { lock.unlock(); } } @Override public V put(K key, V value) { try { lock.lock(); return super.put(key, value); } finally { lock.unlock(); } } @Override public V remove(Object key) { try { lock.lock(); return super.remove(key); } finally { lock.unlock(); } } @Override public int size() { try { lock.lock(); return super.size(); } finally { lock.unlock(); } } @Override public void clear() { try { lock.lock(); super.clear(); } finally { lock.unlock(); } } public int getMaxCapacity() { return maxCapacity; } public void setMaxCapacity(int maxCapacity) { this.maxCapacity = maxCapacity; } } 测试代码及结果package com.ipaynow.tool.lru; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.util.Iterator; import java.util.Map; /** * @author liuzhihang * @date 2018/11/20 10:58 */ public class LRUTest { public static void main(String[] args) throws InterruptedException { LRULinkedHashMap&lt;String, String> map = new LRULinkedHashMap&lt;>(5); for (int i = 0; i &lt; 10; i++) { Thread.sleep(1000); map.put(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss SSS\")), \"value\" + i); } for (Iterator&lt;Map.Entry&lt;String, String>> iterator = map.entrySet().iterator(); iterator.hasNext(); ) { Map.Entry&lt;String, String> entry = iterator.next(); String key = entry.getKey(); String value = entry.getValue(); System.out.println(key + \"------------\" + value); } } } 控制台输出结果: 2018-11-20 11:13:21 398------------value5 2018-11-20 11:13:22 399------------value6 2018-11-20 11:13:23 400------------value7 2018-11-20 11:13:24 400------------value8 2018-11-20 11:13:25 400------------value9 Process finished with exit code 0","categories":[{"name":"Redis","slug":"Redis","permalink":"https://liuzhihang.com/categories/Redis/"},{"name":"cache","slug":"Redis/cache","permalink":"https://liuzhihang.com/categories/Redis/cache/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://liuzhihang.com/tags/Redis/"},{"name":"cache","slug":"cache","permalink":"https://liuzhihang.com/tags/cache/"}]},{"title":"ELK常用启动命令","slug":"elk/elk-start-command","date":"2018-10-29T09:03:38.000Z","updated":"2020-04-04T06:11:20.190Z","comments":true,"path":"2018/10/29/elk-common-start-command.html","link":"","permalink":"https://liuzhihang.com/2018/10/29/elk-common-start-command.html","excerpt":"elasticsearch启动命令# 前台启动 关闭窗口连接后自动退出 ./bin/elasticsearch # 后台启动 ./bin/elasticsearch -d","text":"elasticsearch启动命令# 前台启动 关闭窗口连接后自动退出 ./bin/elasticsearch # 后台启动 ./bin/elasticsearch -d logstash启动命令# 前台启动 -f 后面为配置文件 ./logstash -f logstash.conf # 后台启动 nohup ./logstash -f logstash.conf &amp; kibana启动命令# 前台启动 ./bin/kibana # 后台启动 ./bin/kibana &amp; kibana停止命令当ps -ef | grep kibana 查不到时 可以lsof -i:5601kill -9 线程 filebeat启动命令# 前台启动 ./filebeat -e -c filebeat.yml # 后台启动 不输出日志/输出日志 nohup ./filebeat -e -c filebeat.yml >/dev/null 2>&amp;1 &amp; nohup ./filebeat -e -c filebeat.yml > filebeat.log &amp; jar包启动命令# 前台启动 java -jar server.ja # 后台启动 nohup java -jar server.jar &amp;","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"search-guard-6 配置用户","slug":"elk/search-guard-6-config-user","date":"2018-10-24T09:13:45.000Z","updated":"2020-04-04T06:18:21.574Z","comments":true,"path":"2018/10/24/searchguard6-configuration-user.html","link":"","permalink":"https://liuzhihang.com/2018/10/24/searchguard6-configuration-user.html","excerpt":"search-guard 配置用户路径: /opt/export/app/elasticsearch-6.4.2/plugins/search-guard-6/sgconfig 生成密码执行以下命令, 输入明文 plugins/search-guard-6/tools/hasher.sh -p mycleartextpassword","text":"search-guard 配置用户路径: /opt/export/app/elasticsearch-6.4.2/plugins/search-guard-6/sgconfig 生成密码执行以下命令, 输入明文 plugins/search-guard-6/tools/hasher.sh -p mycleartextpassword 1. 配置用户及密码文件: sg_internal_users.yml zhangsan: hash: $2y$12$yKXk785zSTtB3kE7g.XnbOPrc690g9JE50Znwum924i2M/xYGG4qq roles: - trans_group 格式: 姓名: 密码: XXXX(明文的hash, 使用search-guard的工具生成) 角色: - 角色名称 2. 配置权限文件: sg_roles.xml 配置’?kibana’ 及’?kibana-6’ 权限是为了保证用户在kibana中能够正常使用kibana sg_trans_group: cluster: - cluster:monitor/nodes - cluster:monitor/health indices: 'log-system': '*': - indices:admin/mappings/fields/get - indices:admin/validate/query - indices:data/read/search - indices:data/read/msearch - indices:admin/get - indices:data/read/field_stats '?kibana': '*': - MANAGE - INDEX - READ - DELETE '?kibana-6': '*': - MANAGE - INDEX - READ - DELETE 格式: 权限名称: 集群: - 集群名称:权限 索引: '索引名称': '类型': - 权限 3. 配置角色映射文件: sg_roles_mapping.yml 配置完用户的账户密码, 以及相应角色权限之后, 需要将用户和权限进行关联, 关联之后即可使用 sg_trans_group: backendroles: - trans_group 格式: 映射名称: 角色: - 用户的角色 也可以使用以下方式进行关联: sg_trans_group: users: - zhangsan - lisi # 即 映射名称: 用户名称: - 用户名 4. 使配置生效使用以下命令 ./sgadmin.sh -cn 集群名称 -cd ../sgconfig -ks ../../../config/sgadmin-keystore.jks -kspass changeit -ts ../../../config/truststore.jks -tspass changeit -nhnv","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"search-guard-6 安装","slug":"elk/search-guard-6-install","date":"2018-10-23T11:19:45.000Z","updated":"2020-04-04T06:18:30.040Z","comments":true,"path":"2018/10/23/searchguard6-installation.html","link":"","permalink":"https://liuzhihang.com/2018/10/23/searchguard6-installation.html","excerpt":"ES 安装 search-guard-6安装插件☞ 官方网站在ES目录下执行命令 bin/elasticsearch-plugin install -b com.floragunn:search-guard-6:6.4.2-23.1注: 安装版本需要和Elasticsearch版本相对应. 查看版本 这里不使用官方的快速构建方法","text":"ES 安装 search-guard-6安装插件☞ 官方网站在ES目录下执行命令 bin/elasticsearch-plugin install -b com.floragunn:search-guard-6:6.4.2-23.1注: 安装版本需要和Elasticsearch版本相对应. 查看版本 这里不使用官方的快速构建方法 生成证书 下载脚本 git clone https://github.com/floragunncom/search-guard-ssl.git 证书配置 路径 **/elasticsearch-6.4.2/search-guard-ssl/example-pki-scripts 目录内容 etc下可对证书进行配置 修改example.sh #!/bin/bash OPENSSL_VER=\"$(openssl version)\" if [[ $OPENSSL_VER == *\"0.9\"* ]]; then echo \"Your OpenSSL version is too old: $OPENSSL_VER\" echo \"Please install version 1.0.1 or later\" exit -1 else echo \"Your OpenSSL version is: $OPENSSL_VER\" fi set -e ./clean.sh # 第一个参数为CA根证书密码，第二个参数为TS密码(truststore，信任证书密码) ./gen_root_ca.sh capass changeit # 生成节点证书： 第一个参数为节点编号，第二个参数为keystore文件密码，第三个参数为CA根证书密码。 # 此处我们只生成两个节点证书 ./gen_node_cert.sh 0 changeit capass &amp;&amp; ./gen_node_cert.sh 1 changeit capass # 生成客户端证书： 第一个参数为客户端名称, 第二个参数为keystore文件名称，第三个参数为CA根证书名称。 ./gen_client_node_cert.sh spock changeit capass ./gen_client_node_cert.sh kirk changeit capass ./gen_client_node_cert.sh logstash changeit capass ./gen_client_node_cert.sh filebeat changeit capass ./gen_client_node_cert.sh kibana changeit capass # 生成一个sgadmin客户端证书，用于配置管理 ./gen_client_node_cert.sh sgadmin changeit capass # 生成一个javaapi访问的客户端证书 ./gen_client_node_cert.sh javaapi changeit capass rm -f ./*tmp* 生成证书移动到elasticsearch config 在ES目录下 ./example.sh cp node-0-keystore.jks sgadmin-keystore.jks truststore.jks /opt/export/app/elasticsearch-6.4.2/config/ 配置elasticsearch.yml, 增加以下配置 # 配置节点间通信证书，节点间通信使用TLS是强制的 searchguard.ssl.transport.keystore_filepath: node-0-keystore.jks searchguard.ssl.transport.keystore_password: changeit searchguard.ssl.transport.truststore_filepath: truststore.jks searchguard.ssl.transport.truststore_password: changeit # 设置不校验hostname searchguard.ssl.transport.enforce_hostname_verification: false searchguard.ssl.transport.resolve_hostname: false # 配置管理员证书DN searchguard.authcz.admin_dn: - CN=sgadmin,OU=client,O=client,L=Test, C=DE bootstrap.memory_lock: false bootstrap.system_call_filter: false xpack.security.enabled: false 启动访问需要权限 添加脚本权限并初始化用户cd /opt/export/app/elasticsearch-6.4.2/plugins/search-guard-6/tools chmod +x *.sh ./sgadmin.sh -cn cluster-es -cd ../sgconfig -ks ../../../config/sgadmin-keystore.jks -kspass changeit -ts ../../../config/truststore.jks -tspass changeit -nhnv 每次更新用户权限或者新增修改用户, 只需要重新执行第三条命令, 更新用户信息即可 Kibana安装参照官方网站安装配置即可. 官方网站, 或者按照以下步骤. 在kibana安装目录下执行一下吗命令 bin/kibana-plugin install https://search.maven.org/remotecontent?filepath=com/floragunn/search-guard-kibana-plugin/6.4.2-15/search-guard-kibana-plugin-6.4.2-15.zip 修改kibana.yml # Use HTTPS instead of HTTP # elasticsearch.url: \"https://localhost:9200\" elasticsearch.url: \"http://localhost:9200\" # Configure the Kibana internal server user elasticsearch.username: \"kibanaserver\" elasticsearch.password: \"kibanaserver\" # Disable SSL verification because we use self-signed demo certificates elasticsearch.ssl.verificationMode: none # Whitelist the Search Guard Multi Tenancy Header elasticsearch.requestHeadersWhitelist: [ \"Authorization\", \"sgtenant\" ] 打开对应域名登录http://localhost:5601/ 注:以上内容为参考自M醉逍遥, 并搭建成功后总结记录, 以作备忘. 链接如下:https://www.jianshu.com/p/319913a944af","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"hexo搭建博客","slug":"hexo/hexo-blog","date":"2018-10-08T12:17:11.000Z","updated":"2020-04-04T04:12:06.986Z","comments":true,"path":"2018/10/08/hexo-build-blog.html","link":"","permalink":"https://liuzhihang.com/2018/10/08/hexo-build-blog.html","excerpt":"安装node下载地址: https://nodejs.org 查看当前版本: node -v 安装hexonpm install也可以使用淘宝镜像 npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install hexo","text":"安装node下载地址: https://nodejs.org 查看当前版本: node -v 安装hexonpm install也可以使用淘宝镜像 npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install hexo hexo常用命令初始化hexo init清除缓存hexo clean生成静态文件hexo g hexo generate启动hexo s hexo server部署hexo d hexo deploy生成并部署hexo g -d","categories":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://liuzhihang.com/tags/hexo/"}]},{"title":"服务器cpu占用率高","slug":"issue/cpu-high-occupancy-rate","date":"2018-09-25T10:38:31.000Z","updated":"2020-04-04T06:23:27.480Z","comments":true,"path":"2018/09/25/server-cpu-occupancy-rate-is-high.html","link":"","permalink":"https://liuzhihang.com/2018/09/25/server-cpu-occupancy-rate-is-high.html","excerpt":"1. top 命令找到占用cpu最高的进程top - 14:37:14 up 34 days, 13:27, 2 users, load average: 0.21, 0.29, 0.29 Tasks: 151 total, 1 running, 150 sleeping, 0 stopped, 0 zombie Cpu(s): 4.4%us, 2.7%sy, 0.0%ni, 90.9%id, 0.5%wa, 0.0%hi, 0.2%si, 1.3%st Mem: 16334064k total, 16171240k used, 162824k free, 16716k buffers Swap: 16383996k total, 4470816k used, 11913180k free, 539788k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1818 tomcat 20 0 3643m 983m 7548 S 0.7 24.8 190:40.13 java","text":"1. top 命令找到占用cpu最高的进程top - 14:37:14 up 34 days, 13:27, 2 users, load average: 0.21, 0.29, 0.29 Tasks: 151 total, 1 running, 150 sleeping, 0 stopped, 0 zombie Cpu(s): 4.4%us, 2.7%sy, 0.0%ni, 90.9%id, 0.5%wa, 0.0%hi, 0.2%si, 1.3%st Mem: 16334064k total, 16171240k used, 162824k free, 16716k buffers Swap: 16383996k total, 4470816k used, 11913180k free, 539788k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1818 tomcat 20 0 3643m 983m 7548 S 0.7 24.8 190:40.13 java 字段解释:top - 时间 运行时间 用户 系统负载Tasks: 进程相关信息Cpu(s): cpu相关信息Mem: 内存相关Swap: 交换区相关信息 进程相关信息PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2. 使用top -H -p 查看该进程内所有线程top -H -p 1818 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 6656 tomcat 20 0 4193m 608m 11m R 21.0 3.8 1419:44 java 3. printf “%x\\n” 将10进制线程号转换为16进制结果[liuzhihang@test08 ~]$ printf \"%x\\n\" 1876 754 [liuzhihang@test08 ~]$ 4. jstack |grep jstack 1818 | grep 754 -A 30 pid 为第一次执行top命令时的 pidtid 为将第二次的pid进行十六进制转换后的结果 \"catalina-8180-89\" #1842 daemon prio=5 os_prio=0 tid=0x00007f4ec4096000 nid=0x5d96 waiting on condition [0x00007f4e87545000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000f418f898> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:104) at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:32) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:748) \"catalina-8180-88\" #1841 daemon prio=5 os_prio=0 tid=0x00007f4eb848e800 nid=0x5d94 waiting on condition [0x00007f4e8bd8b000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method)","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"}]},{"title":"final finally finalize区别","slug":"source-code/java/final-finally-finalize","date":"2018-09-06T09:58:38.000Z","updated":"2020-04-04T06:21:20.355Z","comments":true,"path":"2018/09/06/final-finally-finalize-difference.html","link":"","permalink":"https://liuzhihang.com/2018/09/06/final-finally-finalize-difference.html","excerpt":"finalfinal为java关键字, 可以作用于成员变量、方法、类上1.作用于成员变量上, 基本类型则值不可修改, 如果成员变量为对象, 则该对象的引用不可修改.2.作用于方法, 该方法不可被重写3.作用于类, 该类不可继承","text":"finalfinal为java关键字, 可以作用于成员变量、方法、类上1.作用于成员变量上, 基本类型则值不可修改, 如果成员变量为对象, 则该对象的引用不可修改.2.作用于方法, 该方法不可被重写3.作用于类, 该类不可继承 finally异常处理的关键字, 无论异常是否发生, finally内逻辑总会执行. finally 和 return 的执行顺序1.一般使用逻辑, return在try-catch-finally之后, 证明, 无论是否异常, finally都会执行 public class MainTest { public static void main(String[] args) { System.out.println(finallyTest()); } private static String finallyTest() { try { System.out.println(\"处理逻辑\"); // int i = 1 / 0; } catch (Exception e) { System.out.println(\"异常逻辑\"); } finally { System.out.println(\"finally执行了\"); } return \"最终return返回\"; } } 2.在try/catch内添加returntry/catch内的return执行完后会继续执行finally, 但是从打印结果来开, finally的语句先打印, 原因是因为 return的 public class MainTest { public static void main(String[] args) { System.out.println(finallyTest()); } private static String finallyTest() { try { System.out.println(\"处理逻辑\"); // int i = 1 / 0; return \"try - return返回\"; } catch (Exception e) { System.out.println(\"异常逻辑\"); // return \"catch - return返回\"; } finally { System.out.println(\"finally执行了\"); } return \"最终return返回\"; } } 输出结果 处理逻辑 finally执行了 try - return返回 3.finally里面添加return语句finally里面return执行完后会直接返回, 不会再执行try块中的return语句 public class MainTest { public static void main(String[] args) { System.out.println(finallyTest()); } private static String finallyTest() { try { System.out.println(\"处理逻辑\"); // int i = 1 / 0; return \"try - return返回\"; } catch (Exception e) { System.out.println(\"异常逻辑\"); // return \"catch - return返回\"; } finally { System.out.println(\"finally执行了\"); return \"finally - return返回\"; } // return \"最终return返回\"; } } 执行结果 处理逻辑 finally执行了 finally - return返回 4.finally内添加逻辑改变变量值1).try中的return值只是暂时放在栈中, 所以最终返回的还是 10, finally中并没有改变其值2).try中的return值如果是对象, 栈中存放的是对象的引用, 对象属性值还是可以通过finally修改 public class MainTest { public static void main(String[] args) { System.out.println(finallyTest()); } private static String finallyTest() { int temp = 10; try { System.out.println(\"处理逻辑\"); return \"try - return返回: \" + temp; } catch (Exception e) { System.out.println(\"异常逻辑\"); // return \"catch - return返回\"; } finally { temp = 100; System.out.println(\"finally执行了\"); } return \"最终return返回: \" + temp; } } 输出结果 处理逻辑 finally执行了 try - return返回: 10 public class MainTest { public static void main(String[] args) { Temp temp = new Temp(); temp.temp = 1; System.out.println(finallyTest(temp).toString()); } private static Temp finallyTest(Temp temp) { try { System.out.println(\"处理逻辑\"); return temp; } catch (Exception e) { System.out.println(\"异常逻辑\"); // return \"catch - return返回\"; } finally { temp.temp = 100; System.out.println(\"finally执行了\"); } return temp; } } class Temp { int temp; @Override public String toString() { return \"Temp{\" + \"temp=\" + temp + '}'; } } 打印结果 处理逻辑 finally执行了 Temp{temp=100} finalize方法Object类的方法, 子类可重写, 主要是垃圾回收时使用.","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}]},{"title":"线程池原理及源码解析","slug":"concurrent/thread-pool","date":"2018-09-05T08:40:35.000Z","updated":"2020-04-04T06:49:14.278Z","comments":true,"path":"2018/09/05/thread-pool-principle-and-source-code-analysis.html","link":"","permalink":"https://liuzhihang.com/2018/09/05/thread-pool-principle-and-source-code-analysis.html","excerpt":"线程池处理流程 判断核心线程池是否已满, 不满则创建新线程执行任务 等待队列如果有界, 判断等待队列是否已满, 不满, 则添加任务到等待队列 判断最大线程数是否已满, 不满则创建新线程执行任务 最大线程数已满, 按照既定策略处理新任务","text":"线程池处理流程 判断核心线程池是否已满, 不满则创建新线程执行任务 等待队列如果有界, 判断等待队列是否已满, 不满, 则添加任务到等待队列 判断最大线程数是否已满, 不满则创建新线程执行任务 最大线程数已满, 按照既定策略处理新任务 全参构造及各参数含义public class ThreadPoolExecutor extends AbstractExecutorService { public ThreadPoolExecutor(int corePoolSize, // 核心线程数 int maximumPoolSize, // 最大线程数 long keepAliveTime, // 核心线程外线程的存活时间 TimeUnit unit, // 存活时间的单位 BlockingQueue&lt;Runnable> workQueue, // 保存等待执行的线程的阻塞队列 ThreadFactory threadFactory, // 线程工厂 RejectedExecutionHandler handler) { // 线程拒绝策略 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } // 省略 . . . } workQueue阻塞队列ArrayBlockingQueue: 是一个基于数组结构的有界阻塞队列, 此队列按 FIFO(先进先出) 原则对元素进行排序.LinkedBlockingQueue: 一个基于链表结构的阻塞队列,此队列按 FIFO(先进先出) 排序元素, 吞吐量通常要高于ArrayBlockingQueue. 静态工厂方法Executors.newFixedThreadPool()使用了这个队列SynchronousQueue: 一个不存储元素的阻塞队列. 每个插入操作必须等到另一个线程调用移除操作, 否则插入操作一直处于阻塞状态, 吞吐量通常要高于LinkedBlockingQueue, 静态工厂方法Executors.newCachedThreadPool使用了这个队列.PriorityBlockingQueue: 一个具有优先级的无限阻塞队列. 2.threadFactory线程工厂可以使用默认的工厂也可以自定义工厂, 或者使用 google guava 提供的工厂, 可以为线程命名和设置是否为守护线程 // 默认工厂 ThreadFactory threadFactory = Executors.defaultThreadFactory(); // google guava工具提供 ThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(\"demo-pool-%d\").build(); 3.handler线程拒绝策略当线程池达到最大线程数, 并且队列满了, 新的线程要采取的处理策略.1.AbortPolicy 拒绝新任务并抛出RejectedExecutionException异常2.CallerRunsPolicy 直接在调用程序的线程中运行3.DiscardOldestPolicy 放弃最早的任务, 即队列最前面的任务4.DiscardPolicy 丢弃, 不处理 Executors初始化线程池的四种方式这四种初始化线程池的方式, 前三种都是调用 ThreadPoolExecutor 类的构造创建的线程池, 只不过使用的阻塞队列方式不同. newFixedThreadPool() public class Executors { /** * 固定线程池 * 核心线程数 = 最大线程数 * 超时时间为0 * LinkedBlockingQueue无界队列, 会持续等待 * 使用默认拒绝策略 AbortPolicy */ public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>()); } } newCachedThreadPool() public class Executors { /** * 无界线程池 * 核心线程数0 最大线程数 (2³¹ -1) * 超时时间 60秒 * SynchronousQueue不存储元素的阻塞队列 * 线程空闲时间超过60秒, 会自动释放资源, 提交任务如果没有空闲线程, 则会创建新线程 */ public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable>()); } } 3.newSingleThreadExecutor() public class Executors { /** * 创建只有 1个线程的线程池 * 如果线程异常, 则创建一个新的线程继续执行任务 * */ public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>())); } } 4.newSingleThreadExecutor() public class Executors { /** * ScheduledThreadPoolExecutor 继承 ThreadPoolExecutor 类 * 可以在指定时间周期内执行任务 * */ public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize); } } 源码解析变量public class ThreadPoolExecutor extends AbstractExecutorService { /** * ctx 为原子类型的变量, 有两个概念 * workerCount, 表示有效的线程数 * runState, 表示线程状态, 是否正在运行, 关闭等 */ private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // 29 private static final int COUNT_BITS = Integer.SIZE - 3; // 容量 2²⁹-1 private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits 线程池的五中状态 // 即高3位为111, 接受新任务并处理排队任务 private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 即高3位为000, 不接受新任务, 但处理排队任务 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 即高3位为001, 不接受新任务, 不处理排队任务, 并中断正在进行的任务 private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 即高3位为010, 所有任务都已终止, 工作线程为0, 线程转换到状态TIDYING, 将运行terminate()钩子方法 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 即高3位为011, 标识terminate（）已经完成 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl 用来计算线程的方法 private static int runStateOf(int c) { return c &amp; ~CAPACITY; } private static int workerCountOf(int c) { return c &amp; CAPACITY; } private static int ctlOf(int rs, int wc) { return rs | wc; } } execute方法public class ThreadPoolExecutor extends AbstractExecutorService { public void execute(Runnable command) { // 空则抛出异常 if (command == null) throw new NullPointerException(); // 获取当前线程池的状态 int c = ctl.get(); // 计算工作线程数 并判断是否小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) { // addWorker提交任务, 提交成功则结束 if (addWorker(command, true)) return; // 提交失败再次获取当前状态 c = ctl.get(); } // 判断线程状态, 并插入队列, 失败则移除 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { // 再次获取状态 int recheck = ctl.get(); // 如果状态不是RUNNING, 并移除失败 if (! isRunning(recheck) &amp;&amp; remove(command)) // 调用拒绝策略 reject(command); // 如果工作线程为0 则调用 addWorker else if (workerCountOf(recheck) == 0) addWorker(null, false); } // 提交任务失败 走拒绝策略 else if (!addWorker(command, false)) reject(command); } } addWorker方法public class ThreadPoolExecutor extends AbstractExecutorService { /** * 检查任务是否可以提交 * */ private boolean addWorker(Runnable firstTask, boolean core) { retry: // 外层循环 for (;;) { // 获取当前状态 int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. 检查线程池是否关闭 if (rs >= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; // 内层循环 for (;;) { int wc = workerCountOf(c); // 工作线程大于容量 或者大于 核心或最大线程数 if (wc >= CAPACITY || wc >= (core ? corePoolSize : maximumPoolSize)) return false; // CAS 线程数增加, 成功则调到外层循环 if (compareAndIncrementWorkerCount(c)) break retry; // 失败则再次获取线程状态 c = ctl.get(); // Re-read ctl // 不相等则重新走外层循环 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop } } /** * 创建新worker 开始新线程 */ boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; // 加锁 mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { // 判断线程是否存活, 已存活抛出非法异常 if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 设置包含池中的所有工作线程。仅在持有mainLock时访问 workers是 HashSet 集合 // private final HashSet&lt;Worker> workers = new HashSet&lt;Worker>(); workers.add(w); int s = workers.size(); // 设置池最大大小, 并将 workerAdded设置为 true if (s > largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { // 解锁 mainLock.unlock(); } // 添加成功 开始启动线程 并将 workerStarted 设置为 true if (workerAdded) { t.start(); workerStarted = true; } } } finally { // 启动线程失败 if (! workerStarted) addWorkerFailed(w); } return workerStarted; } /** * 启动线程失败, 加锁 * 移除线程, 并减少线程总数 * 转换状态 */ private void addWorkerFailed(Worker w) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (w != null) workers.remove(w); decrementWorkerCount(); tryTerminate(); } finally { mainLock.unlock(); } } }","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"https://liuzhihang.com/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"多线程相关","slug":"concurrent/multi-thread","date":"2018-09-04T11:08:03.000Z","updated":"2020-04-04T06:16:02.599Z","comments":true,"path":"2018/09/04/multithreaded-correlation.html","link":"","permalink":"https://liuzhihang.com/2018/09/04/multithreaded-correlation.html","excerpt":"多线程多个线程同时或交替运行, 单核CPU为顺序执行(交替执行), 多核情况下, 每个CPU有自己的运算器, 所以在多个CPU中可以同时运行.","text":"多线程多个线程同时或交替运行, 单核CPU为顺序执行(交替执行), 多核情况下, 每个CPU有自己的运算器, 所以在多个CPU中可以同时运行. 创建线程的方式1.继承Thread public class MyThread extends Thread { @Override public void run() { super.run(); System.out.println(Thread.currentThread().getName() + \"执行完毕\"); } } public class ThreadTest { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.setName(\"测试\"); myThread.start(); System.out.println(Thread.currentThread().getName() + \"执行完毕\"); } } 开始线程, 可以看出main线程和测试线程是两个独立的线程调用myThread.run();方法相当于直接在主线程运行run方法, 而不是开启一个新的线程去执行 2.实现Runnable接口 public class MyRunable implements Runnable { @Override public void run() { System.out.println(Thread.currentThread().getName() + \"执行完毕\"); } } public class ThreadTest { public static void main(String[] args) { MyRunable runable = new MyRunable(); Thread thread = new Thread(runable); thread.start(); System.out.println(Thread.currentThread().getName() + \"执行完毕\"); } } 3.使用线程池3.1 可以在spring中配置相关线程池, 使用时从容器取出即可, 也可以自己声明线程池 &lt;bean id=\"threadPool\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\"> &lt;!-- 核心线程数，默认为1 --> &lt;property name=\"corePoolSize\" value=\"5\"/> &lt;!-- 最大线程数，默认为Integer.MAX_VALUE --> &lt;property name=\"maxPoolSize\" value=\"20\"/> &lt;!-- 队列最大长度，一般需要设置值>=notifyScheduledMainExecutor.maxNum；默认为Integer.MAX_VALUE &lt;property name=\"queueCapacity\" value=\"1000\" /> --> &lt;!-- 线程池维护线程所允许的空闲时间，默认为60s --> &lt;property name=\"keepAliveSeconds\" value=\"300\"/> &lt;!-- 队列最大长度 --> &lt;property name=\"queueCapacity\" value=\"2000\"/> &lt;!-- 线程池对拒绝任务（无线程可用）的处理策略，目前只支持AbortPolicy、CallerRunsPolicy；默认为后者 --> &lt;property name=\"rejectedExecutionHandler\"> &lt;!-- AbortPolicy:直接抛出java.utils.concurrent.RejectedExecutionException异常 --> &lt;!-- CallerRunsPolicy:主线程直接执行该任务，执行完之后尝试添加下一个任务到线程池中，可以有效降低向线程池内添加任务的速度 --> &lt;!-- DiscardOldestPolicy:抛弃旧的任务、暂不支持；会导致被丢弃的任务无法再次被执行 --> &lt;!-- DiscardPolicy:抛弃当前任务、暂不支持；会导致被丢弃的任务无法再次被执行 --> &lt;bean class=\"java.util.concurrent.ThreadPoolExecutor$CallerRunsPolicy\"/> &lt;/property> &lt;/bean> 3.2 Executors 创建线程池 public class ThreadTest { public static void main(String[] args) { ExecutorService threadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 10; i++) { threadPool.execute(new MyRunable()); } } } 当手动创建线程池时, 如果IDEA安装阿里 P3C 插件后会报错提示以下内容, 建议 线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明： Executors 返回的线程池对象的弊端如下： 1） FixedThreadPool 和 SingleThreadPool: 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 2） CachedThreadPool 和 ScheduledThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE， 可能会创建大量的线程，从而导致 OOM。 建议使用如下方式: public class ThreadTest { public static void main(String[] args) { // 定时任务 建议为线程起名 ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(3, new BasicThreadFactory.Builder().namingPattern(\"example-schedule-pool-%d\").build()); executorService.scheduleAtFixedRate(new MyRunable(), 0, 1, TimeUnit.SECONDS); } } public class ThreadTest { public static void main(String[] args) { // 线程工厂 ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(\"demo-pool-%d\").build(); //Common Thread Pool ExecutorService pool = new ThreadPoolExecutor(5, 20, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;>(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); pool.execute(()-> System.out.println(Thread.currentThread().getName())); pool.shutdown();//gracefully shutdown } } 线程优先级1.myThread.setPriority(1);设置优先级2.优先级从低到高为 1-10, Thread类提供 Thread.MIN_PRIORITY=1, Thread.NORM_PRIORITY=5, Thread.MAX_PRIORITY=103.默认优先级为 5 即 NORM_PRIORITY4.优先级高的仅代表获取进入运行机会的几率大, 并不代表一定会比优先级低的先执行 sleep()和wait()1.sleep()线程未释放锁, 时间结束后线程继续执行2.wait线程释放锁, 需要使用notify或notifyAll3.wait常用于线程之间的交互 package com.liuzhihang.tool.alternate; /** * 交替打印奇偶数 * * @author liuzhihang * @date 2018/9/4 18:39 */ public class AlternateNum { public static void main(String[] args) { Num num = new Num(); Thread thread1 = new Thread(new Odd(num)); Thread thread2 = new Thread(new Even(num)); thread1.start(); thread2.start(); } } class Num { int anInt = 1; boolean flag = true; } class Odd implements Runnable { private Num num; public Odd(Num num) { this.num = num; } @Override public void run() { while (num.anInt &lt; 1000) { // 使用同一把锁 synchronized (num) { if (num.flag) { System.out.println(\"奇数 -> \" + num.anInt); num.anInt++; num.flag = false; num.notify(); } else { try { num.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } } } } class Even implements Runnable { private Num num; public Even(Num num) { this.num = num; } @Override public void run() { while (num.anInt &lt; 1000) { // 使用同一把锁 synchronized (num) { if (!num.flag) { System.out.println(\"偶数 -> \" + num.anInt); num.anInt++; num.flag = true; num.notify(); } else { try { num.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } } } }","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"反射和序列化破解单例","slug":"source-code/java/ReflectSingleton","date":"2018-08-27T09:31:23.000Z","updated":"2020-04-04T06:55:36.741Z","comments":true,"path":"2018/08/27/reflection-and-serialization-cracking-singleton.html","link":"","permalink":"https://liuzhihang.com/2018/08/27/reflection-and-serialization-cracking-singleton.html","excerpt":"介绍主要介绍通过反射的方式获取单例对象, 验证单例模式的安全性.主要从以下几个角度来介绍反射下的单例饿汉式双重锁检查枚举单例","text":"介绍主要介绍通过反射的方式获取单例对象, 验证单例模式的安全性.主要从以下几个角度来介绍反射下的单例饿汉式双重锁检查枚举单例 饿汉式饿汉式直接使用反射即可破解单例模式 public class ReflectTest { public static void main(String[] args) { try { HungerPattern hungerPattern = HungerPattern.getHungerPattern(); Class&lt;HungerPattern> hungerPatternClass = HungerPattern.class; Constructor&lt;HungerPattern> conA = hungerPatternClass.getDeclaredConstructor(); Constructor&lt;HungerPattern> conB = hungerPatternClass.getDeclaredConstructor(); conA.setAccessible(true); conB.setAccessible(true); HungerPattern instanceA = conA.newInstance(); HungerPattern instanceB = conB.newInstance(); // instanceA 和 instanceB 不是同一对象 System.out.println(hungerPattern.hashCode()); System.out.println(instanceA.hashCode()); System.out.println(instanceB.hashCode()); } catch (Exception e) { e.printStackTrace(); } } } 输出结果 D:\\jdk1.8\\bin\\java.exe . . . 713338599 168423058 821270929 Process finished with exit code 0 双重锁检查双重锁检查同样存在相同的情况 直接使用public class ReflectTest { public static void main(String[] args) { try { DoubleCheckLockLazyPattern pattern = DoubleCheckLockLazyPattern.getDoubleCheckLockLazyPattern(); Class&lt;DoubleCheckLockLazyPattern&gt; patternClass = DoubleCheckLockLazyPattern.class; Constructor&lt;DoubleCheckLockLazyPattern&gt; conA = patternClass.getDeclaredConstructor(); Constructor&lt;DoubleCheckLockLazyPattern&gt; conB = patternClass.getDeclaredConstructor(); conA.setAccessible(true); conB.setAccessible(true); DoubleCheckLockLazyPattern patternA = conA.newInstance(); DoubleCheckLockLazyPattern patternB = conA.newInstance(); System.out.println(pattern.hashCode()); System.out.println(patternA.hashCode()); System.out.println(patternB.hashCode()); } catch (Exception e) { e.printStackTrace(); } }} 输出结果 ```bash D:\\jdk1.8\\bin\\java.exe . . . 713338599 168423058 821270929 Process finished with exit code 0 在双重锁检查私有构造内加入异常 public class DoubleCheckLockLazyPattern { private DoubleCheckLockLazyPattern() { // 加入异常判断, 防止反射 if (doubleCheckLockLazyPattern != null) { throw new RuntimeException(); } } private static volatile DoubleCheckLockLazyPattern doubleCheckLockLazyPattern = null; public static DoubleCheckLockLazyPattern getDoubleCheckLockLazyPattern() { try { if (doubleCheckLockLazyPattern == null) { // 一系列操作 Thread.sleep(100); synchronized (DoubleCheckLockLazyPattern.class) { // 二次检查 if (doubleCheckLockLazyPattern == null) { doubleCheckLockLazyPattern = new DoubleCheckLockLazyPattern(); } } } } catch (InterruptedException e) { e.printStackTrace(); } return doubleCheckLockLazyPattern; } } 输出结果 D:\\jdk1.8\\bin\\java.exe . . . java.lang.reflect.InvocationTargetException at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:423) at com.liuzhihang.demo.singleton.ReflectTest.main(ReflectTest.java:24) Caused by: java.lang.RuntimeException at com.liuzhihang.demo.singleton.DoubleCheckLockLazyPattern.&lt;init>(DoubleCheckLockLazyPattern.java:15) ... 5 more 通过序列化反序列化获取对象 DoubleCheckLockLazyPattern 实现序列化 public class ReflectTest { public static void main(String[] args) { try { DoubleCheckLockLazyPattern pattern = DoubleCheckLockLazyPattern.getDoubleCheckLockLazyPattern(); FileOutputStream fos= new FileOutputStream(\"C:/Users/liuzhihang/desktop/pattern.txt\"); ObjectOutputStream oos = new ObjectOutputStream(fos); oos.writeObject(pattern); oos.close(); fos.close(); ObjectInputStream oisA = new ObjectInputStream(new FileInputStream(\"C:/Users/liuzhihang/desktop/pattern.txt\")); DoubleCheckLockLazyPattern patternA= (DoubleCheckLockLazyPattern) oisA.readObject(); ObjectInputStream oisB = new ObjectInputStream(new FileInputStream(\"C:/Users/liuzhihang/desktop/pattern.txt\")); DoubleCheckLockLazyPattern patternB= (DoubleCheckLockLazyPattern) oisB.readObject(); System.out.println(pattern.hashCode()); System.out.println(patternA.hashCode()); System.out.println(patternB.hashCode()); } catch (Exception e) { e.printStackTrace(); } } } 输出结果 D:\\jdk1.8\\bin\\java.exe . . . 258952499 1702297201 1996181658 Process finished with exit code 0 修改反序列化方法, 可以防止反序列化 添加以下方法 private Object readResolve() { return doubleCheckLockLazyPattern; } 输出结果 D:\\jdk1.8\\bin\\java.exe . . . 258952499 258952499 258952499 Process finished with exit code 0 枚举单例public enum SingletonEnum { /** * 单例 */ INSTANCE; private Resource resource; SingletonEnum() { this.resource = new Resource(); } public Resource getResource() { return resource; } } class Resource { } 枚举单例分析在枚举反射获取对象时抛出异常, 通过 Constructor类 源码可以看出, 在反射创建对象时会判断是否是枚举修饰, 是则抛出异常 @CallerSensitive public T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException { if (!override) { if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) { Class&lt;?> caller = Reflection.getCallerClass(); checkAccess(caller, clazz, null, modifiers); } } if ((clazz.getModifiers() &amp; Modifier.ENUM) != 0) throw new IllegalArgumentException(\"Cannot reflectively create enum objects\"); ConstructorAccessor ca = constructorAccessor; // read volatile if (ca == null) { ca = acquireConstructorAccessor(); } @SuppressWarnings(\"unchecked\") T inst = (T) ca.newInstance(initargs); return inst; } 同时在父类 Enum类 中重写了 readObject方法, 所以枚举也可以避免反序列化 /** * prevent default deserialization */ private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException { throw new InvalidObjectException(\"can't deserialize enum\"); }","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"反射","slug":"反射","permalink":"https://liuzhihang.com/tags/%E5%8F%8D%E5%B0%84/"}]},{"title":"反射","slug":"utils/reflection/Reflect","date":"2018-08-24T11:24:38.000Z","updated":"2020-04-04T07:33:24.454Z","comments":true,"path":"2018/08/24/reflection.html","link":"","permalink":"https://liuzhihang.com/2018/08/24/reflection.html","excerpt":"介绍java反射可以在运行时获取对象的成员和属性, 并且可以动态的创建对象并调用对象的属性.反射一般编程中很少使用,但是在很多框架中都使用了反射, 比如配置Spring的Xml配置文件中, 就使用全类名配置方式, 其实就是反射的一种使用方式. 同时反射对单例模式有一定的影响, 可以参考反射获取单例对象","text":"介绍java反射可以在运行时获取对象的成员和属性, 并且可以动态的创建对象并调用对象的属性.反射一般编程中很少使用,但是在很多框架中都使用了反射, 比如配置Spring的Xml配置文件中, 就使用全类名配置方式, 其实就是反射的一种使用方式. 同时反射对单例模式有一定的影响, 可以参考反射获取单例对象 获取反射对象获取反射Class对象一共三种方式 // 1. 使用实例获取 User user = new User(); Class&lt;? extends User> aClass = user.getClass(); // 2. 使用类获取 Class&lt;User> userClass = User.class; // 3. 全类名获取, 可能会抛出 ClassNotFoundException 异常 Class&lt;?> aClass1 = Class.forName(\"com.liuzhihang.tool.reflect.User\"); 获取属性 获取字段// 获取所有公有字段 (public) Field[] fields = aClass.getFields(); // 获取所有字段 (public 缺省, protected, private) Field[] fields = aClass.getDeclaredFields() // 获取指定公共字段 Field age = aClass.getField(\"age\"); // 获取指定字段 (public 缺省, protected, private) Field userName = aClass.getDeclaredField(\"userName\"); 获取构造 获取构造// 获取所有构造 不能获取私有 Constructor&lt;?>[] constructors = aClass.getConstructors(); // 获取指定参数类型的构造 不能获取私有 空则获取空参构造 getConstructor(Class&lt;?&gt;… parameterTypes)Constructor constructor = aClass.getConstructor(String.class); // 获取所有构造 包含私有Constructor&lt;?&gt;[] declaredConstructors = aClass.getDeclaredConstructors(); // 获取指定参数类型的构造 可以获取私有 空则获取空参构造 getDeclaredConstructor(Class&lt;?&gt;… parameterTypes)Constructor declaredConstructor = aClass.getDeclaredConstructor(String.class); 2. 使用构造创建对象 可以通过 constructor.setAccessible(true); 暴力破解忽略访问修饰符, 来使用私有构造参数 ```bash Constructor&lt;User&gt; constructor = aClass.getDeclaredConstructor(String.class); // 暴力破解 constructor.setAccessible(true); User test = constructor.newInstance(&quot;test&quot;); 获取方法 获取方法// 获取所有公共方法(包含父类) Method[] methods = aClass.getMethods(); // 获取所有方法 Method[] methods = aClass.getDeclaredMethods(); // 获取私有方法 第一个参数填方法名称 Method address = aClass.getDeclaredMethod(\"setAddress\", String.class); // 获取公共方法 Method address = aClass.getMethod(\"setAddress\", String.class); 2. 使用方法 ```bash Class&lt;?&gt; aClass = Class.forName(&quot;com.liuzhihang.tool.reflect.User&quot;) Method address = aClass.getDeclaredMethod(&quot;setAddress&quot;, String.class); User user = aClass.getConstructor().newInstance(); System.out.println(user.toString()); // 解除私有限制 address.setAccessible(true); // 使用invoke来调用方法 address.invoke(user, &quot;北京&quot;); System.out.println(user.toString()); 获取其他属性还可以获取类实现的接口, 父类, 注解, 以及判断类的类型等多种使用方式.","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"反射","slug":"反射","permalink":"https://liuzhihang.com/tags/%E5%8F%8D%E5%B0%84/"}]},{"title":"LinkList相关学习","slug":"source-code/java/LinkList","date":"2018-08-23T09:56:29.000Z","updated":"2020-04-04T06:54:14.566Z","comments":true,"path":"2018/08/23/linklist-related-learning.html","link":"","permalink":"https://liuzhihang.com/2018/08/23/linklist-related-learning.html","excerpt":"介绍 LinkList也是工作中常见的集合, 底层使用双向链表结构比较适合新增和删除, 查询和修改需要遍历相对ArrayList比较消耗性能","text":"介绍 LinkList也是工作中常见的集合, 底层使用双向链表结构比较适合新增和删除, 查询和修改需要遍历相对ArrayList比较消耗性能 内部类 Nodeprivate static class Node&lt;E> { // 元素值 E item; // 下一个节点 Node&lt;E> next; // 上一个几点 Node&lt;E> prev; // 构造一个新节点 指向上一个节点和下一个节点 Node(Node&lt;E> prev, E element, Node&lt;E> next) { this.item = element; this.next = next; this.prev = prev; } } add 新增通过代码可以看出, 在新增元素时只需要创建一个新节点 Node, 并将原始链表最后一个Node的next指向新Node public boolean add(E e) { linkLast(e); return true; } /** * Links e as last element. */ void linkLast(E e) { // 声明 l 为最后一个节点 final Node&lt;E> l = last; // 创建新节点, 指向上一个节点, 下一个节点为空 final Node&lt;E> newNode = new Node&lt;>(l, e, null); // 最后一个节点为新创建的节点 last = newNode; // 判断是否为第一个元素, 否则将 新创建的 Node加入链表 if (l == null) first = newNode; else l.next = newNode; size++; modCount++; } remove 删除1.删除操作需要遍历链表找到相应元素, 然后移动指针即可2.删除首尾元素直接移动指针即可 removeFirst()/removeLast() 方法 public boolean remove(Object o) { if (o == null) { // 遍历链表 for (Node&lt;E> x = first; x != null; x = x.next) { if (x.item == null) { unlink(x); return true; } } } else { for (Node&lt;E> x = first; x != null; x = x.next) { if (o.equals(x.item)) { unlink(x); return true; } } } return false; } /** * 删除元素 */ E unlink(Node&lt;E> x) { // assert x != null; final E element = x.item; final Node&lt;E> next = x.next; final Node&lt;E> prev = x.prev; // 判断上一个Node是否为空 if (prev == null) { // 空, 该节点为链表头, 将下一个节点设置为链表头 first = next; } else { // 不为空, 将上一个节点的next 指向当前节点的 next, 并将当前节点的 prev置为空 prev.next = next; x.prev = null; } // 判断下一个Node是否为空 if (next == null) { // 空, 该节点为链表尾, 将链表尾设置为当前节点的上一个节点 last = prev; } else { // 不为空, 将下一个节点的prev, 设置为上一个节点, 并将当前节点的 next置为空 next.prev = prev; x.next = null; } x.item = null; size--; modCount++; return element; } get/setget/set时都需要获取指定索引的元素, 使用二分法查找, 然后进行遍历查找, 所以此处相较于ArrayList多了遍历查询, 虽然使用了二分法进行优化, 但是get/set操作相比ArrayList来说性能还是相对较差 public E get(int index) { // 校验索引 checkElementIndex(index); // 二分法遍历查找节点 return node(index).item; } public E set(int index, E element) { // 校验索引 checkElementIndex(index); // 二分法遍历查找节点 Node&lt;E> x = node(index); // 修改Node节点的 item值 E oldVal = x.item; x.item = element; return oldVal; } /** * 返回指定索引处非null节点. */ Node&lt;E> node(int index) { // assert isElementIndex(index); // 判断索引是否小于长度的一半 (二分法) 然后遍历查找 if (index &lt; (size >> 1)) { Node&lt;E> x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; } else { Node&lt;E> x = last; for (int i = size - 1; i > index; i--) x = x.prev; return x; } }","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"LinkList","slug":"LinkList","permalink":"https://liuzhihang.com/tags/LinkList/"}]},{"title":"ArrayList相关学习","slug":"source-code/java/ArrayList","date":"2018-08-23T07:17:40.000Z","updated":"2020-04-04T06:20:52.869Z","comments":true,"path":"2018/08/23/arraylist-related-learning.html","link":"","permalink":"https://liuzhihang.com/2018/08/23/arraylist-related-learning.html","excerpt":"ArrayList是工作中常用的集合, 基于数组实现, 可以插入空数据, 也支持随机访问.ArrayList比较适合 get/set操作, 因为 add/remove需要移动数据, 相对来说比较消耗性能. 默认初始长度1.默认初始长度为 102.底层结构为Object[] 数组","text":"ArrayList是工作中常用的集合, 基于数组实现, 可以插入空数据, 也支持随机访问.ArrayList比较适合 get/set操作, 因为 add/remove需要移动数据, 相对来说比较消耗性能. 默认初始长度1.默认初始长度为 102.底层结构为Object[] 数组 private static final int DEFAULT_CAPACITY = 10; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * 构造一个初始容量为10的空列表 */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } 添加方法 add() 向数组中添加元素, 流程如下 /** * 将指定的元素追加到此列表的末尾. */ public boolean add(E e) { // 扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 添加元素 elementData[size++] = e; return true; } 2.扩容过程 transient Object[] elementData; // 扩容 private void ensureCapacityInternal(int minCapacity) { ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); } // 计算容量, elementData为空 则使用默认容量 10, 指定容量 private static int calculateCapacity(Object[] elementData, int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { return Math.max(DEFAULT_CAPACITY, minCapacity); } return minCapacity; } // 修改次数自增, 并且如果 新的长度-原长度>0 则使用 grow(minCapacity)方法进行扩容 private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length > 0) grow(minCapacity); } 添加元素赋值elementData[size++] = e; 扩容流程 grow(minCapacity)通过扩容流程可以看出扩容过程中, 是将创建一个原数组1.5倍大小的新数组, 同时将数组元素复制到新数组, 所以一般使用中, 尽量指定数组大小, 从而避免数组的复制. /** * 增加容量确保能容纳 minCapacity 数量的元素 */ private void grow(int minCapacity) { // overflow-conscious code // 获取当前 elementData 的长度 int oldCapacity = elementData.length; // 获取新的长度 为当前长度的 1.5倍 int newCapacity = oldCapacity + (oldCapacity >> 1); // 比较并交换 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 防止超出最大长度 if (newCapacity - MAX_ARRAY_SIZE > 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 数组复制 elementData = Arrays.copyOf(elementData, newCapacity); } 删除 remove 方法删除过程中使用 System.arraycopy 本地方法, 对数组进行复制, 所以 ArrayList的 新增和删除方法性能不如, LinkList, 但是 get和set方法, 则直接根据索引修改数据, 比较适合对数据进行修改的操作. /** * 删除指定位置的元素, 后面的元素将前移 */ public E remove(int index) { // 检查索引 否则抛出 IndexOutOfBoundsException(outOfBoundsMsg(index)) rangeCheck(index); // 修改次数自增 modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved > 0) // 数组复制 System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; } /** * 删除指定元素 */ public boolean remove(Object o) { if (o == null) { for (int index = 0; index &lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false; } /** * System.arraycopy 方法拷贝 删除 */ private void fastRemove(int index) { modCount++; int numMoved = size - index - 1; if (numMoved > 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work }","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}]},{"title":"@Value注入属性的小bug","slug":"issue/inject-bean","date":"2018-08-21T06:47:41.000Z","updated":"2020-04-04T06:23:27.471Z","comments":true,"path":"2018/08/21/value-injects-a-small-bug-in-the-property.html","link":"","permalink":"https://liuzhihang.com/2018/08/21/value-injects-a-small-bug-in-the-property.html","excerpt":"@Value注入属性工作中一些公共属性, 一般通过@Value注入的对象的属性中, 使用方式如下 @Configuration public class WeChatConfig { /** * 微信支付参数 */ @Value(&quot;${wx.appId}&quot;) public String WX_APP_ID; } 通过@Value注解, 将配置文件中的值注入到对象属性中, 在使用时只需要注入WeChatConfig对象然后调用即可, 而实际工作中, 往往用静态属性, 方便使用, 于是可以写成如下方式","text":"@Value注入属性工作中一些公共属性, 一般通过@Value注入的对象的属性中, 使用方式如下 @Configuration public class WeChatConfig { /** * 微信支付参数 */ @Value(\"${wx.appId}\") public String WX_APP_ID; } 通过@Value注解, 将配置文件中的值注入到对象属性中, 在使用时只需要注入WeChatConfig对象然后调用即可, 而实际工作中, 往往用静态属性, 方便使用, 于是可以写成如下方式 @Configuration public class WeChatConfig { /** * 微信支付参数 */ @Value(\"${wx.appId}\") public static String WX_APP_ID; } 使用此方式不会报错, 但是却取不到属性值, 并且不会报错. 变通方式可以如下: @Configuration public class WeChatConfig { /** * 微信支付参数 */ @Value(\"${wx.appId}\") public static String WX_APP_ID; @Value(\"${wx.app.id}\") private void setWxAppId(String wxAppId) { WX_APP_ID = wxAppId; } } 注意: 此处的 set方法不可以设置为静态, 否则同样不能注入属性","categories":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/categories/issue/"}],"tags":[{"name":"issue","slug":"issue","permalink":"https://liuzhihang.com/tags/issue/"}]},{"title":"使用枚举实现单例","slug":"design-patterns/单例模式-枚举实现","date":"2018-08-17T12:05:10.000Z","updated":"2020-04-04T04:12:06.877Z","comments":true,"path":"2018/08/17/use-enumeration-to-implement-a-singleton.html","link":"","permalink":"https://liuzhihang.com/2018/08/17/use-enumeration-to-implement-a-singleton.html","excerpt":"简介介绍使用枚举的方式创建单例, 其他方式可以参考单例模式","text":"简介介绍使用枚举的方式创建单例, 其他方式可以参考单例模式 代码 /** * 使用枚举单例 * * @author liuzhihang * @date 2018/8/17 17:34 */ public class SingletonPattern { private SingletonPattern() { } public static SingletonPattern getInstance() { return SingleEnum.INSTANCE.getSingletonPattern(); } private enum SingleEnum { /** * 单例 */ INSTANCE; private SingletonPattern singletonPattern; SingleEnum() { this.singletonPattern = new SingletonPattern(); } public SingletonPattern getSingletonPattern() { return singletonPattern; } } } 优点1.比双重锁检查相对简洁2.线程安全3.自动处理序列化4.防止反射","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","permalink":"https://liuzhihang.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"Elasticsearch基本语句","slug":"elk/es-query","date":"2018-06-26T13:30:29.000Z","updated":"2020-04-04T06:17:49.305Z","comments":true,"path":"2018/06/26/elasticsearch-basic-statement.html","link":"","permalink":"https://liuzhihang.com/2018/06/26/elasticsearch-basic-statement.html","excerpt":"查看集群1. 查看集群健康curl -X GET &quot;localhost:9200/_cat/health?v&quot; 2. 查看集群节点curl -X GET &quot;localhost:9200/_cat/nodes?v&quot;","text":"查看集群1. 查看集群健康curl -X GET \"localhost:9200/_cat/health?v\" 2. 查看集群节点curl -X GET \"localhost:9200/_cat/nodes?v\" 3. 查看集群所有索引curl -X GET \"localhost:9200/_cat/indices?v\" get 获取指定数据1. 直接获取数据curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK?pretty\" 格式为 /{index}/{type}/{id} 字段 含义 monitor_log_mch_order_out 索引 (_index) logs 索引的类型 (_type), 不知道类型可以用 _all 匹配 AWSudIFgTuj3oZBEhyxK id (_id) pretty json格式显示数据, 可省略 #### 2. 屏蔽或只查看 _source ```bash curl -X GET “localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK?pretty&amp;_source=false” ``` 添加 _source=false 即可 ```bash curl -X GET “localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK/_source?pretty” ``` 3. 过滤字段curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK?pretty&amp;_source_include=log*&amp;_source_exclude=logType\" 获取包含 log* 且不为 logType 的字段 curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/AWSudIFgTuj3oZBEhyxK?pretty&amp;_source=logType,logLevel\" 只查询指定字段的简易写法 mget 多条件匹配查询 匹配多个索引, 同时查询多个id的数据 curl -X GET \"localhost:9200/_mget?pretty\" -H 'Content-Type: application/json' -d' { \"docs\" : [ { \"_index\" : \"monitor_log_mch_order_out\", \"_type\" : \"logs\", \"_id\" : \"AWSudIFgTuj3oZBEhyxK\" }, { \"_index\" : \"monitor_log_mch_order_out\", \"_type\" : \"logs\", \"_id\" : \"AWSuXewETuj3oZBEhywS\" } ] } ' 可以将索引写在host后面, 代表查询的都为同一索引下的数据 curl -X GET \"localhost:9200/monitor_log_mch_order_out/_mget?pretty\" -H 'Content-Type: application/json' -d' { \"docs\" : [ { \"_type\" : \"logs\", \"_id\" : \"AWSudIFgTuj3oZBEhyxK\" }, { \"_type\" : \"logs\", \"_id\" : \"AWSuXewETuj3oZBEhywS\" } ] } ' 合并index和type, 代表查询的都为同一索引下type也相同的数据 curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_mget?pretty\" -H 'Content-Type: application/json' -d' { \"docs\" : [ { \"_id\" : \"AWSudIFgTuj3oZBEhyxK\" }, { \"_id\" : \"AWSuXewETuj3oZBEhywS\" } ] } ' 简化后如下: curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_mget?pretty\" -H 'Content-Type: application/json' -d' { \"ids\" : [\"AWSudIFgTuj3oZBEhyxK\", \"AWSuXewETuj3oZBEhywS\"] } ' 注: 当多个条件的 _type 相同时 可以使用 _all 或者省略 过滤字段, 每个Id分别对 _source进行过滤curl -X GET \"localhost:9200/monitor_log_mch_order_out/_mget?pretty\" -H 'Content-Type: application/json' -d' { \"docs\" : [ { \"_id\" : \"AWSudIFgTuj3oZBEhyxK\", \"_source\" : false }, { \"_id\" : \"AWSuXewETuj3oZBEhywS\", \"_source\" : [\"bizId\", \"method\"] }, { \"_id\" : \"AWSuLAYqTuj3oZBEhysH\", \"_source\" : { \"include\": [\"log*\"], \"exclude\": [\"logLevel\"] } } ] } ' _search 搜索1. 匹配bizId 查询curl -X GET \"localhost:9200/monitor_log_mch_order_out/_search?pretty&amp;q=bizId:2009011201807190133430748068\" 2. 同时指定类型同时指定类型, 多个类型用 ‘,’ 隔开, 也支持多个索引勇士搜索, 多个索引用 ‘,’ 隔开, 或者模糊搜索 curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_search?pretty&amp;q=bizId:2009011201807190133430748068\" 3. 占位符 _all 匹配所有索引curl -X GET \"localhost:9200/_all/logs/_search?pretty&amp;q=bizId:2009011201807190133430748068\" 4. 匹配所有索引所有类型curl -X GET \"localhost:9200/_search?pretty&amp;q=bizId:2009011201807190133430748068\" 注: q 代表映射query_string 5. 请求体的方式curl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_search?pretty\" -H 'Content-Type: application/json' -d' { \"query\" : { \"term\" : { \"bizId\" : \"2009011201807190133430748068\" } } } ' 6. 分页查询 from/sizecurl -X GET \"localhost:9200/monitor_log_mch_order_out/logs/_search?pretty\" -H 'Content-Type: application/json' -d' { \"from\" : 0, \"size\" : 1, \"query\" : { \"term\" : { \"bizId\" : \"2009011201807190133430748068\" } } } ' 7. 查询并过滤字段根据字段查询并筛选掉指定字段 curl -X GET \"localhost:9200/_search?pretty\" -H 'Content-Type: application/json' -d' { \"_source\": { \"includes\": [ \"costTime\", \"bizId\" ], \"excludes\": [ \"logLevel\" ] }, \"query\" : { \"term\" : { \"bizId\" : \"2009011201807190133430748068\" } } } ' 范围查询1. 按照时间范围查询可以省略索引查询全部 curl -X GET \"localhost:9200/monitor_log_mch_order_out/_search?pretty\" -H 'Content-Type: application/json' -d' { \"query\": { \"range\" : { \"time\" : { \"gte\": \"2018-07-19 00:14:25:000\", \"lte\": \"2018-07-19 00:14:30:000\", \"format\": \"yyyy-MM-dd HH:mm:ss:SSS\" } } } } '","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"logstash配置","slug":"elk/logstash-config","date":"2018-06-20T14:28:02.000Z","updated":"2020-04-04T06:18:05.805Z","comments":true,"path":"2018/06/20/logstash-configuration.html","link":"","permalink":"https://liuzhihang.com/2018/06/20/logstash-configuration.html","excerpt":"输入input { beats { port =&gt; &quot;5043&quot; } } 配置日志输入方式为 filebeat, 并配置端口","text":"输入input { beats { port => \"5043\" } } 配置日志输入方式为 filebeat, 并配置端口 过滤filter { grok { match => { \"message\" => \"\\[%{DATA:time}\\]-\\[%{DATA:method}\\] - \\[%{DATA:catalina}\\] -\\[%{DATA:logLevel}\\] - \\[%{DATA:index_prefix}\\|%{WORD:logType}\\|%{WORD:sysNo}\\|%{WORD:objType}\\|%{DATA:funcode}\\|%{WORD:monitorObjNo}\\|%{WORD:bizId}\\|%{WORD:respCode}\\|%{DATA:respMsg}\\|%{WORD:costTime}|%{DATA:exField}\\]\" } } grok{ match => { \"time\" => [\"%{INT:y_index}-%{INT:M_index}-%{INT:d_index}\"]} } mutate { add_field => { \"[@metadata][index_suffix]\" => \"%{y_index}%{M_index}%{d_index}\" } remove_field => [\"beat\",\"host\",\"thread\",\"class\",\"source\",\"tags\",\"type\",\"y_index\",\"M_index\",\"d_index\"] lowercase => [ \"index_prefix\" ] lowercase => [ \"funcode\" ] lowercase => [ \"objType\" ] lowercase => [ \"monitorObjNo\" ] } } 使用gork过滤器对日志进行筛选, 并对部分字段赋值. 使用mutate插件对字段进行转换, add_field 为添加字段 [@metadata][index_suffix] 意思是添加临时字段, 该字段不会输出到es中 输出output { if [logType] == \"info\" { elasticsearch { hosts => [ \"xxx.xxx.xxx.xxx:9200\" ] index => \"%{index_prefix}_%{objType}_%{funcode}_%{[@metadata][index_suffix]}\" user => elastic password => xxx } } if [logType] == \"error\" { redis { data_type => \"list\" db => 0 #key => \"%{index_prefix}_%{sysNo}_%{objType}_%{funcode}_%{[@metadata][index_suffix]}\" key => \"%{index_prefix}_%{sysNo}_%{objType}_%{monitorObjNo}\" host => \"xxx.xxx.xxx.xxx\" port => \"6379\" password => \"xxx\" } } } 将过滤后的字段按照类型输出到Es或者redis队列中 启动命令 ./bin/logstash -f first-pipelines.yml nohup ./logstash -f ../first-pipelines.yml &gt;/dev/null 2&gt;&amp;1 &amp;其他配置# 输出到控制台 stdout { codec => rubydebug }","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"filebeat配置","slug":"elk/filebeat-config","date":"2018-06-20T13:30:29.000Z","updated":"2020-04-04T06:17:59.180Z","comments":true,"path":"2018/06/20/filebeat-configuration.html","link":"","permalink":"https://liuzhihang.com/2018/06/20/filebeat-configuration.html","excerpt":"","text":"filebeat配置filebeat.prospectors: - input_type: log #读取日志的路径 paths: - /opt/export/log/info-xxx.log fields: log_type: \"monitor_log\" fields_under_root: true #过滤部分日志 include_lines: ['Monitor_log'] #----------------------------- Logstash output -------------------------------- output.logstash: # The Logstash hosts hosts: [\"xxx.xxx.xxx.xxx:5043\",\"xxx.xxx.xxx.xxx:5043\"] loadbalance: true #================================ Logging ===================================== logging.level: info logging.to_files: true logging.to_syslog: false logging.files: path: /opt/export/app/filebeat/logs name: mybeat.log keepfiles: 5 过滤不包含指定字段的日志, 并仅仅输出到logstash, 也可以直接输出到Elasticsearch 启动命令 前台启动：关闭窗口连接后自动退出 ./filebeat -e -c filebeat.yml 后台启动: nohup ./filebeat -e -c filebeat.yml >/dev/null 2>&amp;1 &amp; 关闭: kill -9 xxxx","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"监控系统架构","slug":"elk/framework","date":"2018-06-20T12:25:29.000Z","updated":"2020-04-04T06:18:02.309Z","comments":true,"path":"2018/06/20/monitoring-system-architecture.html","link":"","permalink":"https://liuzhihang.com/2018/06/20/monitoring-system-architecture.html","excerpt":"监控系统基本框架","text":"监控系统基本框架 解释 各业务系统按照指定格式打印日志 filebeat自动读取日志信息, 并进行过滤, 输出到logstash logstash进行二次处理, 将日志内容格式化, 并将 info日志和error日志分别存放到Elasticsearch和redis队列中 监控系统定时从Es和redis中获取数据, 存放到mysql并进行报警分析 使用EChart图形化展示信息…","categories":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/categories/ELK/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://liuzhihang.com/tags/ELK/"}]},{"title":"线程的生命周期","slug":"concurrent/thread-life-cycle","date":"2018-06-15T11:31:00.000Z","updated":"2020-04-04T06:16:51.741Z","comments":true,"path":"2018/06/15/thread-life-cycle.html","link":"","permalink":"https://liuzhihang.com/2018/06/15/thread-life-cycle.html","excerpt":"线程的生命周期","text":"线程的生命周期 图解析1.一般情况下线程主要经历: 准备, 就绪, 运行, 死亡四种状态.2.准备:即创建线程, 包括集成Thread, 线程池, spring方式等等3.就绪:线程创建并调用start()方法并不代表线程将立即获得资源, 而是进入到就绪状态进行资源分配4.运行:抢占到资源的线程将执行, 执行过程可能会含有一些别的操作&emsp;1).线程等待, 直到调用 notify()或notifyAll()方法被唤醒, 这里唤醒后不会立即继续执行线程, 而是进入就绪状态重新抢占资源&emsp;2).线程休眠, 直到休眠时间结束, 同样结束后不会立即继续执行线程, 而是进入就绪状态重新抢占资源&emsp;3).线程阻塞, IO资源阻塞, 锁等方式使线程进入阻塞队列, 释放锁将继续执行5.死亡: 调用stop()方法, 线程中断, 或线程执行完毕则线程死亡","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"synchronized锁的介绍","slug":"concurrent/synchronized-thread","date":"2018-06-13T12:25:00.000Z","updated":"2020-04-04T06:16:28.556Z","comments":true,"path":"2018/06/13/introduction-of-synchronized-lock.html","link":"","permalink":"https://liuzhihang.com/2018/06/13/introduction-of-synchronized-lock.html","excerpt":"synchronized锁的使用synchronized可以使用在方法和代码块中, 使用的方式不同锁代表的含义不同, 下面将从几个方面进行介绍. 普通方法 静态方法 代码块synchronized(this) 代码块synchronized(*.class)","text":"synchronized锁的使用synchronized可以使用在方法和代码块中, 使用的方式不同锁代表的含义不同, 下面将从几个方面进行介绍. 普通方法 静态方法 代码块synchronized(this) 代码块synchronized(*.class) 结论 在使用synchronized关键字中锁主要分为两类, 一种是对象锁, 另一种类锁 普通加锁方法和synchronized(this)都是对象锁, 静态加锁方法和synchronized(*.class)都是类锁 对象锁: 同一对象持有锁, 相同对象等待, 其他对象不受影响; 不同对象持有锁, 互不影响. 类锁: 类锁时, 只要该类的对象持有锁, 无论是否为同一对象访问静态同步方法时都等待, 访问非静态同步方法不受影响. 对象锁和类锁互相不影响 测试代码及过程package com.liuzhihang.tool.sync; /** * @author liuzhihang * @date 2018/7/11 16:25 */ public class SyncMainTest { public static void main(String[] args) { SyncTest syncTest1 = new SyncTest(); // SyncTest syncTest2 = new SyncTest(); new Thread(() -> syncTest1.methodA(), \"线程 01 \").start(); new Thread(() -> syncTest1.methodB(), \"线程 02 \").start(); } } class SyncTest { void methodA() { System.out.println(Thread.currentThread().getName() + \"start\"); try { System.out.println(Thread.currentThread().getName() + \"sleep\"); Thread.sleep(500); } catch (InterruptedException e) { } System.out.println(Thread.currentThread().getName() + \"end\"); } void methodB() { System.out.println(Thread.currentThread().getName() + \"start\"); try { System.out.println(Thread.currentThread().getName() + \"sleep\"); Thread.sleep(300); } catch (InterruptedException e) { } System.out.println(Thread.currentThread().getName() + \"end\"); } } 以上为一个简单的测试代码, 指使用两个线程分别调用两个方法, 通过打印结果可以看出顺序是乱序的, 其中线程的 start() 顺序并不代表线程的执行顺序, 在下面测试中假设是 “线程01” 先执行. 1.A B 方法分别添加synchronized关键字 + 同一对象class SyncTest { synchronized void methodA() { // ... } synchronized void methodB() { // ... } } 结论: 方法 A 阻塞, 方法 B 等待 A 执行完毕后才继续执行. 2.A B 方法分别添加synchronized关键字 + 不同对象public class SyncMainTest { public static void main(String[] args) { SyncTest syncTest1 = new SyncTest(); SyncTest syncTest2 = new SyncTest(); new Thread(() -> syncTest1.methodA(), \"线程 01 \").start(); new Thread(() -> syncTest2.methodB(), \"线程 02 \").start(); } } class SyncTest { synchronized void methodA() { // ... } synchronized void methodB() { // ... } } 结论: 方法 A 阻塞, 方法 B 不受影响. 3.A 方法分别添加synchronized关键字 B方法不添加class SyncTest { synchronized void methodA() { // ... } void methodB() { // ... } } 结论: 方法 A 阻塞, 方法 B 不受影响. 4.A B 方法分别添加 static synchronized + 不同对象public class SyncMainTest { public static void main(String[] args) { SyncTest syncTest1 = new SyncTest(); SyncTest syncTest2 = new SyncTest(); new Thread(() -> syncTest1.methodA(), \"线程 01 \").start(); new Thread(() -> syncTest2.methodB(), \"线程 02 \").start(); } } class SyncTest { static synchronized void methodA() { // ... } static synchronized void methodB() { // ... } } 结论: 方法 A 阻塞, 方法 B 等待 A结束后继续执行. 5.A 方法添加 static synchronized, B 方法添加 synchronized + 不同对象public class SyncMainTest { public static void main(String[] args) { SyncTest syncTest1 = new SyncTest(); SyncTest syncTest2 = new SyncTest(); new Thread(() -> syncTest1.methodA(), \"线程 01 \").start(); new Thread(() -> syncTest2.methodB(), \"线程 02 \").start(); } } class SyncTest { static synchronized void methodA() { // ... } synchronized void methodB() { // ... } } 结论: 方法 A 阻塞, 方法 B 不受影响. 6.A B 方法内添加 synchronized(this)class SyncTest { void methodA() { synchronized (this) { // ... } } void methodB() { synchronized (this) { // ... } } } 结论: 同一对象 A 阻塞 B等待, 不同对象 A阻塞 B不受影响 7.A B 方法内添加 synchronized(SyncTest.class)class SyncTest { void methodA() { synchronized (SyncTest.class) { // ... } } void methodB() { synchronized (SyncTest.class) { // ... } } } 结论: 同一/不同对象 A 阻塞 B等待 8.A 方法内添加 synchronized(SyncTest.class), B 方法内添加 synchronized(this)class SyncTest { void methodA() { synchronized (SyncTest.class) { // ... } } void methodB() { synchronized (this) { // ... } } } 结论: 同一/不同对象 A 阻塞 B不受影响 9.A 方法内添加 synchronized(SyncTest.class), B 方法内添加 synchronized(OtherObj)class SyncTest { private String string = \"lock\"; void methodA() { synchronized (SyncTest.class) { // ... } } void methodB() { synchronized (string) { // ... } } } 结论: 同一/不同对象 A 阻塞 B不受影响","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"synchronized同步锁原理","slug":"concurrent/synchronized","date":"2018-06-11T12:25:29.000Z","updated":"2020-04-04T06:16:09.670Z","comments":true,"path":"2018/06/11/synchronized-synchronous-lock-principle.html","link":"","permalink":"https://liuzhihang.com/2018/06/11/synchronized-synchronous-lock-principle.html","excerpt":"介绍 在多线程操作中volatile关键字可以保证共享变量的内存可见性, 但是并不能保证操作的原子性, 这时候就需要用到锁, synchronized同步锁是java关键字, 是内置的语言实现. synchronized加锁和线程结束或异常锁的释放过程由JVM进行控制 synchronized关键字可以使用在方法和同步代码块中, 不同的使用方式, 锁的结果是不同的 重量级锁 + 可重入","text":"介绍 在多线程操作中volatile关键字可以保证共享变量的内存可见性, 但是并不能保证操作的原子性, 这时候就需要用到锁, synchronized同步锁是java关键字, 是内置的语言实现. synchronized加锁和线程结束或异常锁的释放过程由JVM进行控制 synchronized关键字可以使用在方法和同步代码块中, 不同的使用方式, 锁的结果是不同的 重量级锁 + 可重入 synchronized底层原理1.代码示例 package com.liuzhihang.tool.java; /** * @author liuzhihang * @date 2018/06/11 16:05 */ public class SynchronizedTest { private int i; private int j; public void syncTest1() { synchronized (this) { i++; } } public synchronized void syncTest2() { j++; } } 2.使用 javap -v SynchronizedTest.class 查看代码的对应字节码如下: $ javap -v SynchronizedTest.class Classfile /C:/Users/liuzhihang/Desktop/SynchronizedTest.class Last modified 2018-7-10; size 518 bytes MD5 checksum ba48def77b226e7b9ac28121ec423c16 Compiled from &quot;SynchronizedTest.java&quot; public class com.liuzhihang.tool.java.SynchronizedTest minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: // 常量池省略 { // 构造方法省略 public void syncTest1(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: aload_0 5: dup 6: getfield #2 // Field i:I 9: iconst_1 10: iadd 11: putfield #2 // Field i:I 14: aload_1 15: monitorexit 16: goto 24 19: astore_2 20: aload_1 21: monitorexit 22: aload_2 23: athrow 24: return Exception table: // 省略代码 public synchronized void syncTest2(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #3 // Field j:I 5: iconst_1 6: iadd 7: putfield #3 // Field j:I 10: return LineNumberTable: line 22: 0 line 23: 10 } SourceFile: &quot;SynchronizedTest.java&quot; 3.结论 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令, 其中有两个 monitorexit 因为不能确保是正常结束还是异常结束, 所以另一个是用来确保异常结束时释放 monitor指令. 同步方法时使用的是 flags中的 ACC_SYNCHRONIZED 来标识该方法为同步方法, JVM在调用该方法时便会执行相应的同步调用. 每个线程都维护自己的监视器(monitor), 只要是同步调用进行相关操作时要先获得 monitor, 否则将被阻塞","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://liuzhihang.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"volatile关键字","slug":"concurrent/volatile","date":"2018-06-09T14:31:29.000Z","updated":"2020-04-04T06:49:14.260Z","comments":true,"path":"2018/06/09/volatile-keyword.html","link":"","permalink":"https://liuzhihang.com/2018/06/09/volatile-keyword.html","excerpt":"介绍在多线程操作共享变量时, 会使用volatile修饰共享变量, 比如单例模式的双重锁检查中, 并且在concurrent包下也大量使用了volatile关键字;volatile可以对类属性进行修饰, 从而确保线程每次都是从主存中获取属性, 操作完毕后写回主存.","text":"介绍在多线程操作共享变量时, 会使用volatile修饰共享变量, 比如单例模式的双重锁检查中, 并且在concurrent包下也大量使用了volatile关键字;volatile可以对类属性进行修饰, 从而确保线程每次都是从主存中获取属性, 操作完毕后写回主存. java内存模型 在多线程同时对共享变量进行操作过程中, 每个线程会拷贝一份共享变量到自己的工作内存中进行相关操作, 操作完毕后会将结果写入到主存中. 而volatile关键字可以保证操作的可见性和有序性, 但是却不能保证原子性. 扩展原子性指一个操作或者多个操作要么全部执行要么全部都不执行, 操作过程整体是一个原子, 不被分割打断. 可见性当多个线程访问同一个变量时, 一个线程修改了这个变量的值, 其他线程能够立即看得到修改的值. 有序性即程序执行的顺序按照代码的先后顺序执行主要原因是因为处理器在处理程序时会进行指令重排, 对代码进行优化, 指令重排在单线程中得到的结果是一致的, 但是在多线程中就会造成各种错误. volatile关键字作用1.使用volatile关键字修饰的变量,会强制将修改的值写入到主存中2.volatile不保证原子性, 在多线程操作下仅能保证操作别的线程可见, 在多线程情况下同时操作共享变量依然会有数据不正确的情况.3.volatile会防止指令重排","categories":[{"name":"并发和锁","slug":"并发和锁","permalink":"https://liuzhihang.com/categories/%E5%B9%B6%E5%8F%91%E5%92%8C%E9%94%81/"}],"tags":[{"name":"volatile","slug":"volatile","permalink":"https://liuzhihang.com/tags/volatile/"}]},{"title":"SpringAop代理的选择","slug":"spring/springAop","date":"2018-05-21T06:50:13.000Z","updated":"2020-04-04T04:12:06.927Z","comments":true,"path":"2018/05/21/springaop-agent-selection.html","link":"","permalink":"https://liuzhihang.com/2018/05/21/springaop-agent-selection.html","excerpt":"介绍Spring动态创建bean过程, 是如何进行选择使用 jdk还是cglib进行代理的, 可以通过源码进行解析 执行过程通过断点进行跟踪主要执行过程在 DefaultAopProxyFactory, 通过判断条件是使用Cglib还是Jdk","text":"介绍Spring动态创建bean过程, 是如何进行选择使用 jdk还是cglib进行代理的, 可以通过源码进行解析 执行过程通过断点进行跟踪主要执行过程在 DefaultAopProxyFactory, 通过判断条件是使用Cglib还是Jdk 相关源码解析public class DefaultAopProxyFactory implements AopProxyFactory, Serializable { @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException { //判断条件 是否优化, 返回是否直接代理目标类以及任何接口或者没有用户提供的代理接口 if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) { Class&lt;?> targetClass = config.getTargetClass(); if (targetClass == null) { throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); } //判断是否是接口, 和已经使用jdk代理 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) { return new JdkDynamicAopProxy(config); } return new ObjenesisCglibAopProxy(config); } else { return new JdkDynamicAopProxy(config); } } /** * Determine whether the supplied {@link AdvisedSupport} has only the * {@link org.springframework.aop.SpringProxy} interface specified * (or no proxy interfaces specified at all). */ private boolean hasNoUserSuppliedProxyInterfaces(AdvisedSupport config) { Class&lt;?>[] ifcs = config.getProxiedInterfaces(); return (ifcs.length == 0 || (ifcs.length == 1 &amp;&amp; SpringProxy.class.isAssignableFrom(ifcs[0]))); } }","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"aop","slug":"aop","permalink":"https://liuzhihang.com/tags/aop/"}]},{"title":"cglib动态代理","slug":"spring/CglibProxy","date":"2018-05-18T11:55:01.000Z","updated":"2020-04-04T06:26:10.822Z","comments":true,"path":"2018/05/18/cglib-dynamic-proxy.html","link":"","permalink":"https://liuzhihang.com/2018/05/18/cglib-dynamic-proxy.html","excerpt":"介绍Spring动态代理可以选择使用jdk动态代理, 或者cglib动态代理, cglib动态代理位于 net.sf.cglib.proxy 包下. 使用时涉及接口: net.sf.cglib.proxy.MethodInterceptor用来生成动态子类的类类: net.sf.cglib.proxy.Enhancer 注意: cglib 动态代理是基于类的代理, 是通过对指定的业务类生成一个子类, 并覆盖其中业务方法实现代理. 因为使用继承, 所以被代理类不能使 final 修饰","text":"介绍Spring动态代理可以选择使用jdk动态代理, 或者cglib动态代理, cglib动态代理位于 net.sf.cglib.proxy 包下. 使用时涉及接口: net.sf.cglib.proxy.MethodInterceptor用来生成动态子类的类类: net.sf.cglib.proxy.Enhancer 注意: cglib 动态代理是基于类的代理, 是通过对指定的业务类生成一个子类, 并覆盖其中业务方法实现代理. 因为使用继承, 所以被代理类不能使 final 修饰 使用步骤1.创建MethodInterceptor接口的实现类, 并编写intercept方法的实现2.通过methodProxy.invokeSuper(o, objects);调用父类的方法3.创建Enhancer, 通过 setSuperclass(Class superclass)方法指定父类(被代理类), 通过 setCallback(final Callback callback)方法指定代理4.enhancer.create() 生成代理, 调用被代理类的方法 代码演示按照步骤编写简易逻辑代码. 创建MethodInterceptor接口的实现类/** * 基于类的代理 即使类没有实现接口也可以被代理 * 主要是基于类生成一个继承的子类 所以 类和方法不要声明为 final * * * @author liuzhihang * @date 2018/5/18 10:10 */ public class MyMethodInterceptor implements MethodInterceptor { @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(\"cglib动态代理 before . . .\"); Object invoke = null; try { invoke = methodProxy.invokeSuper(o, objects); } catch (Throwable throwable) { throwable.printStackTrace(); System.err.println(\"cglib动态代理 error: \" + throwable.getMessage()); } finally { System.out.println(\"cglib动态代理 after . . .\"); } return invoke; } } 创建Enhancer创建Enhancer, 通过 setSuperclass(Class superclass)方法指定父类(被代理类), 通过 setCallback(final Callback callback)方法指定代理 public class CglibMainTest { public static void main(String[] args) { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(SubjectCglib.class); enhancer.setCallback(new MyMethodInterceptor()); SubjectCglib subjectCglib = (SubjectCglib) enhancer.create(); System.err.println(subjectCglib.getAge(\"liuzhihang\")); } } 可以将二者合并到MyInterceptor中/** * 基于类的代理 即使类没有实现接口也可以被代理 * * * @author liuzhihang * @date 2018/5/18 10:10 */ public class MyCglibInterceptor implements MethodInterceptor { private Object object; public Object getInstance(Object object) { this.object = object; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(object.getClass()); enhancer.setCallback(this); return enhancer.create(); } @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(\"cglib动态代理 before . . .\"); Object invoke = null; try { invoke = methodProxy.invokeSuper(o, objects); } catch (Throwable throwable) { throwable.printStackTrace(); System.err.println(\"cglib动态代理 error: \" + throwable.getMessage()); } finally { System.out.println(\"cglib动态代理 after . . .\"); } return invoke; } }","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"动态代理","slug":"动态代理","permalink":"https://liuzhihang.com/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"jdk动态代理及源码解析","slug":"spring/JDKProxy","date":"2018-05-17T11:55:01.000Z","updated":"2020-04-04T06:27:13.047Z","comments":true,"path":"2018/05/17/jdk-dynamic-proxy-and-source-code-analysis.html","link":"","permalink":"https://liuzhihang.com/2018/05/17/jdk-dynamic-proxy-and-source-code-analysis.html","excerpt":"介绍Spring动态代理可以选择使用jdk动态代理, 或者cglib动态代理, jdk动态代理位于 java.lang.reflect 包下. 使用时涉及接口: java.lang.reflect.InvocationHandler动态代理类: java.lang.reflect.Proxy 注意: JDK 动态代理是基于接口的代理, 只能对实现接口的类生成代理, 不能对类进行代理","text":"介绍Spring动态代理可以选择使用jdk动态代理, 或者cglib动态代理, jdk动态代理位于 java.lang.reflect 包下. 使用时涉及接口: java.lang.reflect.InvocationHandler动态代理类: java.lang.reflect.Proxy 注意: JDK 动态代理是基于接口的代理, 只能对实现接口的类生成代理, 不能对类进行代理 使用步骤1.创建InvocationHandler接口的实现类, 并编写invoke方法的实现2.创建被代理类的接口及实现类3.使用动态代理类Proxy的静态方法生成代理类实例4.使用实例调用方法 代码演示按照步骤编写简易逻辑代码. 创建InvocationHandler接口的实现类/** * JDK 动态代理 * 基于接口的代理, 只能对实现接口的类生成代理, 不能对类进行代理 * * @author liuzhihang * @date 2018/5/17 10:36 */ public class MyInvocationHandler implements InvocationHandler { /** * 目标对象 */ private Object target; public MyInvocationHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"jdk 动态代理 before . . . \"); System.out.println(\"当前代理方法为:\" + method); Object invoke = method.invoke(target, args); System.out.println(\"jdk 动态代理 after . . . \"); return invoke; } } 创建被代理类的接口及实现类/** * 被代理类的接口 * @author liuzhihang * @date 2018/5/17 10:47 */ public interface Subject { /** * 获取名字 * @return */ String getName(); /** * 获取年龄 * @param name * @return */ String getAge(String name); } /** * 被代理类 * * @author liuzhihang * @date 2018/5/17 10:48 */ public class SubjectImpl implements Subject { @Override public String getName() { System.out.println(\"SubjectImpl的获取名字方法 . . .\"); return \"liuzhihang\"; } @Override public String getAge(String name) { System.out.println(name + \"开始获取年龄 . . .\"); return \"25\"; } } 使用动态代理类Proxy的静态方法生成代理类实例获取代理类实例有以下两种方式, 一种是通过Proxy.newProxyInstance(..)获取, 一种是通过 Proxy.getProxyClass(..) 方式获取1.Proxy.newProxyInstance(..) /** * 当代理类实例调用方法时, 会自动跳转到代理类关联的 handler 对象, 通过 method.invoke(target, args) 进行调用 * * * @author liuzhihang * @date 2018/5/17 10:49 */ public class ProxyMainTest { public static void main(String[] args) { Subject subject = new SubjectImpl(); ClassLoader classLoader = subject.getClass().getClassLoader(); Class&lt;?>[] interfaces = subject.getClass().getInterfaces(); MyInvocationHandler handler = new MyInvocationHandler(subject); // 生成代理类实例 Subject proxyInstance = (Subject) Proxy.newProxyInstance(classLoader, interfaces, handler); String name = proxyInstance.getName(); String instanceAge = proxyInstance.getAge(\"liuzhihang\"); System.err.println(name + \" \" + instanceAge); } } 2.Proxy.getProxyClass(..) /** * 当代理类实例调用方法时, 会自动跳转到代理类关联的 handler 对象, 通过 method.invoke(target, args) 进行调用 * 此方式有异常抛出 * * @author liuzhihang * @date 2018/5/17 10:49 */ public class ProxyMainTest { public static void main(String[] args) { try { Subject subject = new SubjectImpl(); ClassLoader classLoader = subject.getClass().getClassLoader(); Class&lt;?>[] interfaces = subject.getClass().getInterfaces(); MyInvocationHandler handler = new MyInvocationHandler(subject); Class&lt;?> proxyClass = Proxy.getProxyClass(classLoader, interfaces); Constructor&lt;?> constructor = proxyClass.getConstructor(InvocationHandler.class); Subject subject1 = (Subject) constructor.newInstance(handler); String name1 = subject1.getName(); String instanceAge1 = subject1.getAge(\"liuzhihang\"); System.err.println(name1 + \" \" + instanceAge1); } catch (NoSuchMethodException | IllegalAccessException | InvocationTargetException | InstantiationException e) { e.printStackTrace(); } } } 执行结果D:\\jdk1.8\\bin\\java.exe . . . liuzhihang 25 jdk 动态代理 before . . . 当前代理方法为:public abstract java.lang.String com.liuzhihang.tool.proxy.jdk.Subject.getName() SubjectImpl的获取名字方法 . . . jdk 动态代理 after . . . jdk 动态代理 before . . . 当前代理方法为:public abstract java.lang.String com.liuzhihang.tool.proxy.jdk.Subject.getAge(java.lang.String) liuzhihang开始获取年龄 . . . jdk 动态代理 after . . . Process finished with exit code 0结论: 代理实例在每次调用方法是都会通过代理类进行调用 相关源码解析完整注释可自己查看相关源码, 源码过程应当DeBug多走走.1.调用 Proxy.newProxyInstance 方法 /** * 返回指定接口的代理类实例，该接口将方法调用分派给指定的调用处理程序 */ @CallerSensitive public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException { // 非空校验 Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); // 获取系统安全接口 final SecurityManager sm = System.getSecurityManager(); if (sm != null) { // 校验权限 checkProxyAccess(Reflection.getCallerClass(), loader, intfs); } /* * 从缓存中获取代理类 或者 生成新的代理类 */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * 通过反射获取构造函数对象并生成代理类实例 */ try { if (sm != null) { checkNewProxyPermission(Reflection.getCallerClass(), cl); } // 获取构造 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; // 验证代理类的修饰符 if (!Modifier.isPublic(cl.getModifiers())) { // 修改访问权限 AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { // 将此对象的可访问标志设置为指定的布尔值, true表示反射对象在使用时应禁止Java语言访问检查, false表示反射对象应强制执行Java语言访问检查 cons.setAccessible(true); return null; } }); } //生成实例, 并将参数传入构造 return cons.newInstance(new Object[]{h}); } catch (IllegalAccessException | InstantiationException e) { throw new InternalError(e.toString(), e); } catch (InvocationTargetException e) { Throwable t = e.getCause(); if (t instanceof RuntimeException) { throw (RuntimeException) t; } else { throw new InternalError(t.toString(), t); } } catch (NoSuchMethodException e) { throw new InternalError(e.toString(), e); } } 可以看出获取代理类是在 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); 处, 继续相关逻辑2.获取代理类相关逻辑 /** * 生成代理类, 之前必须进行权限检查 */ private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) { if (interfaces.length &gt; 65535) { throw new IllegalArgumentException(&quot;interface limit exceeded&quot;); } //如果由实现给定接口的给定加载器定义的代理类存在，则它将简单地返回缓存副本; 否则，它将通过Proxy Class Factory创建代理类 return proxyClassCache.get(loader, interfaces); }3.proxyClassCache.get(loader, interfaces);java.lang.reflect.WeakCache#get(..) 介绍 /** * 通过缓存查找值, 如果缓存中没有给定的（key，sub Key）对的条目或条目已被清除，则它总是评估{Key sub Key Factory}函数并可选择评估{Factory value}函数 */ public V get(K key, P parameter) { // 非空校验 Objects.requireNonNull(parameter); // 判断移除队列 expungeStaleEntries(); // 缓存key Object cacheKey = CacheKey.valueOf(key, refQueue); // 延迟加载使用二级map ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey); if (valuesMap == null) { ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey, valuesMap = new ConcurrentHashMap&lt;&gt;()); if (oldValuesMap != null) { valuesMap = oldValuesMap; } } // 创建子key 并根据key 检索supplier Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); // 根据key获取supplier Supplier&lt;V&gt; supplier = valuesMap.get(subKey); Factory factory = null; while (true) { if (supplier != null) { // supplier 可能为 Factory 或者 CacheValue&lt;V&gt; 的实例, 从缓存中获取到则直接返回 V value = supplier.get(); if (value != null) { return value; } } // factory不存在则创建 if (factory == null) { factory = new Factory(key, parameter, subKey, valuesMap); } // supplier 为null if (supplier == null) { // 从valuesMap获取supplier supplier = valuesMap.putIfAbsent(subKey, factory); if (supplier == null) { // successfully installed Factory supplier = factory; } // else retry with winning supplier } else { if (valuesMap.replace(subKey, supplier, factory)) { // successfully replaced // cleared CacheEntry / unsuccessful Factory // with our Factory supplier = factory; } else { // retry with current supplier supplier = valuesMap.get(subKey); } } } } 可以发现重点在 Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); 获取 subKey 的过程中.4.subKeyFactory.apply(key, parameter)Debug发现在此处调用的是 java.lang.reflect.Proxy.ProxyClassFactory 静态内部类,此处根据接口的数量生成二级缓存 /** * 一个工厂函数, 用于生成, 定义并返回给定ClassLoader和接口数组的代理类 */ private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?>[], Class&lt;?>> { // 所有代理类的前缀 private static final String proxyClassNamePrefix = \"$Proxy\"; // next number to use for generation of unique proxy class names private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?> apply(ClassLoader loader, Class&lt;?>[] interfaces) { // 在IdentityHashMap中, 当且仅当两个key严格相等（key1==key2）时，IdentityHashMap才认为两个key相等 Map&lt;Class&lt;?>, Boolean> interfaceSet = new IdentityHashMap&lt;>(interfaces.length); // 循环接口数组 for (Class&lt;?> intf : interfaces) { /* * 验证类加载器是否将此接口的名称解析为同一个Class对象 */ Class&lt;?> interfaceClass = null; try { // 获取接口的 class interfaceClass = Class.forName(intf.getName(), false, loader); } catch (ClassNotFoundException e) { } if (interfaceClass != intf) { throw new IllegalArgumentException( intf + \" is not visible from class loader\"); } /* * 验证interfaceClass是否为接口 */ if (!interfaceClass.isInterface()) { throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); } /* * 验证接口是否重复 */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) { throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); } } String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * 验证所有非公开代理接口是否在同一个包中 */ for (Class&lt;?> intf : interfaces) { int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) { accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) { proxyPkg = pkg; } else if (!pkg.equals(proxyPkg)) { throw new IllegalArgumentException( \"non-public interfaces from different packages\"); } } } if (proxyPkg == null) { // 如果没有非公开的代理接口，使用 com.sun.proxy package proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; } /* * 为要生成的代理类选择一个名称 */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * 生成代理类 */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); try { return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); } catch (ClassFormatError e) { /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); } } } 5.生辰给代理类byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags);可以在测试类中添加以下内容打印出代理类: System.setProperty(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;);代理类内容如下: // // Source code recreated from a .class file by IntelliJ IDEA // (powered by Fernflower decompiler) // package com.sun.proxy; import com.liuzhihang.tool.proxy.jdk.Subject; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; public final class $Proxy0 extends Proxy implements Subject { private static Method m1; private static Method m3; private static Method m2; private static Method m4; private static Method m0; public $Proxy0(InvocationHandler var1) throws { super(var1); } public final boolean equals(Object var1) throws { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var3) { throw var3; } catch (Throwable var4) { throw new UndeclaredThrowableException(var4); } } public final String getName() throws { try { return (String)super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() throws { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String getAge(String var1) throws { try { return (String)super.h.invoke(this, m4, new Object[]{var1}); } catch (RuntimeException | Error var3) { throw var3; } catch (Throwable var4) { throw new UndeclaredThrowableException(var4); } } public final int hashCode() throws { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { try { m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m3 = Class.forName(\"com.liuzhihang.tool.proxy.jdk.Subject\").getMethod(\"getName\"); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m4 = Class.forName(\"com.liuzhihang.tool.proxy.jdk.Subject\").getMethod(\"getAge\", Class.forName(\"java.lang.String\")); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } } 可以看出生成的$Proxy0类继承Proxy动态代理类并实现了Subject被代理接口, 实现所有方法通过 super.h.invoke(this, m1, new Object[]{var1}) 内部调用了 InvocationHandler.invoke(…)方法, 通过反射调用代理实例的方法","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"动态代理","slug":"动态代理","permalink":"https://liuzhihang.com/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"懒汉单例模式线程安全","slug":"design-patterns/单例模式","date":"2018-02-21T09:15:29.000Z","updated":"2020-04-04T04:12:06.880Z","comments":true,"path":"2018/02/21/lazy-singleton-mode-thread-safe.html","link":"","permalink":"https://liuzhihang.com/2018/02/21/lazy-singleton-mode-thread-safe.html","excerpt":"一个类中只有一个实例, 且能够自行实例化提供这个实例, 同时提供全局访问的方法. 结构1.构造私有化: 确保外部不能使用new直接创建对象2.内部静态属性创建实例3.对外公共静态获取对象方法","text":"一个类中只有一个实例, 且能够自行实例化提供这个实例, 同时提供全局访问的方法. 结构1.构造私有化: 确保外部不能使用new直接创建对象2.内部静态属性创建实例3.对外公共静态获取对象方法 demo/** * 单例模式 * 1. 构造私有化: 确保外部不能使用new直接创建对象 * 2. 内部静态属性创建实例 * 3. 对外公共静态获取对象方法 * * @author liuzhihang * @date 2018/3/27 17:45 */ public class SingletonPattern { private SingletonPattern() { } private static SingletonPattern singletonPattern = null; public static SingletonPattern getSingletonPattern() { if (singletonPattern == null) { singletonPattern = new SingletonPattern(); } return singletonPattern; } } 分类1.懒汉式: 懒汉模式, 项目启动时不生成对象, 而是在首次创建该对象的时候生成唯一实例 /** * 懒汉模式, 项目启动时不生成对象, 而是在首次创建该对象的时候生成唯一实例 * * @author liuzhihang * @date 2018/4/2 16:24 */ public class LazyPattern { private LazyPattern() { } private static LazyPattern lazyPattern = null; public static LazyPattern getLazyPattern() { try { if (lazyPattern == null) { // 模拟一系列耗时操作 Thread.sleep(50); lazyPattern = new LazyPattern(); } } catch (InterruptedException e) { e.printStackTrace(); } return lazyPattern; } } 2.饿汉式: 项目启动时, 进行加载, 会导致项目启动较慢, 并且无论后面是否用到都会进行加载 /** * * 饿汉式单例模式 * 项目启动时, 进行加载, 会导致项目启动较慢, 并且无论后面是否用到都会进行加载 * * @author liuzhihang * @date 2018/4/2 18:44 */ public class HungerPattern { private HungerPattern() { } private static HungerPattern hungerPattern = new HungerPattern(); public static HungerPattern getHungerPattern() { return hungerPattern; } } 测试用例在多线程情况下对单例模式进行测试: /** * @author liuzhihang * @date 2018/3/27 19:02 */ public class SingletonTest { public static void main(String[] args) { ThreadTest[] threadTests = new ThreadTest[10]; for (int i = 0; i &lt; threadTests.length; i++) { threadTests[i] = new ThreadTest(); } for (int i = 0; i &lt; threadTests.length; i++) { threadTests[i].start(); } } } class ThreadTest extends Thread { @Override public void run() { // 懒汉模式 System.out.println(LazyPattern.getLazyPattern().hashCode()); // 饿汉模式 // System.out.println(HungerPattern.getHungerPattern().hashCode()); } } 结果: 1.饿汉模式 D:\\jdk1.8\\bin\\java.exe . . . 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 1294123621 Process finished with exit code 02.懒汉模式 D:\\jdk1.8\\bin\\java.exe . . . 140919816 1359128134 1385166630 924507082 67641385 508832262 574926395 140919816 1442414714 896298396 Process finished with exit code 0结论: 在懒汉单例模式下不能保证线程的安全性 懒汉模式的线程安全优化饿汉模式会造成资源浪费, 启动慢等结果, 下面对懒汉模式进行线程安全优化. synchronized 锁住静态方法锁住静态方法 类级锁 影响范围较大, 导致效率相对较低 /** * 懒汉式 * 在方法上添加 synchronized 关键字 锁类 * 同步方法的方式, 导致效率相对较低 * * @author liuzhihang * @date 2018/4/3 14:27 */ public class SyncLazyPattern { private SyncLazyPattern() { } private static SyncLazyPattern syncLazyPattern = null; public static synchronized SyncLazyPattern getSyncLazyPattern() { try { if (syncLazyPattern == null) { Thread.sleep(100); syncLazyPattern = new SyncLazyPattern(); } } catch (InterruptedException e) { e.printStackTrace(); } return syncLazyPattern; } } synchronized 锁住代码块package com.liuzhihang.demo.singleton; /** * 锁代码块的方式虽然可以保证结果一致性 * 但锁住很多操作, 同样会导致效率低下 * * @author liuzhihang * @date 2018/4/3 15:22 */ public class SyncCodeBlockLazyPattern { private SyncCodeBlockLazyPattern() { } private static SyncCodeBlockLazyPattern syncCodeBlockLazyPattern = null; public static SyncCodeBlockLazyPattern getSyncCodeBlockLazyPattern() { try { // 锁住具体执行业务逻辑的代码 synchronized (SyncCodeBlockLazyPattern.class) { if (syncCodeBlockLazyPattern == null) { Thread.sleep(100); syncCodeBlockLazyPattern = new SyncCodeBlockLazyPattern(); } } } catch (InterruptedException e) { e.printStackTrace(); } return syncCodeBlockLazyPattern; } } 双重检查锁机制(推荐)package com.liuzhihang.demo.singleton; /** * 双重锁检查机制, 仅锁住创建对象的部分代码 * 注意: 在对象前 添加 volatile 关键字 确保可见性, 即 每次获取值从主内存中获取, 同时防止指令重排序 * * @author liuzhihang * @date 2018/4/3 15:29 */ public class DubboCheckLockLazyPattern { private DubboCheckLockLazyPattern() { } private static volatile DubboCheckLockLazyPattern dubboCheckLockLazyPattern = null; public static DubboCheckLockLazyPattern getDubboCheckLockLazyPattern() { try { if (dubboCheckLockLazyPattern == null) { // 一系列操作 Thread.sleep(100); synchronized (DubboCheckLockLazyPattern.class) { // 二次检查 if (dubboCheckLockLazyPattern == null) { dubboCheckLockLazyPattern = new DubboCheckLockLazyPattern(); } } } } catch (InterruptedException e) { e.printStackTrace(); } return dubboCheckLockLazyPattern; } }","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://liuzhihang.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"单例模式","slug":"单例模式","permalink":"https://liuzhihang.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"}]},{"title":"poi读写Excel简单介绍","slug":"utils/excel/poiForExcel","date":"2018-02-15T10:12:20.000Z","updated":"2020-04-04T07:33:24.451Z","comments":true,"path":"2018/02/15/poi-read-and-write-excel-brief-introduction.html","link":"","permalink":"https://liuzhihang.com/2018/02/15/poi-read-and-write-excel-brief-introduction.html","excerpt":"Apache POI 可以对Microsoft Office 进行操作, 下面是工作中使用的对Excel进行读写操作的常用方式. 引入依赖 &lt;!-- excel poi --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.17&lt;/version&gt; &lt;/dependency&gt;","text":"Apache POI 可以对Microsoft Office 进行操作, 下面是工作中使用的对Excel进行读写操作的常用方式. 引入依赖 &lt;!-- excel poi --> &lt;dependency> &lt;groupId>org.apache.poi&lt;/groupId> &lt;artifactId>poi&lt;/artifactId> &lt;version>3.17&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.apache.poi&lt;/groupId> &lt;artifactId>poi-ooxml&lt;/artifactId> &lt;version>3.17&lt;/version> &lt;/dependency> 简单使用主要介绍读写时, 分别常用到的一些对象及其含义, 方便自己编写util. package com.liuzhihang.tool.excel.poi; import org.apache.poi.hssf.usermodel.HSSFWorkbook; import org.apache.poi.ss.usermodel.Row; import org.apache.poi.ss.usermodel.Sheet; import org.apache.poi.ss.usermodel.Workbook; import org.apache.poi.xssf.usermodel.XSSFSheet; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File; import java.io.FileOutputStream; import java.io.IOException; import java.io.OutputStream; /** * @author liuzhihang * @date 2018/4/20 16:12 */ public class ExcelTest { public static void main(String[] args) throws Exception { // readerTest(); writerTest(); } private static void writerTest() throws IOException { File file = new File(\"c:Users/liuzhihang/Desktop/test.xlsx\"); if (file.exists()) { System.out.println(\"读取的文件存在!\"); file.delete(); } file.createNewFile(); // 操作 .xls 的 workbook Workbook hssfWorkbook = new HSSFWorkbook(); // 操作 .xlsx 的 workbook XSSFWorkbook xssfWorkbook = new XSSFWorkbook(); // 创建 sheet 页 XSSFSheet sheet = xssfWorkbook.createSheet(); // 创建 0 行 操作对象 Row row0 = sheet.createRow(0); // 创建单元格并赋值 row0.createCell(0).setCellValue(\"序号\"); OutputStream outputStream = new FileOutputStream(file); // 写入文件 xssfWorkbook.write(outputStream); } private static void readerTest() throws Exception { File file = new File(\"c:Users/liuzhihang/Desktop/parkingLotTempLate.xlsx\"); Workbook workBook = ExcelUtil.getWorkBook(file); // 获取 excel 页 // Sheet sheetByIndex = workBook.getSheetAt(0); // Sheet sheetByName = workBook.getSheet(\"Sheet0\"); // 操作 sheet Sheet sheet = workBook.getSheetAt(0); // 获取最后一行行数 从 0 开始 int lastRowNum = sheet.getLastRowNum(); // 获取总行数 int physicalNumberOfRows = sheet.getPhysicalNumberOfRows(); // 操作行 获取第0行 Row row = sheet.getRow(0); String value = row.getCell(0).getStringCellValue(); } } ExcelUtil 简单工具poi读写 excel 的简单工具 ExcelUtil, 实际工作中可结合javaBean使用并重新编写util. package com.liuzhihang.tool.excel.poi; import lombok.extern.log4j.Log4j2; import org.apache.commons.lang.StringUtils; import org.apache.poi.hssf.usermodel.HSSFWorkbook; import org.apache.poi.ss.usermodel.Cell; import org.apache.poi.ss.usermodel.Row; import org.apache.poi.ss.usermodel.Sheet; import org.apache.poi.ss.usermodel.Workbook; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.*; import java.util.ArrayList; import java.util.List; /** * @author liuzhihang * @date 2018/4/20 12:02 */ @Log4j2 public class ExcelUtil { /** * 读取两列excel 返回第二列的集合 * * @param workbook * @return */ public static List&lt;String> readExcelForTwoColumns(Workbook workbook) { if (workbook == null) { log.info(\"获取 workbook 为null\"); return null; } List&lt;String> list = new ArrayList&lt;>(); try { Sheet sheet = workbook.getSheetAt(0); //获取总行数 int rowNum = sheet.getLastRowNum(); //正文内容应该从第二行开始，第一行为文件的标头的标题 for (int i = 0; i &lt; rowNum; i++) { Row row = sheet.getRow(i + 1); String value = getCellValue(row.getCell(1)).toString(); if (StringUtils.isNotBlank(value)) { list.add(value); } } } catch (Exception e) { log.error(e.getMessage()); } return list; } /** * 写 excel * * @param excelFile * @param list */ public static void writerExcelForTwoColumns(File excelFile, List&lt;String> list) { OutputStream outputStream = null; try { outputStream = new FileOutputStream(excelFile); Workbook workBook = null; String fileName = excelFile.getName(); if (fileName.endsWith(\".xls\")) { workBook = new HSSFWorkbook(); } else if (fileName.endsWith(\".xlsx\")) { workBook = new XSSFWorkbook(); } else { log.info(\"文件格式不正确!, 当前文件名:{}\", fileName); throw new Exception(\"文件格式不正确\"); } // 创建第 0 页 Sheet sheet = workBook.createSheet(); Row row1 = sheet.createRow(0); row1.createCell(0).setCellValue(\"序号\"); row1.createCell(1).setCellValue(\"编号\"); for (int i = 0; i &lt; list.size(); i++) { Row row = sheet.createRow(i + 1); row.createCell(0).setCellValue(i + 1); row.createCell(1).setCellValue(list.get(i)); } workBook.write(outputStream); } catch (Exception e) { log.error(\"写excel失败\", e); } finally { try { outputStream.close(); } catch (IOException e) { e.printStackTrace(); } } } /** * 获取工作表 * * @param file * @return */ public static Workbook getWorkBook(File file) throws Exception { String fileName = file.getName(); Workbook workbook = null; try { InputStream inputStream = new FileInputStream(file); if (fileName.endsWith(\".xls\")) { workbook = new HSSFWorkbook(inputStream); } else if (fileName.endsWith(\".xlsx\")) { workbook = new XSSFWorkbook(inputStream); } else { log.info(\"文件格式不正确!, 当前文件名:{}\", fileName); throw new Exception(\"文件格式不正确\"); } } catch (Exception e) { throw e; } return workbook; } /** * 获取单元格的数据 * * @param cell * @return */ public static Object getCellValue(Cell cell) { if (cell != null) { switch (cell.getCellTypeEnum()) { // 数字 case NUMERIC: return cell.getNumericCellValue(); // 字符串 case STRING: return cell.getStringCellValue(); // 公式 case FORMULA: return cell.getCellFormula(); // 布尔 case BOOLEAN: return cell.getBooleanCellValue(); case ERROR: return cell.getErrorCellValue(); // 空 default: return \"\"; } } return \"\"; } }","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"poi","slug":"poi","permalink":"https://liuzhihang.com/tags/poi/"},{"name":"excel","slug":"excel","permalink":"https://liuzhihang.com/tags/excel/"}]},{"title":"protostuff序列化工具","slug":"utils/serialize/protostuff","date":"2018-02-05T12:12:20.000Z","updated":"2020-04-04T07:33:24.448Z","comments":true,"path":"2018/02/05/protostuff-serialization-tool.html","link":"","permalink":"https://liuzhihang.com/2018/02/05/protostuff-serialization-tool.html","excerpt":"介绍在很多地方都需要用到序列化, 比如在使用redis缓存对象时, 一般情况是实现java Serializable接口. 简单介绍下在慕课网学习到的一个新的序列化工具 —- protostuff. 在学习中介绍使用该工具可以大大减少对象序列化后字节所占空间, 并提高序列化时间等. 1.慕课网课程地址2.序列化相关工具比较","text":"介绍在很多地方都需要用到序列化, 比如在使用redis缓存对象时, 一般情况是实现java Serializable接口. 简单介绍下在慕课网学习到的一个新的序列化工具 —- protostuff. 在学习中介绍使用该工具可以大大减少对象序列化后字节所占空间, 并提高序列化时间等. 1.慕课网课程地址2.序列化相关工具比较 引入依赖 &lt;!-- protostuff 序列化工具 --> &lt;dependency> &lt;groupId>com.dyuproject.protostuff&lt;/groupId> &lt;artifactId>protostuff-core&lt;/artifactId> &lt;version>1.1.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.dyuproject.protostuff&lt;/groupId> &lt;artifactId>protostuff-runtime&lt;/artifactId> &lt;version>1.1.3&lt;/version> &lt;/dependency> 相关使用import com.dyuproject.protostuff.LinkedBuffer; import com.dyuproject.protostuff.ProtostuffIOUtil; import com.dyuproject.protostuff.runtime.RuntimeSchema; /** * @author liuzhihang * @date 2018/4/18 15:04 */ public class ProtostuffUtil { public static &lt;T> byte[] serialize(T t, Class&lt;T> cls) { RuntimeSchema&lt;T> schema = RuntimeSchema.createFrom(cls); return ProtostuffIOUtil.toByteArray(t, schema, LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE)); } public static &lt;T> T unSerialize(byte[] bytes, Class&lt;T> cls) { RuntimeSchema&lt;T> schema = RuntimeSchema.createFrom(cls); T message = schema.newMessage(); ProtostuffIOUtil.mergeFrom(bytes, message, schema); return message; } } 测试import lombok.Data; /** * @author liuzhihang * @date 2018/4/17 19:01 */ @Data public class User { private String id; private String userName; } import com.alibaba.fastjson.JSON; /** * @author liuzhihang * @date 2018/4/17 19:02 */ public class ProtostuffTest { public static void main(String[] args) { User user = new User(); user.setId(\"test0001\"); user.setUserName(\"测试用户0001\"); System.out.println(JSON.toJSONString(user)); byte[] serialize = ProtostuffUtil.serialize(user, User.class); User unSerialize = ProtostuffUtil.unSerialize(serialize, User.class); System.err.println(JSON.toJSONString(unSerialize)); } } 结果: {\"id\":\"test0001\",\"userName\":\"测试用户0001\"} {\"id\":\"test0001\",\"userName\":\"测试用户0001\"}","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"serialize","slug":"serialize","permalink":"https://liuzhihang.com/tags/serialize/"}]},{"title":"Transactional声明式事务","slug":"spring/Transactional","date":"2018-01-27T03:50:13.000Z","updated":"2020-04-04T04:12:06.921Z","comments":true,"path":"2018/01/27/transactional-declarative-transaction.html","link":"","permalink":"https://liuzhihang.com/2018/01/27/transactional-declarative-transaction.html","excerpt":"介绍1.声明式事务管理建立在AOP之上的. 其本质是对方法前后进行拦截, 然后在目标方法开始之前创建或者加入一个事务, 在执行完目标方法之后根据执行情况提交或者回滚事务.2.声明式事务最大的优点就是不需要通过编程的方式管理事务, 这样就不需要在业务逻辑代码中掺杂事务管理的代码, 只需在配置文件中做相关的事务规则声明(或通过基于@Transactional注解的方式), 便可以将事务规则应用到业务逻辑中.3.声明式事务不足的地方在于, 与编程式事务相比, 只能作用到方法级别, 无法像编程式事务那样可以作用到代码块级别. xml配置1.添加命名空间","text":"介绍1.声明式事务管理建立在AOP之上的. 其本质是对方法前后进行拦截, 然后在目标方法开始之前创建或者加入一个事务, 在执行完目标方法之后根据执行情况提交或者回滚事务.2.声明式事务最大的优点就是不需要通过编程的方式管理事务, 这样就不需要在业务逻辑代码中掺杂事务管理的代码, 只需在配置文件中做相关的事务规则声明(或通过基于@Transactional注解的方式), 便可以将事务规则应用到业务逻辑中.3.声明式事务不足的地方在于, 与编程式事务相比, 只能作用到方法级别, 无法像编程式事务那样可以作用到代码块级别. xml配置1.添加命名空间 &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" . . . xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\" . . . http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd\"> 2.添加相关事务支持 &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"> &lt;!-- 指向数据源 --> &lt;property name=\"dataSource\" ref=\"masterDataSource\"/> &lt;/bean> &lt;!-- 开启事务的Annotation支持 --> &lt;tx:annotation-driven transaction-manager=\"transactionManager\"/> @Transactional注解 使用@Transactional 可以作用于接口,接口方法,类以及类方法上. 只需要在相应接口,类或方法上加上@Transactional注解即可. @Transactional 注解介绍package org.springframework.transaction.annotation; import java.lang.annotation.Documented; import java.lang.annotation.ElementType; import java.lang.annotation.Inherited; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; import org.springframework.core.annotation.AliasFor; import org.springframework.transaction.TransactionDefinition; import org.springframework.transaction.annotation.Isolation; import org.springframework.transaction.annotation.Propagation; /** * @Target({ElementType.METHOD, ElementType.TYPE}) : 可用于接口, 类, 枚举, 注解, 方法 * @Retention(RetentionPolicy.RUNTIME) : 注解会在class字节码文件中存在，在运行时可以通过反射获取到 * @Inherited : 子类可以继承父类中的注解 * @Documented : 注解将被包含在javadoc中 */ @Target({ElementType.METHOD, ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Inherited @Documented public @interface Transactional { /** * 事务管理器的别名 * 系统指定多个事务管理器时可通过别名进行区分 */ @AliasFor(\"transactionManager\") String value() default \"\"; /** * 可通过在 transactionManager 中设置 &lt;qualifier value=\"managerOne\"/> 属性类指定名称 * 可用于确定目标事务管理器，匹配特定的限定符值（或bean名称） */ @AliasFor(\"value\") String transactionManager() default \"\"; /** * 事务的传播机制 * 默认 Propagation.REQUIRED */ Propagation propagation() default Propagation.REQUIRED; /** * 事务的隔离级别 * 默认 Isolation.DEFAULT */ Isolation isolation() default Isolation.DEFAULT; /** * 事务超时时间 * 默认 TransactionDefinition.TIMEOUT_DEFAULT 即 -1 */ int timeout() default TransactionDefinition.TIMEOUT_DEFAULT; /** * 设置事务只读 */ boolean readOnly() default false; /** * 设置需要进行回滚的异常类数组，当方法中抛出指定异常数组中的异常时，则进行事务回滚 * rollbackFor = Exception.class 或 rollbackFor = {RuntimeException.class, Exception.class} */ Class&lt;? extends Throwable>[] rollbackFor() default {}; /** * 设置需要进行回滚的异常类名称数组，当方法中抛出指定异常名称数组中的异常时, 事务进行回滚 */ String[] rollbackForClassName() default {}; /** * 设置不需要进行回滚的异常类数组，当方法中抛出指定异常数组中的异常时，则不进行事务回滚 */ Class&lt;? extends Throwable>[] noRollbackFor() default {}; /** * 设置不需要进行回滚的异常类名称数组，当方法中抛出指定异常名称数组中的异常时, 事务不进行回滚 */ String[] noRollbackForClassName() default {}; } 传播行为介绍事务的传播行为, 一共 7 种1.枚举介绍 package org.springframework.transaction.annotation; import org.springframework.transaction.TransactionDefinition; public enum Propagation { /** * 支持当前事务, 如果不存在, 则创建一个新事务 * 事务的默认设置 */ REQUIRED(TransactionDefinition.PROPAGATION_REQUIRED), /** * 支持当前事务, 如果不存在, 则以非事务方式执行 */ SUPPORTS(TransactionDefinition.PROPAGATION_SUPPORTS), /** * 支持当前事务, 如果不存在则抛出异常 */ MANDATORY(TransactionDefinition.PROPAGATION_MANDATORY), /** * 开始一个新的事务, 并暂停当前事务(如果存在) */ REQUIRES_NEW(TransactionDefinition.PROPAGATION_REQUIRES_NEW), /** * 以非事务方式执行, 暂停当前事务(如果存在) */ NOT_SUPPORTED(TransactionDefinition.PROPAGATION_NOT_SUPPORTED), /** * 以非事务方式执行, 如果存在则抛出异常 */ NEVER(TransactionDefinition.PROPAGATION_NEVER), /** * 如果当前事务存在, 则在嵌套事务中执行. * 如果事务不存在, 则等同于 PROPAGATION_REQUIRED */ NESTED(TransactionDefinition.PROPAGATION_NESTED); private final int value; Propagation(int value) { this.value = value; } public int value() { return this.value; } } 2.列表 Propagation 含义 REQUIRED 支持当前事务, 如果不存在, 则创建一个新事务 SUPPORTS 支持当前事务, 如果不存在, 则以非事务方式执行 MANDATORY 支持当前事务, 如果不存在则抛出异常 REQUIRES_NEW 开始一个新的事务, 并暂停当前事务(如果存在) NOT_SUPPORTED 以非事务方式执行, 暂停当前事务(如果存在) NEVER 以非事务方式执行, 如果存在则抛出异常 NESTED 如果当前事务存在, 则在嵌套事务中执行. 如果事务不存在, 则等同于 PROPAGATION_REQUIRED 隔离级别介绍1.枚举介绍 package org.springframework.transaction.annotation; import org.springframework.transaction.TransactionDefinition; public enum Isolation { /** * 使用底层数据存储默认的隔离级别 * 一般存储底层默认为: READ_COMMITTED */ DEFAULT(TransactionDefinition.ISOLATION_DEFAULT), /** * 读未提交 * 会出现脏读和不可重复读, 一般不使用 */ READ_UNCOMMITTED(TransactionDefinition.ISOLATION_READ_UNCOMMITTED), /** * 读已提交 * 该级别仅禁止事务读取其中未提交更改的行 * 可能会出现不可重复读取和幻像读取 */ READ_COMMITTED(TransactionDefinition.ISOLATION_READ_COMMITTED), /** * 可重复读 * 禁止事务读取其中有未提交更改的行, 并且还禁止一个事务读取一行, 第二个事务更改该行. 并且第一个事务重新读取该行, 第二次获取不同值的情况 * 即 禁止 读未提交, 不可重复读 * 会出现幻读 */ REPEATABLE_READ(TransactionDefinition.ISOLATION_REPEATABLE_READ), /** * 串行 * 所有事物依次执行, 不会影响别的事务, 所以会防止 不可重复读 脏读 幻读 * 会影响性能 */ SERIALIZABLE(TransactionDefinition.ISOLATION_SERIALIZABLE); private final int value; Isolation(int value) { this.value = value; } public int value() { return this.value; } } 2.列表 Isolation 含义 DEFAULT 使用底层数据存储默认的隔离级别, 一般存储底层默认为: READ_COMMITTED READ_UNCOMMITTED 读未提交, 会出现脏读和不可重复读, 一般不使用 READ_COMMITTED 该级别仅禁止事务读取其中未提交更改的行. 可能会出现不可重复读取和幻像读取 REPEATABLE_READ 可重复读, 禁止事务读取其中有未提交更改的行, 并且还禁止一个事务读取一行, 第二个事务更改该行. 并且第一个事务重新读取该行, 第二次获取不同值的情况. 即 禁止 读未提交, 不可重复读. 会出现幻读 SERIALIZABLE 串行, 所有事物依次执行, 不会影响别的事务, 所以会防止 不可重复读 脏读 幻读. 会影响性能 3.脏读 幻读 不可重复读 脏读 当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。 幻读 事务读取时不存在该数据, 读取后发现该数据存在. 中间因为别的事务在进行插入操作 不可重复读 一个事务在读取该数据时另一个事务在修改该数据, 导致多次读取数据内容不一致","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"transactional","slug":"transactional","permalink":"https://liuzhihang.com/tags/transactional/"}]},{"title":"整数包装类型的缓存","slug":"source-code/java/IntegerCache","date":"2018-01-15T12:12:20.000Z","updated":"2020-04-04T06:53:41.581Z","comments":true,"path":"2018/01/15/integer-wrapper-type-cache.html","link":"","permalink":"https://liuzhihang.com/2018/01/15/integer-wrapper-type-cache.html","excerpt":"部分包装类型存在缓存机制, 会在JVM启动时, 缓存一定数量的对象, 有助于节省内存, 提高性能. 缓存区间 类型 范围 是否修改 Integer -128 到 127 true : -XX:AutoBoxCacheMax=size 修改 ByteCache -128 到 127 false ShortCache -128 到 127 false LongCache -128 到 127 false CharacterCache 0 到 127 false","text":"部分包装类型存在缓存机制, 会在JVM启动时, 缓存一定数量的对象, 有助于节省内存, 提高性能. 缓存区间 类型 范围 是否修改 Integer -128 到 127 true : -XX:AutoBoxCacheMax=size 修改 ByteCache -128 到 127 false ShortCache -128 到 127 false LongCache -128 到 127 false CharacterCache 0 到 127 false 举例 Integer a = 100; Integer b = 100; Integer c = 1000; Integer d = 1000; Integer e = new Integer(100); Integer f = Integer.valueOf(100); System.out.println(a == b); // true System.out.println(c == d); // false System.out.println(a == e); // false System.out.println(f == e); // false System.out.println(a == f); // true 分析== 在比较对象时, 判断是否指向同一地址 a b f 都是从缓存中取出数据, 所以地址是相同的 c d 不在缓存范围内, 所以是新的对象 e 是新对象 IntegerCacheprivate static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high >= 127; } private IntegerCache() {} } 可以通过设置 java.lang.Integer.IntegerCache.high 来修改缓存的值. 方法为修改 JVM 的启动参数 -XX:AutoBoxCacheMax=size","categories":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"name":"java","slug":"源码学习/java","permalink":"https://liuzhihang.com/categories/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/java/"}],"tags":[{"name":"源码学习","slug":"源码学习","permalink":"https://liuzhihang.com/tags/%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"}]},{"title":"Interceptor拦截器","slug":"spring/Interceptor","date":"2018-01-10T06:50:13.000Z","updated":"2020-04-04T04:12:06.923Z","comments":true,"path":"2018/01/10/interceptor.html","link":"","permalink":"https://liuzhihang.com/2018/01/10/interceptor.html","excerpt":"介绍Interceptor: 拦截器，作用类似 Filter, 主要作用是拦截用户请求, 在 Action 执行的前后各执行一段代码, 进行相应的业务处理. 作用权限认证统一逻辑处理日志监控等","text":"介绍Interceptor: 拦截器，作用类似 Filter, 主要作用是拦截用户请求, 在 Action 执行的前后各执行一段代码, 进行相应的业务处理. 作用权限认证统一逻辑处理日志监控等 使用方式及方法介绍使用方式分为两种, 一种为: 实现HandlerInterceptor接口或者是继承实现了HandlerInterceptor接口的类, 另一种为: 实现Spring的WebRequestInterceptor接口, 或者是继承实现了WebRequestInterceptor的类.1.HandlerInterceptor 介绍 package org.springframework.web.servlet; import org.springframework.web.servlet.ModelAndView; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public interface HandlerInterceptor { /** * 请求处理之前调用 链式 会按照声明顺序依次执行 * 返回 true 则继续执行下一个 Interceptor 无则执行 Controller * 返回 false 请求结束 */ boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; /** * 在请求处理之后，DispatcherServlet进行视图返回渲染之前进行调用，可以在这个方法中对Controller 处理之后的ModelAndView 对象进行操作。 * 调度程序Servlet在执行链中处理一个处理程序，由任意数量的拦截器组成，处理器本身在最后。 使用这种方法，每个拦截器可以后处理一个执行，并按照执行链的相反顺序进行应用 */ void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception; /** * 请求处理完成后的回调，即渲染视图后的回调。 将被调用处理程序执行的任何结果，从而允许适当的资源清理。 * 注意：只有当这个拦截器的预处理方法已经成功完成并返回时才会被调用 * 与postHandle方法一样，该方法将以相反的顺序在链中的每个拦截器上调用，因此第一个拦截器将成为最后被调用的拦截器 */ void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception; } 2.WebRequestInterceptor 介绍 package org.springframework.web.context.request; import org.springframework.ui.ModelMap; import org.springframework.web.context.request.WebRequest; public interface WebRequestInterceptor { /** * 在调用之前拦截请求处理程序的执行。 允许准备上下文资源（如Hibernate Session）并将它们公开为请求属性或线程本地对象. * 即 准备一些需要的资源, 例如, 将请求属性放置到 WebRequest 中 * 无返回对象 */ void preHandle(WebRequest request) throws Exception; /** * 在视图呈现前（如果有的话）在成功调用之后拦截请求处理程序的执行。 * 允许在成功处理程序执行后修改上下文资源（例如，刷新休眠会话） * 可以通过修改 ModelMap 的属性来改变你返回的试图模型 */ void postHandle(WebRequest request, ModelMap model) throws Exception; /** * 求处理完成后的回调，即渲染视图后的回调。 将被调用处理程序执行的任何结果，从而允许适当的资源清理。 * 注意：只有在拦截器的预处理方法成功完成时才会调用 */ void afterCompletion(WebRequest request, Exception ex) throws Exception; } xml 配置1.在 *-servlet.xml 中添加 MVC schema xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\" http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd\" 2.配置 mvc:interceptors 标签 &lt;mvc:interceptors> &lt;mvc:interceptor> &lt;!-- 拦截路径 --> &lt;mvc:mapping path=\"/**\"/> &lt;!-- 指定拦截器 --> &lt;bean class=\"com.liuzhihang.myprojext.controller.interceptor.RequestInterceptor\"/> &lt;/mvc:interceptor> &lt;/mvc:interceptors> 使用示例package com.liuzhihang.myprojext.controller.interceptor; import org.springframework.web.servlet.HandlerInterceptor; import org.springframework.web.servlet.ModelAndView; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; public class RequestInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { // 处理逻辑 return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { } }","categories":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://liuzhihang.com/tags/Spring/"},{"name":"interceptor","slug":"interceptor","permalink":"https://liuzhihang.com/tags/interceptor/"},{"name":"servlet","slug":"servlet","permalink":"https://liuzhihang.com/tags/servlet/"}]},{"title":"utils工具--ValidationUtil 参数校验","slug":"utils/validation/ValidationUtil","date":"2017-12-30T13:20:20.000Z","updated":"2020-04-04T07:33:24.457Z","comments":true,"path":"2017/12/30/utils-tool-validationutil-parameter-check.html","link":"","permalink":"https://liuzhihang.com/2017/12/30/utils-tool-validationutil-parameter-check.html","excerpt":"在工作中不可避免的要面对很多参数校验, 比如写新接口时需要对传入VO的必要字段进行校验, String 是否为空, Integer 最小值, 对象是否为null, 等等.而使用 hibernate的validator工具对参数进行校验, 可以极大的简化流程, 当然不可避免的就是需要在被校验字段上加上注解信息. 1. 相关依赖 &lt;!-- 参数校验工具 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.4.2.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.glassfish.web&lt;/groupId&gt; &lt;artifactId&gt;el-impl&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/dependency&gt;","text":"在工作中不可避免的要面对很多参数校验, 比如写新接口时需要对传入VO的必要字段进行校验, String 是否为空, Integer 最小值, 对象是否为null, 等等.而使用 hibernate的validator工具对参数进行校验, 可以极大的简化流程, 当然不可避免的就是需要在被校验字段上加上注解信息. 1. 相关依赖 &lt;!-- 参数校验工具 --> &lt;dependency> &lt;groupId>org.hibernate&lt;/groupId> &lt;artifactId>hibernate-validator&lt;/artifactId> &lt;version>5.4.2.Final&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.glassfish.web&lt;/groupId> &lt;artifactId>el-impl&lt;/artifactId> &lt;version>2.2&lt;/version> &lt;/dependency> 2. ValidationUtil对加上相关注解字段进行校验, 使用到 ValidationUtil.java和ValidationResult.java两个文件, 也可在工具中直接抛出异常. ValidationUtil 内容如下: package com.liuzhihang.tool.validate; import org.apache.commons.collections.CollectionUtils; import javax.validation.ConstraintViolation; import javax.validation.Validation; import javax.validation.Validator; import java.beans.IntrospectionException; import java.beans.Introspector; import java.beans.PropertyDescriptor; import java.util.Set; /** * 对添加 hibernate.validator 注解的字段进行校验 * * 使用前 需要引入 hibernate-validator 依赖 * * @author liuzhihang * @date 2017/11/22 11:08 */ public class ValidationUtil { private static Validator validator = Validation.buildDefaultValidatorFactory().getValidator(); /** * 会 验证 所有字段 * * @param obj * @param &lt;T> * @return 返回所有不符合的信息 */ public static &lt;T> ValidationResult validateAllField(T obj) { ValidationResult result = new ValidationResult(true); StringBuilder errorMsg = new StringBuilder(); if (obj == null) { result.setHasPass(false); result.setErrorMsg(\"The class is null!\"); return result; } Set&lt;ConstraintViolation&lt;T>> violationSet = validator.validate(obj); if (CollectionUtils.isNotEmpty(violationSet)) { for (ConstraintViolation&lt;T> violation : violationSet) { errorMsg.append(violation.getMessage()); } result.setHasPass(false); result.setErrorMsg(errorMsg.toString()); } return result; } /** * 验证指定字段 是否符合信息 * * @param obj * @param fieldName * @param &lt;T> * @return */ public static &lt;T> ValidationResult validateOneField(T obj, String fieldName) { ValidationResult result = new ValidationResult(true); if (obj == null) { result.setHasPass(false); result.setErrorMsg(\"The class is null!\"); return result; } Set&lt;ConstraintViolation&lt;T>> violationSet = validator.validateProperty(obj, fieldName); if (CollectionUtils.isNotEmpty(violationSet)) { for (ConstraintViolation&lt;T> violation : violationSet) { result.setHasPass(false); result.setErrorMsg(violation.getMessage()); } } return result; } /** * 验证 所有字段, 当第一个不符合时 则直接返回信息 * * @param obj * @param &lt;T> * @return */ public static &lt;T> ValidationResult validateAllFieldForOneBack(T obj) { ValidationResult result = new ValidationResult(true); if (obj == null) { result.setHasPass(false); result.setErrorMsg(\"The class is null!\"); return result; } try { PropertyDescriptor[] propertyDescriptors = Introspector.getBeanInfo(obj.getClass()).getPropertyDescriptors(); for (PropertyDescriptor propertyDescriptor : propertyDescriptors) { result = validateOneField(obj, propertyDescriptor.getName()); if (result.getHasPass()) { return result; } } } catch (IntrospectionException e) { result.setHasPass(false); result.setErrorMsg(\"This validate has error : \" + e); } return result; } } ValidationResult 内容如下: package com.liuzhihang.tool.validate; /** * @Description: * @Author: liuzhihang * @Date: 2018/1/6 17:57 */ public class ValidationResult { private Boolean hasPass; private String errorMsg; public ValidationResult(Boolean hasPass) { this.hasPass = hasPass; } public Boolean getHasPass() { return hasPass; } public void setHasPass(Boolean hasPass) { this.hasPass = hasPass; } public String getErrorMsg() { return errorMsg; } public void setErrorMsg(String errorMsg) { this.errorMsg = errorMsg; } @Override public String toString() { return \"ValidationResult{\" + \"hasPass=\" + hasPass + \", errorMsg='\" + errorMsg + '\\'' + '}'; } } 3. 常用注解Bean Validation 中内置的 constraint @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max=, min=) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(regex=,flag=) 被注释的元素必须符合指定的正则表达式 Hibernate Validator 附加的 constraint @NotBlank(message =) 验证字符串非null，且长度必须大于0 @Email 被注释的元素必须是电子邮箱地址 @Length(min=,max=) 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range(min=,max=,message=) 被注释的元素必须在合适的范围内4 测试示例代码: package com.liuzhihang.tool.validate; import lombok.Data; import org.hibernate.validator.constraints.NotBlank; import org.hibernate.validator.constraints.NotEmpty; import javax.validation.constraints.Min; import javax.validation.constraints.NotNull; /** * @author liuzhihang * @date 2017/11/22 18:25 */ @Data public class ValidationVo { @NotBlank(message = \"The name must notEmpty!\") private String name; @NotNull(message = \"The age must notNull!\") @Min(value = 1, message = \"The age must greater than 0!\") private Integer age; public static void main(String[] args) { ValidationVo validationVo = new ValidationVo(); System.out.println(ValidationUtil.validateAllField(validationVo).toString()); validationVo.setAge(1); System.out.println(ValidationUtil.validateAllField(validationVo).toString()); validationVo.setName(\"二蛋\"); System.out.println(ValidationUtil.validateAllField(validationVo).toString()); } } 输出结果: ValidationResult{hasPass=false, errorMsg=&#39;The name must notEmpty!The age must notNull!&#39;} ValidationResult{hasPass=false, errorMsg=&#39;The name must notEmpty!&#39;} ValidationResult{hasPass=true, errorMsg=&#39;null&#39;}","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"validation","slug":"validation","permalink":"https://liuzhihang.com/tags/validation/"}]},{"title":"xml解析--dom4j","slug":"utils/xml/xml-dom4j","date":"2017-12-30T12:12:20.000Z","updated":"2020-04-04T07:33:24.442Z","comments":true,"path":"2017/12/30/xml-parsing-dom4j.html","link":"","permalink":"https://liuzhihang.com/2017/12/30/xml-parsing-dom4j.html","excerpt":"在工作中有时候会用到dom4j对xml文件或者字符串进行解析, 以下内容为随手笔记, 防止以后遗忘. 1. 相关依赖 &lt;!-- dom4j --&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt;","text":"在工作中有时候会用到dom4j对xml文件或者字符串进行解析, 以下内容为随手笔记, 防止以后遗忘. 1. 相关依赖 &lt;!-- dom4j --> &lt;dependency> &lt;groupId>dom4j&lt;/groupId> &lt;artifactId>dom4j&lt;/artifactId> &lt;version>1.6.1&lt;/version> &lt;/dependency> 2. 获取dom对象获取dom对象方式主要以下几种: // 读取 xml 文件 方式 SAXReader reader = new SAXReader(); Document doc1 = reader.read(new File(\"src/main/java/com/liuzhihang/tool/xml/alipay.xml\")); // 解析 xml 文本 方式 String aliPayStr = XmlTest.getAliPayStr(); Document doc2 = DocumentHelper.parseText(aliPayStr); // 主动创建 Document doc3 = DocumentHelper.createDocument(); Element element = doc3.addElement(\"Test\"); 3. 操作dom对象当获取到dom对象后便可以通过以下方式对dom进行操作 // 获取根节点 Element rootElement = dom.getRootElement(); // System.out.println(rootElement.getName()); // 获取子节点 Element element = rootElement.element(\"response\").element(\"alipay\"); // System.out.println(element.asXML()); // 获取节点的文字 String text = element.element(\"alipay_buyer_login_id\").getText(); // System.out.println(text); // 获取节点下的所有节点 快捷键 iter / itco List elements = element.elements(); // for (Object o : elements) { // Element tempElement = (Element) o; // System.out.println(tempElement.getName() + \"\\t\" + tempElement.getText()); // } // for (Iterator iterator = elements.iterator(); iterator.hasNext(); ) { // Element next = (Element)iterator.next(); // System.out.println(next.getName() + \"\\t\" + next.getText()); // } // 获取节点下所有节点 Iterator对象 快捷键 itit Iterator iterator = element.elementIterator(); // while (iterator.hasNext()) { // Element next = (Element)iterator.next(); // System.out.println(next.getName() + \"\\t\" + next.getText()); // } // 添加节点 Element testElement = element.addElement(\"testElement\"); // 指定添加文字 testElement.setText(\"测试添加文字\"); System.out.println(element.asXML()); // 删除节点 boolean remove = element.remove(testElement); System.out.println(remove + \"\\n\" + element.asXML()); 4. 详细代码Dom4jTest.java","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"xml","slug":"xml","permalink":"https://liuzhihang.com/tags/xml/"}]},{"title":"xml解析--JaxbUtil","slug":"utils/xml/xml-jaxb","date":"2017-12-17T12:12:20.000Z","updated":"2020-04-04T07:33:24.445Z","comments":true,"path":"2017/12/17/xml-parsing-jaxbutil.html","link":"","permalink":"https://liuzhihang.com/2017/12/17/xml-parsing-jaxbutil.html","excerpt":"主要介绍使用jaxb对xml进行解析, 互转. jaxb 是相对较多的xml工具, 只需要在javaBean的属性上添加相应注解, 就可以使用工具进行解析. 具体使用过程如下: 1. 编写javaBean并添加注解使用过程中一般常用@XmlRootElement, @XmlAccessorType, @XmlElement, @XmlAttribute四个注解, 其余使用方式可以再自行深入研究. @XmlRootElement: 根元素 @XmlAccessorType: java对象生成xml文件时对java对象属性的访问方式 属性为XmlAccessType.FIELD 指java所有成员变量 @XmlElement: 子节点, name 可指定节点名 @XmlAttribute: 映射为xml文件的属性, name 可指定属性名","text":"主要介绍使用jaxb对xml进行解析, 互转. jaxb 是相对较多的xml工具, 只需要在javaBean的属性上添加相应注解, 就可以使用工具进行解析. 具体使用过程如下: 1. 编写javaBean并添加注解使用过程中一般常用@XmlRootElement, @XmlAccessorType, @XmlElement, @XmlAttribute四个注解, 其余使用方式可以再自行深入研究. @XmlRootElement: 根元素 @XmlAccessorType: java对象生成xml文件时对java对象属性的访问方式 属性为XmlAccessType.FIELD 指java所有成员变量 @XmlElement: 子节点, name 可指定节点名 @XmlAttribute: 映射为xml文件的属性, name 可指定属性名 javaBean: @Data @XmlRootElement(name = \"alipay\") @XmlAccessorType(XmlAccessType.FIELD) class AliPayXml { @XmlElement(name = \"alipay_buyer_login_id\" ) private String buyerLoginId; @XmlElement(name = \"alipay_buyer_user_id\") private String buyerUserId; } 2. 使用 JaxbUtilJaxbUtil代码 package com.liuzhihang.tool.xml; import javax.xml.bind.JAXBContext; import javax.xml.bind.JAXBException; import javax.xml.bind.Marshaller; import javax.xml.bind.Unmarshaller; import java.io.StringReader; import java.io.StringWriter; /** * Jaxb 工具 * * @author liuzhihang * @date 2017/11/28 19:13 */ public class JaxbUtil { private static final String CHARTSET = \"UTF-8\"; public static String bean2Xml(Object obj) throws JAXBException { return bean2Xml(obj, CHARTSET); } public static String bean2Xml(Object obj, String chartset) throws JAXBException { JAXBContext jaxbContext = JAXBContext.newInstance(obj.getClass()); Marshaller marshaller = jaxbContext.createMarshaller(); marshaller.setProperty(Marshaller.JAXB_FORMATTED_OUTPUT, true); marshaller.setProperty(Marshaller.JAXB_ENCODING, chartset); StringWriter writer = new StringWriter(); marshaller.marshal(obj, writer); return writer.getBuffer().toString(); } public static &lt;T> T xml2Bean(String xmlString, Class&lt;T> clazz) throws JAXBException { JAXBContext jaxbContext = JAXBContext.newInstance(clazz); Unmarshaller unmarshaller = jaxbContext.createUnmarshaller(); T t = (T) unmarshaller.unmarshal(new StringReader(xmlString)); return t; } } 3. 测试代码待测试字符串: xmlStr &lt;alipay> &lt;alipay_buyer_login_id>176****3035&lt;/alipay_buyer_login_id> &lt;alipay_buyer_user_id>2088912868994947&lt;/alipay_buyer_user_id> &lt;/alipay> 测试代码: /** * @Description: * @Author: liuzhihang * @Date: 2017/12/17 23:11 */ public class JaxbTest { public static void main(String[] args) throws JAXBException { String aliPayXmlStr = \"&lt;alipay>\\n\" + \" &lt;alipay_buyer_login_id>176****3035&lt;/alipay_buyer_login_id>\\n\" + \" &lt;alipay_buyer_user_id>2088912868994947&lt;/alipay_buyer_user_id>\\n\" + \"&lt;/alipay>\"; AliPayXml aliPayXml = JaxbUtil.xml2Bean(aliPayXmlStr, AliPayXml.class); System.out.println(JSON.toJSONString(aliPayXml)); } } 测试结果: 打印的为json格式结果, 可debugger查看. 同样也可以将javaBean转换为xmlStr {&quot;buyerLoginId&quot;:&quot;176****3035&quot;,&quot;buyerUserId&quot;:&quot;2088912868994947&quot;}","categories":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/categories/utils/"}],"tags":[{"name":"utils","slug":"utils","permalink":"https://liuzhihang.com/tags/utils/"},{"name":"xml","slug":"xml","permalink":"https://liuzhihang.com/tags/xml/"}]}]}